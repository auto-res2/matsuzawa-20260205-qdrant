{
  "research_topic": "Automated prompt optimization through iterative refinement and performance feedback",
  "queries": [
    "prompt optimization",
    "iterative prompt refinement",
    "feedback-guided prompting"
  ],
  "research_study_list": [
    {
      "title": "Large Language Models as Optimizers",
      "full_text": "LARGE LANGUAGE MODELS AS OPTIMIZERS Chengrun Yang* Xuezhi Wang Yifeng Lu Hanxiao Liu Quoc V . Le Denny Zhou Xinyun Chen * {chengrun, xuezhiw, yifenglu, hanxiaol}@google.com {qvl, dennyzhou, xinyunchen}@google.com Google DeepMind * Equal contribution ABSTRACT Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to our main application in prompt optimization, where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks. Code at https://github.com/google-deepmind/opro. 0 50 100 150 # steps 50.0 60.0 70.0 80.0training accuracy  GSM8K (a) GSM8K 0 50 100 150 200 # steps 60.0 80.0 100.0training accuracy BBH movie_recommendation (b) BBH movie_recommendation Figure 1: Prompt optimization on GSM8K (Cobbe et al., 2021) and BBH (Suzgun et al., 2022) movie_recommendation. The optimization on GSM8K has pre-trained PaLM 2-L as the scorer and the instruction-tuned PaLM 2-L (denoted PaLM 2-L-IT) as the optimizer; the optimization on BBH movie_recommendation has text-bison as the scorer and PaLM 2-L-IT as the optimizer. Each dot is the average accuracy across all (up to 8) generated instructions in the single step, and the shaded region represents standard deviation. See Section 5 for more details on experimental setup. Table 1: Top instructions with the highest GSM8K zero-shot test accuracies from prompt optimization with different optimizer LLMs. All results use the pre-trained PaLM 2-L as the scorer. Source Instruction Acc Baselines (Kojima et al., 2022) Let’s think step by step. 71.8 (Zhou et al., 2022b) Let’s work this out in a step by step way to be sure we have the right answer.58.8 (empty string) 34.0 Ours PaLM 2-L-IT Take a deep breath and work on this problem step-by-step.80.2 PaLM 2-L Break this down. 79.9 gpt-3.5-turbo A little bit of arithmetic and a logical approach will help us quickly arrive at the solution to this problem. 78.5 gpt-4 Let’s combine our numerical command and clear thinking to quickly and accurately decipher the answer. 74.5 1 arXiv:2309.03409v3  [cs.LG]  15 Apr 2024Large Language Models as Optimizers 1 I NTRODUCTION Optimization is critical for all areas. Many optimization techniques are iterative: the optimization starts from an initial solution, then iteratively updates the solution to optimize the objective func- tion (Amari, 1993; Qian, 1999; Kingma & Ba, 2015; Bäck & Schwefel, 1993; Rios & Sahinidis, 2013; Reeves, 1993). The optimization algorithm typically needs to be customized for an individual task to deal with the specific challenges posed by the decision space and the performance landscape, especially for derivative-free optimization. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to utilize large language models (LLMs) as optimizers. With the advancement of prompting techniques, LLMs have achieved impressive performance in various domains (Wei et al., 2022; Kojima et al., 2022; Wang et al., 2022; Zhou et al., 2022a; Madaan et al., 2023; Bai et al., 2022; Chen et al., 2023e). Their ability to understand natural language lays out a new possibility for optimization: instead of formally defining the optimization problem and deriving the update step with a programmed solver, we describe the optimization problem in natural language, then instruct the LLM to iteratively generate new solutions based on the problem description and the previously found solutions. Optimization with LLMs enables quick adaptation to different tasks by changing the problem description in the prompt, and the optimization process can be customized by adding instructions to specify the desired properties of the solutions. To demonstrate the potential of LLMs for optimization, we first present case studies on linear regression and the traveling salesman problem, which are two classic optimization problems that underpin many others in mathematical optimization, computer science, and operations research. On small-scale optimization problems, we show that LLMs are able to find good-quality solutions simply through prompting, and sometimes match or surpass hand-designed heuristic algorithms. Next, we demonstrate the ability of LLMs to optimize prompts: the goal is to find a prompt that maximizes the task accuracy. Specifically, we focus on natural language tasks where both the task input and output are texts. LLMs are shown to be sensitive to the prompt format (Zhao et al., 2021; Lu et al., 2021; Wei et al., 2023; Madaan & Yazdanbakhsh, 2022); in particular, semantically similar prompts may have drastically different performance (Kojima et al., 2022; Zhou et al., 2022b; Zhang et al., 2023), and the optimal prompt formats can be model-specific and task-specific (Ma et al., 2023; Chen et al., 2023c). Therefore, prompt engineering is often important for LLMs to achieve good performance (Reynolds & McDonell, 2021). However, the large and discrete prompt space makes it challenging for optimization, especially when only API access to the LLM is available. Following prior work on continuous and discrete prompt optimization (Lester et al., 2021; Li & Liang, 2021; Zhou et al., 2022b; Pryzant et al., 2023), we assume a training set is available to compute the training accuracy as the objective value for optimization, and we show in experiments that optimizing the prompt for accuracy on a small training set is sufficient to reach high performance on the test set. The prompt to the LLM serves as a call to the optimizer, and we name it the meta-prompt. Figure 3 shows an example. The meta-prompt contains two core pieces of information. The first piece is previously generated prompts with their corresponding training accuracies. The second piece is the optimization problem description, which includes several exemplars randomly selected from the training set to exemplify the task of interest. We also provide instructions for the LLM to understand the relationships among different parts and the desired output format. Different from recent work on using LLMs for automatic prompt generation (Zhou et al., 2022b; Pryzant et al., 2023), each optimization step in our work generates new prompts that aim to increase the test accuracy based on a trajectory of previously generated prompts, instead of editing one input prompt according to natural language feedback (Pryzant et al., 2023) or requiring the new prompt to follow the same semantic meaning (Zhou et al., 2022b). Making use of the full optimization trajectory, OPRO enables the LLM to gradually generate new prompts that improve the task accuracy throughout the optimization process, where the initial prompts have low task accuracies. We conduct comprehensive evaluation on several LLMs, includingtext-bison and Palm 2-L in the PaLM-2 model family (Anil et al., 2023), as well asgpt-3.5-turbo and gpt-4 in the GPT model family. We optimize prompts on GSM8K (Cobbe et al., 2021) and Big-Bench Hard (Suzgun et al., 2022), which are reasoning benchmarks where prompting techniques have achieved remarkable performance breakthrough (Wei et al., 2022; Kojima et al., 2022; Suzgun et al., 2022). Starting from initial prompts with low task accuracies, we show that all LLMs in our evaluation are able to 2Large Language Models as Optimizers scores generated solutions LLM as optimizer objective function evaluator return top solutions when finish meta-prompt  solution-score pairs task description Figure 2: An overview of the OPRO framework. Given the meta-prompt as the input, the LLM generates new solutions to the objective function, then the new solutions and their scores are added into the meta-prompt for the next optimization step. The meta-prompt contains the solution-score pairs obtained throughout optimization, a natural language description of the task, and (in prompt optimization) a few task exemplars. Figure 3 shows a sample meta-prompt for prompt optimization. serve as optimizers, which consistently improve the performance of the generated prompts through iterative optimization until convergence (see Figure 1). In particular, while these LLMs generally produce instructions of different styles (see Table 1), with zero-shot prompting, their best generated instructions match the few-shot chain-of-thought prompting performance when applied to PaLM 2-L, outperforming the zero-shot performance with human-designed prompts by up to 8% on GSM8K. Additionally, we observe that the OPRO-optimized prompts transfer to other benchmarks of the same domain and also deliver notable performance gain. 2 OPRO: LLM AS THE OPTIMIZER Figure 2 illustrates the overall framework of OPRO. In each optimization step, the LLM generates candidate solutions to the optimization task based on the optimization problem description and previously evaluated solutions in the meta-prompt. Then the new solutions are evaluated and added to the meta-prompt for the subsequent optimization process. The optimization process terminates when the LLM is unable to propose new solutions with better optimization scores, or a maximum number of optimization steps has reached. We first outline the desired features of LLMs for optimization, then describe the key design choices based on these desirables. 2.1 D ESIRABLES OF OPTIMIZATION BY LLM S Making use of natural language descriptions. The main advantage of LLMs for optimization is their ability of understanding natural language, which allows people to describe their optimization tasks without formal specifications. For instance, in prompt optimization where the goal is to find a prompt that optimizes the task accuracy, the task can be described with a high-level text summary along with input-output examples. Trading off exploration and exploitation. The exploration-exploitation trade-off is a fundamental challenge in optimization, and it is important for LLMs serving as optimizers to balance these two competing goals. This means that the LLM should be able to exploit promising areas of the search space where good solutions are already found, while also exploring new regions of the search space so as to not miss potentially better solutions. 2.2 M ETA-PROMPT DESIGN As the input to the optimizer LLM, the meta-prompt contains the following two essential parts. Optimization problem description. The first part is the text description of the optimization problem, including the objective function and solution constraints. For example, for prompt optimization, the LLM can be instructed to “generate a new instruction that achieves a higher accuracy”, and we denote such instructions in the meta-prompt as meta-instructions. We can also provide customized 3Large Language Models as Optimizers meta-instructions as an informal regularization of the generated solutions, such as “the instruction should be concise and generally applicable”. Optimization trajectory. Besides understanding natural language instructions, LLMs are also shown to be able to recognize patterns from in-context demonstrations (Wei et al., 2023; Madaan & Yazdanbakhsh, 2022; Mirchandani et al., 2023). Our meta-prompt makes use of this property and in- structs the LLM to leverage the optimization trajectory for generating new solutions. Specifically, the optimization trajectory includes past solutions and their optimization scores, sorted in the ascending order. Including optimization trajectory in the meta-prompt allows the LLM to identify similarities of solutions with high scores, encouraging the LLM to build upon existing good solutions to construct potentially better ones without the need of explicitly defining how the solution should be updated. 2.3 S OLUTION GENERATION At the solution generation step, the LLM generates new solutions with the meta-prompt as input. The following are the key optimization challenges we address in this stage. Optimization stability. In the optimization process, not all solutions achieve high scores and monotonically improve over prior ones. Due to the sensitivity of in-context learning to the prompt, LLM output can be drastically affected by low-quality solutions in the input optimization trajectory, especially at the beginning when the solution space has not been adequately explored. This sometimes results in optimization instability and large variance. To improve stability, we prompt the LLM to generate multiple solutions at each optimization step, allowing the LLM to simultaneously explore multiple possibilities and quickly discover promising directions to move forward. Exploration-exploitation trade-off. We tune the LLM sampling temperature to balance between exploration and exploitation. A lower temperature encourages the LLM to exploit the solution space around the previously found solutions and make small adaptations, while a high temperature allows the LLM to more aggressively explore solutions that can be notably different. 3 M OTIVATING EXAMPLE : M ATHEMATICAL OPTIMIZATION We first demonstrate the potential of LLMs in serving as optimizers for mathematical optimization. In particular, we present a case study on linear regression as an example of continuous optimization, and on the Traveling Salesman Problem (TSP) as an example of discrete optimization. On both tasks, we see LLMs properly capture the optimization directions on small-scale problems merely based on the past optimization trajectory provided in the meta-prompt. 3.1 L INEAR REGRESSION In linear regression problems, the goal is to find the linear coefficients that probabilistically best explain the response from the input variables. We study the setting in which the independent and dependent variables X and y are both one-dimensional and an intercept b is present, so that there are two one-dimensional variables w, b to optimize over. In a synthetic setting, we sample ground truth values for one-dimensional variables wtrue and btrue, and generate 50 data points by y = wtruex + btrue + ϵ, in which x ranges from 1 to 50 and ϵ is the standard Gaussian noise. Our optimization starts from 5 randomly sampled (w, b) pairs. In each step, we prompt an instruction- tuned LLM with a meta-prompt that includes the best 20 (w, b) pairs in history and their sorted objective values. The meta-prompt then asks for a new (w, b) pair that further decreases the objective value. A sample meta-prompt is shown in Figure 19 of Appendix C.1. We prompt the meta-prompt 8 times to generate at most 8 new (w, b) pairs in each step to improve optimization stability. Then we evaluate the objective value of the proposed pair and add it to history. We do black-box optimization: the analytic form does not appear in the meta-prompt text. This is because the LLM can often calculate the solution directly from the analytic form. Table 2 summarizes the results with one of the following optimizer LLMs: text-bison, gpt-3.5-turbo, and gpt-4. We study three settings of wtrue and btrue: within the starting region [10, 20] × [10, 20], “near outside” (each of wtrue and btrue is outside the starting region but the distance is less than 10), and “far outside” (each of wtrue and btrue is outside the starting region and the distance is greater than 10). We see: 4Large Language Models as Optimizers Table 2: Linear regression by optimizer LLMs: the mean ± standard deviation of the number of steps and the number of unique (w, b) pairs explored before reaching the global optima. Both w and b start from 5 random starting points in [10, 20]. We use temperature 1.0 for all models. We run each setting 5 times. The starting points are the same across optimizer LLMs but are different across 5 runs, and are grouped by: within the starting region, outside and close to the starting region, and outside and farther from the starting region. Bold numbers indicate the best among three LLMs in each setting. wtrue btrue number of steps number of unique (w, b)pairs explored text-bison gpt-3.5-turbo gpt-4 text-bison gpt-3.5-turbo gpt-4 15 14 5.8 ±2.6 7.6±4.5 4.0±1.5 40.0±12.4 36.0±15.2 17.2±5.1 17 17 4.0±1.8 12.6±6.0 6.0±3.7 33.4±11.7 53.8±16.9 26.0±10.6 16 10 3.8±2.2 10.4±5.4 6.2±3.1 30.2±13.4 42.8±16.3 24.2±8.2 3 5 9.8±2.8 10.8±2.7 12.2±2.0 55.8±16.1 39.6±10.1 33.0±4.0 25 23 19.6 ±11.4 26.4±18.3 12.2±3.7 104.0±52.3 78.6±26.2 44.2±8.3 2 30 31.4±6.3 42.8±9.7 38.0±15.9 126.4±17.7 125.6±21.7 99.0±24.6 36 -1 35.8±6.4 45.4±16.9 50.4±18.8 174.0±28.2 142.2±31.2 116.4±32.7 • The number of unique (w, b) pairs explored by each model is fewer than exhaustive search, indicating these models are able to to do black-box optimization: compare the numbers and propose a descent direction. • The text-bison and gpt-4 models outperform gpt-3.5-turbo in convergence speed: they arrive at the optima with fewer steps. The gpt-4 model also outperforms in finding the optima with fewer explored unique points. Taking a closer look at the optimization trajectory, we see gpt-4 is the best at proposing a reasonable next step from the history: for example, when the history shows the objective values of (w, b) = (8, 7), (w, b) = (8, 6), and (w, b) = (8, 5) are decreasing, it has a highest chance to propose (w, b) = (8, 4) for evaluation. • The problem becomes harder for all models when the ground truth moves farther from the starting region: all models need more explorations and more steps. 3.2 T RAVELING SALESMAN PROBLEM (TSP) Next, we consider the Traveling Salesman Problem (TSP) (Jünger et al., 1995; Gutin & Punnen, 2006), a classical combinatorial optimization problem with numerous algorithms proposed in literature, including heuristic algorithms and solvers (Rosenkrantz et al., 1977; Golden et al., 1980; Optimization et al., 2020; Applegate et al., 2006; Helsgaun, 2017), and approaches based on training deep neural networks (Kool et al., 2019; Deudon et al., 2018; Chen & Tian, 2019; Nazari et al., 2018). Specifically, given a set of n nodes with their coordinates, the TSP task is to find the shortest route that traverses all nodes from the starting node and finally returns to the starting node. Our optimization process with LLMs starts from 5 randomly generated solutions, and each optimiza- tion step produces at most 8 new solutions. We present the meta-prompt in Figure 20 of Appendix C.1. We generate the problem instances by samplingn nodes with both x and y coordinates in [−100, 100]. We use the Gurobi solver (Optimization et al., 2020) to construct the oracle solutions and compute the optimality gap for all approaches, where the optimality gap is defined as the difference between the distance in the solution constructed by the evaluated approach and the distance achieved by the oracle solution, divided by the distance of the oracle solution. Besides evaluating OPRO with different LLMs including text-bison, gpt-3.5-turbo and gpt-4, we also compare OPRO to the following heuristics: • Nearest Neighbor (NN). Starting from an initial node, the solution is constructed with the nearest neighbor heuristic: At each step, among the remaining nodes that are not included in the current partial solution, NN selects the node with the shortest distance to the end node of the partial solution, and adds it as the new end node. The process finishes when all nodes have been added to the solution. • Farthest Insertion (FI). One caveat of the nearest neighbor heuristic is that it does not take the distance between the start and end node into consideration when constructing partial solutions. To address this issue, FI aims to optimize the cost of inserting new nodes into the partial solution at each step. Define the minimal insertion cost of adding a new node k as 5Large Language Models as Optimizers Table 3: Results of the Traveling Salesman Problem (TSP) with different number of nodes n, where each n contains 5 problems. “# steps” calculates the mean ± standard error of optimization steps for successful runs that find the optimal solution. “# successes” counts the number of problems that OPRO results in the optimal solution. When no optimal solution is found for any evaluated problem, the corresponding number of steps is N/A. n optimality gap (%) # steps (# successes) NN FI text-bison gpt-3.5-turbo gpt-4 text-bison gpt-3.5-turbo gpt-4 10 13.0±1.3 3.2±1.4 0.0±0.0 0.0±0.0 0.0±0.0 40.4±5.6(5) 46.8±9.3(5) 9.6±3.0(5) 15 9.4 ±3.7 1.2±0.6 4.4±1.3 1.2±1.1 0.2±0.2 N/A (0) 202.0 ±41.1(4) 58.5±29.0(4) 20 16.0±3.9 0.2±0.1 30.4±10.6 4.4±2.5 1.4±0.6 N/A (0) 438.0 ±0.0(1) 195.5±127.6(2) 50 19.7±3.1 9.8±1.5 219.8±13.7 133.0±6.8 11.0±2.6 N/A (0) N/A (0) N/A (0) c(k) = min(i,j) d(i, k) +d(k, j) − d(i, j), where i and j are adjacent nodes in the current tour, and d(·, ·) represents the distance between two nodes. At each step, FI adds a new node that maximizes the minimal insertion cost. We present the results in Table 3. We randomly generate 5 problem instances for each number of nodes n. In addition to measuring the optimality gap, on problems where the LLM finds the optimal solutions, we also show the number of optimization steps taken to reach the global optimum. First, we observe that gpt-4 significantly outperforms gpt-3.5-turbo and text-bison across all problem sizes. Specifically, on smaller-scale problems, gpt-4 reaches the global optimum about 4× faster than other LLMs. On larger-scale problems, especially withn = 50, gpt-4 still finds solutions with a comparable quality to heuristic algorithms, while both text-bison and gpt-3.5-turbo get stuck at local optima with up to 20× worse optimality gaps. On the other hand, the performance of OPRO degrades dramatically on problems with larger sizes. When n = 10, all LLMs find the optimal solutions for every evaluated problem; as the problem size gets larger, the OPRO optimality gaps increase quickly, and the farthest insertion heuristic starts to outperform all LLMs in the optimality gap. Limitations. We would like to note that OPRO is designed for neither outperforming the state- of-the-art gradient-based optimization algorithms for continuous mathematical optimization, nor surpassing the performance of specialized solvers for classical combinatorial optimization problems such as TSP. Instead, the goal is to demonstrate that LLMs are able to optimize different kinds of objective functions simply through prompting, and reach the global optimum for some small- scale problems. Our evaluation reveals several limitations of OPRO for mathematical optimization. Specifically, the length limit of the LLM context window makes it hard to fit large-scale optimization problem descriptions in the prompt, e.g., linear regression with high-dimensional data, and traveling salesman problems with a large set of nodes to visit. In addition, the optimization landscape of some objective functions are too bumpy for the LLM to propose a correct descending direction, causing the optimization to get stuck halfway. We further elaborate our observed failure cases in Appendix A. 4 A PPLICATION : P ROMPT OPTIMIZATION Next, we demonstrate the effectiveness of OPRO on prompt optimization, where the objective is to find the prompt that maximizes task accuracy. We first introduce the problem setup, then illustrate the meta-prompt design. 4.1 P ROBLEM SETUP We focus on prompt optimization for natural language tasks, where both the input and output are in the text format. The task is represented as a dataset with training and test splits, where the training set is used to calculate the training accuracy as the objective value during the optimization process, and we compute the test accuracy on the test set after the optimization finishes. While traditional optimization often requires a decently large training set, our experiment shows that a small number or fraction of training samples (e.g., 3.5% of the training set for GSM8K (Cobbe et al., 2021), 20% for Big-Bench Hard (Suzgun et al., 2022)) is sufficient. The objective function evaluator is an LLM 6Large Language Models as Optimizers I have some texts along with their corresponding scores. The texts are arranged in ascending order based on their scores, where higher scores indicate better quality. text: Let’s figure it out! score: 61 text: Let’s solve the problem. score: 63 (. . . more instructions and scores . . . ) The following exemplars show how to apply your text: you replace <INS> in each input with your text, then read the input and give an output. We say your output is wrong if your output is different from the given output, and we say your output is correct if they are the same. input: Q: Alannah, Beatrix, and Queen are preparing for the new school year and have been given books by their parents. Alannah has 20 more books than Beatrix. Queen has 1/5 times more books than Alannah. If Beatrix has 30 books, how many books do the three have together? A: <INS> output: 140 (. . . more exemplars . . . ) Write your new text that is different from the old ones and has a score as high as possible. Write the text in square brackets. Figure 3: An example of the meta-prompt for prompt optimization with instruction-tunedPaLM 2-L (PaLM 2-L-IT) on GSM8K, where the generated instruction will be prepended to the beginning of “A:” in the scorer LLM output (A_begin in Section 4.1). <INS> denotes the position where the generated instruction will be added. The blue text contains solution-score pairs; the purple text describes the optimization task and output format; the orange text are meta-instructions. to which the optimized prompt will be applied, and it can be the same or different from the LLM for optimization. We denote the LLM for objective function evaluation as the scorer LLM, and the LLM for optimization as the optimizer LLM. The output of the optimizer LLM is an instruction, which is concatenated to the question part of every exemplar and prompts the scorer LLM. We consider the following positions to insert the instruction: • Q_begin: the instruction is added before the original question. • Q_end: the instruction is added after the original question. • A_begin: the instruction is added to the beginning of the scorer LLM output. This is applicable to pretrained LLMs without instruction tuning, where the prompt is formatted as a sequence of QA pairs. We exemplify these prompting formats in Appendix B. 4.2 M ETA-PROMPT DESIGN Figure 3 shows an example of the meta-prompt for prompt optimization on GSM8K (Cobbe et al., 2021). More details are as follows. 7Large Language Models as Optimizers Optimization problem examples. The problem description includes a few examples taken from the training set to demonstrate the task for the generated instructions. For example, from the input-output pair in Figure 3, we can infer this is a math word problem. The input-output pair also demonstrates the position where the generated instruction will be added to, and this is essential for the optimizer LLM to generate instructions of the same style. In each optimization step, we add several (three for example) training examples to the meta-prompt by random sampling the training set or choose the ones the previous instructions fall short of. Optimization trajectory. The optimization trajectory includes instructions generated from the past optimization steps, along with their scores. The old instructions and scores are sorted by the score in ascending order. The score is the training accuracy in prompt optimization. We only keep instructions with the highest scores in the meta-prompt in consideration of the LLM context length limit. Meta-instructions. We also addmeta-instructions: the instructions to the optimizer LLM that explain the optimization goal and instruct the model how to use the above information. The meta-instructions may also specify the desired generated instruction format for easier parsing. 5 P ROMPT OPTIMIZATION EXPERIMENTS We present the evaluation results for prompt optimization in this section. Our experiments demonstrate that OPRO brings a significant performance gain across the board, with different combinations of LLMs as the optimizer and the scorer. Section 5.1 describes the experiment setup. Section 5.2 shows main results on reasoning tasks like GSM8K and BBH. Section 5.3 shows ablation studies. Section 5.4 analyzes overfitting in prompt optimization. Section 5.5 compares the prompt optimization performance of meta-prompts in OPRO and EvoPrompt (Guo et al., 2023). 5.1 E VALUATION SETUP Models. The LLMs we use as the optimizer and the scorer are: • Optimizer LLM: Pre-trained PaLM 2-L (Anil et al., 2023), instruction-tuned PaLM 2-L (denoted PaLM 2-L-IT), text-bison, gpt-3.5-turbo, and gpt-4. • Scorer LLM: Pre-trained PaLM 2-L and text-bison. With pre-trained PaLM 2-L as the scorer, the optimizer LLM generates A_begin instructions. Since text-bison has been instruction-tuned, the optimizer LLM generates Q_begin and Q_end instructions when text-bison is used as the scorer. Benchmarks. Our primary evaluation benchmarks are GSM8K (Cobbe et al., 2021) and Big-Bench Hard (BBH) (Suzgun et al., 2022). GSM8K is a benchmark of grade school math word problems with 7,473 training samples and 1,319 test samples, where chain-of-thought prompting (Wei et al., 2022) and the zero-shot instruction “Let’s think step by step.” (Kojima et al., 2022) have drastically improved the performance over the standard prompting. BBH is a suite of 23 challenging BIG-Bench tasks (Srivastava et al., 2022) that covers a wide range of topics beyond arithmetic reasoning, including symbolic manipulation and commonsense reasoning. Each task contains up to 250 examples in total. To examine the transferability of the optimized instructions, we also evaluate the instructions op- timized for GSM8K on two other mathematical reasoning datasets, i.e., MultiArith (Roy & Roth, 2016) and AQuA (Ling et al., 2017). Implementation details. We set the temperature to be 0 when evaluating the performance of generated instructions, in which case the scorer LLM greedily decodes. Unless otherwise specified, we set the default temperature to be 1.0 for optimizer LLMs to generate diverse and creative instructions. At each optimization step, we prompt the optimizer LLM with the meta-prompt 8 times to generate 8 instructions, then we add these instructions with their training scores to the optimization trajectory in the meta-prompt. Our meta-prompt at each step contains the best 20 instructions so far and 3 randomly picked exemplars from the training set. We study the effect of different hyperparameters in ablation studies (Section 5.3). Appendix C.2 presents the full meta-prompts for different optimizer LLMs. 8Large Language Models as Optimizers Table 4: Test accuracies on GSM8K. We show the instruction with the highest test accuracy for each scorer-optimizer pair. Scorer Optimizer / Source Instruction position Top instruction Acc Baselines PaLM 2-L (Kojima et al., 2022) A_begin Let’s think step by step. 71.8 PaLM 2-L (Zhou et al., 2022b) A_begin Let’s work this out in a step by step way to be sure we have the right answer. 58.8 PaLM 2-L A_begin Let’s solve the problem. 60.8 PaLM 2-L A_begin (empty string) 34.0 text-bison (Kojima et al., 2022) Q_begin Let’s think step by step. 64.4 text-bison (Zhou et al., 2022b) Q_begin Let’s work this out in a step by step way to be sure we have the right answer. 65.6 text-bison Q_begin Let’s solve the problem. 59.1 text-bison Q_begin (empty string) 56.8 Ours PaLM 2-L PaLM 2-L-IT A_begin Take a deep breath and work on this problem step-by-step. 80.2 PaLM 2-L PaLM 2-L A_begin Break this down. 79.9 PaLM 2-L gpt-3.5-turboA_begin A little bit of arithmetic and a logical approach will help us quickly arrive at the solution to this problem. 78.5 PaLM 2-L gpt-4 A_begin Let’s combine our numerical command and clear thinking to quickly and accurately decipher the answer. 74.5 text-bison PaLM 2-L-IT Q_begin Let’s work together to solve math word problems! First, we will read and discuss the problem together to make sure we understand it. Then, we will work together to find the solution. I will give you hints and help you work through the problem if you get stuck. 64.4 text-bison text-bison Q_end Let’s work through this problem step-by-step: 68.5 text-bison gpt-3.5-turboQ_end Analyze the given information, break down the problem into manageable steps, apply suitable mathematical operations, and provide a clear, accurate, and concise solution, ensuring precise rounding if necessary. Consider all variables and carefully consider the problem’s context for an efficient solution. 66.5 text-bison gpt-4 Q_begin Start by dissecting the problem to highlight important numbers and their relations. Decide on the necessary mathematical operations like addition, subtraction, multiplication, or division, required for resolution. Implement these operations, keeping in mind any units or conditions. Round off by ensuring your solution fits the context of the problem to ensure accuracy. 62.7 5.2 M AIN RESULTS We show prompt optimization curves on GSM8K and two BBH tasks in this section. The curves on other BBH tasks are deferred to Appendix D, and the tables containing all accuracy numbers are in Appendix E. 5.2.1 GSM8K For prompt optimization, we randomly sample 3.5% examples from the GSM8K training set. The same subset is used throughout optimization, so that the task accuracies computed at intermediate optimization steps are approximations of the training accuracy on all 7,473 training examples. This balances the evaluation cost with the generalization performance. After the optimization procedure finishes, we evaluate the found instructions on the entire GSM8K test set. Figure 1(a) in Section 1 shows prompt optimization curves with pre-trained PaLM 2-L as scorer and PaLM 2-L-IT as optimizer, and the initial instruction is “Let’s solve the problem” with a (approximated, and same below) training accuracy of 60.5. We observe that the optimization curve shows an overall upward trend with several leaps throughout the optimization process, for example: 9Large Language Models as Optimizers • “Let’s think carefully about the problem and solve it together.” at Step 2 with the training accuracy 63.2; • “Let’s break it down!” at Step 4 with training accuracy 71.3; • “Let’s calculate our way to the solution!” at Step 5 with training accuracy 73.9; • “Let’s do the math!” at Step 6 with training accuracy 78.2. The optimization curves also generally show a decrease of the variance among the accuracies of instructions generated at each step, indicating that the optimizer LLM generates distributionally better instructions throughout the optimization. Next, we present the results of generating Q_begin instructions with the text-bison scorer and the PaLM 2-L-IT optimizer, starting from an empty instruction with a 57.1 training accuracy. The optimization curve in Figure 4(a) shows a similar upward trend, during which a few leaps in the training accuracy include: • “Solve the following problems using the given information.” at Step 2 with training accuracy 59.8; • “Solve the following problems by applying the given information and using the appropriate mathematical operations.” at Step 3 with training accuracy 64.0; • “Let’s read the problem carefully and identify the given information. Then, we can create an equation and solve for the unknown variable.” at Step 4 with training accuracy 67.0; • “I’m always down for solving a math word problem together. Just give me a moment to read and understand the problem. Then, I’ll create an equation that models the problem, which I’ll solve for the unknown variable. I also may or may not use some helpful diagrams or visuals to understand the problem. Lastly, be sure to allow me some time to carefully check my work before submitting any responses!” at Step 29 with training accuracy 70.1. Note that although our default setting is to run OPRO for 200 steps in prompt optimization, we need much fewer steps if the goal is to find some outstanding instructions. An example is that the Figure 1(a) experiment found “Let’s do the math!” at Step 6 with training accuracy 78.2, almost matching the “Take a deep breath and work on this problem step-by-step.” found at the 107th step with training accuracy 80.2, at a point where the optimization curve is still trending upwards. This is because a leap in our optimization curve does not always correspond to a much better instruction being discovered; instead, it can be due to a large qualitative improvement of all 8 generated instructions in this step. The latter usually happens several steps after the former: after a much better instruction is discovered in one step, the meta-prompt gradually gets rid of worse instructions in the latter steps by generating instructions similar to the much-better one. The top instructions kept in the meta-prompt gradually improves in this procedure. At a point when the meta-prompt only triggers higher quality instructions, the leap happens. Finally, Figure 4(b) shows that the pre-trained PaLM 2-L can also serve as the optimizer LLM and improve its own prediction performance. Different from other optimizer LLMs that are instruction- tuned, the pre-trained PaLM 2-L performs better when the prompt is formatted in a few-shot manner. Therefore, we include two initial instructions to start the optimization: the empty instruction (with a training accuracy 32.2) and “The answer is” (with a training accuracy 33.3). See Figure 21 in Appendix C for the meta-prompt format. The generated instructions follow the same style as “The answer is”: most instructions are also phrases suitable as the prefix of a sentence, like “Here you go:” (generated at Step 11 with training accuracy 61.3) and “Let’s do it:” (generated at Step 13 with training accuracy 75.1). Table 4 summarizes top instructions found on GSM8K with different scorer and optimizer LLMs. We observe that: • The styles of instructions found by different optimizer LLMs vary a lot: PaLM 2-L-IT and text-bison ones are concise, while GPT ones are long and detailed. • Although some top instructions contain the “step-by-step” phrase, most others achieve a compa- rable or better accuracy with different semantic meanings. 10Large Language Models as Optimizers 0 50 100 150 200 # steps 50.0 60.0 70.0training accuracy GSM8K (scorer: text-bison) (a) PaLM 2-L-IT optimizer 0 20 40 60 80 # steps 20.0 40.0 60.0 80.0training accuracy GSM8K (scorer and optimizer: PaLM 2-L) (b) pre-trained PaLM 2-L optimizer Figure 4: Prompt optimization on GSM8K with (a) thetext-bison scorer and thePaLM 2-L-IT optimizer, and (b) pre-trained PaLM 2-L as both scorer and optimizer. 5.2.2 BBH On BBH, the optimization starts from an empty string as the initial instruction by default. The instructions are placed at A_begin when the scorer is PaLM 2-L, and at Q_begin when the scorer is text-bison. For each task, we utilize a subset of 20% examples for prompt optimization, and the rest examples are for testing. We show experimental results on more variants of the instruction position and initialization in Appendix E. Figure 5 visualizes the per-task accuracy difference on all 23 BBH tasks compared to the instruction “Let’s think step by step.” (Kojima et al., 2022) and the empty instruction, and we present the concrete accuracies in Table 7 of Appendix E. We show that the instructions found by OPRO outperform “Let’s think step by step.” on almost all tasks by a large margin: our instructions outperform by over 5% on 19/23 tasks with the PaLM 2-L scorer, and on 15/23 tasks with the text-bison scorer. Our prompt optimization algorithm also improves instructions from the empty starting point by over 5% on most tasks: 20/23 with the PaLM 2-L scorer and 15/23 with the text-bison scorer. Similar to GSM8K, we observe upward trends in optimization curves on almost all BBH tasks, as shown in Figure 6. See Figure 23 and 24 in Appendix D for more curves on other BBH tasks. We next show some examples of instructions found through the course of optimization. On the task ruin_names, starting from the empty instruction (with 64.0 training accuracy), with thetext-bison scorer and the PaLM 2-L-IT optimizer, the following instructions are generated: • “Consider the following when editing artist or movie names humorously:” at Step 1 with training accuracy 72.0; • “When making humorous edits of artist or movie names, you can change one or more letters or even create puns by adding new words that sound similar.” at Step 18 with training accuracy 80.0; • “We can make humorous edits of artist/movie names by changing letters to create new words that are similar in sound but have different meanings. For example, The Police can be changed to The Polite, The Abyss can be changed to Toe Abyss, and Schindler’s List can be changed to Schindler’s Lost.” at Step 38 with training accuracy 82.0. Although the above instructions are semantically similar, a paraphrase by the optimizer LLM offers a notable accuracy improvement. We further highlight this observation in Section 5.2.3. Below are some instructions generated when performing prompt optimization on temporal_sequences, starting from the empty instruction (with the training accuracy of 64.0): • “To solve this problem, we need to first identify the time period when the person was not seen doing anything else. Then, we need to check if the place they went to was open during that time period. If it was, then that is the time period when they could have gone to that place.” at Step 2 with training accuracy 42.0; • “To find the time period when a person could have gone to a place, identify the time periods when they were not seen doing anything else and the place was open. If there are multiple time periods that match these criteria, then the person could have gone to the place during any of these time periods.” at Step 18 with training accuracy 54.0; 11Large Language Models as Optimizers boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting -20 0 20 40 accuracy difference (a) PaLM 2-L scorer, ours minus “Let’s think step by step.” boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40 60accuracy difference (b) PaLM 2-L scorer, ours minus empty starting point boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40 60accuracy difference (c) text-bison scorer, ours minus “Let’s think step by step.” boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40accuracy difference (d) text-bison scorer, ours minus empty starting point Figure 5: On 23 BBH tasks, the accuracy differences among instructions found by prompt opti- mization (with the PaLM 2-L-IT optimizer), “Let’s think step by step.”, and the empty string (optimization starting point). • “To determine the possible time period when a person went to a place, first identify all the time periods when the person was not seen doing anything else and the place was open. Then, rule out any time periods during which the person was seen doing something else. The remaining time periods are the possible times when the person could have gone to the place.” at Step 41 with training accuracy 72.0. Table 5 presents the best instructions generated on movie_recommendation, ruin_names, and tem- poral_sequences tasks with different combinations of the optimizer and the scorer LLMs. Again, 12Large Language Models as Optimizers 0 50 100 150 200 # steps 70.0 80.0 90.0training accuracy  BBH ruin_names (a) BBH ruin_names 0 50 100 150 # steps 30.0 50.0 70.0training accuracy  BBH temporal_sequences (b) BBH temporal_sequences Figure 6: Training accuracy curves of prompt optimization on BBH ruin_names and tempo- ral_sequences with the text-bison scorer and the PaLM 2-L-IT optimizer. The optimizations start from the empty string. different optimizer LLMs produce instructions of different styles. See Appendix E for results on more BBH tasks. 5.2.3 S EMANTICALLY SIMILAR INSTRUCTIONS MAY ACHIEVE DRASTICALLY DIFFERENT ACCURACIES One challenge of prompt optimization is the sensitivity of model performance to subtle changes in the instruction. For example, with the PaLM 2-L scorer on the GSM8K test set, “Let’s think step by step.” achieves accuracy 71.8, “Let’s solve the problem together.” has accuracy 60.5, while the accuracy of “Let’s work together to solve this problem step by step.” is only 49.4, although it is the semantic combination of the two upper instructions. This behavior increases both the variance across single-step instructions and the oscillation during optimization, and motivates us to generate multiple instructions at each step to improve the optimization stability. 5.2.4 T RANSFERABILITY OF FOUND INSTRUCTIONS We assess the transferability of found prompts to different datasets of the same domain, where we evaluate the top instructions found for GSM8K on two more math reasoning benchmarks Multi- Arith (Roy & Roth, 2016) and AQuA (Ling et al., 2017). Table 6 shows that our optimized prompts also outperform baseline prompts with different scorer LLMs on these two benchmarks. 5.3 A BLATION STUDIES We use text-bison as the scorer and PaLM 2-L as the optimizer for all ablation studies. The tasks we evaluate are GSM8K (math reasoning) and BBH sports_understanding (non-math reasoning). Meta-prompt design. The meta-prompt design is crucial in achieving good prompt optimization performance. We investigate the following core design choices: • The order of the previous instructions. We compare the following options: (1) from lowest to highest (our default setting); (2) from highest to lowest; (3) random. Figures 7(a) and 7(b) show that the default setting achieves better final accuracies and converges faster. One hypothesis is that the optimizer LLM output is affected more by the past instructions closer to the end of the meta-prompt. This is consistent with the recency bias observed in Zhao et al. (2021), which states that LLMs are more likely to generate tokens similar to the end of the prompt. • The effect of instruction scores. In terms of how to present the accuracy scores, we compare three options: (1) rounding the accuracies to integers, which is equivalent to bucketizing the accuracy scores to 100 buckets (our default setting); (2) bucketizing the accuracies to 20 buckets; (3) not showing the accuracies, only showing the instructions in the ascending order. Figures 7(c) and 7(d) show that the accuracy scores assists the optimizer LLM in better understanding the quality difference among previous instructions, and thus the optimizer LLM proposes better new instructions that are similar to the best ones in the input optimization trajectory. • The effect of exemplars. We compare three options: (1) showing 3 exemplars from the task (default); (2) showing 10 exemplars from the task; (3) no exemplars. Figures 7(e) and 7(f) show 13Large Language Models as Optimizers Table 5: Top instructions with the highest accuracies found in prompt optimization on BBH movie_recommendation, ruin_names, and temporal_sequences. Scorer Optimizer Instruction position Instruction Acc movie_recommendation PaLM 2-L PaLM 2-L-IT A_begin Based on your input, I have analyzed the given movies in terms of genre, plot, tone, audience rating, year of release, director, cast, and reviews. I have also taken into account the given options. The movie that is most similar to the given movies in terms of all these factors is: 90.8 PaLM 2-L PaLM 2-L A_begin The best film: 88.4 PaLM 2-L gpt-3.5-turboA_begin Let’s uncover the perfect movie recommendation from the options provided, ensuring an exceptional cinematic experience together as we select the most captivating and satisfying choice that will keep us thoroughly engaged and immersed until the very end. 88.0 text-bison PaLM 2-L-ITQ_begin What is the highest-rated movie similar to the given movies, with a similar IMDb rating and released in the same year? 91.6 text-bison gpt-3.5-turboQ_begin Based on the movie list provided, carefully consider your preferences and make a well-informed decision. 70.8 ruin_names PaLM 2-L PaLM 2-L-IT A_begin Which is the funniest pun on the artist or movie name?88.0 PaLM 2-L PaLM 2-L A_begin Answer for ruin: 83.6 PaLM 2-L gpt-3.5-turboA_begin Prepare to have a side-splittingly funny time as we uncover the most clever and hilarious alternatives for these artist or movie names, challenging your wit to guess the correct one with a burst of creativity, humor, and imaginative twists! 86.8 text-bison PaLM 2-L-ITQ_begin A humorous edit of an artist or movie name can be created by replacing one or more letters to form a new word or phrase that sounds similar but has a different meaning. The new word or phrase should be relevant to the original word, but it should also be a surprise, which makes the edit funny. For example, the artist or movie name \"Rocky\" can be changed to \"Ricky,\" and \"Schindler’s List\" can be changed to \"Schindler’s Lift.\" Be creative and have fun! 83.6 text-bison gpt-3.5-turboQ_begin Choose the option that offers the most clever and humorous alteration of the given artist or movie name. Let your creativity shine and select the answer that will undoubtedly bring a smile to your face! Make sure to think outside the box! 75.2 temporal_sequences(noPaLM 2-Las scorer results because its training accuracy on empty string is 100.0) text-bison PaLM 2-L-ITQ_begin To determine the time period when a person went to a place, first identify all the time periods when the person’s whereabouts are unknown. Then, rule out any time periods during which the person was seen doing something else or the place was closed. The remaining time periods are the possible times when the person could have gone to the place. 80.4 text-bison gpt-3.5-turboQ_begin Identify the optimal time slot for the individual to engage in the mentioned location/activity considering the given sightings and waking up time, taking into account the opening and closing times of the location and the duration of each event. 53.6 14Large Language Models as Optimizers Table 6: Transferability across datasets: accuracies of top instructions found for GSM8K on Multi- Arith and AQuA. Scorer Source Instruction position Instruction Accuracy MultiArith AQuA Baselines PaLM 2-L (Kojima et al., 2022) A_begin Let’s think step by step. 85.7 44.9 PaLM 2-L (Zhou et al., 2022b) A_begin Let’s work this out in a step by step way to be sure we have the right answer. 72.8 48.4 PaLM 2-L A_begin Let’s solve the problem. 87.5 44.1 PaLM 2-L A_begin (empty string) 69.3 37.8 text-bison (Kojima et al., 2022) Q_begin Let’s think step by step. 92.5 31.9 text-bison (Zhou et al., 2022b) Q_begin Let’s work this out in a step by step way to be sure we have the right answer. 93.7 32.3 text-bison Q_begin Let’s solve the problem. 85.5 29.9 text-bison Q_begin (empty string) 82.2 33.5 Ours PaLM 2-L PaLM 2-L-IT on GSM8K A_begin Take a deep breath and work on this problem step-by-step. 95.3 54.3 text-bison PaLM 2-L-IT on GSM8K Q_begin Let’s work together to solve math word problems! First, we will read and discuss the problem together to make sure we understand it. Then, we will work together to find the solution. I will give you hints and help you work through the problem if you get stuck. 96.8 37.8 that presenting exemplars in the meta-prompt is critical, as it provides information on what the task looks like and helps the optimizer model phrase new instructions better. However, more exemplars do not necessarily improve the performance, as a few exemplars are usually sufficient to describe the task. In addition, including more exemplars results in a longer meta-prompt with a dominating exemplar part, which may distract the optimizer LLM from other important components like the optimization trajectory. The number of generated instructions per step. Computing a mini-batch of gradients reduces the variance of a stochastic gradient descent procedure. Similarly, generating multiple instructions in each step improves the optimization stability with LLMs. On the other hand, to achieve better performance with a fixed budget for the number of instructions to evaluate, the number of per-step instructions should not be too large, so as to allow more optimization steps to incorporate richer information of past instructions with their accuracies. Taking both aspects into consideration, Figure 8 compares the optimization performance of sampling 1 / 2 / 4 / 8 (default) / 16 instructions in each step, showing that sampling 8 instructions at each step overall achieves the best performance. Starting point. We study the effect of different initial instructions for prompt optimization. Our default setting is to start from an empty string when the scorer LLM is (instruction-tuned) text-bison, and to start from either the empty string (on BBH tasks) or “Let’s solve the problem.” (on GSM8K) with instruction position A_begin when the scorer LLM is the (pre-trained)PaLM 2-L. Figure 9(a) shows the performance of text-bison as the scorer LLM with 3 options of initial instructions: (1) the empty string; (2) “Solve the following problem.”; or (3) “Solve the following problem.” and “Let’s solve the problem.”. We observe that the accuracies do not differ much with different starting points. Interestingly, the styles of the generated instructions are also similar. For example, most of the generated instructions starting from (1) and (2) contain the phrase “solve this problem”, like “Let’s work together to solve this problem.” in Step 4 with training accuracy 64.8 from (1), and “Let’s solve the following problems using the given information.” in Step 3 with training accuracy 62.8 from (2). 15Large Language Models as Optimizers 0 50 100 150 200 # steps 50.0 60.0 70.0accuracy ascending (default) descending random (a) instruction ordering (GSM8K) 0 50 100 150 200 # steps 0.0 50.0 100.0accuracy ascending (default) descending random (b) instruction ordering (BBH sports_understanding) 0 50 100 150 200 # steps 50.0 60.0 70.0accuracy 100 buckets (default) 20 buckets no scores (c) instruction scores (GSM8K) 0 50 100 150 200 # steps 0.0 50.0 100.0accuracy 100 buckets (default) 20 buckets no scores (d) instruction scores (BBH sports_understanding) 0 50 100 150 200 # steps 50.0 60.0 70.0accuracy 3 exemplars (default) 10 exemplars no exemplars (e) # exemplars (GSM8K) 0 50 100 150 200 # steps 0.0 50.0 100.0accuracy 3 exemplars (default) 10 exemplars no exemplars (f) # exemplars (BBH sports_understanding) Figure 7: Ablation studies: how each part of the meta-prompt matters. The dots are the average values across 3 optimization repetitions, and the shaded regions represent standard deviations. 16Large Language Models as Optimizers 0 400 800 1200 1600 # evaluated instructions 50.0 60.0 70.0accuracy 1 2 4 8 (default) 16 (a) GSM8K 0 400 800 1200 1600 # evaluated instructions 0.0 50.0 100.0accuracy 1 2 4 8 (default) 16 (b) BBH sports_understanding Figure 8: Ablation studies: the number of generated instructions in each step. The dots are the average values across 3 optimization repetitions, and the shaded regions represent standard deviations. The x-axis represents the total number of evaluated instructions through the optimization; e.g., we run 200 optimization steps when sampling 8 instructions in each step, run 400 steps when sampling 4 instructions in each step, etc. 0 50 100 150 200 # steps 50.0 60.0 70.0accuracy from \"\" (default) from \"Solve the following problem.\" from \"\", \"Solve the following problem.\", and \"Let's solve the problem.\" (a) GSM8K, text-bison scorer, Q_begin 0 50 100 150 200 # steps 40.0 60.0 80.0accuracy from \"Let's solve the problem\" (default) from \"\" from \"Let's think step by step.\" (b) GSM8K, PaLM 2-L scorer, A_begin Figure 9: Ablation studies: the initial instructions for prompt optimization. The dots are the average values across 3 optimization repetitions, and the shaded regions represent standard deviations. Figure 9(b) presents the results of of PaLM 2-L as the scorer LLM with the following options of initial instructions: (1) “Let’s solve the problem.”; (2) the empty string; or (3) “Let’s think step by step.”. We notice that the performance differs much more with different initial instructions, especially at the beginning of the optimization. Specifically, starting from (1) leads to better generated instructions than (2) in the first 30 steps, while the instructions optimized from both (1) and (2) are worse than (3) throughout. A similar observation holds when using PaLM 2-L as scorer and gpt-3.5-turbo as optimizer for BBH tasks, by comparing the results starting from the empty string (Appendix E.2) and from “Let’s solve the problem.” (Appendix E.3). Taking a closer look into the optimization process of (2), we find that although both “solve the problem” and “step by step” show up in generated instructions at Step 5, it takes the optimizer LLM more steps to get rid of worse instructions presented in the meta-prompt when starting from instructions with lower accuracies. Therefore, one direction for future work is to accelerate convergence from weaker starting points. 17Large Language Models as Optimizers 0 50 100 150 200 # steps 50.0 60.0 70.0accuracy 0.0 0.5 1.0 (default) 1.5 2.0 (a) GSM8K 0 50 100 150 200 # steps 0.0 50.0 100.0accuracy 0.0 0.5 1.0 (default) 1.5 2.0 (b) BBH sports_understanding Figure 10: Ablation studies: temperature of the optimizer model. The dots are the average values across 3 optimization repetitions, and the shaded regions represent standard deviations. Diversity per step. We evaluate the following temperatures of the optimizer LLM: {0.0, 0.5, 1.0 (default), 1.5, 2.0}. Figure 10 shows the default temperature 1.0 achieves the best performance. Specifically, optimizations with smaller temperatures (0.0 and 0.5) lack exploration and thus creativity, and the optimizer LLM often gets stuck at the same instruction for tens of steps, resulting in flat optimization curves. On the other hand, with larger temperatures (1.5 and 2.0), the optimizer LLM more often ignores the trajectory of previous instructions presented in the meta-prompt and thus lacks exploitation, therefore the optimization curve does not have a steady upward trend. Comparison with one-step instruction generation. Our current iterative procedure runs for multiple steps and generates a new batch of solutions in each step. To validate the importance of leveraging the optimization trajectory for generating new prompts, we compare to a baseline that generates all instructions in a single step without entering into the optimization procedure. We compare these two approaches on GSM8K and BBH sports_understanding with the PaLM 2-L-IT optimizer. For GSM8K the scorer LLM is pre-trained PaLM 2-L and the initial instruction is “Let’s solve the problem”, and for BBH sports_understanding the scorer LLM is text-bison and the initial instruction is the empty string. The baseline generates 50 instructions in a single step, thus its meta-prompt only includes task exemplars, the initial instruction with its accuracy, and the same meta-instructions as our full meta-prompt for performing optimization. All the other hyperparameters remain the same. Our results show that this one-step instruction generation performs much worse than our optimization approach. Specifically: (1) On GSM8K, the best instruction among all 50 is still “Let’s solve the problem”, with a 64.4 training accuracy and a 60.8 test accuracy. On the other hand, our approach (corresponding to Figure 1(a) in the main paper) found “Let’s do the math!” with a 78.2 training accuracy and a 76.3 test accuracy at the 5th step by generating 8 instructions at each step. (2) Similarly, on BBH sports_understanding, the best instruction among all 50 achieved a 84.0 training accuracy and 80.0 test accuracy. This is again worse than the instruction found by our approach at Step 4, which achieved a 88.0 training accuracy and a 84.5 test accuracy. 5.4 O VERFITTING ANALYSIS IN PROMPT OPTIMIZATION For simplicity, we do not set aside a validation set in our default setting of prompt optimization. We made this decision based on the experiments when a validation set is present. Overfitting may result in training accuracy being much higher than the validation/test accuracy. It is difficult to avoid overfitting, but overfitting is less harmful when each candidate solution (natural language instruction in the prompt optimization context) overfits to a similar extent. In this case, a higher training accuracy solution still achieves a higher validation/test accuracy, and one can adopt solutions with the highest training accuracies as the final result. Figure 11 shows this is the case for OPRO in prompt optimization: when setting aside a validation set with the same size as the training 18Large Language Models as Optimizers 0 50 100 150 200 # steps 50 70 90accuracy training validation (a) BBH snarks, PaLM 2-L as scorer, PaLM 2-L-IT as optimizer, starting from “Let’s solve the problem.” 0 50 100 # steps 40 60 80accuracy training validation (b) BBH sports_understanding, text-bison as scorer, gpt-3.5-turbo as optimizer, start- ing from the empty string Figure 11: Overfitting analysis. The exemplars are splitted to 1/3 training, 1/3 validation and 1/3 test. We compute the validation accuracy every 3 steps. The training/validation dots are the average training/validation accuracies across 3 optimization repetitions, respectively, and the shaded regions represent standard deviations. set, the validation accuracy curves trend up and down alongside the training curves in both prompt optimization settings. Of course, overfitting still occurs in the instructions found by our prompt optimization: in Table 7 and 10, our training accuracies are often 5%-20% higher than our test accuracies, despite that our test and overall accuracies are still mostly higher than human-written counterparts. Setting aside a larger training set and optimizing for fewer steps (early stopping) may help reduce overfitting. 5.5 C OMPARISON WITH EVOPROMPT Some concurrent works on prompt optimization propose meta-prompts that explicitly ask the LLM to perform mutation and crossovers of existing prompts (Fernando et al., 2023; Guo et al., 2023). In our evaluation, we compare our approach to the Genetic Algorithm (GA) and Differential Evolution (DE) versions of EvoPrompt (Guo et al., 2023). Specifically, in the GA meta-prompt, given two prompts, the meta-prompt instructs the LLM to cross over the two prompts and generates a new one, then mutates the newly generated prompt to produce the final prompt. DE extends the GA meta-prompt to include more detailed instructions, e.g., asking the LLM to identify different parts between the two given prompts before performing the mutation. This is in contrast with OPRO, which leverages the optimization trajectory including multiple past prompts, instead of only 2 previous prompts. Meanwhile, OPRO also provides the LLM with richer information to facilitate the understanding of the optimization problem, including exemplars and task accuracies of different prompts. Figure 12 presents the results on GSM8K and BBH sports_understanding benchmarks, where we use gpt-3.5-turbo as the optimizer. On GSM8K, the initial instructions of all approaches are “Let’s solve the problem.” and “Here is the answer.”, which are simple and generic. Again, we observe that OPRO performance steadily improves with more optimization steps. On the other hand, both versions of EvoPrompt even degrade the performance on GSM8K. The main reason is because EvoPrompt does not utilize exemplars for prompt optimization, thus it lacks the understanding of the task to optimize for. In this way, EvoPrompt relies on good-quality and task-specific initial prompts to optimize from. Given this observation, we provide more task-specific initial instructions for experiments on BBH sports_understanding, which are “Solve the sports understanding problem.” and “Give me the answer to sports understanding.” In this case, EvoPrompt (DE) is able to find better prompts than the initial ones, but the optimization curve is less stable than OPRO. This indicates that leveraging the optimization trajectory helps the LLM to identify promising directions to improve existing prompts. 19Large Language Models as Optimizers 0 50 100 150 # steps 20 50 80accuracy OPRO EvoPrompt (GA) EvoPrompt (DE) (a) GSM8K, PaLM 2-L scorer, A_begin 0 50 100 150 200 # steps 50 90accuracy OPRO EvoPrompt (GA) EvoPrompt (DE) (b) BBH sports_understanding, text-bison scorer, Q_begin Figure 12: Comparison with EvoPrompt in prompt optimization. We use the gpt-3.5-turbo optimizer for both experiments. “EvoPrompt (GA)” uses the meta-prompt from Guo et al. (2023), Figure 1; “EvoPrompt (DE)” uses the meta-prompt from Guo et al. (2023), Figure 2. All optimizations in (a) use the pre-trained PaLM 2-L scorer and start from two simple instructions “Let’s solve the problem.” and “Here is the answer.”; all optimizations in (b) use thetext-bison scorer and start from two richer (task-specific) instructions “Solve the sports understanding problem.” and “Give me the answer to sports understanding.”. The dots are the average values across 3 optimization repetitions, and the shaded regions represent standard deviations. We use temperature 1.0 for OPRO and temperature 0.5 for EvoPrompt, same as the default settings in respective works. 6 R ELATED WORK Prompt optimization. Prior works have developed soft prompt-tuning methods that optimize the prompt represented as task-specific continuous vectors (Lester et al., 2021; Li & Liang, 2021; Liu et al., 2021; Qin & Eisner, 2021), as well as performing discrete prompt optimization by gradient-guided search (Shin et al., 2020; Wen et al., 2023; Gao et al., 2020; Chen et al., 2023d) and reinforcement learning (Deng et al., 2022; Zhang et al., 2023). These approaches become inapplicable when there is only API access to the LLM. Other works designed edit-based approaches for gradient-free prompt optimization (Xu et al., 2022; Prasad et al., 2022), where the editing can be done with human- defined operations (e.g., swapping two phrases) (Prasad et al., 2022) or language models (e.g., back translation) (Xu et al., 2022). Some recent works investigate LLMs for prompt optimization (Zhou et al., 2022b; Pryzant et al., 2023; Xu et al., 2023). Specifically, APE (Zhou et al., 2022b) first uses the LLM to generate initial instructions. Afterwards, APE selects top instructions with the highest accuracies, then prompts the LLM with each individual instruction to generate a semantically similar variant of the initial instruction. APO (Pryzant et al., 2023) in each step instructs the LLM to produce text feedback on how to update an old instruction. Different from edit-based approaches, the optimizer LLM in our work directly generates new instructions at each optimization step, and the optimizer LLM is merely asked to improve the task accuracy without being required to imitate past instructions. Compared to Zhou et al. (2022b) and Pryzant et al. (2023), our optimization process incorporates the past generated instructions with their scores in the meta-prompt, enabling the optimizer LLM to discover common patterns of high-quality instructions. Prompting with natural language feedback. A recent line of work investigates approaches to improve the LLM performance by prompting with natural language feedback to revise the model output, which has shown effectiveness in reducing harmful LLM outputs (Bai et al., 2022; Ganguli et al., 2023), improving reasoning (Shinn et al., 2023; Madaan et al., 2023) and code generation performance (Chen et al., 2023e; Olausson et al., 2023; Shinn et al., 2023; Chen et al., 2023b), dialogue applications (Nair et al., 2023; Madaan et al., 2023; Yuan et al., 2023), and so on (Kim et al., 2023; Wang et al., 2023). Specifically, Yuan et al. (2023) develops a human-in-the-loop framework for deriving system-level feedback from a collection of instance-level feedback, which is then used 20Large Language Models as Optimizers for refining data. In our work, the optimizer LLM utilizes the optimization trajectory in the prompt, which implicitly requires the LLM to summarize the common characteristics among solutions with similar scores. We consider incorporating explicit natural language feedback on generated solutions for later optimization steps as future work. Tuning language models for optimization. Some previous works tune or prompt language models to behave as mutation and crossover operators in evolutionary algorithms. Meyerson et al. (2023) utilizes language models with few-shot exemplars to propose evolutionary cross-overs on tasks such as image and code generation. In Lehman et al. (2022), the large language model trained on code diff generation is used as the mutation operator, and they further design a fine-tuning method to improve performance in the Sodarace domain for robot simulation. EvoPrompting (Chen et al., 2023a) uses large language models to evolve neural network architectures, where they combine evolutionary search with soft prompt tuning. With respect to taking the trajectory as the input for optimization, OptFormer (Chen et al., 2022) trains a transformer model on large collections of hyperparameter optimization data. On the other hand, our work performs optimization solely by prompting without additional training. 7 C ONCLUSION We embark on employing LLMs as optimizers, where the LLM progressively generates new solutions to optimize an objective function. We first motivate OPRO with linear regression and traveling salesman problems, then proceed to prompt optimization as a concrete application. Our evaluation demonstrates that LLMs have the capacity of gradually improving the generated solutions based on the past optimization trajectory. Interestingly, on small-scale traveling salesman problems, OPRO performs on par with some hand-crafted heuristic algorithms. For prompt optimization, optimized prompts outperform human-designed prompts on GSM8K and Big-Bench Hard by a significant margin, sometimes over 50%. A number of unresolved questions are open for future research on LLMs for optimization. In general, how to reduce the sensitivity to initialization and better balance exploitation with exploration remains a challenge. Specifically, for prompt optimization, one limitation of our current implementation is that the optimizer LLM does not effectively utilize error cases in the training set to infer promising directions to improve the generated instructions. In our experiments, we tried including error cases in the meta-prompt rather than randomly sampling from the training set at each optimization step, but the results are similar, indicating that the error cases alone are not informative enough for the optimizer LLM to grasp the cause of the wrong prediction. Another limitation is that prompt optimization requires a training set to compute the accuracy that guides the optimization process. Currently the training set at least contains tens of samples, so that the optimized prompt does not severely overfit to the training samples. A promising direction is to incorporate richer feedback about the error cases besides the aggregated accuracy, and summarize the key features that distinguish between high-quality and low-quality generated prompts in the optimization trajectory. Such information may inform the optimizer LLM of how to more efficiently improve over the past generated instructions, and potentially further reduce the example set size needed for prompt optimization. ETHICS STATEMENT This work uses synthetic math problems for linear regression and traveling salesman problems, and uses public datasets like GSM8K and Big-Bench Hard for prompt optimization. These tasks have been commonly used in similar works and should not be regarded controversial. There is a peril that LLMs may generate harmful information that poses safety risks; how to safeguard model behavior remains valuable future work. REPRODUCIBILITY STATEMENT We evaluate on public benchmarks. The text-bison API is available at: https://cloud. google.com/vertex-ai/docs/generative-ai/learn/models. The GPT models are available here: http://openai.com/api/. This work uses gpt-3.5-turbo-0613 and gpt-4-0613. 21Large Language Models as Optimizers ACKNOWLEDGMENTS We thank Daiyi Peng, Yanqi Zhou, Jerry Wei, Shuo Chen, Tim Rocktäschel, Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Ed H. Chi for their valuable feedback, and thank several anonymous reviewers for helpful comments. REFERENCES Shun-ichi Amari. Backpropagation and stochastic gradient descent method. Neurocomputing, 5(4-5): 185–196, 1993. Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report.arXiv preprint arXiv:2305.10403, 2023. David Applegate, Ribert Bixby, Vasek Chvatal, and William Cook. Concorde tsp solver, 2006. Thomas Bäck and Hans-Paul Schwefel. An overview of evolutionary algorithms for parameter optimization. Evolutionary computation, 1(1):1–23, 1993. Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. arXiv preprint arXiv:2212.08073, 2022. Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as tool makers. arXiv preprint arXiv:2305.17126, 2023. Angelica Chen, David M Dohan, and David R So. Evoprompting: Language models for code-level neural architecture search. arXiv preprint arXiv:2302.14838, 2023a. Angelica Chen, Jérémy Scheurer, Tomasz Korbak, Jon Ander Campos, Jun Shern Chan, Samuel R Bowman, Kyunghyun Cho, and Ethan Perez. Improving code generation by training with natural language feedback. arXiv preprint arXiv:2303.16749, 2023b. Jiuhai Chen, Lichang Chen, Heng Huang, and Tianyi Zhou. When do you need chain-of-thought prompting for chatgpt? arXiv preprint arXiv:2304.03262, 2023c. Lichang Chen, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. Instructzero: Efficient instruction optimization for black-box large language models. arXiv preprint arXiv:2306.03082, 2023d. Xinyun Chen and Yuandong Tian. Learning to perform local rewriting for combinatorial optimization. Advances in Neural Information Processing Systems, 32, 2019. Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou. Teaching large language models to self-debug. arXiv preprint arXiv:2304.05128, 2023e. Yutian Chen, Xingyou Song, Chansoo Lee, Zi Wang, Richard Zhang, David Dohan, Kazuya Kawakami, Greg Kochanski, Arnaud Doucet, Marc’aurelio Ranzato, et al. Towards learning universal hyperparameter optimizers with transformers. Advances in Neural Information Process- ing Systems, 35:32053–32068, 2022. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021. Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P Xing, and Zhiting Hu. Rlprompt: Optimizing discrete text prompts with reinforcement learning. arXiv preprint arXiv:2205.12548, 2022. Michel Deudon, Pierre Cournut, Alexandre Lacoste, Yossiri Adulyasak, and Louis-Martin Rousseau. Learning heuristics for the tsp by policy gradient. In International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research, pp. 170–181. Springer, 2018. 22Large Language Models as Optimizers Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rock- täschel. Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint arXiv:2309.16797, 2023. Deep Ganguli, Amanda Askell, Nicholas Schiefer, Thomas Liao, Kamil ˙e Lukoši¯ut˙e, Anna Chen, Anna Goldie, Azalia Mirhoseini, Catherine Olsson, Danny Hernandez, et al. The capacity for moral self-correction in large language models. arXiv preprint arXiv:2302.07459, 2023. Tianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot learners. arXiv preprint arXiv:2012.15723, 2020. Bruce Golden, Lawrence Bodin, T Doyle, and W Stewart Jr. Approximate traveling salesman algorithms. Operations research, 28(3-part-ii):694–711, 1980. Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang. Connecting large language models with evolutionary algorithms yields powerful prompt optimizers. arXiv preprint arXiv:2309.08532, 2023. Gregory Gutin and Abraham P Punnen.The traveling salesman problem and its variations, volume 12. Springer Science & Business Media, 2006. Keld Helsgaun. An extension of the lin-kernighan-helsgaun tsp solver for constrained traveling salesman and vehicle routing problems. Roskilde: Roskilde University, 12, 2017. Michael Jünger, Gerhard Reinelt, and Giovanni Rinaldi. The traveling salesman problem. Handbooks in operations research and management science, 7:225–330, 1995. Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve computer tasks. arXiv preprint arXiv:2303.17491, 2023. Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations, 2015. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022. Wouter Kool, Herke van Hoof, and Max Welling. Attention, learn to solve routing problems! In International Conference on Learning Representations, 2019. URL https://openreview. net/forum?id=ByxBFsRqYm. Joel Lehman, Jonathan Gordon, Shawn Jain, Kamal Ndousse, Cathy Yeh, and Kenneth O Stanley. Evolution through large models. arXiv preprint arXiv:2206.08896, 2022. Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691, 2021. Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190, 2021. Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale genera- tion: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146, 2017. Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. arXiv preprint arXiv:2103.10385, 2021. Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv:2104.08786, 2021. Xiao Ma, Swaroop Mishra, Ahmad Beirami, Alex Beutel, and Jilin Chen. Let’s do a thought experiment: Using counterfactuals to improve moral reasoning. arXiv preprint arXiv:2306.14308, 2023. 23Large Language Models as Optimizers Aman Madaan and Amir Yazdanbakhsh. Text and patterns: For effective chain of thought, it takes two to tango. arXiv preprint arXiv:2209.07686, 2022. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651, 2023. Elliot Meyerson, Mark J Nelson, Herbie Bradley, Arash Moradi, Amy K Hoover, and Joel Lehman. Language model crossover: Variation through few-shot prompting. arXiv preprint arXiv:2302.12170, 2023. Suvir Mirchandani, Fei Xia, Pete Florence, Brian Ichter, Danny Driess, Montserrat Gonzalez Arenas, Kanishka Rao, Dorsa Sadigh, and Andy Zeng. Large language models as general pattern machines. arXiv preprint arXiv:2307.04721, 2023. Varun Nair, Elliot Schumacher, Geoffrey Tso, and Anitha Kannan. Dera: Enhancing large language model completions with dialog-enabled resolving agents. arXiv preprint arXiv:2303.17071, 2023. MohammadReza Nazari, Afshin Oroojlooy, Lawrence Snyder, and Martin Takac. Reinforcement learning for solving the vehicle routing problem. In Advances in Neural Information Processing Systems, pp. 9861–9871, 2018. Theo X Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, and Armando Solar-Lezama. Demystifying gpt self-repair for code generation. arXiv preprint arXiv:2306.09896, 2023. Gurobi Optimization et al. Gurobi optimizer reference manual, 2020. Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal. Grips: Gradient-free, edit-based instruction search for prompting large language models. arXiv preprint arXiv:2203.07281, 2022. Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. Automatic prompt optimization with\" gradient descent\" and beam search. arXiv preprint arXiv:2305.03495, 2023. Ning Qian. On the momentum term in gradient descent learning algorithms. Neural networks, 12(1): 145–151, 1999. Guanghui Qin and Jason Eisner. Learning how to ask: Querying lms with mixtures of soft prompts. arXiv preprint arXiv:2104.06599, 2021. Colin R Reeves. Modern heuristic techniques for combinatorial problems. John Wiley & Sons, Inc., 1993. Laria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1–7, 2021. Luis Miguel Rios and Nikolaos V Sahinidis. Derivative-free optimization: a review of algorithms and comparison of software implementations. Journal of Global Optimization, 56:1247–1293, 2013. Daniel J Rosenkrantz, Richard E Stearns, and Philip M Lewis, II. An analysis of several heuristics for the traveling salesman problem. SIAM journal on computing, 6(3):563–581, 1977. Subhro Roy and Dan Roth. Solving general arithmetic word problems. arXiv preprint arXiv:1608.01413, 2016. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023. Taylor Shin, Yasaman Razeghi, Robert L Logan IV , Eric Wallace, and Sameer Singh. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. arXiv preprint arXiv:2010.15980, 2020. Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366, 2023. 24Large Language Models as Optimizers Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022. Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261, 2022. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. V oyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh- ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022. Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. Larger language models do in-context learning differently. arXiv preprint arXiv:2303.03846, 2023. Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery. arXiv preprint arXiv:2302.03668, 2023. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244, 2023. Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Yanggang Wang, Haiyu Li, and Zhilin Yang. Gps: Genetic prompt search for efficient few-shot learning. arXiv preprint arXiv:2210.17041, 2022. Weizhe Yuan, Kyunghyun Cho, and Jason Weston. System-level natural language feedback.arXiv preprint arXiv:2306.13588, 2023. Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans, and Joseph E Gonzalez. Tempera: Test-time prompt editing via reinforcement learning. In The Eleventh International Conference on Learning Representations, 2023. Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving few-shot performance of language models. In International Conference on Machine Learning, pp. 12697–12706. PMLR, 2021. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a. Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b. 25Large Language Models as Optimizers A S OME FAILURE CASES Although LLMs show the power of optimizing basic math problems (Section 3) and prompts (Sec- tion 4), we see some limitations across all optimizer LLMs that may impede their power of solving more challenging problems. These limitations include: • Hallucinating the values that need to come from math calculation: The optimizer LLMs often output contents like “the function value at (5, 3) is 15” despite that the true value is not 15. The model will get it right if external tools that can reliably calculate the value are triggered. When and how to trigger such tool use cases remains an interesting topic (see e.g., (Schick et al., 2023; Cai et al., 2023)). • Generating solutions already appeared in context even if we tell it to \"Give me a new (w, b) pair that is different from all pairs above\": the optimizer LLMs do not 100% reliably follow this instruction even if its own outputs often include sentences like “I will provide a new pair that is different”, making the output self-contradictory. The output is almost guaranteed to be different from in-context old solutions when the model output contains a comparison of the new pair and all old pairs, though. Thus (implicitly) triggering such behaviors may be a solution. How to implement this feature without harming the instruction following performance of other parts remains an interesting topic to study. • In black-box math optimization, getting stuck at a point that is neither global nor local optimal: This often occurs in two linear regression cases: (a) The in-context exemplars all share the same w or b that is different from wtrue or btrue. This case is more likely to be avoided when a larger number of past solutions are included in the meta-prompt; (b) one or several of the best previous solutions in the meta-prompt have ws and bs in quantitatively opposite directions from the global optima wtrue and btrue: for example, the ws are all smaller than wtrue while the bs are all larger than btrue. Since the optimizer model often proposes to only increase w or decrease b when the past solutions in meta-prompt share w or b, the optimization will get stuck if either increasing w or decreasing b would increase the objective value. This issue is mitigated by sampling multiple new solutions (thus more exploration) at each step. • Hard to navigate a bumpy loss landscape: Like other optimizers, it is harder for the optimizer LLM to optimize black-box functions when the loss landscape gets more complicated. For example, when minimizing the Rosenbrock functionf(x, y) = (a−x)2+b(y−x2)2 with a = 20 (whose global optimal point is x = 20, y = 400) with 5 starting points in [10, 20] × [10, 20], the optimization often gets stuck at around (0, 0). This is because the optimizer LLM sees a decrease of objective value when it drastically decreases both x and y to 0. Then starting from (0, 0), the optimizer LLM is hard to further navigate x and y along the narrow valley in the loss landscape towards (20, 400) (Figure 13). x 0 5 10 15 20y 0 100 200 300 400 f(x, y) 50000 100000 150000 Figure 13: A visualization of the landscape of the Rosenbrock functionf(x, y) = (a−x)2+b(y−x2)2 with a = 20and b = 1. The global optima is at x = 20, y = 400with function value 0. The function value at x = 0, y = 0is 400. The landscape has a narrow valley between (0, 0) and (20, 400). 26Large Language Models as Optimizers B P ROMPTING FORMATS FOR SCORER LLM Figure 14, 15, and 16 show examples of the Q_begin, Q_end, and A_begin prompting formats when the “QA” pattern is present. The “QA” pattern is eliminated when prompting instruction-tuned scorer models like text-bison with the Q_begin and Q_end formats (Figure 17 and 18). Q: {instruction} Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers’ market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers’ market? A: Figure 14: The Q_begin prompting format on a GSM8K test exemplar with the \"QA\" pattern. Q: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers’ market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers’ market? {instruction} A: Figure 15: The Q_end prompting format on a GSM8K test exemplar with the \"QA\" pattern. Q: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers’ market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers’ market? A: {instruction} Figure 16: The A_begin prompting format on a GSM8K test exemplar. {instruction} Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers’ market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers’ market? Figure 17: The Q_begin prompting format on a GSM8K test exemplar without the \"QA\" pattern. Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers’ market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers’ market? {instruction} Figure 18: The Q_end prompting format on a GSM8K test exemplar without the \"QA\" pattern. 27Large Language Models as Optimizers C M ETA-PROMPTS C.1 M ETA-PROMPT FOR MATH OPTIMIZATION Now you will help me minimize a function with two input variables w, b. I have some (w, b) pairs and the function values at those points. The pairs are arranged in descending order based on their function values, where lower values are better. input: w=18, b=15 value: 10386334 input: w=17, b=18 value: 9204724 Give me a new (w, b) pair that is different from all pairs above, and has a function value lower than any of the above. Do not write code. The output must end with a pair [w, b], where w and b are numerical values. Figure 19: An example of the meta-prompt for linear regression. The blue text contains solution-score pairs; the orange text are meta-instructions. You are given a list of points with coordinates below: (0): (-4, 5), (1): (17, 76), (2): (-9, 0), (3): (-31, -86), (4): (53, -35), (5): (26, 91), (6): (65, -33), (7): (26, 86), (8): (-13, -70), (9): (13, 79), (10): (-73, -86), (11): (-45, 93), (12): (74, 24), (13): (67, -42), (14): (87, 51), (15): (83, 94), (16): (-7, 52), (17): (-89, 47), (18): (0, -38), (19): (61, 58). Below are some previous traces and their lengths. The traces are arranged in descending order based on their lengths, where lower values are better. <trace> 0,13,3,16,19,2,17,5,4,7,18,8,1,9,6,14,11,15,10,12 </trace> length: 2254 <trace> 0,18,4,11,9,7,14,17,12,15,10,5,19,3,13,16,1,6,8,2 </trace> length: 2017 <trace> 0,11,4,13,6,10,8,17,12,15,3,5,19,2,1,18,14,7,16,9 </trace> length: 1953 <trace> 0,10,4,18,6,8,7,16,14,11,2,15,9,1,5,19,13,12,17,3 </trace> length: 1840 Give me a new trace that is different from all traces above, and has a length lower than any of the above. The trace should traverse all points exactly once. The trace should start with <trace> and end with </trace>. Figure 20: An example of the meta-prompt for Traveling Salesman Problems with problem size n = 20. The blue text contains solution-score pairs; the orange text are meta-instructions. 28Large Language Models as Optimizers C.2 M ETA-PROMPT FOR PROMPT OPTIMIZATION Different optimizer models work the best on different styles of meta-prompts. Figure 3 in the main paper shows the meta-prompt for PaLM 2-L-IT; Figure 21 shows that for pre-trained PaLM 2-L; Figure 22 shows that for GPT models. Create a piece of text at the beginning of the answer to enhance the precision in solving diverse grade school math problems. Precision: 4 <TEXT>A dime</TEXT> Precision: 17 <TEXT>The answer is a function. It is</TEXT> Precision: 19 <TEXT>So how can we find out what this equation means?</TEXT> Precision: 20 <TEXT>Solutions:</TEXT> Figure 21: An example of the meta-prompt for prompt optimization with pre-trained PaLM 2-L on GSM8K, where the generated instruction will be prepended to the beginning of the scorer LLM output (A_begin in Section 4.1). Your task is to generate the instruction <INS>. Below are some previous instructions with their scores. The score ranges from 0 to 100. text: Let’s figure it out! score: 61 text: Let’s solve the problem. score: 63 (. . . more instructions and scores . . . ) Below are some problems. Problem: Q: Alannah, Beatrix, and Queen are preparing for the new school year and have been given books by their parents. Alannah has 20 more books than Beatrix. Queen has 1/5 times more books than Alannah. If Beatrix has 30 books, how many books do the three have together? A: <INS> Ground truth answer: 140 (. . . more exemplars . . . ) Generate an instruction that is different from all the instructions <INS> above, and has a higher score than all the instructions <INS> above. The instruction should begin with <INS> and end with </INS>. The instruction should be concise, effective, and generally applicable to all problems above. Figure 22: An example of the meta-prompt for prompt optimization with GPT models (gpt-3.5-turbo or gpt-4) on GSM8K, where the generated instruction will be prepended to the beginning of the scorer LLM output (A_begin in Section 4.1). The blue text contains solution- score pairs; the purple text describes the optimization task and output format; the orange text are meta-instructions. 29Large Language Models as Optimizers D P ROMPT OPTIMIZATION CURVES ON THE REMAINING BBH TASKS 0 50 100 # steps 50.0 70.0 90.0training accuracy  BBH boolean_expressions (a) BBH boolean_expressions 0 50 100 # steps 60.0 70.0 80.0training accuracy  BBH causal_judgement (b) BBH causal_judgement 0 50 100 150 # steps 40.0 50.0 60.0training accuracy  BBH date_understanding (c) BBH date_understanding 0 50 100 # steps 40.0 50.0 60.0training accuracy  BBH disambiguation_qa (d) BBH disambiguation_qa 0 50 100 # steps 98.0 100.0training accuracy  BBH dyck_languages (e) BBH dyck_languages 0 20 40 60 # steps 50.0 60.0 70.0training accuracy  BBH formal_fallacies (f) BBH formal_fallacies 0 50 100 150 200 # steps 20.0 30.0training accuracy  BBH geometric_shapes (g) BBH geometric_shapes 0 50 100 150 200 # steps 60.0 70.0 80.0training accuracy  BBH hyperbaton (h) BBH hyperbaton 0 50 100 150 200 # steps 55 60 65training accuracy BBH logical_deduction_ seven_objects (i) BBH logical_deduction_seven_objects 0 50 100 150 200 # steps 60 70 80 90 100training accuracy  BBH movie_ recommendation (j) BBH movie_recommendation 0 50 100 150 200 # steps 0 10 20 30training accuracy  BBH multistep_ arithmetic_two (k) BBH multistep_arithmetic_two 0 40 80 120 # steps 55 60 65 70training accuracy  BBH navigate (l) BBH navigate 0 50 100 # steps 40 50 60 70training accuracy BBH object_counting (m) BBH object_counting 0 50 100 # steps 60 70training accuracy BBH penguins_in_a_table (n) BBH penguins_in_a_table 0 20 40 60 # steps 70 80training accuracy BBH reasoning_about_ colored_objects (o) BBH reasoning_about_colored_objects Figure 23: Prompt optimization on 21 BBH tasks (except ruin_names and temporal_sequences already shown in Figure 6) with the text-bison scorer and the PaLM 2-L-IT optimizer, Part I. Most curves have upward trends. 30Large Language Models as Optimizers 0 20 40 # steps 30 40training accuracy BBH salient_translation_ error_detection (a) BBH salient_translation_error_detection 0 50 100 150 200 # steps 70 80training accuracy  BBH snarks (b) BBH snarks 0 20 40 # steps 40 60 80 100training accuracy  BBH sports_ understanding (c) BBH sports_understanding 0 50 100 150 200 # steps 10 20training accuracy BBH tracking_shuffled_ objects_seven_objects (d) BBH tracking_shuffled_ objects_seven_objects 0 50 100 150 200 # steps 50 60training accuracy  BBH web_of_lies (e) BBH web_of_lies 0 50 100 150 200 # steps 10 20training accuracy  BBH word_sorting (f) BBH word_sorting Figure 24: Prompt optimization on 21 BBH tasks (except ruin_names and temporal_sequences in Figure 6) with the text-bison scorer and the PaLM 2-L-IT optimizer, Part II. All curves have upward trends. E PROMPT OPTIMIZATION ON BBH TASKS – TABULATED ACCURACIES AND FOUND INSTRUCTIONS E.1 PALM 2-L-IT AS OPTIMIZER , OPTIMIZATION STARTING FROM THE EMPTY STRING Table 8 and 9 show the instructions found by prompt optimization. A comparison of their accuracies with baselines “Let’s think step by step.” (Kojima et al., 2022), “Let’s work this out in a step by step way to be sure we have the right answer.” (Zhou et al., 2022b), and the empty string is in Table 7; a visualization is in Section 5.2 Figure 5. 31Large Language Models as Optimizers Table 7: Accuracies on BBH tasks: our found instructions with the PaLM 2-L-IT optimizer vs baseline. The optimization starts from the empty string. Because of the 20-80 train-test split, we show accuracies with the format “training / test / overall (training + test)”. ThePaLM 2-L scores are from A_begin instructions; the text-bison scores are from Q_begin instructions. Bold numbers indicate the best for the corresponding task. Task Scorer Our Acc “Let’s think step by step.” Acc “Let’s work this out in a step by step way to be sure we have the right answer.” Acc empty string “” Acc training / test / overall training / test / overall training / test / overall training / test / overall boolean_expressions PaLM 2-L 90.0 / 83.5 / 84.8 90.0 / 83.0 / 84.4 82.0 / 74.0 / 75.6 74.0 / 71.0 / 71.6 causal_judgement PaLM 2-L 84.8 / 58.0 / 63.1 73.0 / 55.3 / 58.8 59.5 / 57.3 / 57.8 29.7 / 49.3 / 45.5 date_understanding PaLM 2-L 86.0 / 84.5 / 84.8 76.0 / 80.0 / 79.2 74.0 / 77.0 / 76.4 70.0 / 74.0 / 73.2 disambiguation_qa PaLM 2-L 80.0 / 69.0 / 71.2 40.0 / 52.5 / 50.0 48.0 / 47.0 / 47.2 54.0 / 57.5 / 56.8 dyck_languages PaLM 2-L 100.0 / 100.0 / 100.0 96.0 / 94.5 / 94.8 100.0 / 93.5 / 94.8 94.0 / 95.0 / 94.8 formal_fallacies PaLM 2-L 84.0 / 64.0 / 68.4 78.0 / 59.5 / 63.2 68.0 / 63.0 / 64.0 66.0 / 59.0 / 60.4 geometric_shapes PaLM 2-L 76.0 / 57.0 / 60.8 42.0 / 33.0 / 34.8 42.0 / 32.0 / 34.0 34.0 / 33.0 / 33.2 hyperbaton PaLM 2-L 100.0 / 96.0 / 96.8 78.0 / 75.0 / 75.6 74.0 / 72.5 / 72.8 88.0 / 89.0 / 88.8 logical_deduction_seven_objects PaLM 2-L 74.0 / 57.0 / 60.4 46.0 / 37.0 / 38.8 34.0 / 30.5 / 31.2 46.0 / 45.5 / 45.6 movie_recommendation PaLM 2-L 92.0 / 90.5 / 90.8 62.0 / 52.5 / 54.4 52.0 / 48.0 / 48.8 80.0 / 83.0 / 82.4 multistep_arithmetic_two PaLM 2-L 72.0 / 55.5 / 58.8 42.0 / 46.0 / 45.2 60.0 / 50.5 / 52.4 4.0 / 3.5 / 3.6 navigate PaLM 2-L 92.0 / 75.0 / 78.4 68.0 / 62.0 / 63.2 70.0 / 64.0 / 65.2 38.0 / 37.5 / 37.6 object_counting PaLM 2-L 84.0 / 86.5 / 86.0 36.0 / 46.5 / 44.4 60.0 / 62.0 / 61.6 28.0 / 27.0 / 27.2 penguins_in_a_table PaLM 2-L 86.2 / 71.8 / 74.7 79.3 / 64.1 / 67.1 62.1 / 58.1 / 58.9 72.4 / 69.2 / 69.9 reasoning_about_colored_objects PaLM 2-L 98.0 / 85.5 / 88.0 82.0 / 79.5 / 80.0 82.0 / 75.0 / 76.4 42.0 / 35.0 / 36.4 ruin_names PaLM 2-L 88.0 / 88.0 / 88.0 70.0 / 55.0 / 58.0 80.0 / 75.5 / 76.4 88.0 / 76.5 / 78.8 salient_translation_error_detection PaLM 2-L 62.0 / 67.0 / 66.0 42.0 / 50.0 / 48.4 58.0 / 46.0 / 48.4 56.0 / 56.5 / 56.4 snarks PaLM 2-L 85.7 / 83.2 / 83.7 60.0 / 62.2 / 61.8 54.3 / 53.1 / 53.4 51.4 / 60.1 / 58.4 sports_understanding PaLM 2-L 98.0 / 88.0 / 90.0 50.0 / 46.5 / 47.2 60.0 / 52.5 / 54.0 52.0 / 41.5 / 43.6 temporal_sequences PaLM 2-L 100.0 / 100.0 / 100.0 100.0 / 96.0 / 96.8 90.0 / 87.0 / 87.6 100.0 / 99.5 / 99.6 tracking_shuffled_objects_seven_objectsPaLM 2-L 32.0 / 16.5 / 19.6 58.0 / 61.5 / 60.8 54.0 / 55.5 / 55.2 14.0 / 23.5 / 21.6 web_of_lies PaLM 2-L 62.0 / 52.0 / 54.0 46.0 / 41.5 / 42.4 24.0 / 31.0 / 29.6 54.0 / 54.0 / 54.0 word_sorting PaLM 2-L 54.0 / 54.5 / 54.4 2.0 / 4.5 / 4.0 12.0 / 9.5 / 10.0 20.0 / 22.5 / 22.0 boolean_expressions text-bison 98.0 / 87.0 / 89.2 72.0 / 61.5 / 63.6 88.0 / 78.0 / 80.0 80.0 / 68.5 / 70.8 causal_judgement text-bison 78.4 / 58.0 / 62.0 70.3 / 50.7 / 54.5 73.0 / 55.3 / 58.8 78.4 / 58.0 / 62.0 date_understanding text-bison 60.0 / 50.0 / 52.0 44.0 / 45.5 / 45.2 48.0 / 45.0 / 45.6 44.0 / 45.0 / 44.8 disambiguation_qa text-bison 68.0 / 73.0 / 72.0 4.0 / 6.0 / 5.6 4.0 / 15.5 / 13.2 52.0 / 68.5 / 65.2 dyck_languages text-bison100.0 / 100.0 / 100.0 100.0 / 95.5 / 96.4 100.0 / 94.5 / 95.6 100.0 / 98.5 / 98.8 formal_fallacies text-bison 70.0 / 53.0 / 56.4 64.0 / 54.5 / 56.4 84.0 / 82.5 / 82.8 70.0 / 54.5 / 57.6 geometric_shapes text-bison 40.0 / 19.5 / 23.6 22.0 / 13.0 / 14.8 18.0 / 12.0 / 13.2 20.0 / 14.5 / 15.6 hyperbaton text-bison 80.0 / 79.5 / 79.6 64.0 / 67.5 / 66.8 64.0 / 69.0 / 68.0 64.0 / 64.0 / 64.0 logical_deduction_seven_objects text-bison 66.0 / 53.5 / 56.0 56.0 / 58.0 / 57.6 56.0 / 56.0 / 56.0 58.0 / 56.5 / 56.8 movie_recommendation text-bison 98.0 / 90.0 / 91.6 68.0 / 63.0 / 64.0 66.0 / 62.0 / 62.8 68.0 / 64.0 / 64.8 multistep_arithmetic_two text-bison 32.0 / 16.5 / 19.6 12.0 / 18.0 / 16.8 18.0 / 17.5 / 17.6 16.0 / 18.5 / 18.0 navigate text-bison 72.0 / 61.0 / 63.2 56.0 / 55.0 / 55.2 60.0 / 56.5 / 57.2 56.0 / 57.0 / 56.8 object_counting text-bison 72.0 / 62.0 / 64.0 58.0 / 57.0 / 57.2 62.0 / 55.5 / 56.8 50.0 / 57.0 / 55.6 penguins_in_a_table text-bison 72.4 / 56.4 / 59.6 58.6 / 53.0 / 54.1 55.2 / 55.6 / 55.5 58.6 / 53.0 / 54.1 reasoning_about_colored_objects text-bison 82.0 / 77.0 / 78.0 76.0 / 72.5 / 73.2 78.0 / 73.0 / 74.0 74.0 / 69.5 / 70.4 ruin_names text-bison 88.0 / 82.5 / 83.6 66.0 / 65.5 / 65.6 66.0 / 62.5 / 63.2 64.0 / 66.0 / 65.6 salient_translation _error_detection text-bison 46.0 / 50.5 / 49.6 42.0 / 47.5 / 46.4 42.0 / 49.5 / 48.0 44.0 / 50.0 / 48.8 snarks text-bison 80.0 / 81.8 / 81.5 68.6 / 77.6 / 75.8 71.4 / 76.2 / 75.3 77.1 / 84.6 / 73.1 sports_understanding text-bison 94.0 / 82.5 / 84.8 86.0 / 79.0 / 80.4 90.0 / 81.0 / 82.8 38.0 / 44.5 / 43.2 temporal_sequences text-bison 78.0 / 81.0 / 80.4 36.0 / 43.5 / 42.0 32.0 / 45.0 / 42.4 36.0 / 43.0 / 41.6 tracking_shuffled_objects_seven_objectstext-bison 32.0 / 15.5 / 18.8 10.0 / 17.0 / 15.6 10.0 / 18.0 / 16.4 12.0 / 15.5 / 14.8 web_of_lies text-bison 62.0 / 50.0 / 52.4 48.0 / 45.5 / 46.0 48.0 / 44.0 / 44.8 52.0 / 51.5 / 51.2 word_sorting text-bison 24.0 / 17.5 / 18.8 10.0 / 12.0 / 11.6 4.0 / 8.0 / 7.2 4.0 / 7.5 / 6.8 32Large Language Models as Optimizers Table 8: BBH task-wise instructions found by prompt optimization with the PaLM 2-L scorer and the PaLM 2-L-IT optimizer. The optimization starts from the empty string. Task Our Instruction boolean_expressions A Boolean expression is a well-formed expression consisting of variables, values, and logical operators. The expression must evaluate to a single True or False value. The order of precedence of the logical operators is as follows: NOT, AND, OR, XOR, IMP. Parentheses can be used to group subexpressions and to control the order of evaluation. causal_judgement When considering questions about causation, a typical person would consider the following factors: whether the action or event was a necessary condition for the outcome to occur, a sufficient condition, a proximate cause, or a foreseeable cause. date_understanding To find the date X time ago from today, first find today’s date. Then subtract X time from today’s date. If the current date is the last day of a month, then the date a month ago is the last day of the previous month. If the current date is not the last day of a month, then the date a month ago is the same day of the previous month. For example, if today is March 31, 2023, then the date a month ago is February 28, 2023. If today is April 1, 2023, then the date a month ago is March 1, 2023. disambiguation_qa Identifying Antecedents of Pronouns: A Comprehensive Guide dyck_languages First, look for the opening parentheses. Then, count the number of opening parentheses. Finally, close the parentheses in the reverse order that they were opened. formal_fallacies A deductive argument is one where the conclusion follows necessarily from the premises. If the premises are true, then the conclusion must also be true. An invalid argument is one where it is possible for the premises to be true and the conclusion to be false. geometric_shapes A closed polygonal chain is a series of connected line segments. The line segments can be straight or curved. The first and last line segments are connected. The line segments do not intersect each other except at their endpoints. A closed polygon can be described by an SVG path element, which starts at a given point, goes to one or more additional points, and then ends at the starting point. The path element can consist of straight line segments, curved segments, or a mixture of both. hyperbaton The correct adjective order in English is opinion, size, shape, age, color, origin, material, and purpose. If you have more than one adjective of the same type, they are usually placed in order of importance. For example, you would say \"a large, old, Pakistani ship\" rather than \"an old, large, Pakistani ship.\" There are a few exceptions to these rules, but they are generally followed in most cases. logical_deduction _seven_objects The following questions will test your ability to use deductive reasoning. You will be given a set of statements about a group of objects. You will then be asked to answer questions about the objects based on the statements. The statements in the questions are logically consistent, so you can use them to deduce the order of the objects. For each question, you must choose the option that is logically consistent with the information in the questions. movie_recommendation Based on your input, I have analyzed the given movies in terms of genre, plot, tone, audience rating, year of release, director, cast, and reviews. I have also taken into account the given options. The movie that is most similar to the given movies in terms of all these factors is: multistep_arithmetic _two The order of operations in mathematics is PEMDAS, which stands for Parentheses, Exponents, Multiplication, Division, Addition, and Subtraction. When there are multiple operations of the same precedence, they must be performed from left to right. Note that multiplication and division have the same precedence, as do addition and subtraction. navigate You will return to the starting point if and only if (1) the total number of steps you take forward is equal to the total number of steps you take back, and (2) the total number of turns you make is a multiple of 180 degrees. object_counting Here is a list of the objects you mentioned and their corresponding counts: penguins_in_a_table Here is my new text: reasoning_about _colored_objects Starting from the leftmost object in the row, I observe the following objects arranged in this order: ruin_names Which is the funniest pun on the artist or movie name? salient_translation _error_detection Instructions: Read the German sentence and its English translation carefully, then identify the type of error in the translation and select the correct option. There are six possible types of errors: Named Entities, Numerical Values, Modifiers or Adjectives, Negation or Antonyms, Facts, and Dropped Content. snarks Identify the sarcastic statement by considering the following factors: incongruity, exaggeration, understatement, context, speaker’s intent, and audience’s reaction. I will also consider the speaker’s tone of voice, facial expressions, and body language. sports_understanding I will determine if a sentence about an athlete is plausible by first checking if it is grammatically correct. If it is, I will then check if it is consistent with the athlete’s sport, position, and real-world statistics. I will also check if it is consistent with the rules of the athlete’s sport. If the sentence is consistent with all of these things, I will answer \"yes\", otherwise I will answer \"no\". temporal_sequences The answer is the time that is not mentioned in the given statements. tracking_shuffled_objects _seven_objects Claire has the blue ball, Gertrude has the black ball, and Dave has the green ball. They are all happy with their new balls. web_of_lies The answer to a question is yes if there are an odd number of liars before the current speaker, and no if there are an even number of liars before the current speaker. If the current speaker is a truth-teller, they will say the opposite of what the previous person said, while a liar will say the same thing as the previous person said. word_sorting Alphabetical order of given words: 33Large Language Models as Optimizers Table 9: BBH task-wise instructions found by prompt optimization with the text-bison scorer and the PaLM 2-L-IT optimizer. The optimization starts from the empty string. Task Our Instruction boolean_expressions Not (not False) and not not False is False causal_judgement A typical person would likely answer the questions about causation as follows: date_understanding Today is February 28, 2023. It is a Tuesday. Yesterday was Monday, February 27, 2023. Tomorrow will be Wednesday, March 1, 2023. A week ago, it was February 21, 2023, and a month ago, it was January 28, 2023. A year from now, it will be February 28, 2024. The day of the week is important to note because it will help us to correctly answer the questions below. Not all years are leap years that contain February 29. disambiguation_qa A pronoun is a word that stands in for a noun. The noun that a pronoun refers to is called its antecedent. To identify the antecedent of a pronoun, look for the noun that the pronoun could be referring to. If there is only one possible noun, then that is the antecedent. If there are two or more possible nouns, then the antecedent is ambiguous. Use the context of the sentence to help you determine the correct antecedent. dyck_languages { } formal_fallacies How to Evaluate Deductive Validity of an Argument geometric_shapes What shape is this SVG code drawing, and how many sides does it have? hyperbaton In English, adjectives are typically placed before nouns in a specific order. The order is: opinion, size, shape, age, color, origin, material, purpose, noun. For example, the sentence \"the big, old, red barn\" would be considered grammatically correct, while the sentence \"the old, big, red barn\" would not. Adjectives that come before nouns are called attributive adjectives, while adjectives that come after nouns are called predicative adjectives. logical_deduction _seven_objects In this logical reasoning task, you will be given a series of paragraphs, each of which describes a set of objects arranged in a fixed order. The statements in each paragraph are logically consistent. You must read each paragraph carefully and use the information given to determine the logical relationships between the objects. You will then be asked a question about the order of the objects. Read each question carefully and choose the option that answers the question correctly. movie_recommendation What is the highest-rated movie similar to the given movies, with a similar IMDb rating and released in the same year? multistep_arithmetic_two Let’s solve these equations using PEMDAS order of operations. Remember that PEMDAS stands for parentheses, exponents, multiplication and division, and addition and subtraction. navigate Starting at the origin, facing north, follow the instructions. If your displacement from the origin is zero and your direction is unchanged, then your answer is Yes. Otherwise, your answer is No. object_counting Let me help you count the items you have. Just list them one by one, separated by commas. I will then count each item and tell you how many items there are in total. penguins_in_a_table This table shows information about penguins. The columns show the penguin’s name, age, height (in cm), and weight (in kg). The penguins are listed in order of their age, from youngest to oldest. reasoning_about _colored_objects First, read the input carefully. Then, identify all the objects mentioned, their colors, and their positions. Next, visualize the objects and their positions in your mind. Finally, answer the questions accurately based on the information given. Make sure to pay attention to the order of the objects. ruin_names A humorous edit of an artist or movie name can be created by replacing one or more letters to form a new word or phrase that sounds similar but has a different meaning. The new word or phrase should be relevant to the original word, but it should also be a surprise, which makes the edit funny. For example, the artist or movie name \"Rocky\" can be changed to \"Ricky,\" and \"Schindler’s List\" can be changed to \"Schindler’s Lift.\" Be creative and have fun! salient_translation _error_detection The following translations from German to English contain a particular error. The error may be one of the following types: Named Entities, Numerical Values, Modifiers or Adjectives, Negation or Antonyms, Facts, or Dropped Content. Please identify the error. snarks The statement sports_understanding To determine the plausibility of a sports sentence, I will first identify the sport, athletes, teams, and events mentioned in the sentence. Then, I will use my knowledge of the rules of the sport, the context of the sentence, common sense, and my knowledge of the world to determine whether the sentence is plausible. I will also consider the time period and location, as well as any other relevant information. Finally, I will return a score of 1 for plausible sentences and 0 for implausible ones. temporal_sequences To determine the time period when a person went to a place, first identify all the time periods when the person’s whereabouts are unknown. Then, rule out any time periods during which the person was seen doing something else or the place was closed. The remaining time periods are the possible times when the person could have gone to the place. tracking_shuffled_objects _seven_objects At the start of the game, Claire has a blue ball. Throughout the game, pairs of people swap balls. Claire ends up with the yellow ball. web_of_lies People in a group either tell the truth or lie. The truthfulness of a person’s statement is determined by the statement of the previous person. If the previous person told the truth, then the current person who says the opposite is lying. If the previous person lied, then the current person who says the opposite is telling the truth. This rule applies to all subsequent statements. word_sorting Sort the following words alphabetically, ignoring case and punctuation. Print the sorted list. 34Large Language Models as Optimizers E.2 G P T-3.5-T U R B OAS OPTIMIZER , OPTIMIZATION STARTING FROM THE EMPTY STRING Table 11, 12 and 13 show the instructions found by prompt optimization. Their accuracies are listed in Table 10. Figure 25 visualizes the difference between their accuracies and those of the baselines “Let’s think step by step.” and the empty string. The optimizations find instructions better than the empty starting point, and most of the found instructions are better than “Let’s think step by step”. One caveat in the A_begin instructions (Table 11) is that a lot of the found instructions are imperative or interrogative sentences that are more suitable to be put into “Q:” rather than “A:”, like “Solve the sequence by properly closing the parentheses.” for dyck_languages and “Which movie option from the given choices ...?” for movie_recommendation. Such styles appear more often here than the PaLM 2-L-IT optimizer results (Table 8), showing PaLM 2-L-IT understands the needed style better. In Section E.3, we show the A_begin optimization results with the non-empty starting point “Let’s solve the problem.”. Most results there are declarative sentences – more suitable for A_begin. boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting -20 0 20 40 accuracy difference (a) PaLM 2-L, ours minus “Let’s think step by step.” boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40accuracy difference(b) PaLM 2-L, ours minus empty starting point boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40 60accuracy difference (c) text-bison, ours minus “Let’s think step by step.” boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40accuracy difference (d) text-bison, ours minus empty starting point Figure 25: On 23 BBH tasks, the accuracy differences among instructions found by prompt opti- mization (with the gpt-3.5-turbo optimizer), “Let’s think step by step.”, and the empty string (optimization starting point). 35Large Language Models as Optimizers Table 10: Accuracies on BBH tasks with the gpt-3.5-turbo optimizer that starts from the empty string. The PaLM 2-L scores are from A_begin (left) instructions; thetext-bison scores include Q_begin (left) and Q_end (right) instructions. Task Scorer Our Acc (begin) Our Acc ( end) training / test / overall training / test / overall boolean_expressions PaLM 2-L 92.0 / 86.5 / 87.6 N/A causal_judgement PaLM 2-L 81.1 / 58.7 / 63.1 N/A date_understanding PaLM 2-L 86.0 / 82.0 / 82.8 N/A disambiguation_qa PaLM 2-L 80.0 / 74.0 / 75.2 N/A dyck_languages PaLM 2-L 100.0 / 100.0 / 100.0 N/A formal_fallacies PaLM 2-L 88.0 / 63.5 / 68.4 N/A geometric_shapes PaLM 2-L 60.0 / 41.0 / 44.8 N/A hyperbaton PaLM 2-L 88.0 / 93.0 / 92.0 N/A logical_deduction_seven_objects PaLM 2-L 76.0 / 56.5 / 60.4 N/A movie_recommendation PaLM 2-L 84.0 / 86.0 / 85.6 N/A multistep_arithmetic_two PaLM 2-L 52.0 / 49.0 / 49.6 N/A navigate PaLM 2-L 76.0 / 67.0 / 68.8 N/A object_counting PaLM 2-L 78.0 / 79.0 / 78.8 N/A penguins_in_a_table PaLM 2-L 82.8 / 72.6 / 74.7 N/A reasoning_about _colored_objects PaLM 2-L 86.0 / 67.5 / 71.2 N/A ruin_names PaLM 2-L 90.0 / 83.0 / 84.4 N/A salient_translation_error_detection PaLM 2-L 62.0 / 65.0 / 64.4 N/A snarks PaLM 2-L 85.7 / 70.6 / 73.6 N/A sports_understanding PaLM 2-L 68.0 / 57.5 / 59.6 N/A temporal_sequences PaLM 2-L 100.0 / 99.5 / 99.6 N/A tracking_shuffled_objects_seven_objects PaLM 2-L 44.0 / 34.5 / 36.4 N/A web_of_lies PaLM 2-L 92.0 / 91.0 / 91.2 N/A word_sorting PaLM 2-L 62.0 / 52.0 / 54.0 N/A boolean_expressions text-bison 84.0 / 78.5 / 79.6 80.0 / 78.0 / 78.4 causal_judgement text-bison 78.4 / 57.3 / 61.5 83.8 / 53.3 / 59.4 date_understanding text-bison 52.0 / 45.0 / 46.4 64.0 / 52.4 / 54.8 disambiguation_qa text-bison 68.0 / 75.5 / 74.0 64.0 / 71.5 / 70.0 dyck_languages text-bison 100.0 / 99.5 / 99.6 100.0 / 100.0 / 100.0 formal_fallacies text-bison 70.0 / 54.5 / 57.6 74.0 / 53.5 / 57.6 geometric_shapes text-bison 28.0 / 15.0 / 17.6 48.0 / 28.0 / 32.0 hyperbaton text-bison 86.0 / 85.0 / 85.2 80.0 / 76.5 / 77.2 logical_deduction_seven_objects text-bison 66.0 / 57.5 / 59.2 62.0 / 55.0 / 56.4 movie_recommendation text-bison 76.0 / 69.5 / 70.8 82.0 / 70.5 / 72.8 multistep_arithmetic_two text-bison 28.0 / 20.5 / 22.0 28.0 / 22.5 / 23.6 navigate text-bison 72.0 / 61.0 / 63.2 68.0 / 59.5 / 61.2 object_counting text-bison 68.0 / 71.0 / 70.4 72.0 / 69.0 / 69.6 penguins_in_a_table text-bison 65.5 / 59.8 / 61.0 79.3 / 53.0 / 58.2 reasoning_about_colored_objects text-bison 84.0 / 76.5 / 78.0 86.0 / 74.0 / 76.4 ruin_names text-bison 80.0 / 74.0 / 75.2 74.0 / 75.0 / 74.8 salient_translation_error_detection text-bison 44.0 / 50.5 / 49.2 48.0 / 51.0 / 50.4 snarks text-bison 82.9 / 79.7 / 80.3 88.6 / 84.6 / 85.4 sports_understanding text-bison 84.0 / 76.5 / 78.0 90.0 / 80.0 / 82.0 temporal_sequences text-bison 50.0 / 54.5 / 53.6 64.0 / 61.5 / 62.0 tracking_shuffled_objects_seven_objects text-bison 22.0 / 18.5 / 19.2 30.0 / 21.5 / 23.2 web_of_lies text-bison 64.0 / 57.5 / 58.8 68.0 / 55.0 / 57.6 word_sorting text-bison 26.0 / 19.0 / 20.4 32.0 / 25.5 / 26.8 36Large Language Models as Optimizers Table 11: BBH task-wise instructions found by prompt optimization with the PaLM 2-L scorer and the gpt-3.5-turbo optimizer. The optimizations start from the empty string. Task Our Instruction boolean_expressions An accurate evaluation of logical expressions involves correctly applying Boolean operators, considering the order of operations, and analyzing the truth values of the operands in accordance with Boolean logic principles. causal_judgement Understanding causality is critical for accurately assessing cause and effect relationships in various scenarios, leading to well-informed judgments, precise conclusions, and definitive answers to questions about the outcomes involved. date_understanding What is the specific date mentioned or required in each given problem or question, taking into account all relevant information, available options, and the provided context? Please provide the accurate answer in the format MM/DD/YYYY . disambiguation_qa Accurately analyze and clarify the pronoun-antecedent relationship in the given sentences, identifying the appropriate referent to eliminate any potential confusion or ambiguity and ensure a precise understanding of the intended meaning. dyck_languages Solve the sequence by properly closing the parentheses. formal_fallacies In determining the deductive validity of arguments based on explicit premises, a meticulous analysis of the logical relationships and implications is essential for definitively establishing their soundness, confirming their validity or invalidity, and ensuring a reliable and robust assessment of the arguments at hand. geometric_shapes The SVG path element with the \"d\" attribute plays a crucial role in web development, allowing for the precise definition and rendering of various shapes on a webpage. hyperbaton Understanding the correct order of adjectives is crucial for constructing grammatically accurate and coherent sentences that effectively convey the intended meaning in diverse contexts while ensuring clarity, cohesion, and consistency throughout consistently and effortlessly. logical_deduction _seven_objects By conducting a meticulous analysis of the given information and ensuring logical consistency within each paragraph, we can accurately determine the precise order or ranking of the mentioned objects, allowing us to confidently and consistently identify the correct answer in every presented scenario with utmost precision and confidence. movie_recommendation Which movie option from the given choices closely matches the mentioned films in terms of themes, storylines, and characteristics, guaranteeing the highest possible similarity score among them all? multistep_arithmetic_two Evaluate the given mathematical expressions step by step to determine the correct solutions accurately. navigate Is it possible to determine, with absolute certainty, whether strictly adhering to the given instructions will unfailingly bring you back to the original starting point without any exceptions, errors, or deviations? object_counting Determine the total number of objects or entities mentioned in the given list, covering various categories and types, to accurately calculate the overall count. penguins_in_a_table From the given table, what information can we gather about the mentioned animals and their respective attributes, including names, ages, heights, and weights? reasoning_about _colored_objects By thoroughly examining the given information, accurately determine the answers for each question by considering the specific characteristics, colors, and positions of the mentioned objects. ruin_names Select the most amusing and clever alteration from the options provided for the given artist, movie, or title name, and accurately choose the correct answer to test your wit and creativity. salient_translation _error_detection Thoroughly examine the given translations from German to English and accurately identify any errors by carefully analyzing the text and selecting the appropriate option with meticulous attention to detail, precision, utmost accuracy, and comprehensive understanding of the language for precise evaluation and categorization. snarks Which option delivers the most devastatingly sarcastic response, brilliantly exposing the sheer absurdity and leaving absolutely no doubt whatsoever in all the given situations? sports_understanding Maintaining the accuracy, reliability, and integrity of sports event representation is essential for upholding the highest standards of credibility, trustworthiness, and overall quality in conveying information, without any compromise, misrepresentation, or distortion, thereby ensuring the factual accuracy of sports journalism. temporal_sequences Based on the provided timeline and observed activities, we can accurately determine the possible time range when each individual could have visited their intended destinations and answer questions about their visitation time. tracking_shuffled_objects _seven_objects An important point to note is that each person in the group starts with one specific book at the beginning of the semester. web_of_lies Analyzing the consistency and accuracy of statements provided by each person is crucial for determining the truthfulness of individuals in every scenario. word_sorting Please sort the given words in alphabetical order: The list of words to be sorted contains - 37Large Language Models as Optimizers Table 12: BBH task-wise Q_begin instructions found by prompt optimization with thetext-bison scorer and the gpt-3.5-turbo optimizer. The optimizations start from the empty string. Task Our Instruction boolean_expressions Group sub-expressions with parentheses to accurately evaluate logical operations: not, and, and finally or. Determine the resulting value as either True or False. causal_judgement Consider the intentions and actions of the individuals involved. date_understanding Determine the one-day difference in the given date and express it in the format MM/DD/YYYY . disambiguation_qa Determine the precise antecedent of the pronoun in the given sentence and select the correct option or state if it is ambiguous. dyck_languages Ensure that all opening brackets have a corresponding closing bracket, and that the closing brackets are in the correct order. formal_fallacies Thoroughly analyze the explicitly provided premises and determine the deductive validity of the argument based on all necessary conditions, implications, exclusions, and dependencies given. geometric_shapes Analyze the given SVG path element carefully and confidently select the correct option from the provided choices to accurately determine the corresponding shape. Pay close attention to the specific path details and confidently make the most suitable choice. hyperbaton Select the sentence that strictly adheres to the standard order of adjectives: opinion, size, age, shape, color, origin, material, and purpose. Ensure there are no deviations or alterations in the adjective order. Choose the option without any changes. logical_deduction _seven_objects Analyze the given information to accurately determine the precise order and ranking of the mentioned objects/people, considering their relationships, positions, and any provided comparisons, for a definitive and logical progression with maximum accuracy and efficiency. movie_recommendation Based on the movie list provided, carefully consider your preferences and make a well-informed decision. multistep_arithmetic_two First, simplify any expressions within parentheses following the correct order of operations to accurately evaluate the final answer with efficiency and precision. navigate Always face forward. Take 10 steps forward. Turn left. Take 5 steps forward. Take 3 steps backward. Finally, take 7 steps forward. Turn around and take 1 step forward. Repeat the previous sequence three times. Follow the given path precisely without any deviations. At the end, turn right and take 11 steps forward. If you follow these instructions, will you return to the starting point? Options: - Yes - No object_counting Determine the total count of mentioned vegetables accurately and state the final count as the answer. penguins_in_a_table Analyze the given table to accurately determine the required information based on the provided criteria and attributes of the penguins and giraffes. Utilize efficient problem-solving strategies to arrive at the correct answer. reasoning_about _colored_objects State the color of the object mentioned in the given arrangement with utmost accuracy. ruin_names Choose the option that offers the most clever and humorous alteration of the given artist or movie name. Let your creativity shine and select the answer that will undoubtedly bring a smile to your face! Make sure to think outside the box! salient_translation _error_detection Analyze the translation and accurately identify the specific error type based on the source text, providing the most appropriate corresponding option. snarks Choose the option that wickedly embodies sarcasm. sports_understanding Determine the plausibility of the given statement by evaluating factual accuracy, logical consistency, and contextual relevance, then provide a succinct and well-justified response. temporal_sequences Identify the optimal time slot for the individual to engage in the mentioned location/activity considering the given sightings and waking up time, taking into account the opening and closing times of the location and the duration of each event. tracking_shuffled_objects _seven_objects Pay attention to the given information and track the swaps/exchanges carefully to accurately determine the final possession/position/outcome for the specified individual. web_of_lies To determine the truthfulness of the last person mentioned, analyze the consistency of each statement and count the number of individuals accusing the previous person of lying. If the count of accusers is even, that person tells the truth; if it is odd, that person lies. word_sorting Alphabetically sort the given list of words, ensuring all words are included and in ascending order. 38Large Language Models as Optimizers Table 13: BBH task-wise Q_end instructions found by prompt optimization with the text-bison scorer and the gpt-3.5-turbo optimizer. The optimizations start from the empty string. Task Our Instruction boolean_expressions Accurately use order of operations and parentheses to evaluate logical expressions and determine truth values efficiently. causal_judgement Consider all relevant factors, prioritize overall well-being and ethical considerations, make well-informed decisions while foreseeing potential consequences efficiently, and consistently strive for optimal outcomes with empathy and adaptability in a thoughtful and comprehensive manner. date_understanding Subtract the specified number of days from the given date and format the outcome as MM/DD/YYYY to accurately determine the desired result in an efficient manner. disambiguation_qa Clearly identify and select the unambiguous antecedent for the pronoun or designate it as \"Ambiguous\" if it is unclear. dyck_languages Add the missing closing parentheses. formal_fallacies Determine the deductive validity of the argument presented based on the explicitly stated premises and reach a definitive conclusion. geometric_shapes Analyzing the given SVG path element, accurately determine its shape by closely examining its curves and coordinates, then select the correct option. hyperbaton Choose the option with the correct adjective order in each sentence, prioritizing specific attributes like size, color, and origin. Place the most specific adjective before the more general ones for precise and standardized ordering across all examples. Ensure accurate alignment of the adjectives based on their respective attributes for consistent and standardized ordering. logical_deduction _seven_objects Determine the precise order of the given objects/participants based on the provided information and establish the final ranking accurately, considering all relevant factors, while maintaining logical consistency with maximum efficiency. movie_recommendation Choose the most similar option from the choices provided that closely aligns with the given movies’ themes, genres, and impact for the most accurate recommendation possible. Make your selection wisely. multistep_arithmetic_two Carefully follow the order of operations to precisely simplify the expressions within parentheses and efficiently find the accurate final answer. navigate Always face forward. Take 10 steps forward. Turn right and walk for 5 steps. Then, make a left turn and continue for 9 steps. Proceed by walking 6 steps backward. Finally, turn around and take 200 steps. Accurately track your movements, diligently adhere to the given path, and ensure to return to the starting point without any deviations or obstacles. object_counting Determine the total count of items mentioned, including all listed items, using an efficient and concise method. State the final count as your answer. penguins_in_a_table Identify the animal with the maximum measurement (weight, age, or height) in the table and state its name and species. reasoning_about _colored_objects Determine the color of each item in the given scenario and select the correct color option from the provided choices for accurate responses, ensuring utmost precision and completeness. ruin_names Choose the option that creatively and hilariously transforms the given artist or movie name. salient_translation _error_detection Carefully analyze the translations and select the most suitable option from the given choices to rectify the specific error category, ensuring complete precision, accuracy, and faithful representation of the intended meaning, while considering all relevant information in the source text. snarks Choose the option that cleverly employs sarcasm to defy all expectations and leave everyone utterly dumbfounded, questioning the very essence of their own perception. sports_understanding Evaluate the plausibility of each given statement and provide a well-supported justification based on logical reasoning, contextual understanding, and relevant evidence to arrive at a definitive and conclusive answer. temporal_sequences Identify the possible time slot for the desired activity based on the given information and sightings, then select the correct option. tracking_shuffled_objects _seven_objects Thoroughly analyze the given scenarios, systematically consider all available information, and confidently determine the final outcome with exceptional precision and optimal efficiency, while maintaining a strategic and logical approach throughout the process. web_of_lies Examine each person’s statements meticulously to accurately determine the truth and confidently identify who is telling the truth, enabling you to effectively solve the given problem. word_sorting Sort the given words alphabetically using spaces as separators while maintaining their original order and including all words. 39Large Language Models as Optimizers E.3 PALM 2-L AS SCORER , G P T-3.5-T U R B OAS OPTIMIZER , OPTIMIZATION STARTING FROM “LET’S SOLVE THE PROBLEM .” Figure 26 and Table 14 compare the accuracies of found instructions vs “Let’s solve the problem.”, “Let’s think step by step.”, and the instructions in Table 11. Table 15 details the found instructions. The “Let’s” pattern appears more often in the found instructions because of the starting points, and the instructions are more often declarative that are more suitable for A_begin, even if some are semantically far from “Let’s solve the problem”. In fact, “Let’s” was adopted by Zhou et al. (2022b) as a fixed pattern in generated prompts, possibly because of the same reason. boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40accuracy difference (a) ours minus “Let’s think step by step.” boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting 0 20 40accuracy difference (b) ours minus “Let’s solve the problem.” starting point boolean_expressions causal_judgementdate_understandingdisambiguation_qa dyck_languagesformal_fallacies geometric_shapes hyperbaton logical_deduction_seven_objects movie_recommendationmultistep_arithmetic_two navigate object_counting penguins_in_a_table reasoning_about_colored_objects ruin_names salient_translation_error_detection snarks sports_understandingtemporal_sequences tracking_shuffled_objects_seven_objects web_of_liesword_sorting -20 0 20 accuracy difference (c) ours minus the instructions found with the empty starting point Figure 26: On 23 BBH tasks, the accuracy differences among instructions found by prompt opti- mization (with the text-bison scorer and the gpt-3.5-turbo optimizer), “Let’s think step by step.”, and “Let’s solve the problem.” (optimization starting point). The found instructions mostly outperform the “Let’s think step by step.” baseline, the “Let’s solve the problem.” starting point, and the instructions in Table 11 found by prompt optimization from the empty string. 40Large Language Models as Optimizers Table 14: Accuracies on BBH tasks with thePaLM 2-L scorer and the gpt-3.5-turbo optimizer that starts from “Let’s solve the problem”. The scores are from A_begin instructions. Task Scorer Our Acc “Let’s solve the problem.” Acc training / test / overall training / test / overall boolean_expressions PaLM 2-L 98.0 / 89.5 / 91.2 78.0 / 69.0 / 70.8 causal_judgement PaLM 2-L 83.8 / 58.7 / 63.6 62.0 / 61.3 / 61.5 date_understanding PaLM 2-L 90.0 / 82.0 / 83.6 74.0 / 71.0 / 71.6 disambiguation_qa PaLM 2-L 78.0 / 68.0 / 70.0 52.0 / 54.5 / 54.0 dyck_languages PaLM 2-L 100.0 / 100.0 / 100.0 94.0 / 97.0 / 96.4 formal_fallacies PaLM 2-L 84.0 / 62.0 / 66.4 68.0 / 54.0 / 56.8 geometric_shapes PaLM 2-L 62.0 / 42.5 / 46.4 30.0 / 22.0 / 23.6 hyperbaton PaLM 2-L 94.0 / 91.5 / 92.0 72.0 / 77.0 / 76.0 logical_deduction_seven_objects PaLM 2-L 66.0 / 53.0 / 55.6 38.0 / 36.5 / 36.8 movie_recommendation PaLM 2-L 88.0 / 88.0 / 88.0 66.0 / 76.0 / 74.0 multistep_arithmetic_two PaLM 2-L 66.0 / 55.0 / 57.2 30.0 / 22.0 / 23.6 navigate PaLM 2-L 76.0 / 67.0 / 68.8 54.0 / 63.5 / 61.6 object_counting PaLM 2-L 96.0 / 92.5 / 93.2 58.0 / 58.0 / 58.0 penguins_in_a_table PaLM 2-L 86.2 / 70.9 / 74.0 69.0 / 72.6 / 71.9 reasoning_about _colored_objects PaLM 2-L 88.0 / 69.0 / 72.8 78.0 / 69.5 / 71.2 ruin_names PaLM 2-L 92.0 / 85.5 / 86.8 76.0 / 79.5 / 80.8 salient_translation_error_detection PaLM 2-L 66.0 / 67.5 / 67.2 30.0 / 35.5 / 34.4 snarks PaLM 2-L 88.6 / 76.9 / 79.2 80.0 / 70.6 / 72.5 sports_understanding PaLM 2-L 72.0 / 63.5 / 65.2 60.0 / 50.5 / 52.4 temporal_sequences PaLM 2-L 100.0 / 99.5 / 99.6 96.0 / 92.5 / 93.2 tracking_shuffled_objects_seven_objects PaLM 2-L 56.0 / 63.5 / 62.0 42.0 / 51.5 / 49.6 web_of_lies PaLM 2-L 56.0 / 58.5 / 58.0 0.0 / 4.0 / 3.2 word_sorting PaLM 2-L 52.0 / 44.5 / 46.0 18.0 / 20.5 / 20.0 41Large Language Models as Optimizers Table 15: BBH task-wise Q_begin instructions found by prompt optimization with the PaLM 2-L scorer and the gpt-3.5-turbo optimizer. The optimizations start from “Let’s solve the problem”. Task Our Instruction boolean_expressions Let’s accurately assess the given conditions and determine their corresponding Boolean values. causal_judgement Let’s conduct a meticulous evaluation of the given scenarios, accurately determine the causal relationships, and provide definitive answers through comprehensive analysis, ensuring a precise understanding of causation and a thorough determination of events in each situation. date_understanding Let’s accurately determine the correct date based on the given information and select the corresponding option in the standard MM/DD/YYYY format with utmost precision and reliability, ensuring the most definitive and reliable solution possible for accurate representation in all scenarios without any room for ambiguity, error, or confusion, and providing the highest level of accuracy and reliability. disambiguation_qa Let’s thoroughly analyze the given sentences to accurately determine the unambiguous antecedents of the pronouns used, ensuring clear understanding, effective communication, and leaving no room for any confusion or ambiguity. dyck_languages Let’s find the correct closing parentheses and brackets for the given sequences. formal_fallacies Let’s thoroughly analyze the explicitly stated premises and draw definitive conclusions to accurately determine the deductive validity of the arguments provided in each question, employing precise and logical reasoning in our assessments for unwavering confidence in our determinations. geometric_shapes Let’s accurately determine the shape represented by the given SVG path element by carefully analyzing its path data and considering all available options for a precise identification. hyperbaton Let’s quickly identify the correct adjective order. logical_deduction _seven_objects Let’s methodically analyze the given information, employ logical reasoning, thoroughly evaluate all relevant details, and accurately determine the solutions for each problem by considering all provided options comprehensively and strategically, ensuring an efficient and effective approach towards arriving at the correct answers. movie_recommendation Let’s uncover the perfect movie recommendation from the options provided, ensuring an exceptional cinematic experience together as we select the most captivating and satisfying choice that will keep us thoroughly engaged and immersed until the very end. multistep_arithmetic_two Let’s tackle the following calculations. navigate Let’s accurately and efficiently determine the correct solution for each given scenario, ensuring the highest level of precision, reliability, and consistency throughout. object_counting Let’s determine the total count of various items/objects/ingredients/animals mentioned in order to accurately and efficiently find the answer. penguins_in_a_table Let’s analyze the given information and determine the correct answer. reasoning_about _colored_objects Let’s systematically analyze the given information and carefully evaluate each answer choice to confidently determine the accurate and optimal solutions, considering all available options and specific details provided in each question for precise and concise responses, ensuring complete accuracy and clarity in our answers. ruin_names Prepare to have a side-splittingly funny time as we uncover the most clever and hilarious alternatives for these artist or movie names, challenging your wit to guess the correct one with a burst of creativity, humor, and imaginative twists! salient_translation _error_detection Let’s meticulously analyze the provided translations, accurately identifying any errors or discrepancies, and conduct a comprehensive evaluation to ensure the highest level of translation quality and fidelity. By considering contextual nuances, cultural references, linguistic conventions, potential factual errors, and any dropped content, our ultimate aim is to achieve precise and thorough assessments for optimal translation accuracy and adherence to the source text. snarks Let’s expertly determine the sarcastic statement among the given options and confidently provide the definitive answer without any room for doubt or confusion, ensuring absolute precision, clarity, and unwavering expertise in our response, while carefully analyzing the context, tone, and intention behind each statement to achieve unrivaled accuracy and unwavering confidence. sports_understanding Let’s find the accurate information. temporal_sequences The flawless approach tracking_shuffled_objects _seven_objects By meticulously analyzing the given scenarios and accurately determining the final outcomes through a series of trades, swaps, and exchanges among the individuals involved, let’s ascertain the conclusive results. web_of_lies Let’s scrutinize each statement provided to accurately determine the truth-teller and uncover the veracity behind their words with unwavering analysis. word_sorting Employing efficient and precise measures, sort the given list of words in alphabetical order to provide an optimal solution for any sorting problem, ensuring maximum performance and effectiveness. 42",
      "references": [
        "Backpropagation and stochastic gradient descent method.",
        "Palm 2 technical report.",
        "Concorde tsp solver,",
        "An overview of evolutionary algorithms for parameter optimization.",
        "Constitutional ai: Harmlessness from ai feedback.",
        "Large language models as tool makers.",
        "Evoprompting: Language models for code-level neural architecture search.",
        "Improving code generation by training with natural language feedback.",
        "When do you need chain-of-thought prompting for chatgpt?",
        "Instructzero: Efficient instruction optimization for black-box large language models.",
        "Learning to perform local rewriting for combinatorial optimization.",
        "Teaching large language models to self-debug.",
        "Towards learning universal hyperparameter optimizers with transformers.",
        "Training verifiers to solve math word problems.",
        "Rlprompt: Optimizing discrete text prompts with reinforcement learning.",
        "Learning heuristics for the tsp by policy gradient.",
        "Promptbreeder: Self-referential self-improvement via prompt evolution.",
        "The capacity for moral self-correction in large language models.",
        "Making pre-trained language models better few-shot learners.",
        "Approximate traveling salesman algorithms.",
        "Connecting large language models with evolutionary algorithms yields powerful prompt optimizers.",
        "The traveling salesman problem and its variations",
        "An extension of the lin-kernighan-helsgaun tsp solver for constrained traveling salesman and vehicle routing problems.",
        "The traveling salesman problem.",
        "Language models can solve computer tasks.",
        "Adam: A method for stochastic optimization.",
        "Large language models are zero-shot reasoners.",
        "Attention, learn to solve routing problems!",
        "Evolution through large models.",
        "The power of scale for parameter-efficient prompt tuning.",
        "Prefix-tuning: Optimizing continuous prompts for generation.",
        "Program induction by rationale genera- tion: Learning to solve and explain algebraic word problems.",
        "Gpt understands, too.",
        "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity.",
        "Let’s do a thought experiment: Using counterfactuals to improve moral reasoning.",
        "Text and patterns: For effective chain of thought, it takes two to tango.",
        "Self-refine: Iterative refinement with self-feedback.",
        "Language model crossover: Variation through few-shot prompting.",
        "Large language models as general pattern machines.",
        "Dera: Enhancing large language model completions with dialog-enabled resolving agents.",
        "Reinforcement learning for solving the vehicle routing problem.",
        "Demystifying gpt self-repair for code generation.",
        "Gurobi optimizer reference manual,",
        "Grips: Gradient-free, edit-based instruction search for prompting large language models.",
        "Automatic prompt optimization with\" gradient descent\" and beam search.",
        "On the momentum term in gradient descent learning algorithms.",
        "Learning how to ask: Querying lms with mixtures of soft prompts.",
        "Modern heuristic techniques for combinatorial problems.",
        "Prompt programming for large language models: Beyond the few-shot paradigm.",
        "Derivative-free optimization: a review of algorithms and comparison of software implementations.",
        "An analysis of several heuristics for the traveling salesman problem.",
        "Solving general arithmetic word problems.",
        "Toolformer: Language models can teach themselves to use tools.",
        "Autoprompt: Eliciting knowledge from language models with automatically generated prompts.",
        "Reflexion: an autonomous agent with dynamic memory and self-reflection.",
        "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.",
        "Challenging big-bench tasks and whether chain-of-thought can solve them.",
        "V oyager: An open-ended embodied agent with large language models.",
        "Self-consistency improves chain of thought reasoning in language models.",
        "Chain of thought prompting elicits reasoning in large language models.",
        "Larger language models do in-context learning differently.",
        "Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery.",
        "Wizardlm: Empowering large language models to follow complex instructions.",
        "Gps: Genetic prompt search for efficient few-shot learning.",
        "System-level natural language feedback.",
        "Tempera: Test-time prompt editing via reinforcement learning.",
        "Calibrate before use: Improving few-shot performance of language models.",
        "Least-to-most prompting enables complex reasoning in large language models.",
        "Large language models are human-level prompt engineers."
      ],
      "meta_data": {
        "arxiv_id": "2309.03409v3",
        "authors": [
          "Chengrun Yang",
          "Xuezhi Wang",
          "Yifeng Lu",
          "Hanxiao Liu",
          "Quoc V. Le",
          "Denny Zhou",
          "Xinyun Chen"
        ],
        "published_date": "2023-09-07T00:07:15Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces Optimization by PROmpting (OPRO), a general derivative-free optimization framework that uses an LLM as an iterative optimizer via a natural-language “meta-prompt” containing (i) the optimization problem description/constraints and (ii) an optimization trajectory (past solutions paired with objective scores). Demonstrates that LLMs can perform black-box search by proposing improved candidate solutions from scored histories across continuous (linear regression) and discrete (TSP) problems, and shows a strong practical application to prompt optimization: automatically discovering task instructions that maximize downstream LLM accuracy. Reports that OPRO-optimized prompts exceed human-designed baselines (e.g., “Let’s think step by step.”) by up to ~8% absolute on GSM8K and up to ~50% on certain Big-Bench Hard (BBH) tasks, with some transfer to related math datasets.",
        "methodology": "Iterative loop: (1) construct a meta-prompt with task description + a sorted list of prior solution–score pairs; (2) sample the optimizer LLM multiple times per step (batch generation) at a tuned temperature to balance exploration/exploitation; (3) evaluate each candidate with an external objective evaluator (often an LLM scorer run with greedy decoding, or exact computation/solver for math tasks); (4) append top-K solution–score pairs to the trajectory (keep best ~20 due to context limits) and repeat until convergence or max steps. For prompt optimization, the “solution” is a natural-language instruction inserted at specified positions (Q_begin/Q_end/A_begin) into scorer prompts; objective is accuracy on a small training subset. Key design choices: ascending score ordering in trajectory (leveraging recency bias), include explicit numeric scores (bucketized), include few task exemplars, and generate multiple candidates per step for stability.",
        "experimental_setup": "Math case studies: (a) 1D linear regression with intercept (optimize w,b) on synthetic data: 50 points generated as y=w_true x + b_true + noise; start from 5 random (w,b) in [10,20]^2; each step proposes up to 8 candidates; history includes best 20 pairs; evaluate convergence steps/unique points across 5 runs for text-bison, gpt-3.5-turbo, gpt-4. (b) TSP with n∈{10,15,20,50}: coordinates sampled uniformly in [-100,100]; start from 5 random tours; propose up to 8 tours/step; evaluate tour length; compute optimality gap vs Gurobi oracle; compare to heuristics Nearest Neighbor and Farthest Insertion; report successes reaching optimum and steps for successful runs.\nPrompt optimization: Optimizer LLMs: PaLM 2-L (pretrained), PaLM 2-L-IT, text-bison, gpt-3.5-turbo, gpt-4. Scorer LLMs: pretrained PaLM 2-L and instruction-tuned text-bison. Benchmarks: GSM8K (7,473 train/1,319 test) using 3.5% train subset during optimization; BBH 23 tasks using 20% examples for optimization and 80% for test; also evaluate transfer of GSM8K-optimized instructions to MultiArith and AQuA. Evaluation: scorer decoded with temperature 0 (greedy); optimizer default temperature 1.0; 8 candidates per step; up to 200 steps; meta-prompt keeps best 20 instructions and 3 exemplars/step. Ablations: trajectory ordering, score display/bucketing, number of exemplars, candidates per step, initialization, optimizer temperature; overfitting check with explicit train/val splits on select tasks; comparison to EvoPrompt GA/DE meta-prompts.",
        "limitations": "Context window limits restrict scaling to large problem descriptions/trajectories (e.g., high-dimensional regression, large-n TSP) and force keeping only a small top-K history. Performance degrades rapidly with problem size/complexity and bumpy landscapes; OPRO can get stuck in local minima or misleading descent directions (e.g., Rosenbrock valley, larger TSP). Optimizer LLM can hallucinate objective values, repeat previously seen solutions despite constraints, and exhibit sensitivity to prompt wording/initialization; optimization can be unstable due to prompt sensitivity and high variance. Prompt optimization requires an explicit training set and repeated expensive scoring calls; risk of overfitting (training accuracy often 5–20% above test), no validation set by default. Error-case conditioning was not very effective: including mispredicted examples alone did not yield clear gains, suggesting limited diagnostic use of failures under the current meta-prompt.",
        "future_research_directions": "Improve scalability and efficiency: memory/compression of trajectories, retrieval-based or hierarchical histories, and better stopping/early-stopping with validation or Bayesian-style budgeting. Integrate richer feedback beyond scalar accuracy—e.g., per-example error analyses, natural-language critiques, or structured reward signals—and train/prompt the optimizer to summarize distinguishing features of high- vs low-performing prompts. Develop mechanisms to reduce sensitivity to initialization and better control exploration–exploitation (adaptive temperature, bandit strategies, diversity/novelty constraints). Combine OPRO with tool use (calculators/solvers) to prevent hallucinated evaluations and to support hybrid optimization where LLM proposes candidates and tools verify/repair. Extend to broader optimization domains: hyperparameter tuning, program synthesis, black-box RL objectives, multi-objective constraints (conciseness/safety), and cross-model transfer/robustness of optimized prompts.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery",
      "full_text": "Simulations of multivariant Si I to Si II phase transformation in polycrystalline silicon with ﬁnite-strain scale-free phase-ﬁeld approach Hamed Babaeia, Raghunandan Pratooria, Valery I. Levitasa,b,c aDepartment of Aerospace Engineering, Iowa State University, Ames, IA 50011, USA bDepartments of Mechanical Engineering, Iowa State University, Ames, IA 50011, USA cAmes Laboratory, Division of Materials Science and Engineering, Ames, IA 50011, USA Abstract Scale-free phase-ﬁeld approach (PFA) at large strains and corresponding ﬁnite element method (FEM) sim- ulations for multivariant martensitic phase transformation (PT) from cubic Si I to tetragonal Si II in a polycrystalline aggregate are presented. Important features of the model are large and very anisotropic transformation strain tensor εεεt = {0.1753; 0.1753; −0.447}and stress-tensor dependent athermal dissipative threshold for PT, which produce essential challenges for computations. 3D polycrystals with 55 and 910 stochastically oriented grains are subjected to uniaxial strain- and stress-controlled loadings under periodic boundary conditions and zero averaged lateral strains. Coupled evolution of discrete martensitic microstruc- ture, volume fractions of martensitic variants and Si II, stress and transformation strain tensors, and texture are presented and analyzed. Macroscopic variables eﬀectively representing multivariant transformational be- havior are introduced. Macroscopic stress-strain and transformational behavior for 55 and 910 grains are close (less than 10% diﬀerence). This allows the determination of macroscopic constitutive equations by treating aggregate with a small number of grains. Large transformation strains and grain boundaries lead to huge internal stresses of tens GPa, which aﬀect microstructure evolution and macroscopic behavior. In contrast to a single crystal, the local mechanical instabilities due to PT and negative local tangent modulus are stabilized at the macroscale by arresting/slowing the growth of Si II regions by the grain boundaries and generating the internal back stresses. This leads to increasing stress during PT. The developed methodol- ogy can be used for studying similar PTs with large transformation strains and for further development by including plastic strain and strain-induced PTs. Keywords: Multivariant martensitic phase transformation, Silicon polycrystal, Scale-free phase-ﬁeld approach, Finite element simulations, Stress-dependent eﬀective threshold, Finite strain 1. Introduction Silicon is the second most abundant material in the earth’s crust. The semiconducting Si I phase (cubic diamond lattice, Fd3mspace group) is extensively used in microelectronics, integrated circuits, photovoltaics, and MEMS/ NEMS technologies. Single-crystal Si is also used in high-power lasers. Polycrystalline Si is widely used in solar panels [1], thin transistors [2], and very large-scale integration (VLSI) manufacturing. It Preprint submitted to Elsevier February 14, 2023 arXiv:2302.05952v1  [cond-mat.mtrl-sci]  12 Feb 2023also has low toxicity and high stability. Due to high demands, the recent CHIPS and Science Act will provide new funding to boost the research and manufacturing of semiconductors in the US. Under the pressure of 10-16 GPa, semiconducting Si I transforms to metallic phase Si II (β-tin structure, I41/amdspace group). Si I is very strong and brittle, and hence its bulk hardness is 12 GPa and is determined by Si I →Si II PT rather then dislocational plasticity [3, 4]. Stresses exceed 10 GPa for machining (turning, polishing, scratching, etc.) of single and polycrystalline Si [5]; such loads cause plastic ﬂow, Si I →Si II and some other PTs, e.g., amorphization. High-pressure torsion of Si at 24 GPa is used to produce nanostructured metastable phases [6, 7]. Machining of strong brittle semiconducting Si-I is accompanied by microcrack propagation inside the bulk. PT from Si I to ductile and weaker Si II is utilized to develop ductile machining regimes [8], which reduces forces, energy, and damage. This also may eliminate the necessity of using chemical additives during machining, which brings deﬁnite environmental beneﬁts by reducing pollution. Since transformation strain tensor that describes the transformation of cubic to tetragonal Si I →Si II PT has large and very anisotropic principal components εεεt = {0.1753; 0.1753; −0.447}[9–11], it is clear from thermodynamics that deviatoric part of the stress tensor should strongly aﬀect this PT. Both pressure- and stress-induced PTs start at pre-existing defects (diﬀerent dislocation conﬁgurations, grain boundaries), which represent stress concentrators. However, in many of the applications, like turning, polishing, scratching, fric- tion, high-pressure torsion and ball milling, PTs occur during plastic deformation. According to classiﬁcation [12–14], such PTs are called plastic strain-induced PT under high pressure, and they occur at defects per- manently generated during plastic ﬂow. Strain-induced PTs require completely diﬀerent thermodynamic, kinetic, and experimental treatments than pressure- and stress-induced PTs. There are numerous very strong eﬀects of plastic deformations on PTs, summarized in [12–18]; one of the most important is a drastic reduction in PT pressure. Thus, plastic strain-induced PTs from graphite to hexagonal and cubic diamonds were obtained at 0.4 and 0.7 GPa, 50 and 100 times lower than under hydrostatic loading, respectively, and well below the phase equilibrium pressure of 2.45 GPa [18]. About an order of magnitude reduction in PT pressure was reported for PT from rhombohedral to cubic BN [19], hexagonal to wurtzitic BN [20], and from α to ω Zr [21, 22]. The eﬀect of plastic straining on PTs in Si is also very strong but more sophisticated. Thus, under compression and shear in rotational diamond anvil cell [23], Si II was obtained at 5.2 GPa, but not directly from Si I, but via Si III. However, in these experiments, only optical, pressure, and electric resistivity measurements were utilized without in situ x-ray diﬀraction. In our recent in situ x-ray diﬀraction experiments [24], the PTs pressure for direct Si I→Si II PT was reduced from 13.5 (hydrostatic loading) to 2.5 GPa (plastic straining) for micron size Si particles and from 16.2 GPa to 0.4 GPa for 100 nm Si nanoparticles, i.e., by a factor of 40.5 (and 26.3 below the phase equilibrium pressure of 10.5 GPa [25]). To understand the eﬀect of stress tensor and plastic strain on Si I→Si II PT, various techniques at multiple scales are used. With ﬁrst principle simulations, the lattice instability for Si I under two-parametric loadings was studied in [26–29]. Although it is not speciﬁed, it is related to Si I →Si II PT. The stress-strain behavior 2and elastic instabilities leading to Si I→Si II PT under all six components of the stress tensor were determined in [30, 31]. While this seems to be impossible due to a large number of combinations, the following solution was found. First, the analytical expression for crystal lattice instability criterion was formulated within the PFA [10, 11, 32]. Then it was conﬁrmed and quantiﬁed with ﬁrst principle simulations in [30]. A similar approach was realized earlier with molecular dynamics simulations [10, 11] under the action of three normal stresses. Molecular dynamics simulations of PTs in Si during various loadings, nanoindentation, scratching, and surface processing were performed in [4, 33–37]. Nanoscale PFA for PT Si I→Si II in a single crystal with corresponding simulations was developed in [38– 42]. It was calibrated by results of molecular dynamics simulations in [10, 11]. The eﬀect of a single dislocation on this PT under uniaxial compression is modeled in [40]. The main general problem with nanoscale PFA is that the width of the martensitic interface is 1 nm and one needs at least 3-5 ﬁnite elements within the interface [43], making problem computationally expensive for large samples. Hence this model can be used to treat nano-sized samples only. Here, we will consider scale-free PFA for modeling discrete martensitic microstructure. It was developed for small strains in [44, 45] and updated and applied to NiTi shape memory alloy in [46]. The only ﬁnite- strain generalization of the scale-free model for ﬁnite strains is presented in [47]. This model was applied for simulations of Si I→Si II PT in a single crystal. The main diﬀerences between scale-free and nanoscale PFAs are: 1. The energy term that includes gradients of the order parameters and determines the phase interface widths and the interface energies is excluded. This makes the model scale-free. Interface width is getting equal to a single ﬁnite element, which is much more computationally economical than in the nanoscale approach, where 3-5 elements are usually required to reproduce analytical solution for an interface [43]. However, this leads to two problems. (a) The solution is mesh dependent. However, detailed computational experiments in [44, 45, 47] show that the solution becomes practically mesh- independent after the mesh size is 80 times smaller than the sample size. (b) Since the volume fraction of martensite varies from 0 to 1 within the one-element thick interface, for large transformation strains, there are large strain gradients within the interface, which leads often to divergence in the FEM solution. 2. The interfaces between individual martensitic variants are not resolved. Each of these variant has a width of d≃10 nm, i.e., thousands of interfaces at the microscale, making the problem computationally impractical. Here, martensite is considered a mixture of martensitic variants with corresponding volume fractions. 3. Since there is no need to reproduce atomic level energy landscape versus order parameters, the linear mixture rule is applied for all material properties. This is in contrast to higher-order polynomials in order parameters for nanoscale PFA. Also, the athermal dissipative threshold for interface propagation (interface friction) can be easily introduced in the scale-free model, while this is a problem for the nanoscale model. 34. The volume fraction of the martensite is the order parameter, i.e., it is responsible for the material instability and transformation strain localization at the interface between austenite and martensite. The volume fractions of the individual martensitic variants are only internal variables and do not produce any instabilities. That is how we eliminate interfaces between martensitic variants. All the above features allow us to economically model multivariant martensitic PTs in a sample of arbitrary size. The next natural step is to simulate PTs in Si and discrete martensitic microstructure in a polycrystalline sample, which was not done yet. This is also an important step in studying plastic strain-induced PTs. The main hypothesis [12] is that they initiate at the tip of dislocation pileups against grain boundaries, which causes strong stress concentration for all stress components proportional to the number of dislocations in a pileup. These stresses drastically reduce the required external pressure needed for nucleation and further growth. Nanoscale PFA allows us to treat a bicrystal and to qualitatively prove this hypothesis [48–50], however, for 2D and small strain formulation. Our scale-free PFA [51, 52] has been applied to 2D polycrystalline samples with several dozen grains and also for small strain formulation. In this work, we extend the modeling presented in [47] to Si I→Si II PT in 3D polycrystalline samples with up to 1000 grains. The main challenge is to reach convergence of the computational procedure due to strong nonlinearities, large transformation strain localization with large gradients within a single-element diﬀuse interface, and potential elastic instabilities. For a single crystal, just two loadings, uniaxial and hydrostatic, have been considered in [47]. However, each grain is subjected to diﬀerent complex and heterogeneous loading in a polycrystal. While we used the simplest quadratic in elastic Lagrangian strain expression (7) for the elastic energy, it is shown in [53] that even simple uniaxial compression leads to elastic instability. This instability can cause additional strain localization and divergence of solution. Due to the variety of heterogeneous complex loadings, diﬀerent for diﬀerent grains, chances for various elastic instabilities and divergence are very high. That is why several computational parameters have been varied to reach convergence of the solution. Periodic boundary conditions along the lateral surfaces played important part in the avoiding divergence. Another problem is to adequately quantitatively present the evolution of the local and average volume fraction of martensitic variants; a straightforward approach leads to contradictory results. The paper is organized as follows. In Section 2 complete system of coupled PFA and nonlinear mechanics equations is presented. Materials parameters for the model are given in Section 3. Problem formulations, results of simulations, and their analyses are presented in Section 4. Concluding remarks are summarized in Section 5. Vectors and tensors are designated with boldface symbols. We designate contractions of tensors AAA= {Aij}and BBB = {Bji}over one and two indices as AAA···BBB = {AijBjk}and AAA:::BBB = AijBji. The transpose of AAA is AAAT; III is the unit tensor; ∇∇∇0 is the gradient operator in the undeformed state. 42. Model description Here, we expand the microscale model for multivariant martensitic PTs developed in [47] for a polycrys- talline elastic materials. 2.1. Kinematics: Let us consider polycrystalline Si I aggregate in the undeformed stress-free conﬁguration Ω 0. The ori- entation of each grain is characterized by the rotation tensor RRRg in the undeformed conﬁguration, which rotates local cubic crystallographic axes of the grain to the global coordinate system. Tensors RRRg do not evolve during loading and PTs. The deformation gradient FFF is multiplicatively split into the elastic FFFe and the transformational FFFt parts: FFF := ∇∇∇0rrr= FFFe···FFFt; FFFe = RRRe ·UUUe; FFFt = FFFT t . (1) Here, rrr is the position vector in the current deformed conﬁguration Ω; FFFt is deﬁned as FFF after complete local stress release (producing the intermediate conﬁguration Ω t) and is considered to be rotation-free; UUUe is the symmetric elastic right stretch tensor and RRRe is the orthogonal lattice rotation tensor during loading and PT, which determines texture evolution. The transformation deformation gradient is deﬁned using the mixture rule for m variants as FFFt = III+ εεεt = III+ m∑ i=1 RRRg ·˜εεεti ·RRRT gci, (2) where εεεt is the transformation strain, ˜εεεti is the transformation strain of the ith martensitic variant in the local crystallographic basis of the grain, and the ci is the volume fraction of the ith variant in terms of volumes in the reference conﬁguration. The total, elastic, and transformational Lagrangian strains are deﬁned as EEE = 1 2(FFFT···FFF −III); EEEe = 1 2(FFFT e···FFFe −III); EEEt = 1 2(FFFT t ···FFFt −III). (3) Utilization of multiplicative decomposition eq. (1) results in the following relationship: EEEe = FFF−1 t ···(EEE−EEEt)···FFF−1 t . (4) We will also need the ratios of elemental volumes dV and mass densities ρin the diﬀerent conﬁgurations, which are described by the Jacobian determinants: J = dV dV0 = ρ0 ρ = detFFF; Jt = dVt dV0 = ρ0 ρt = detFFFt; Je = dV dVt = ρt ρ = detFFFe. (5) 2.2. Helmholtz Free energy In deﬁning the Helmholtz free energy ψ per unit undeformed volume in Ω 0 of the mixture of austenite and m martensitic variants, contributions from the elastic ψe, thermal ψθ i, and interaction ψin energy are given by ψ(FFFe,ci,θ) = Jtψe(FFFe,ci) + ψθ(θ,ci) + ψin(ci). (6) 5Here, ψe is deﬁned in Ω t, and the Jacobian Jt maps it into Ω 0; ψθ i includes the thermal driving force for the PT and depends on the temperature θ; ψin = Acc0 ≥0 includes the interactions between austenite and martensite, the energy of internal stresses, as well as the austenite-martensite phase interface energy; interaction between martensitic variants is neglected to avoid formation of variant-variant interfaces. Positive Aresults in a negative tangent modulus of the equilibrium stress-strain curve during PT, which results in local mechanical instability and the formation of the localized transformation bands/regions of the product phase. In such a way, a discrete martensitic structure is reproduced, similar to the nanoscale PFA. The elastic energy is expressed as ψe = 1 2EEEe::: ˜CCC:::EEEe = 1 2 ˜CijklEij e Ekl e ; ˜Cijkl = m∑ p=0 ˜Cijkl p cp, (7) where the components of the forth-rank elastic moduli tensor ˜Cijkl p in the global coordinate system are deﬁned in terms of components in the local for each grain crystallographic system Crqnm p and grain rotations Rml g as ˜Cijkl p = Rlm g Rkn g Rjq g Rir g Crqnm p . (8) Since the thermal energy of all martensitic variants is the same, ψθ i = ψθ j = ψθ M, the thermal energy of the mixture is ψθ = m∑ i=0 ciψθ i(θ) = c0ψθ A(θ) + cψθ M(θ); c= m∑ i=1 ci; c0 = 1 −c, (9) where ψθ A is the thermal energy of austenite, cand c0 are the volume fractions of the martensite and austenite. 2.3. Dissipation inequality The Plank’s inequality for isothermal processes is D= PPPT::: ˙FFF − ˙ψ≥0, (10) where D is the dissipation rate per unit undeformed volume; PPP is the ﬁrst Piola-Kirchhoﬀ stress. After traditional thermodynamic manipulations, D can be expressed as the product of the thermodynamic driving forces for A→Mi, Xi0, and Mj →Mi, Xi0, transformations and conjugate rates: D= m∑ i=1 Xi0 ˙ci0 + m−1∑ j=1 m∑ i=j+1 Xij˙cij ≥0; Xi0 = Wi0 −Jt 2 EEEe:::( ¯CCCi −¯CCC0):::EEEe −Jt 2 ( EEEe::: ¯CCC(c):::EEEe ) FFF−1 t :::εεεti −∆ψθ −A(1 −2c); Xij = Wij −Jt 2 EEEe:::( ¯CCCi −¯CCCj):::EEEe −Jt 2 ( EEEe::: ¯CCC(c):::EEEe ) FFF−1 t :::(εεεti −εεεtj); Wi0 = PPPT···FFFe:::εεεti = JFFFT e···σσσ···FFFt−1 e ·FFF−1 t :::εεεti; Wij = PPPT···FFFe:::(εεεti −εεεtj) = JFFFT e···σσσ···FFFt−1 e ·FFF−1 t :::(εεεti −εεεtj). (11) Here, ˙ci0 and ˙cij are the rate of change of volume fraction of variant idue to transformation to the austenite and variant j, respectively; Wi0 is the transformation work for austenite to martensite PT, Wij is the transformation work for variant j to variant i transformation, ∆ ψθ is the jump in thermal energy during transformation, and σσσ= J−1PPP···FFFT is the Cauchy (true) stress tensor. 62.4. Kinetic equations The kinetic equations are formulated as follows for the A↔Mi PTs    ˙ci0 = λi0(Xi0 −ki−0) if {Xi0 −ki−0(ci,σi) >0 & ci <1 & c0 >0} A→Mi ˙ci0 = λi0(Xi0 + ki−0) if {Xi0 + ki−0(ci,σi) <0 & ci >0 & c0 <1} Mi →A ˙ci0 = 0 otherwise; i= 1,2,...,m, (12) and for Mj ↔Mi PTs    ˙cij = λijXij if {Xij >0 & ci <1 & cj >0} j →i or {Xij <0 & ci >0 & cj <1} i→j ˙cij = 0 otherwise; i,j = 1,2,...,m, (13) where ki−0 is the athermal threshold and λi0 and λij are the kinetic coeﬃcients. We neglect the athermal threshold for Mj ↔Mi PTs. The non-strict inequalities for the volume fraction of phases in Eqs. (12)-(13) imply that the PT from any phase does not occur if the parent phase does not exist or if the product phase is complete. 2.5. Macroscopic parameters Macroscopic Cauchy stress and the ﬁrst Piola-Kirchhoﬀ stress, the deformation gradient, transformation strain, and volume fraction of Si II and each martensitic variant, averaged over the sample, are deﬁned as [54–56] ¯σσσ= 1 V ∫ V σσσdV; ¯PPP = 1 V0 ∫ V0 PPPdV0; (14) ¯FFF = 1 V0 ∫ V0 FFFdV0; ¯FFFt ≃ 1 V0 ∫ V0 FFFtdV0; ¯εεεt ≃ 1 V0 ∫ V0 εεεtdV0; (15) ¯c= 1 V0 ∫ V0 cdV0; ¯ ci = 1 V0 ∫ V0 cidV0. (16) For the Cauchy stress and the ﬁrst Piola-Kirchhoﬀ stress, the deformation gradient, and volume fractions c and ci, averaging equations are strict; for the transformation deformation gradient and strain, they are approximate because, in the unloaded stress-free state, they generally are not compatible due to residual elastic strain. We use Eq. (15) because the exact equation is quite bulky and is for ˙FFFt instead of FFFt. Eq. (16) for ci, while formally correct, is misleading (Section 4.1). Other macroscopic parameters are deﬁned via ¯FFF and ¯PPP by equations similar to the corresponding local equations: ¯σσσ= (det ¯FFF)−1 ¯PPP···¯FFF T ; ¯EEE = 1 2( ¯FFF T ···¯FFF −III). (17) Eq. (17) for the Cauchy stress is used instead of Eq. (14) because integration over the ﬁxed parallelepiped with regular cubic mesh is much simpler and faster than the integration over the deformed volume. 73. Model parameters The material parameters required for the implementation of the model, the same as in [47], are presented in section 2 are listed in table 1. The transformation strain tensors are taken from the MD simulations in [10, 11], and in the local crystallographic axes for all three variants are given by ˜εεεt1 =   0.1753 0 0 0 0 .1753 0 0 0 −0.4470  ; ˜εεεt2 =   0.1753 0 0 0 −0.4470 0 0 0 0 .1753  ; ˜εεεt3 =   −0.4470 0 0 0 0 .1753 0 0 0 0 .1753  . (18) The elastic constants for both phases are collected from [31, 57]. The constants Cij 0 in table 1 denote the independent elastic constants of the austenite, and Cij 1 denote those of the ﬁrst variant of the martensite, both in the local crystallographic axes. The components of the tensor of elastic moduli Cijkl can be calculated using Cijkl = 3∑ n=1 [λnδinδjnδknδln + µn(δinδjnδkl + δijδknδln) +νn(δinδjkδln + δjnδikδln + δinδjlδkn + δjnδilδkn)], (19) where λn, µn and νn for a cubic and tetragonal crystal lattice are given by eqs. (20) and (21), respectively: λ1 = λ2 = λ3 = C11 −C12 −2C44, 2µ1 = 2µ2 = 2µ3 = C12, 2ν1 = 2ν2 = 2ν3 = C44. (20) λ1 = λ2 = C11 −(C12 + 2C66), λ3 = C33 + C12 + 2C66 −2(C13 + 2C44), 2µ1 = 2µ2 = C12, 2µ3 = 2C13 −C12, 2ν1 = 2ν2 = C66, 2ν3 = 2C44 −C66. (21) Under hydrostatic conditions, the phase equilibrium pressure peq 0 = 10 .5GPa [25] at Jt = 0 .764. The jump in the thermal energy ∆ ψθ = −peq 0 (Jt −1) = 2 .47GPa, where elastic strain and change in elastic moduli are neglected. Localization of strain is required to reproduce discrete microstructure. As noted in [47], to obtain strain localization, the strain rate should be commensurate with the rate of transformation. The kinetic coeﬃcient λ and interaction parameter A are selected to ensure that this condition is satisﬁed. It is found with the ﬁrst principle and molecular dynamics simulations [10, 11, 30] that the criteria for for Si I ↔Si II PTs are linearly dependent on the Cauchy stress components normal to the cubic faces. We assume the same for the microscale experiments, where the role of defects is eﬀectively included. For cubic 8(a) (b) Figure 1: Grain distribution generated from DREAM.3D for (a) 55 grains showing the local orientations of individual grains (red=1, yellow=2, green=3) and (b) 910 grains. Each grain has a diﬀerent orientation that is randomly assigned to make sure the sample, on the whole, is texture-free. Files with complete information about orientation of each grain for both samples are given in supplementary material. to tetragonal PTs, the PT criteria are given by [40, 47] A→Mi : ad(σ1 + σ2) + bdσ3 >cd; Mi →A: ar(σ1 + σ2) + brσ3 <cr, (22) where ad,bd,cd,ar,br and cr are constants determined empirically. To make the thermodynamic PT con- ditions consistent with experimental conditions, the athermal threshold ki−0 is considered to be stress and volume fraction dependent, as described in detail in [47], and calculated based on the relations ki−0 = J[a1(ci)(σ1 + σ2) + a3(ci)σ3]; ak(ci) = dk + (rk −dk)ci; k= 1 and 3, (23) where dk and rk are the ﬁtting parameters, given in table 1. They are determined by substituting expressions for ki−0 from eq. (23) in the transformation criteria in eq. (12) with the driving forces from eq. (11) and some empirical data. Table 1: Material parameters including kinetic coeﬃcient λ(Pa · s)−1, dimensionless constants in the expression for eﬀective thresholds, as well as interaction coeﬃcient A, jump in the thermal energy ∆ ψθ, and elastic constants, all in GPa. λ A ∆ψθ d1 d3 r1 r3 0.02 2 2.47 0.082 0.111 -0.90 0.338 C11 0 C44 0 C12 0 C11 1 C33 1 C44 1 C66 1 C12 1 C13 1 167.5 80.1 65.0 174.76 136.68 60.24 42.22 102.0 68.0 94. Study of multivariant microstructure evolution A ﬁnite element implementation of the scale-free model is developed in the open-source FEM code deal.II [58] using 8-noded 3D cubic linear elements with ﬁrst-order interpolation and full integration. For such elements, calculations of volume averaged of any parameterain the undeformed conﬁguration is the sum of values a in each quadrature point divided by the number of quadrature points. Microstructure evolution is studied for polycrystalline samples containing two diﬀerent numbers of grains, 55 and 910, as shown in ﬁg. 1. The total number of the ﬁnite elements and integration points were ≃2.1 million and ≃16.7 million, respectively, for both cases. If we consider position vector rrrand volume fractions c1, c2, and c3 as the primary independent variables, then the total number of degrees of freedom is six times the number of the integration points. A 3D unit cube sample is constructed in DREAM.3D [59] with the required number of grains. Each grain in the sample is assigned an orientation randomly so that the overall sample remains texture free. Two types of compression are applied, strain-controlled and stress-controlled. For both cases, periodic boundary conditions are applied in directions 1 and 2 with averaged zero averaged strains in these directions. Application of the periodic boundary conditions signiﬁcantly simpliﬁed elimination of divergence of the computational procedure in comparison with other conditions. Such conditions are realized when Si is clamped in the 1-2 plane; a thin Si layer is attached to the rigid substrate, or within a shock wave. For the strain-controlled case, periodic boundary conditions are applied in the direction 3 as well, and a sample is subjected to a uniaxial compressive averaged strain in direction 3. For the stress-controlled loading, on the external planes orthogonal to axis 3, the sample is subjected to homogeneous compressive normal Cauchy stress in the deformed conﬁguration with zero shear stresses, i.e., like under the action of the liquid. Stress-controlled loading ends with constant ”pressure in liquid ” of 11 GPa. In total, four simulations are run with two diﬀerent numbers of grains and two diﬀerent loading conditions. 4.1. Strain-controlled loading For strain-controlled loading, the initial strain rate used, in the elastic regime, is 1×10−2s−1 and reduced to 5 ×10−5s−1 once the material starts to transform. While we can choose any strain rate, such low strain rates are chosen because they are not achievable in atomistic simulations. Figures 2 and 3 show the evolution of martensite at three intermediate stages (25%, 50%, and 75% of the simulation) and the ﬁnal stage of the simulation. The ﬁrst row shows the total volume fraction of martensite c followed by those for individual martensitic variants. The black lines in ﬁgs. 2 and 3 outline the grain boundaries for all the grains. The videos demonstrating the evolution of the volume fractions are provided in the supplementary material. Volume fractions of each martensitic variant ¯ci and martensite ¯caveraged over the sample based on Eq. 16 vs. strain are shown in Fig. 6. Nucleation starts mostly at the grain boundaries and triple junctions, which represent stress concentrators. Nucleation starts with the dominant variant, which produces maximum transformation work; two other variants appear in the same regions to accommodate the transformation strain and reduce 10internal stresses. A similar proportion between variants remains during further growth. In grains with diﬀerent orientations, growth occurs either along the grain boundaries or inside the grain, which is arrested either at grain boundaries or other martensitic units. In each unit full transformation to Si II occurs quickly, thus forming discrete Si II microstructure, as desired. With increasing strain, both Si II broadening of existing Si II regions and the appearance of new nuclei occur. At the end of the loading, PT is completed almost everywhere, with small residual Si I pockets. They are caused by internal stresses due to large transformation strains. For both numbers of grains, ¯c saturates at 96%. It can be clearly seen from ﬁgs. 2, 3 and 6 that the second and the third variants are dominating over the ﬁrst one, which looks contradictory. To better understand the reasons for these results, let, for simplicity and illustration, consider 5 grains: grain 1 oriented with [100] direction along axis 3 (variant 1); grains 2 and 3, rotated by ±90o about axis 1 (variant 1), and grains 4 and 5, rotated by ±90o about axis 2 (variant 3). Due to symmetry, this is still the same single crystal. If we treat it like a single crystal and transform it homogeneously till completion, we obtain c1 = 1, c2 = c3 = 0, and εεεt = εεεt1. However, if we treat it as a polycrystal, in grain 1, we will have the same c1 = 1, c2 = c3 = 0 and εεεt = εεεt1. In the local coordinate system of grains 2 and 3, this transformation strain looks like εεεt = εεεt2, i.e., c2 = 1, c1 = c3 = 0. Similarly, in the local coordinate system of grains 4 and 5, the transformation strain is εεεt3, i.e., c3 = 1, c1 = c2 = 0. After averaging these volume fractions over the entire sample, we obtain c1 = 1/5, c2 = c3 = 2/5, what we approximately observe in Fig. 6. The main point is that ci for each grain does not have a lot of sense unless the orientation of the grain is shown. That is why we give complete information about orientation of each grain in supplementary material and show orientations in ﬁg. 1a. The average over the sample ¯ ci does not have any physical sense because the orientation of grains is not taken into account; they cannot be used in the macroscopic theories. The average over the sample ¯c has clear physical sense. We suggest the following ways to present a multivariant structure in the polycrystal. For local presen- tation, one can show a triad of local crystallographic axes in each grain along with ﬁelds ci (ﬁg. 1a). One can present ﬁelds of six components of εεεtici for each variant Mi in the global coordinate system, which is 18 ﬁelds. For the above example with 5 grains, in each grain, we will have components of εεεt3 in the global coordinate system, which is consistent with the treatment of the aggregate as a single crystal. More compact is to present six ﬁelds of six components of the total transformation strain εεεt = ∑m i=1 εεεtici in the global coordinate system (Figs. 4 and 5), which takes into account in more averaged sense both an orientation of grain and ﬁelds ci. For the averaged description, one can use a plot of six components of ¯εεεt. As it follows from Figs. 4 and 5, normal components of εεεt vary between extremes -0.447 and 0.1753 corresponding to the full local transformation in single variant oriented along the global coordinate axes, despite zero averaged total lateral strains. Shear components vary between extremes ±0.31, also despite zero averaged. Colors corresponding to zero value of each component of transformation strain is clear from colors of large Si I regions at 25% transformation progress corresponding c = 0 in Figs. 2 and 3. For both grain sizes one sees strong heterogeneity of transformation strains from grain to grain and within grains. Note 11that ﬁelds at the surface do not completely represent ﬁelds in the entire volume, that is why some results may look counterintuitive. For example, while averaged ε33 t is larger than ε11 t and ε22 t , this is not evident from the surface ﬁelds. Despite the fact that for the smaller number of grains size of Si II units is larger, diﬀerence in ¯ c( ¯E33) (and even ¯ci( ¯E33)) for diﬀerent number of grains is small (ﬁg. 6). Initiation of PT occurs at the same stress σzz = −10.33 GPa for both grain sizes, and stress-strain curves in ﬁg. 9 also diﬀer insigniﬁcantly. That means that the current model does not describe experimentally observed eﬀect of the grain size on the Si I to Si II PT pressure or stress [24, 60–62]. The reason is that the current model does not include dislocations as local stress concentrators in bulk and at grain boundaries. This will be the next step in developing the current model. We can use the same approach for introducing discrete dislocations via the solution of the contact problem, as it was done in [51, 52] for small strains and 2D formulations. Of course, it is much more challenging to do this for 3D and large strains. Figures 7 and 8 shows the evolution of all components of Cauchy stresses throughout the simulation. It can be noticed from ﬁgs. 7 and 8 that the grain boundaries and triple junctions have the highest stresses of both signs, which cause nucleation of the dominating variant accompanied by two other variants and growth, often along the grain boundaries. Next, a large stress concentration of both signs appears at the phase interface, causing further nucleation in bulk (so-called autocatalytic eﬀect). The peak stresses are huge for both normal and even shear stresses. Thus, for small grains, σ22 varies from −45 to 35 GPa and σ33 varies from −40 to 10 GPa. Similar, shear stress σ12 varies from −20 to 20 GPa and σ23 varies from −15 to 15 GPa. For large grains, the magnitude of extremes in stresses is smaller by 5 to 10 GPa. Despite this diﬀerence for diﬀerent grain sizes, the macroscopic PT initiation stress σzz = −10.33 GPa is the same, and the entire σzz −εzz curve do not diﬀer signiﬁcantly. The initiation stress is determined by the transformation work, which depends on all components of the stress tensor. While stresses are diﬀerent, the transformation work may be approximately the same for both grain sizes. This is similar to results in [40], where a strong stress concentrator due to a dislocation in Si produced a relatively small contribution to the transformation work. 12Progress 25% 50% 75% 100% Σ3 i=1ci c1 c2 c3 Figure 2: Evolution of volume fractions of phases for strain-controlled loading of a sample with 55 grains. The ﬁgure shows snapshots at diﬀerent stages of completion of simulation (25%, 50%, 75%, and 100%) in diﬀerent columns for Si II, c, and each martensitic variant, ci. 13Progress 25% 50% 75% 100% Σ3 i=1ci c1 c2 c3 Figure 3: Evolution of volume fractions for strain-controlled loading of a sample with 910 grains. 14Progress 25% 50% 75% 100% εt 11 εt 22 εt 33 εt 12 εt 13 εt 23 Figure 4: Evolution of components of the transformation strain tensor εεεt for strain-controlled loading of a sample with 55 grains. 15Progress 25% 50% 75% 100% εt 11 εt 22 εt 33 εt 12 εt 13 εt 23 Figure 5: Evolution of the components of the transformation strain tensor εεεt for strain-controlled loading of a sample with 910 grains. 160.00 0.05 0.10 0.15 0.20 E33 (Lagrangian Strain) 0.0 0.2 0.4 0.6 0.8 1.0Volume fraction c c3 c2 c1 Evolution of volume fraction 55 grains 910 grains Figure 6: Volume fraction of each martensitic variant (¯ci) and the total martensite (¯c) averaged over the sample based on Eq. (16) vs. strain for strain-controlled loading. The lack of physical sense for ¯ ci is described in the text. The stress-strain plots for strain-controlled loading are given in ﬁg. 9. After PT starts at ¯E33 = −0.06 and ¯σ33 = −10.33 GPa for both small and large grains, the stress-strain plots continue along the elastic curve of the austenite with small nonlinearities. This behavior is because, initially, the transformation rate is very low, as can be noticed from ﬁg. 6. Si II nuclei are localized near stress concentrators without essential growth. Only at ¯E33 = −0.07 does intense growth start, which leads to a strong reduction in tangent modulus. Note that for a single crystal, the tangent modulus is getting negative at the onset of the PT, causing macroscopic instability [47]. In contrast, for polycrystals, the local mechanical instabilities due to PT and negative local tangent modulus are stabilized at the macroscale by arresting/slowing the growth of Si II regions by the grain boundaries and generating the internal back stresses. This is reﬂected by the positive tangent moduli in the stress-strain plots in ﬁg. 9. While intuitively, the more grain boundaries we have, the higher the tangent moduli should be, in fact, the response for 910 grains is slightly softer than that of 55 grains ﬁg. 9. The reasons are: (a) more triple junctions and nucleation sites for smaller grains leading to Si II regions; (b) smaller misorientation between neighboring grains leading to easier transfer of PT growth from grain to grain, and (c) a larger number of surrounding grains giving more chances to ﬁnd proper orientation for new nucleation caused by internal stresses in the transforming grains. Although there is a noticeable diﬀerence in the response for both cases, the maximum diﬀerence is <1 GPa or <10%. Such a small diﬀerence implies that it is unnecessary to treat a sample with such a large number of grains to estimate the macroscopic behavior of a polycrystal. Note that the Lagrangian elastic strain at the end of simulation, at ¯E33 = −0.22, is −0.1, i.e., comparable to the transformation strain. 17Progress 25% 50% 75% 100% σ11 σ22 σ33 σ12 σ13 σ23 Figure 7: Evolution of components of the Cauchy stress tensor for strain-controlled loading of a sample with 55 grains. 18Progress 25% 50% 75% 100% σ11 σ22 σ33 σ12 σ13 σ23 Figure 8: Evolution of the components of the Cauchy stress tensor for strain-controlled loading of a sample with 910 grains. 190.00 0.05 0.10 0.15 0.20 E33 (Lagrangian Strain) 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.033 (Cauchy Stress, GPa) Compression in Z direction 55 grains 910 grains Figure 9: Averaged Cauchy stress - Lagrangian strain plot for strain-controlled loading for 55 grains and 910 grains. The dot marker represents the onset of phase transforma- tion. Figures 10 and 11 shows the pole ﬁgures for 55 and 910 grains, respectively. Figure 10(a) and Figure 11(a) for initial austenite demonstrate quite an even spread in all the directions because the random texture of the stress-free initial conﬁguration was chosen. Figure 10(a) shows few low-density regions because of the lower number of grains. Comparing the initial (Figure 10(a)) and ﬁnal (Figure 10(b)) austenite for 55 grains, we can clearly notice depletion of the austenite grains due to their transformation to martensite. Similar depletion is not noticed in Figure 11(b) for 910 grains because many grains do not completely transform to martensite. The increase in density in Figure 10(b) or Figure 11(b) is because of the rotation of part of or entire austenitic grains, which was observed for single crystal as well [47]. Figure 10(c)-(e) and Figure 11(c)-(e) present the pole ﬁgures for the three martensitic variants at the last stage of simulations. As expected, there is a 90 ◦ rotation relation between the ﬁrst and the second or the third variant about the (001) axis. The trends in the volume fractions of the individual martensitic variant in Figures 10 and 11 match that of Figure 6. The ﬁrst variant is the lowest in both cases, as only the grains that have their c-axis aligned with the loading direction can transform to the ﬁrst variant. As for the second or the third variants, they primarily need to be oriented such that their a or b-axis needs to be aligned with the loading direction. But because of the boundary conditions used, there are lateral stresses which can contribute to giving a resultant load in the preferred axes assisting in the transformation. This phenomenon is not possible for the ﬁrst variant as the lateral stresses are only a fraction of the applied load and cannot be the primary contributor to fulﬁlling the phase transformation criteria. 4.2. Stress-controlled loading In stress-controlled, the stress is applied at a rate of -4 MPa/s till it reaches -11 GPa and held constant thereafter. Figures 14 and 15 and ﬁgs. 18 and 19 show the evolution of the volume fraction of Si II and the individual martensitic variants as well as all stress components at diﬀerent simulation stages for 55 and 20(a)(b)(c)(d)(e) Figure 10: Pole ﬁgures of (a) initial austenite, (b) residual austenite, (c) ﬁnal martensitic variant M1, (d) M2, and (e) M3 for strain-controlled loading of 55 grains. The minimum and maximum intensities for each direction are shown in the legend corresponding to each ﬁgure. 21Figure 11: Pole ﬁgures of (a) initial austenite, (b) residual austenite, (c) ﬁnal martensitic variant M1, (d) M2, and (e) M3 for strain-controlled loading of 55 grains. The minimum and maximum intensities for each direction are shown in the legend corresponding to each ﬁgure. 22910 grins. The videos showing the evolution of the volume fractions are provided in the supplementary material. Volume fraction of each martensitic variant ¯ci averaged over the sample based on Eq. 16 and ¯cvs. strain is shown in Fig. 13. There is no signiﬁcant diﬀerence, in comparison with the strain-controlled case, in nucleation at grain boundaries and triple junctions and character of growth of martensitic units, stress concentrations, and that ¯c2 ≃¯c3 ≃2¯c1. The same discussion on the luck of the physical sense in ¯ ci is valid; ¯c has a physical meaning only. 0.00 0.02 0.04 0.06 0.08 0.10 0.12 E33 (Lagrangian Strain) 0 2 4 6 8 10 1233 (Cauchy Stress, GPa) Compression in Z direction 55 grains 910 grains Figure 12: True stress-strain plot for stress-controlled loading for 55 and 910 grains. The dot marker represents the onset of phase transformation. 0.00 0.02 0.04 0.06 0.08 0.10 0.12 E33 (Lagrangian Strain) 0.0 0.1 0.2 0.3 0.4 0.5Volume fraction c c3 c2 c1 Evolution of volume fraction 55 grains 910 grains Figure 13: Volume fraction of each martensitic variant ¯ci and total martensite ¯c) averaged over the sample based on Eq. 16 vs. strain for stress-controlled loading. The lack of physical sense for ¯ci is described in the text. Stress-controlled compression for both numbers of grains is up to 42% transformation to Si II, after which process diverges. The stress-strain plots for strain-controlled loading are given in Figure 12. The PT starts immediately at -11 GPa and continues to the end of simulations at E33 = −0.116. These values are larger than those for strain-controlled loading: at -11 GPa, we have E33 = −0.063 and c= 2.4 ×10−3 only; however, at E33 = −0.116 one gets c = 0.362 for strain-controlled loading. The possibility of larger strains and transformation progress at -11 GPa is related to less constraint deformation at the horizontal external surfaces. Periodic conditions for displacements along the axis 3 for strain-controlled loading lead to more homogenous PT near both horizontal surfaces and small deviations from the ﬂat surfaces. In contrast, for stress-controlled loading, lack of periodic conditions along the axis 3 leads to much pronounced PT near the upper horizontal surface, which spreads in the upper part of the sample. This leads to the loss of stability of Si II nuclei near stress concentrators, their fast growth, interaction, coalescence, and more pronounced auto-catalytic eﬀect. Thus, speciﬁc boundary conditions are very inﬂuential, which is necessary to take into account in the problem formulation. The diﬀerence in volume fractions of Mi for 55 and 910 grains in ﬁg. 6 and ¯c is much smaller than for the strain-controlled loading in Fig. 6, again due to less restrictive boundary conditions. The peak stresses are large but smaller than for strain-controlled loading (ﬁgs. 18 and 19). Thus, for 23Progress 25% 50% 75% 100% Σ3 i=1ci c1 c2 c3 Figure 14: Evolution of volume fractions of phases for stress-controlled loading of a sample with 55 grains. 24Progress 25% 50% 75% 100% Σ3 i=1ci c1 c2 c3 Figure 15: Evolution of volume fractions of phases for strain-controlled loading of a sample with 910 grains. 25Progress 25% 50% 75% 100% εt 11 εt 22 εt 33 εt 12 εt 13 εt 23 Figure 16: Evolution of the components of the transformation strain tensor for stress-controlled loading of a sample with 55 grains. 26Progress 25% 50% 75% 100% εt 11 εt 22 εt 33 εt 12 εt 13 εt 23 Figure 17: Evolution of the components of the transformation strain tensor for strain-controlled loading of a sample with 910 grains. 27Progress 25% 50% 75% 100% σ11 σ22 σ33 σ12 σ13 σ23 Figure 18: Evolution of the components of the Cauchy stress tensor for stress-controlled loading of a sample with 55 grains. 28Progress 25% 50% 75% 100% σ11 σ22 σ33 σ12 σ13 σ23 Figure 19: Evolution of the components of the Cauchy stress tensor for strain-controlled loading of a sample with 910 grains. 29small grains, σ22 varies from −33 to 30 GPa and σ33 varies from −25 to 5 GPa. Similar, shear stress σ12 and σ23 vary from −15 to 15 GPa. For large grains, the magnitude of extremes in stresses are smaller by 5 to 10 GPa, like for strain-controlled loading. Lower peak stresses are partially caused by a smaller volume fraction of Si II. Figures 20 and 21 show the pole ﬁgures for 55 and 910 grains, respectively, for the stress-controlled loading. Figure 20(a) and Figure 21(a) show initial austenite texture for both cases, which are the same as the ones chosen for strain-controlled loading. For both 55 and 910 grains, there is no signiﬁcant depletion of the austenite, unlike for the strain-controlled loading, because the ¯ c = 0 .42 only. This is reﬂected in the small diﬀerence between ﬁg. 20(a) and ﬁg. 20(b), and in sparsely distributed ﬁg. 20(c)-(e). Contrary to this, ﬁg. 21(c)-(e) show the pole ﬁgures with more uniform distributions because grains in many diﬀerent orientations start transforming to martensite like in the case of ﬁg. 11. 30Figure 20: Pole ﬁgures of (a) initial austenite, (b) residual austenite, (c) ﬁnal martensitic variant M1, (d) M2, and (e) M3 for stress-controlled loading of 55 grains. 31Figure 21: Pole ﬁgures of (a) initial austenite, (b) residual austenite, (c) ﬁnal martensitic variant M1, (d) M2, and (e) M3 for stress-controlled loading of 910 grains. 325. Concluding remarks In the paper, the ﬁrst scale-free PFA modeling of the multivariant martensitic PT from cubic Si I to tetrag- onal Si II in a polycrystalline aggregate with up to 1000 grains is presented. All computational challenges related to large and very anisotropic transformation strain tensors, the stress-tensor dependent athermal dis- sipative threshold for the PT, and potential elastic instabilities due to a variety of complex loadings in each grain, are overcome. The importance of the simulations should also be stressed by the fact that since Si II does not exist under ambient conditions, its microstructure cannot be studied using traditional post-mortem methods (SEM, TEM, etc.). For a single crystal, positions of Si I-Si II interfaces can be determined using in- situ high-pressure Laue diﬀraction, but still, in combination with molecular dynamics [37]. For polycrystals, this is currently impossible. Coupled evolution of discrete martensitic microstructure, volume fractions of martensitic variants, and Si II, stress and transformation strain tensors, and texture are presented and analyzed. It is demonstrated that the volume fraction of each martensitic variant ci in each grain does not have a lot of sense unless the orientation of the grain is explicitly shown. The average over the sample ¯ci does not have any physical sense because the orientation of grains is not taken into account; they are misleading and cannot be used in the macroscopic theories. Macroscopic variables eﬀectively representing multivariant transformational behavior are introduced. One can present ﬁelds of six components of εεεtici for each variant Mi in the global coordinate system. More compact is to present six components of the total transformation strain εεεt = ∑m i=1 εεεtici in the global coordinate system. For the averaged description, one can utilize six components of ¯εεεt. For strain-controlled uniaxial compression with periodic conditions in all directions, almost complete (96%) PT was reached with small pockets of residual Si I. For stress-controlled uniaxial compression without periodic conditions in the loading direction, 42% of completion of was achieved at -11 GPa, much larger than 0.24% for the same axial stress for strain-controlled loading, but relatively close volume fraction of Si II was reached for the same strain. Lack of periodic conditions in the loading direction results in less constraint deformation at the horizontal external surfaces and more localized transformation near one of them, which leads to loss of stability of Si II nuclei near stress concentrators, their fast growth, interaction, and coalescence. Thus, tiny detail in the boundary conditions is very inﬂuential, which is necessary to take into account in the problem formulation. In contrast to a single crystal, the local mechanical instabilities due to PT and negative local tangent modulus are stabilized at the macroscale by arresting/slowing the growth of Si II regions by the grain boundaries and generating the internal back stresses. This leads to increasing magnitude of stress during PT. Large transformation strains and grain boundaries lead to huge internal stresses, which aﬀect the mi- crostructure evolution and macroscopic behavior. The peak stresses reach 45 GPa in compression, 35 GPa in tension, and 20 GPa in shear for strain-controlled loading of 910 grains; for 55 grains, the magnitude of extremes in stresses are smaller by 5 to 10 GPa. For stress-controlled loading and small grains, the peak 33stresses reach 35 GPa in compression, 30 GPa in tension, and 15 GPa in shear; for large grains, they are smaller by 5-10 GPa, like for strain-controlled loading. Lower peak stresses for stress-controlled loading are partially caused by a smaller volume fraction of Si II. Despite these diﬀerences, the macroscopic (overall) stress-strain and transformational behavior for 55 and 910 grains are quite close and diﬀer less than by 10% for strain-controlled loading and even less for stress-controlled one. On the good side, this allows the de- termination of the macroscopic constitutive equations by treating aggregate with a small number of grains. On the bad side, that means that the current model does not describe experimentally observed eﬀect of the grain size on the Si I to Si II PT pressure or stress [24, 60–62]. The reason is that the current model does not include dislocations as local stress concentrators in bulk and at grain boundaries. This will be the next step in developing the current model. We can use the same approach for introducing discrete dislocations via the solution of the contact problem, as it was done in [51, 52] for small strains and 2D formulations. Of course, it is much more challenging to do this for 3D and large strains. A more realistic model of the grain boundaries is required as well. The developed methodology can be used for studying various PTs with large transformation strains (e.g., hexagonal and rhombohedral graphite to hexagonal and cubic diamond, similar PTs from graphite-like BN to superhard diamond-like BN, PTs in semiconducting Ge and GaSb, etc.) and for further development for plastic strain-induced PTs. Acknowledgement The support of NSF (CMMI-1943710) and Iowa State University (Vance Coﬀman Faculty Chair Profes- sorship) is gratefully acknowledged. The simulations were performed at Extreme Science and Engineering Discovery Environment (XSEDE), allocation TG-MSS170015. References [1] G. A. Heath, T. J. Silverman, M. Kempe, M. Deceglie, D. Ravikumar, T. Remo, H. Cui, P. Sinha, C. Libby, S. Shaw, et al., Research and development priorities for silicon photovoltaic module recycling to support a circular economy, Nature Energy 5 (7) (2020) 502–510. [2] J. Chelikowsky, Introduction: Silicon in all its forms, in: P. Siﬀert, E. F. Krimmel (Eds.), Silicon: Evolution and Future of a Technology, Springer Berlin Heidelberg, Berlin, Heidelberg, 2004, pp. 1–22. [3] V. Domnich, D. Ge, Y. Gogotsi, Indentation-induced phase transformations in semiconductors, in: V. Domnich, Y. Gogotsi (Eds.), High Pressure Surface Science and Engineering; Section 5.1, Institute of Physics, Bristol, 2004, pp. 381–442. [4] M. S. Kiran, B. Haberl, J. E. Bradby, J. S. Williams, Chapter Five - Nanoindentation of Silicon and Germanium, in: L. Romano, V. Privitera, C. Jagadish (Eds.), Defects in Semiconductors, Vol. 91 of Semiconductors and Semimetals, Elsevier, 2015, pp. 165–203. doi:https://doi.org/10.1016/bs. semsem.2014.12.002. 34[5] S. Goel, X. Luo, A. Agrawal, R. L. Reuben, Diamond machining of silicon: a review of advances in molecular dynamics simulation, International Journal of Machine Tools and Manufacture 88 (2015) 131–164. [6] Y. Ikoma, K. Hayano, K. Edalati, K. Saito, Q. Guo, Z. Horita, Phase transformation and nanograin reﬁnement of silicon by processing through high-pressure torsion, Applied Physics Letters 101 (12) (2012) 121908. [7] Y. Ikoma, K. Hayano, K. Edalati, K. Saito, Q. Guo, Z. Horita, T. Aoki, D. J. Smith, Fabrication of nanograined silicon by high-pressure torsion, Journal of Materials Science 49 (2014) 6565–6569. [8] J. A. Patten, H. Cherukuri, J. Yan, Ductile-regime machining of semiconductors and ceramics, in: V. Domnich, Y. Gogotsi (Eds.), High-Pressure Surface Science and Engineering, Institute of Physics, Bristol, 2004, pp. 543–632. [9] Z. Malyushitskaya, Mechanisms responsible for the strain-induced formation of metastable high-pressure Si, Ge, and GaSb phases with distorted tetrahedral coordination, Inorganic Materials 35 (5) (1999) 425– 430. [10] V. I. Levitas, H. Chen, L. Xiong, Lattice instability during phase transformations under multiaxial stress: Modiﬁed transformation work criterion, Phys. Rev. B 96 (2017) 054118. doi:10.1103/PhysRevB.96. 054118. [11] V. I. Levitas, H. Chen, L. Xiong, Triaxial-Stress-Induced Homogeneous Hysteresis-Free First-Order Phase Transformations with Stable Intermediate Phases, Phys. Rev. Lett. 118 (2017) 025701. doi: 10.1103/PhysRevLett.118.025701. [12] V. I. Levitas, High-pressure mechanochemistry: Conceptual multiscale theory and interpretation of experiments, Phys. Rev. B 70 (2004) 184118. doi:10.1103/PhysRevB.70.184118. [13] V. I. Levitas, High pressure phase transformations revisited, Journal of Physics: Condensed Matter 30 (16) (2018) 163001. doi:10.1088/1361-648X/aab4b0. [14] V. I. Levitas, High-pressure phase transformations under severe plastic deformation by torsion in rota- tional anvils, Materials Transactions 60 (7) (2019) 1294–1301. [15] V. D. Blank, E. I. Estrin, Phase transitions in solids under high pressure, CRC Press, 2013. [16] P. W. Bridgman, Eﬀects of High Shearing Stress Combined with High Hydrostatic Pressure, Phys. Rev. 48 (1935) 825–847. doi:10.1103/PhysRev.48.825. [17] K. Edalati, Z. Horita, A review on high-pressure torsion (HPT) from 1935 to 1988, Materials Science and Engineering: A 652 (2016) 325–352. doi:https://doi.org/10.1016/j.msea.2015.11.074. 35[18] Y. Gao, Y. Ma, Q. An, V. Levitas, Y. Zhang, B. Feng, J. Chaudhuri, W. A. Goddard, Shear driven formation of nano-diamonds at sub-gigapascals and 300 K, Carbon 146 (2019) 364–368. doi:https: //doi.org/10.1016/j.carbon.2019.02.012. [19] V. I. Levitas, L. K. Shvedov, Low-pressure phase transformation from rhombohedral to cubic BN: Experiment and theory, Phys. Rev. B 65 (2002) 104109. doi:10.1103/PhysRevB.65.104109. [20] C. Ji, V. I. Levitas, H. Zhu, J. Chaudhuri, A. Marathe, Y. Ma, Shear-induced phase transition of nanocrystalline hexagonal boron nitride to wurtzitic structure at room temperature and lower pressure, Proceedings of the National Academy of Sciences 109 (47) (2012) 19108–19112. [21] K. Pandey, V. I. Levitas, In situ quantitative study of plastic strain-induced phase transformations under high pressure: Example for ultra-pure Zr, Acta Materialia 196 (2020) 338–346. doi:https: //doi.org/10.1016/j.actamat.2020.06.015. [22] V. Levitas, F. Lin, K. Pandey, S. Yesudhas, C. Park, Laws of high-pressure phase and nanostructure evolution and severe plastic ﬂow, September 9, Research Square (2022) 29 doi:https://doi.org/10. 21203/rs.3.rs-1998605/v1. [23] M. Aleksandrova, V. Blank, S. Buga, Phase transitions in Ge and Si under shear deformation at pressure up to 12 GPa conditions and P-T- gamma[shear] diagrams of these elements, Physics of the Solid State 35 (5) (1993) 1308–17. [24] S. Yesudhas, V. Levitas, F. Lin, K. Pandey, J. Smith, Plastic strain induced phase transformations in micron and nano silicon, in preparation(2023). [25] G. Voronin, C. Pantea, T. Zerda, L. Wang, Y. Zhao, In situ x-ray diﬀraction study of silicon at pressures up to 15.5 GPa and temperatures up to 1073 K, Physical Review B 68 (2) (2003) 020102. [26] J. Pokluda, M. ˇCern` y, M.ˇSob, Y. Umeno, Ab initio calculations of mechanical properties: Methods and applications, Progress in Materials Science 73 (2015) 127–158. [27] Y. Umeno, M. ˇCern` y, Eﬀect of normal stress on the ideal shear strength in covalent crystals, Physical Review B 77 (10) (2008) 100101. [28] R. Telyatnik, A. Osipov, S. Kukushkin, Ab initio modelling of nonlinear elastoplastic properties of diamond-like C, SiC, Si, Ge crystals upon large strains., Materials Physics & Mechanics 29 (1) (2016) 1–16. [29] M. ˇCern` y, P.ˇReh´ ak, Y. Umeno, J. Pokluda, Stability and strength of covalent crystals under uniaxial and triaxial loading from ﬁrst principles, Journal of Physics: Condensed Matter 25 (3) (2012) 035401. 36[30] N. A. Zarkevich, H. Chen, V. I. Levitas, D. D. Johnson, Lattice instability during solid-solid structural transformations under a general applied stress tensor: Example of Si I →Si II with metallization, Physical Review Letters 121 (16) (2018) 165701. [31] H. Chen, N. A. Zarkevich, V. I. Levitas, D. D. Johnson, X. Zhang, Fifth-degree elastic energy for predictive continuum stress–strain relations and elastic instabilities under large strain and complex loading in silicon, NPJ Computational Materials 6 (1) (2020) 115. [32] V. I. Levitas, Phase-ﬁeld theory for martensitic phase transformations at large strains, International Journal of Plasticity 49 (2013) 85–118. [33] P. Valentini, W. W. Gerberich, T. Dumitric˘ a, Phase-Transition Plasticity Response in Uniaxially Com- pressed Silicon Nanospheres, Phys. Rev. Lett. 99 (2007) 175701.doi:10.1103/PhysRevLett.99.175701. [34] D. Chrobak, N. Tymiak, A. Beaber, O. Ugurlu, W. W. Gerberich, R. Nowak, Deconﬁnement leads to changes in the nanoscale plasticity of silicon, Nature Nanotechnology 6 (8) (2011) 480–484. [35] H. Chen, V. I. Levitas, L. Xiong, Amorphization induced by 60 ◦ shuﬄe dislocation pileup against diﬀerent grain boundaries in silicon bicrystal under shear, Acta Materialia 179 (2019) 287–295. [36] L. C. Zhang, W. C. D. Cheong, Molecular dynamics simulation of phase transformations in monocrys- talline silicon, in: V. Domnich, Y. Gogotsi (Eds.), High Pressure Surface Science and Engineering, Institute of Physics, Bristol, 2004, pp. 57–119. [37] H. Chen, V. I. Levitas, D. Popov, N. Velisavljevic, Nontrivial nanostructure, stress relaxation mecha- nisms, and crystallography for pressure-induced Si-I →Si-II phase transformation, Nature Communica- tions 13 (1) (2022) 982. doi:10.1038/S41467-022-28604-1 . [38] V. I. Levitas, Phase ﬁeld approach for stress- and temperature-induced phase transformations that satisﬁes lattice instability conditions. Part I. General theory, International Journal of Plasticity 106 (2018) 164–185. doi:10.1016/J.IJPLAS.2018.03.007. [39] H. Babaei, V. I. Levitas, Phase-ﬁeld approach for stress- and temperature-induced phase transformations that satisﬁes lattice instability conditions. Part 2. Simulations of phase transformations Si I ↔Si II, International Journal of Plasticity 107 (2018) 223–245. doi:10.1016/j.ijplas.2018.04.006. [40] H. Babaei, V. I. Levitas, Eﬀect of 60 ◦ dislocation on transformation stresses, nucleation, and growth for phase transformations between silicon I and silicon II under triaxial loading: Phase-ﬁeld study, Acta Materialia 177 (2019) 178–186. [41] H. Babaei, V. I. Levitas, Stress-Measure Dependence of Phase Transformation Criterion under Finite Strains: Hierarchy of Crystal Lattice Instabilities for Homogeneous and Heterogeneous Transformations, Phys. Rev. Lett. 124 (2020) 075701. doi:10.1103/PhysRevLett.124.075701. 37[42] H. Babaei, A. Basak, V. I. Levitas, Algorithmic aspects and ﬁnite element solutions for advanced phase ﬁeld approach to martensitic phase transformation under large strains, Computational Mechanics 64 (4) (2019) 1177–1197. doi:10.1007/S00466-019-01699-Y . [43] V. I. Levitas, M. Javanbakht, Phase-ﬁeld approach to martensitic phase transformations: Eﬀect of martensite-martensite interface energy, International Journal of Materials Research 102 (6) (2011) 652– 665. doi:10.3139/146.110529. [44] V. I. Levitas, A. V. Idesman, D. L. Preston, Microscale simulation of martensitic microstructure evolu- tion, Physical Review Letters 93 (10) (2004) 105701. [45] A. V. Idesman, V. I. Levitas, D. L. Preston, J.-Y. Cho, Finite element simulations of martensitic phase transitions and microstructures based on a strain softening model, Journal of the Mechanics and Physics of Solids 53 (3) (2005) 495–523. [46] S. E. Esfahani, I. Ghamarian, V. I. Levitas, P. C. Collins, Microscale phase ﬁeld modeling of the marten- sitic transformation during cyclic loading of NiTi single crystal, International Journal of Solids and Structures 146 (2018) 80–96. [47] H. Babaei, V. I. Levitas, Finite-strain scale-free phase-ﬁeld approach to multivariant martensitic phase transformations with stress-dependent eﬀective thresholds, Journal of the Mechanics and Physics of Solids 144 (2020) 104114. [48] V. I. Levitas, M. Javanbakht, Phase transformations in nanograin materials under high pressure and plastic shear: nanoscale mechanisms, Nanoscale 6 (1) (2014) 162–166. [49] M. Javanbakht, V. I. Levitas, Nanoscale mechanisms for high-pressure mechanochemistry: A phase ﬁeld study, Journal of Materials Science 53 (19) (2018) 13343–13363. doi:10.1007/S10853-018-2175-X . [50] M. Javanbakht, V. I. Levitas, Phase ﬁeld simulations of plastic strain-induced phase transformations under high pressure and large shear, Phys. Rev. B 94 (2016) 214104. doi:10.1103/PhysRevB.94. 214104. [51] V. I. Levitas, S. E. Esfahani, I. Ghamarian, Scale-Free Modeling of Coupled Evolution of Discrete Dislocation Bands and Multivariant Martensitic Microstructure, Physical Review Letters 121 (20) (2018) 205701. doi:10.1103/PHYSREVLETT.121.205701/FIGURES/4/MEDIUM. [52] S. E. Esfahani, I. Ghamarian, V. I. Levitas, Strain-induced multivariant martensitic transformations: A scale-independent simulation of interaction between localized shear bands and microstructure, Acta Materialia (2020) 430–443. [53] V. I. Levitas, Elastic model for stress tensor-induced martensitic transformation and lattice instability in silicon under large strains, Materials Research Letters 5 (8) (2017) 554–561. doi:10.1080/21663831. 2017.1362054. 38[54] R. Hill, On Macroscopic Eﬀects Of Heterogeneity In Elastoplastic Media At Finite Strain, Mathe- matical Proceedings of the Cambridge Philosophical Society 95 (3) (1984) 481–494. doi:10.1017/ S0305004100061818. [55] V. I. Levitas, Some relations for ﬁnite inelastic deformation of microheterogeneous materials with mov- ing discontinuity surfaces, in: A. Pineau, A. Zaoui (Eds.), IUTAM Symposium on Micromechanics of Plasticity and Damage of Multiphase Materials, Springer Netherlands, Dordrecht, 1996, pp. 313–320. [56] H. Petryk, Macroscopic rate-variables in solids undergoing phase transformation, Journal of the Me- chanics and Physics of Solids 46 (5) (1998) 873–894. doi:10.1016/S0022-5096(97)00099-9. [57] J. D. Schall, G. Gao, J. A. Harrison, Elastic constants of silicon materials calculated as a function of temperature using a parametrization of the second-generation reactive empirical bond-order potential, Physical Review B 77 (11) (2008) 115209. [58] W. Bangerth, R. Hartmann, G. Kanschat, deal.IIA general-purpose object-oriented ﬁnite element library, ACM Transactions on Mathematical Software (TOMS) 33 (4) (8 2007).doi:10.1145/1268776.1268779. [59] M. A. Groeber, M. A. Jackson, DREAM. 3D: A digital representation environment for the analysis of microstructure in 3D, Integrating Materials and Manufacturing Innovation 3 (1) (2014) 56–72. [60] Z. Zeng, Q. Zeng, M. Ge, B. Chen, H. Lou, X. Chen, J. Yan, W. Yang, H.-k. Mao, D. Yang, et al., Origin of plasticity in nanostructured silicon, Physical Review Letters 124 (18) (2020) 185701. [61] Y. Xuan, L. Tan, B. Cheng, F. Zhang, X. Chen, M. Ge, Q. Zeng, Z. Zeng, Pressure-induced phase transitions in nanostructured silicon, The Journal of Physical Chemistry C 124 (49) (2020) 27089–27096. [62] S. H. Tolbert, A. B. Herhold, L. E. Brus, A. Alivisatos, Pressure-induced structural transformations in Si nanocrystals: surface and shape eﬀects, Physical Review Letters 76 (23) (1996) 4384. 39",
      "references": [
        "Research and development priorities for silicon photovoltaic module recycling to support a circular economy",
        "Introduction: Silicon in all its forms",
        "Indentation-induced phase transformations in semiconductors",
        "Chapter Five - Nanoindentation of Silicon and Germanium",
        "Diamond machining of silicon: a review of advances in molecular dynamics simulation",
        "Phase transformation and nanograin refinement of silicon by processing through high-pressure torsion",
        "Fabrication of nanograined silicon by high-pressure torsion",
        "Ductile-regime machining of semiconductors and ceramics",
        "Mechanisms responsible for the strain-induced formation of metastable high-pressure Si, Ge, and GaSb phases with distorted tetrahedral coordination",
        "Lattice instability during phase transformations under multiaxial stress: Modified transformation work criterion",
        "Triaxial-Stress-Induced Homogeneous Hysteresis-Free First-Order Phase Transformations with Stable Intermediate Phases",
        "High-pressure mechanochemistry: Conceptual multiscale theory and interpretation of experiments",
        "High pressure phase transformations revisited",
        "High-pressure phase transformations under severe plastic deformation by torsion in rotational anvils",
        "Phase transitions in solids under high pressure",
        "Effects of High Shearing Stress Combined with High Hydrostatic Pressure",
        "A review on high-pressure torsion (HPT) from 1935 to 1988",
        "Shear driven formation of nano-diamonds at sub-gigapascals and 300 K",
        "Low-pressure phase transformation from rhombohedral to cubic BN: Experiment and theory",
        "Shear-induced phase transition of nanocrystalline hexagonal boron nitride to wurtzitic structure at room temperature and lower pressure",
        "In situ quantitative study of plastic strain-induced phase transformations under high pressure: Example for ultra-pure Zr",
        "Laws of high-pressure phase and nanostructure evolution and severe plastic flow",
        "Phase transitions in Ge and Si under shear deformation at pressure up to 12 GPa conditions and P-T- gamma[shear] diagrams of these elements",
        "Plastic strain induced phase transformations in micron and nano silicon",
        "In situ x-ray diffraction study of silicon at pressures up to 15.5 GPa and temperatures up to 1073 K",
        "Ab initio calculations of mechanical properties: Methods and applications",
        "Effect of normal stress on the ideal shear strength in covalent crystals",
        "Ab initio modelling of nonlinear elastoplastic properties of diamond-like C, SiC, Si, Ge crystals upon large strains.",
        "Stability and strength of covalent crystals under uniaxial and triaxial loading from first principles",
        "Lattice instability during solid-solid structural transformations under a general applied stress tensor: Example of Si I →Si II with metallization",
        "Fifth-degree elastic energy for predictive continuum stress–strain relations and elastic instabilities under large strain and complex loading in silicon",
        "Phase-ﬁeld theory for martensitic phase transformations at large strains",
        "Phase-Transition Plasticity Response in Uniaxially Com- pressed Silicon Nanospheres",
        "Deconﬁnement leads to changes in the nanoscale plasticity of silicon",
        "Amorphization induced by 60 ◦ shuﬄe dislocation pileup against diﬀerent grain boundaries in silicon bicrystal under shear",
        "Molecular dynamics simulation of phase transformations in monocrys- talline silicon",
        "Nontrivial nanostructure, stress relaxation mecha- nisms, and crystallography for pressure-induced Si-I →Si-II phase transformation",
        "Phase ﬁeld approach for stress- and temperature-induced phase transformations that satisﬁes lattice instability conditions. Part I. General theory",
        "Phase-ﬁeld approach for stress- and temperature-induced phase transformations that satisﬁes lattice instability conditions. Part 2. Simulations of phase transformations Si I ↔Si II",
        "Eﬀect of 60 ◦ dislocation on transformation stresses, nucleation, and growth for phase transformations between silicon I and silicon II under triaxial loading: Phase-ﬁeld study",
        "Stress-Measure Dependence of Phase Transformation Criterion under Finite Strains: Hierarchy of Crystal Lattice Instabilities for Homogeneous and Heterogeneous Transformations",
        "Algorithmic aspects and ﬁnite element solutions for advanced phase ﬁeld approach to martensitic phase transformation under large strains",
        "Phase-ﬁeld approach to martensitic phase transformations: Eﬀect of martensite-martensite interface energy",
        "Microscale simulation of martensitic microstructure evolu- tion",
        "Finite element simulations of martensitic phase transitions and microstructures based on a strain softening model",
        "Microscale phase ﬁeld modeling of the marten- sitic transformation during cyclic loading of NiTi single crystal",
        "Finite-strain scale-free phase-ﬁeld approach to multivariant martensitic phase transformations with stress-dependent eﬀective thresholds",
        "Phase transformations in nanograin materials under high pressure and plastic shear: nanoscale mechanisms",
        "Nanoscale mechanisms for high-pressure mechanochemistry: A phase ﬁeld study",
        "Phase ﬁeld simulations of plastic strain-induced phase transformations under high pressure and large shear",
        "Scale-Free Modeling of Coupled Evolution of Discrete Dislocation Bands and Multivariant Martensitic Microstructure",
        "Strain-induced multivariant martensitic transformations: A scale-independent simulation of interaction between localized shear bands and microstructure",
        "Elastic model for stress tensor-induced martensitic transformation and lattice instability in silicon under large strains",
        "On Macroscopic Eﬀects Of Heterogeneity In Elastoplastic Media At Finite Strain",
        "Some relations for ﬁnite inelastic deformation of microheterogeneous materials with mov- ing discontinuity surfaces",
        "Macroscopic rate-variables in solids undergoing phase transformation",
        "Elastic constants of silicon materials calculated as a function of temperature using a parametrization of the second-generation reactive empirical bond-order potential",
        "deal.IIA general-purpose object-oriented ﬁnite element library",
        "DREAM. 3D: A digital representation environment for the analysis of microstructure in 3D",
        "Origin of plasticity in nanostructured silicon",
        "Pressure-induced phase transitions in nanostructured silicon",
        "Pressure-induced structural transformations in Si nanocrystals: surface and shape eﬀects"
      ],
      "meta_data": {
        "arxiv_id": "2302.05952v1",
        "authors": [
          "Hamed Babaei",
          "Raghunandan Pratoori",
          "Valery I. Levitas"
        ],
        "published_date": "2023-02-12T16:34:04Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "[draft]",
        "methodology": "[draft]",
        "experimental_setup": "[draft]",
        "limitations": "[draft]",
        "future_research_directions": "[draft]",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Localized Zeroth-Order Prompt Optimization",
      "full_text": "Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) On the early stages of vapor bubble growth: From the surface-tension to the inertial regime Orr Avni, Eran Sher, and Yuval Dagan ∗ Faculty of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, 320003, Israel. (Dated: May 28, 2024) This paper presents a new analytical model for the early stages of vapor bubble growth in superheated liquids. The model bridges a gap in current knowledge by focusing on the surface tension-controlled, near-equilibrium growth regime and its transition to an inertia-controlled regime. A unified analytical model is derived by combining a perturbation method for the initial growth regime with a complementary outer solution to model the subsequent bubble growth rate. The model successfully predicts the initial delay in bubble growth due to surface tension effects. Two non-dimensional parameters govern this delay period: the initial perturbation from the equilibrium radius and the Ohnesorge number at the onset of nucleation. The Ohnesorge number encapsulates the interplay between viscous damping and surface tension forces acting on the bubble during its early growth stages. The analytical solutions presented here allow for quantifying the surface-tension, inertial, and transitional regimes while establishing a simple criterion for estimating the influence of thermal effects on early-stage growth. Our findings emphasize the significance of considering the surface tension delay, particularly for short timescales. The derived analytical solutions and the obtained correlation for surface-tension-induced delay may prove a practical tool and could be integrated into existing models of vapor bubble growth. I. INTRODUCTION Nucleation of vapor bubbles within a superheated liquid is a fundamental yet complex and elusive phase-change phenomenon. The ubiquity and role vapor bubbles play in natural processes [1, 2], as well as wide-ranging industrial [3–7], and medical [8–10] applications poses a solid scientific research motivation. Embryonic vapor nucleons constantly form spontaneously in superheated liquids due to the liquid’s inherent local density fluctuations; the contrasting effects of the inward-directed surface tension and outward-directed pressure acting on the nucleated bubble interface cause small nucleons to collapse immediately [11]. However, nucleons surpassing the unstable equilibrium radius initiate localized liquid-vapor phase change. The subsequent growth of a single vapor in an unbounded superheated liquid includes three discernible stages [12, 13]. Surface tension forces predominate the initial growth stage, impeding significant growth for a – usually short – delay period [14]. Following the growth of the nucleon, surface tension influence diminishes, and inertia forces dominate the growth. The constant growth rate is then driven by a steady pressure gradient across the interface, originating from the liquid’s superheat degree [15]. The growth transitions to the last regime as heat consumed by evaporation at the interface cools the liquid boundary layer around it, reducing the vapor pressure inside the bubble. As the pressure gradient tends to zero, the growth is driven solely by heat supplied to the interface via thermal diffusion; hence, during this asymptotic stage, the growth rate is proportional to the square root of time [16]. Most current analytical models focus on the latter stages of the growth; notably, the Mikic–Rohsenow–Griffith (MRG) model [17] pioneered the interpolation between the inertial and thermal regimes. Following works [18–20] have since modified the interpolation and improved its accuracy in the transitional regime. The surface-tension regime was addressed by Miyatake et al.[21], proposing a simple model considering bubble growth acceleration effects, albeit with a delay fitted using experimental data without assessing the influence of viscous damping effects. Recently, Sullivanet al.[22] presented an improved interpolated semi-analytical model capable of approximating the growth of the bubble across all three regimes. The study involved a numerical investigation of near-equilibrium growth, subsequently integrated into a broader analytical framework for comprehensively modeling bubble growth. On the other hand, numerical studies [14, 23, 24] solved the coupled inertial-thermal problem and successfully captured the entirety of the growth process, including the surface tension regime. Another approach to investigate the growth of a post-nucleation vapor bubble is molecular dynamics simulations. Using Lennard-Jones large computational volume simulations of liquid-to-vapor nucleation, Ang ´elil et al.[25] managed to simulate the properties of bubbles from their inception as stable, critically sized bubbles to their continued growth. Crucially, the study reported good agreement up to the molecular scale between molecular dynamics simulations and results obtained via the simplified Rayleigh-Plesset model used in most analytical and numerical models. However, both numerical and molecular-dynamics-based works are limited in their generality and applicability compared with analytical models, which yield immediate predictions without requiring significant computational effort. Studying the early dynamics of vapor bubbles faces experimental challenges; the vapor bubble critical radius may reach extremely small scales [26], especially when considering nucleation in highly superheated liquids. Under such conditions, ∗yuvalda@technion.ac.il arXiv:2402.04690v3  [physics.flu-dyn]  26 May 2024Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) capturing substantial stages of the bubble’s growth – especially the initial surface-tension-dominated period – could be limited by current photography techniques. Therefore, this study focuses on analytical modeling of the near-equilibrium, surface-tension- dominated growth regime and its transition to an inertia-dominated regime, aiming to bridge the existing theory gap. We adopt a regular perturbation method to derive an approximate near-equilibrium solution; the inner solution is then matched with a solution for the transitional regime, yielding a unified model. Using this method, one may explore the underlying physics governing the dynamics of vapor bubbles following nucleation inception, aiming to provide a better understanding of their early growth stages. Section II outlines the methodology and mathematical modeling approach used to derive an analytical solution for near- equilibrium bubble growth and a complementary outer solution for the transitional regime from surface-tension-controlled to inertia-controlled growth. Selected results of the model are presented in section III, followed by an outlook of the present analysis in section IV. II. MATHEMATICAL MODEL The immediate aftermath of a spontaneous nucleation event is considered here: the growth of a vapor bubble driven by a phase change within a superheated liquid. Such vapor-liquid systems are mechanically unstable; the equilibrium bubble radius is predicted by the Young-Laplace relation 𝑅𝑐 = 2𝜎 Δ𝑝0 , (1) where 𝑅𝑐 is the critical bubble radius, 𝜎 is the vapor-liquid surface tension, and Δ𝑝0 is the pressure gradient acting on the interface. Thus, we consider an initially still bubble embryo whose radius is perturbed with respect to the critical radius, ˜𝑅(˜𝑡 =0)= 𝑅𝑐 +˜𝜀. Since the equilibrium embryo distribution 𝑛𝑒(𝑅)is related exponentially to the minimal work required for its formation [11, 27], 𝑛𝑒(˜𝑅)∝ exp \u0014 −4𝜋𝜎𝑅2 𝑐 3𝑘𝑇 \u0012 1 −3(˜𝑅−𝑅𝑐)2 𝑅2𝑐 \u0013\u0015 , (2) this perturbation is associated with the thermodynamic density fluctuations that lead to the bubble’s nucleation. Far from the critical point, the naturally occurring perturbations are in the molecular order of magnitude. Thus, in this study, we postulate that the typical size of the physical perturbations is in the range of ˜𝜀=0.1 𝑛𝑚to ˜𝜀=10 𝑛𝑚. Furthermore, the model assumes a perfectly spherical bubble immersed in a semi-infinite, incompressible liquid medium; thus, any potential interactions between nucleated bubbles are negligible. Our analysis is restricted to early growth stages, wherein thermal diffusion effects are insignificant and constant temperature difference across the sharp interface is maintained. The extent to which this approximation is valid will be further discussed in section III B. Finally, we assume the bubble does not contain dissolved gases and consists solely of vapor molecules, maintaining thermodynamic equilibrium with the outer superheated liquid. Given a constant vapor temperature, a saturated state implies that the growth process is driven by a steady pressure gradient across the bubble interface Δ𝑝0. The steady driving force distinguishes the growth process of a vapor bubble from the dynamics of a gas bubble, wherein the inner pressure is coupled to the bubble’s volume. The simplifying assumptions yield a single ordinary differential equation for the bubble radius ˜𝑅, the Rayleigh-Plesset (RP) equation [16]; ˜𝑅¥˜𝑅+3 2 ¤˜𝑅 2 = Δ𝑝0 𝜌𝑙 − 2 𝜌𝑙 ˜𝑅 \u0010 𝜎+2𝜇𝑙 ¤˜𝑅 \u0011 , (3) where 𝜌𝑙 is the liquid’s density and𝜇𝑙 is its viscosity. The resulting bubble oscillator experiences external forcing from a constant pressure gradient, countered by surface tension spring-like rigidity and the damping effect of viscosity. The inertia terms of the oscillator are nonlinear, originating from the integration of the unsteady (first LHS term) and radially convective (second LHS term) components of the Navier-Stokes equation. Using the critical radius 𝑅𝑐 and the inertial regime velocity ¤˜𝑅𝐼𝑁 = √︄ 2Δ𝑝0 3𝜌𝑙 = √︄ 4𝜎 3𝜌𝑙𝑅𝑐 , (4) we normalize equation (3) and its initial conditions, yielding the following initial value problem (IVP) 2 3 𝑅¥𝑅+ ¤𝑅2 −1 +1 𝑅 \u0012 1 + 4√ 3 Oh𝑐 ¤𝑅 \u0013 =0; 𝑅(0)=1 +𝜀; ¤𝑅(0)=0, (5)Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) where Oh𝑐 is the nucleation Ohnesorge number, defined as Oh𝑐 = 𝜇𝑙 𝜎 √︄ Δ𝑝0 2𝜌𝑙 = √︄ 𝜇2 𝑙 𝜎𝜌𝑙𝑅𝑐 , (6) and the normalized initial perturbation is 𝜀= ˜𝜀 𝑅𝑐 . (7) The nucleation Ohnesorge number Oh 𝑐 signifies the ratio between viscous damping and surface tension forces acting on the critically sized bubbles, i.e., the balance between the two at – and shortly after – nucleation inception. Since the surface tension forces are coupled to the bubble’s characteristic radius, the nucleation Ohnesorge number is governed by both liquid medium properties and the thermodynamic conditions at nucleation. A. Near-equilibrium growth The inherent nonlinearity of the RP equation restricts the attainment of a fully analytical solution to reduced, limiting cases [28]. Hence, we first seek an approximate solution for the initial, near-equilibrium growth of the vapor bubble by substituting a regular perturbation series of the bubble radius 𝑅=𝑅0 +𝜀𝑅1 +𝜀2 𝑅2 +𝜀3 𝑅3 +... (8) in the original IVP. The leading order solution is a trivial one 𝑅0 =1, indicating the stability of the bubble in the absence of any perturbation. The first-order approximation yields a linearized, homogeneous IVP L[𝑅1]= 2 3 ¥𝑅1 + 4√ 3 Oh𝑐 ¤𝑅1 −𝑅1 =0; 𝑅1 (0)=1; ¤𝑅1 (0)=0, (9) and the subsequent terms in the perturbation series yield the following heterogeneous IVP: L[𝑅2]=−4 3 𝑅1 ¥𝑅1 − ¤𝑅1 2; 𝑅2 (0)= ¤𝑅2 (0)=0, (10) and L[𝑅3]=−4 3 \u0000𝑅1 ¥𝑅2 +𝑅2 ¥𝑅1 \u0001 −2 ¤𝑅1 ¤𝑅2 −𝑅1 ¤𝑅1 2 −2 3 𝑅2 1 ¥𝑅1; 𝑅3 (0)= ¤𝑅3 (0)=0. (11) The particular solution for the first-order approximation is 𝑅1 (𝑡)=𝑒− √ 3𝑡Oh𝑐  cosh   √ 3𝑡 √︂ 1 2 +Oh2 𝑐 ! + Oh𝑐√︃ 1 2 +Oh2 𝑐 sinh   √ 3𝑡 √︂ 1 2 +Oh2 𝑐 ! , (12) which may be substituted into equation (10), 2 3 ¥𝑅2 + 4√ 3 Oh𝑐 ¤𝑅2 −𝑅2 = 𝑒−2 √ 3𝑡Oh𝑐 4 +8Oh2 𝑐 \" 1 +16Oh2 𝑐 +7 cosh   2 √ 3𝑡 √︂ 1 2 +Oh2 𝑐 !# , (13) to yield the second-order approximation, 𝑅2 (𝑡)= √ 3 24 𝑒−3 √ 3𝑡Oh𝑐 sinh   √ 3𝑡 √︂ 1 2 +Oh2 𝑐 ! \" 1 +16Oh2 𝑐 +7 cosh   2 √ 3𝑡 √︂ 1 2 +Oh2 𝑐 !# . (14) The linearity of the problem allows for the derivation of higher-order approximations using the same methodology. The perturbation solution is, by definition, limited to near-equilibrium bubble radii. However, in the subsequent section, we derive a complementary analytical solution using different approximations to model the growth of the bubble during its transition from the surface-tension-dominated, near-equilibrium regime to the inertial regime.Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) FIG. 1. Dominant balance analysis of the normalized RP equation using a numerical solution for equation (5), given initial radius perturbation of 𝜀=10−5. (a) Solid lines depict a test case Oh𝑐 =1, whereas the dashed lines depict the results for undamped growth Oh𝑐 =0. (b) Close-up of the initial growth stages. Changes due to increased damping are highlighted with colored arrows. B. Transition to inertial growth Figure 1 presents a dominant balance analysis of the nonlinear oscillator leading terms based on the numerical solution of equation (5) using an RK4 scheme. Each term of the normalized RP equation is plotted individually, allowing one to assess the dominant physical terms throughout the growth. The analysis is conducted for two distinct test cases: generalized, viscosity- affected growth wherein Oh𝑐 =1 (solid lines) and a limit case of undamped growth, wherein Oh 𝑐 →0 (dotted lines). As our model postulates, the normalized pressure term remains constant in both cases; the surface tension and convective inertia terms switch roles as the second dominant terms. The linearized equation (9) and figure 1 suggest the initial growth is governed by the balance between pressure and surface tension forces, justifying the omission of the nonlinear convective inertia term in the linearized IVP. However, as the bubble interface accelerates, the nonlinear term becomes dominant, breaking the assumptions of our linear analysis and inducing a shift in the bubble growth regime. A distinct velocity threshold emerges in both cases, delineating the crossing from a surface-tension-dominated to a transitional regime, where both inertia and surface-tension forces govern the growth. Viscous effects also influence the dominant terms; they delay the surge in the inertia term, playing a significant role immediately post-nucleation and up until the bubble grows beyond the critical radius order of magnitude(𝑅−1)>1. Viscous damping also affects the transitional regime; however, its magnitude diminishes as the bubble radius increases. Thus, it does not influence the inertial regime, wherein the dominant terms are the pressure gradient and the convective acceleration. The dominant balance analysis also indicates that the unsteady inertia term influence is comparatively insignificant in the system response. This observation allows for extracting a reduced outer solution for the intermediate and inertial regime by excluding the unsteady inertia term. Equation (5) simplifies into an autonomous, first-order ODE, 𝑅 \u0010 ¤𝑅2 −1 \u0011 +1 + 4√ 3 Oh𝑐 ¤𝑅=0, (15) amenable to a solution by inversing the ODE \u0012 𝑑𝑡 𝑑𝑅 \u00132 − 4Oh𝑐√ 3(𝑅−1) 𝑑𝑡 𝑑𝑅 − 𝑅 𝑅−1 =0. (16) One may solve for𝑡(𝑅)given 𝑅 >1, yielding 𝑡(𝑅)=𝐶1 + √︄ 𝑅(𝑅−1)+ 4Oh2 𝑐 3 +4Oh𝑐√ 3 ln ©­ « 2 −2𝑅−4Oh𝑐√ 3 +2 √︄ 𝑅(𝑅−1)+ 4Oh2 𝑐 3 ª® ¬ −1 2 \u0012 1 +4Oh𝑐√ 3 \u0013 ln ©­ « 1 −2𝑅+2 √︄ 𝑅(𝑅−1)+ 4Oh2 𝑐 3 ª® ¬ (17)Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) However, the remaining degree of freedom 𝐶1 cannot be independently resolved due to the lack of boundary condition. Nev- ertheless, we may extract a uniform solution by imposing continuity of both radius and velocity terms with the inner solution derived in section II A; for simplicity, we use here the first-order solution equation (12). Velocity continuity necessitates that the solutions are tangent ¤𝑅𝑖𝑛 = ¤𝑅𝑜𝑢𝑡 at their intersection, resulting in a closed-form algebraic system for the tangent intersection point (𝑡𝑡𝑎𝑛,𝑅𝑡𝑎𝑛)and the integration constant 𝐶1 as a function of Oh𝑐 and the 𝜀 1 2 √︂ 3 2 +3Oh2 𝑐𝜀𝑒− √ 3𝑡𝑡𝑎𝑛 Oh𝑐 sinh   √ 3𝑡𝑡𝑎𝑛 √︂ 1 2 +Oh2 𝑐 ! =©­ « 2Oh𝑐√ 3(𝑅𝑡𝑎𝑛 −1) + √︄ 2Oh2 𝑐 −3𝑅𝑡𝑎𝑛 3𝑅𝑡𝑎𝑛 −3 ª® ¬ −1 , 𝑅𝑡𝑎𝑛 =1 +𝜀𝑒− √ 3𝑡𝑡𝑎𝑛 Oh𝑐  cosh   √ 3𝑡𝑡𝑎𝑛 √︂ 1 2 +Oh2 𝑐 ! + Oh𝑐√︃ 1 2 +Oh2 𝑐 sinh   √ 3𝑡𝑡𝑎𝑛 √︂ 1 2 +Oh2 𝑐 ! , 𝐶1 =𝑡𝑡𝑎𝑛 − √︄ 𝑅𝑡𝑎𝑛(𝑅𝑡𝑎𝑛 −1)+ 4Oh2 𝑐 3 −4Oh𝑐√ 3 ln ©­ « 2 −2𝑅𝑡𝑎𝑛 −4Oh𝑐√ 3 +2 √︄ 𝑅𝑡𝑎𝑛(𝑅𝑡𝑎𝑛 −1)+ 4Oh2 𝑐 3 ª® ¬ + 1 2 \u0012 1 +4Oh𝑐√ 3 \u0013 ln ©­ « 1 −2𝑅𝑡𝑎𝑛 +2 √︄ 𝑅𝑡𝑎𝑛(𝑅𝑡𝑎𝑛 −1)+ 4Oh2 𝑐 3 ª® ¬ , (18) which fully resolves the outer solution by setting𝐶1. III. RESULTS AND DISCUSSION We begin by analyzing the inner, near-equilibrium solution, focusing on the immediate aftermath of nucleation events and the early stages of bubble growth. The subsequent section presents results for the unified model, broadening the model’s scope and shedding light on the transition of the growth to the initial regime. A. Surface tension delay time The accuracy and validity region of the approximated solutions is assessed by comparing them with numerical solutions obtained from the original RP oscillator equation equation (5). An exemplary test case for generalized damped growth is considered, where the conditions at nucleation yield an Ohnesorge number of Oh 𝑐 = 1 and an initial perturbation of 𝜀 = 10−5. Figure 2 compares successive orders of the inner solution with a numerical solution. The approximated and numerical solutions converge and are indiscernible at the initial growth stages; as the bubble grows, the approximated solutions diverge as the hyperbolic terms in each approximation asymptotically approach ±∞. A higher order of approximation leads to improved precision and a marginally expanded region of validity. Nevertheless, figure 2(b) reveals a divergence among all solutions emerges when the velocity attains a magnitude of ¤𝑅≈0.1, i.e., when the velocity reaches the inertial velocity order of magnitude. This divergence across all solutions accentuates the critical influence of the nonlinear convective inertia term ¤𝑅2 on the near-equilibrium bubble dynamics and the transition between the distinctly different growth regimes, as suggested by figure 1. The surface tension delay, i.e., the time between nucleation onset and the crossing of the velocity threshold, can be evaluated using the derived inner solution. Figure 3 presents the surface-tension-induced delay as a function of the nucleation Ohnesorge number Oh𝑐 for successive orders of the perturbation solution, comparing them with the prediction of the numerical solution. We observe varying sensitivity to the approximation order; low nucleation Ohnesorge values exhibit greater sensitivity to the approximation order, whereas the results converge for Oh𝑐 >1. A distinct transition of the initial delay behavior as a function of nucleation Ohnesorge number is illuminated by figure 3. For small values of nucleation Ohnesorge number, the surface tension delay remains unaffected by changes in its value. As the nucleation Ohnesorge number tends to Oh 𝑐 =0.1, the delay begins to increase, marking a shift to a linear relation between the two for Oh 𝑐 > 1. This transition indicates a change in the dominant delaying mechanism: for Oh 𝑐 < 0.1, the initial delay is primarily governed by surface tension, rendering it independent of the nucleation Ohnesorge number. Contrarily, for Oh𝑐 > 1, viscous damping becomes the dominant factor setting the initial delay, manifested by the obtained linear correlation between Oh𝑐 and 𝜏𝑆𝑇. Although the least accurate, figure 2 and figure 3 suggest that the first-order solution captures the essence of the initial delayPreprint Published in Chem. Eng. Sci. 296, 120277 (2024) FIG. 2. A comparison between the numerical solution of the RP equation (dashed line) and different orders of the approximated perturbation solution (solid lines), given an initial radius perturbation of 𝜀 =10−5 and Oh𝑐 =1. (a) Bubble radius as a function of time and (b) Bubble interface velocity as a function of bubble radius FIG. 3. Surface-tension-induced delay as a function of the nucleation Ohnesorge number Oh 𝑐, given initial radius perturbation of 𝜀 =10−5. Comparison between results obtained using the numerical solution, represented by the dashed black line, and results obtained using successive orders of the approximated perturbation solution, represented by solid lines. while yielding a closed-form relation for the delay, exp \u0010 − √ 3Oh𝑐𝜏𝑆𝑇 \u0011 sinh   √ 3Oh𝑐 √︂ 1 2 +Oh2 𝑐𝜏𝑆𝑇 ! = √︃ 1 2 +Oh2 𝑐 5 √ 3𝜀 . (19) In the limit case of undamped growth, one may extract an explicit term 𝜏𝑆𝑇 ≈ √︂ 2 3 sinh−1 \u0012 1 5 √ 6𝜀 \u0013 . (20)Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) FIG. 4. Surface-tension-induced delay as a function of the initial perturbation 𝜀 for various values of nucleation Ohnesorge number Oh 𝑐. Solid lines demarcated the delay extracted using the third-order perturbation solution, whereas dashed lines correspond to the prediction of the correlation equation (21). A black dotted line demarcated the limiting case of undamped growth Oh 𝑐 = 0. The surface tension delay reported by Miyatake et al.[21] and extracted from the experimental results of Florschuetzet al.[29] is indicated by a black cross and triangles, respectively. Using the form of equation (20) and numerical solution of equation (19), we derived an explicit correlation for the surface tension delay under generalized, damped growth: 𝜏𝑆𝑇 ≈ \u0010 1 +2.849Oh𝑐𝜀0.001 \u0011 √︂ 2 3 sinh−1 ©­­ « √︃ 1 2 +Oh2 𝑐 5 √ 3𝜀 ª®® ¬ . (21) The surface-tension-induced delay is set by both the nucleation Ohnesorge number and the initial perturbation from the stable radius, with a shorter delay expected for larger deviations from equilibrium. The relation between the two is illustrated by figure 4, presenting the surface tension delay as a function of the normalized perturbation 𝜀 for various values of nucleation Ohnesorge number Oh 𝑐. Figure 4 reveals that delay values for low Ohnesorge values (Oh 𝑐 = 0–10−1) converge as expected, indicating that the delay is primarily controlled by surface-tension forces dictated by the initial perturbation. In this range, the delay exhibits higher relative dependence on𝜀– an order of magnitude change. The transition in dominant delaying mechanisms around Oh𝑐 =10−1–100 also alters the sensitivity to the initial perturbation, with a small relative change at higher Ohnesorge values (Oh𝑐 = 101–102). Yet significant absolute changes in the delay are still expected at these values, highlighting that the perturbation magnitude could not be overlooked when viscosity is the dominant delaying mechanism. The extended correlation, presented here in equation (21), proves accurate for high Ohnesorge values but overestimates the delay, especially for small initial perturbations. Although the definition of the delay is not deterministic and aims to evaluate only the phenomenon’s order of magnitude, the correlation could still provide a prompt estimation of the delay. While limited in its extent, comparing the available data on initial delay reveals its agreement with our model’s predictions. Miyatakeet al.[21] reported, while normalized in terms of our analysis, a delay of 𝜏𝑆𝑇 =6 for an initial perturbation of 𝜀 =10−4. This result was obtained by correlating the undamped analytical, numerical, and experimental results. As illustrated in figure 4, our findings corroborate this observation: this singular value and the predictions derived from our model for Oh 𝑐 =0 agree well. Surface tension delay values were also extracted from the raw data reported by Florschuetzet al.[29]. While our model and these results exhibit some discrepancies, it suggests that the framework developed herein offers a viable approximation for the delay timescale.Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) FIG. 5. Unified approximated solution illustrating (a) bubble radius as a function of time and (b) bubble velocity as a function of time of a vapor bubble. The initial perturbation is 𝜀=10−5 and the nucleation Ohnesorge number is Oh𝑐 =1. The inner, first-order solution, given by equation (12), is depicted by a blue line. The matching outer solution, given by equation (17), is depicted by a red line. Dotted vertical lines demarcate the growth regimes: a surface-tension-dominated regime, defined using velocity threshold ¤𝑅 <0.1, a linear regime, defined using velocity threshold ¤𝑅 >0.99, and an intermediary, transitional regime. B. Unified solution While the inner solution validity is limited to the near-equilibrium bubble radii, its matching outer solution may expand the analysis region of validity to larger radii. The unified solution elucidates three distinct stages in the bubble’s growth and provides a new analytical approximation for the surface-tension-dominated and transitional regimes. The unified solution, equation (12) (inner solution) and equation (17) (outer solution) prediction for the test case (Oh 𝑐 =1,𝜀 =10−5) is presented in figure 5. As previously discussed, the inner solution predicts delayed growth due to the dominance of surface tension forces, starting its transition to the inertial, linear growth regime as the velocity threshold ¤𝑅 ≤0.1 is crossed. In the transitional regime, the bubble velocity increases sharply, as it tends to the inertial velocity limit ¤𝑅 →1. The end of the transitional regime is marked by a second threshold, after which the bubble’s velocity is practically constant, as expected for inertially limited growth. The criterion to distinguish between the two is arbitrarily set here to ¤𝑅 =0.99, demarcating the transition into the fully inertial regime. We offer this criterion to provide a quantifiable indicator, facilitating a distinct separation between the growth regimes. Figure 6 depicts the bubble acceleration as a function of time, presenting a comparison between the unified solution approxi- mation and the numerical solution. Notably, the trade-off inherent to simplifying the original RP oscillator is revealed by figure 6. A discontinuity in acceleration arises when transitioning from the inner to the outer solution, illustrated by a dotted vertical line. The unified solution also overestimates the acceleration during peak acceleration and undershoots at long timescales. Despite these deviations, the pattern of the unified solution mirrors that of the numerical solution, validating its utility as a reasonable approximation, especially for the surface-tension-dominated regime. Figure 7 provides a comparative analysis of different growth models. Standard analytical models such as the MRG model often overlook the initial surface-tension-induced delay and assume the growth begins from the linear regime – as depicted by the dashed brown line. We propose two enhancements for the standard analytical models: the first is the unified solution (solid pink line), and the second involves incorporating the surface tension delay time to retard the onset of linear growth (dashed green line). This simple retardation immediately improves the model’s agreement with the numerical result. However, as illustrated in figure 7, the uniform solution offers a markedly more accurate approximation for short time scales. The deviation between the uniform solution and the numerical result stems from excluding the unsteady inertia term, notably impacting the intermediate regime. The errors relative to the numerical model are depicted in figure 7(b), revealing that the linear model significantly overestimates the bubble size within timescales of up to 100. Introducing a simple retardation immediately enhances accuracy by an order of magnitude. Notably, all models converge at longer timescales, exhibiting a linear decrease in their relative error. Overall, the findings demonstrated in figure 7 emphasize the significance of considering the surface tension delay, particularly during short timescales, and highlight its crucial role in accurately modeling the dynamic behavior of the bubble. In normalized terms and assuming the relation between the vapor pressure and temperature can be expressed by the linearized Clausius- Clapeyron equation, the MRG model [17] predicted that the timescale in which thermal effects begin to affect the bubble growthPreprint Published in Chem. Eng. Sci. 296, 120277 (2024) FIG. 6. Bubble acceleration as a function of time: a comparison between numerical and analytically obtained approximations for initial perturbation of 𝜀=10−5 and nucleation Ohnesorge number of Oh𝑐 =1. The solution transition is indicated by a dotted vertical line. FIG. 7. A comparison of growth models (a), and their associated relative error with respect to the numerical model 𝑒 = |𝑅−𝑅𝑛𝑢𝑚 𝑅𝑛𝑢𝑚 |(b). The dashed black line depicts the numerical solution, while the pink line represents the unified model, both derived for an initial perturbation of 𝜀 =10−5 and nucleation Ohnesorge number of Oh𝑐 =1. The dotted brown line illustrates the estimation of conventional models, such as the MRG model [17], in which the surface tension delay is neglected, and the bubble is assumed to begin its growth in the inertial regime. The green dotted line incorporates the surface tension delay, retarding the linear growth to account for the initial delay. is 𝜏𝑇𝐻 = 18𝛼𝑙 𝜋𝜎   𝑐𝑝,𝑙𝑇sat 𝜌2𝑣ℎ2 fg !2 (𝜌𝑙Δ𝑝0)5/2, (22) where 𝛼𝑙,𝑐𝑝,𝑙 are the liquid heat diffusivity and capacity, correspondingly,𝑇𝑠𝑎𝑡 is the saturation temperature at the liquid far-field pressure, ℎ𝑓𝑔 is the latent heat of vaporization and 𝜌𝑣 is the vapor density. Comparing 𝜏𝑇𝐻 magnitude with 𝜏𝑆𝑇 magnitude illuminates the thermal effects timescale and could suggest whether the isothermal assumption made in our model is justified. If 𝜏𝑆𝑇 is approximately equal to 𝜏𝑇𝐻, then thermal effects modify the bubble’s behavior even during the initial delay. Figure 7 indicates that the transition to fully inertial growth occurs after the growth reaches approximately 𝜏𝐼𝑁 ≈10𝜏𝑆𝑇, implying thatPreprint Published in Chem. Eng. Sci. 296, 120277 (2024) fully inertial growth can only be sustained when the thermal timescale significantly exceeds the timescale associated with surface tension effects 𝜏𝑇𝐻 >> 𝜏𝑆𝑇. Otherwise, the bubble will not stabilize at a constant growth velocity as a direct transition from surface tension regime to thermal regime may occur. 𝜏𝑇𝐻 depends on the superheated liquid’s thermochemical properties and the conditions at the onset of the phase change, serving as a simple yet powerful parameter allowing one to assess the main mechanisms dictating the early bubble growth stages. For example, high liquid superheats result in a relatively long inertial growth regime, while low surface tension shortens the initial delay, thus changing the ratio between the thermal timescales and the other physical mechanisms governing the growth. High heat capacity and thermal diffusivity tend to retard the vapor’s thermal response, whereas a high latent heat accelerates the vapor’s temperature drop to 𝑇sat. This contrasting effect highlights the complex interplay between the underlying physical mechanisms influencing bubble dynamics and growth behavior. IV. CONCLUSIONS This study focuses on a near-equilibrium, surface-tension-dominated growth regime of vapor bubbles and its transition to an inertia-dominated regime. We adopted a regular perturbation method to analytically derive an approximate inner solution that was then matched with an outer solution for the transitional regime. The unified solution offers a closed mathematical formulation for the first time for the early growth stages of vapor bubbles. The analytical solutions were validated with direct numerical solutions of the Rayleigh-Plesset equation, successfully capturing the initial growth delay. Our analysis predicts the initial delay period as a function of two nondimensional parameters: the normalized perturbation from criticality and the nucleation Ohnesorge number, encapsulating the interplay between viscous damping and surface tension forces near criticality. We found that viscous effects play a significant role in the near-equilibrium vapor bubble growth: it may dampen the bubble’s expansion, extending the surface-tension-dominated regime and retarding the transition to the inertial regime. For low nucleation Ohnesorge numbers, Oh𝑐 < 1, the delay is governed by surface tension, while higher values, Oh 𝑐 > 1, lead to a linear correlation with viscous damping. The comparative analysis with standard growth models emphasizes the importance of considering surface tension delay, particularly at short timescales, for accurate modeling of bubble behavior. The developed unified solution suggests a quantifiable indicator facilitating a distinct separation between the three growth stages. The derived analytical solutions, particularly the correlation for surface-tension-induced delay, may be integrated into existing models for vapor bubble growth. Furthermore, a simple parameter, 𝜏𝑆𝑇, was derived to estimate the extent to which thermal effects alter the bubble dynamics during the early growth stages. Altogether, the results presented here offer a rigorous yet simple method to dissect the complex interplay between surface tension, viscosity, inertia, and thermal effects, suggesting that understanding the relative timescales of these mechanisms is crucial for predicting bubble behavior accurately. The obtained results highlight the necessity of further experimental efforts to study post-nucleation vapor bubble dynamics to capture the predicted growth delay. Finally, this approach may be extended to include bubble curvature-dependent and dynamic surface tension models, unsteady external pressure excitation, and gas content effects. Such an extension broadens the applicability and enhances model predictions, especially applicable to bubbles nucleating within highly superheated liquids; an ongoing study aims at unraveling the influence of these phenomena on near-equilibrium dynamics. ACKNOWLEDGMENTS The authors are indebted to Dr. Tali Bar-Kohany for her critical advice and fruitful discussions. This research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 1762/20). ES acknowledges the financial support of Minerva Research Center (Max Plank Society Contract No. AZ5746940764). [1] J. E. Gardner, Geochimica et Cosmochimica Acta 76, 93 (2012). [2] O. Vincent, P. Marmottant, P. A. Quinto-Su, and C.-D. Ohl, Physical Review Letters108, 184502 (2012). [3] R. E. Apfel, Nuclear Instruments and Methods 162, 603 (1979). [4] C. T. Avedisian, W. S. Osborne, F. D. Mcleod, and C. M. Curley, Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 455, 3875 (1999). [5] A. D. Fulvio, C. Domingo, M. D. S. Pedro, E. D’ Agostino, M. Caresana, L. Tana, and F. D’Errico, Radiation Measurements57, 19 (2013). [6] O. Avni, T. Bar-Kohany, and E. Sher, Thermal Science and Engineering Progress32, 101334 (2022). [7] T. Bar-Kohany, D. V. Antonov, P. A. Strizhak, and S. S. Sazhin, Fuel340, 10.1016/j.fuel.2022.126991 (2023). [8] A. D. Maxwell, T.-Y. Wang, C. A. Cain, J. B. Fowlkes, O. A. Sapozhnikov, M. R. Bailey, and Z. Xu, The Journal of the Acoustical Society of America 130, 1888 (2011). [9] K. B. Bader, E. Vlaisavljevich, and A. D. Maxwell, Ultrasound in medicine biology 45, 1056 (2019). [10] L. Mancia, M. Rodriguez, J. Sukovich, Z. Xu, and E. Johnsen, Physics in Medicine and Biology 65, 225014 (2020).Preprint Published in Chem. Eng. Sci. 296, 120277 (2024) [11] P. G. Debenedetti, Metastable Liquids(Princeton University Press, 1997). [12] M. S. Plesset and A. Prosperetti, Annual Review of Fluid Mechanics 9, 145 (1977). [13] A. Prosperetti, Annual Review of Fluid Mechanics 49, 221 (2017). [14] A. Robinson and R. Judd, International Journal of Heat and Mass Transfer 47, 5101 (2004). [15] L. Rayleigh, The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 34, 94 (1917). [16] M. S. Plesset and S. A. Zwick, Journal of Applied Physics 25, 493 (1954). [17] B. Mikic, W. Rohsenow, and P. Griffith, International Journal of Heat and Mass Transfer13, 657 (1970). [18] S. J. Board and R. B. Duffey, Chemical Engineering Science 26, 263 (1971). [19] T. G. Theofanous and P. D. Patel, International Journal of Heat and Mass Transfer 19, 425 (1976). [20] A. Prosperetti and M. S. Plesset, Journal of Fluid Mechanics 85, 349 (1978). [21] O. Miyatake, I. Tanaka, and N. Lior, International Journal of Heat and Mass Transfer 40, 1577 (1997). [22] P. Sullivan, D. Dockar, M. K. Borg, R. Enright, and R. Pillai, Journal of Fluid Mechanics 948, A55 (2022). [23] H. S. Lee and H. Merte, Int. J. Heat Mass Transfer 39, 24272447 (1996). [24] Y. Hao and A. Prosperetti, Physics of Fluids 11, 2008 (1999). [25] R. Ang ´elil, J. Diemand, K. K. Tanaka, and H. Tanaka, Physical Review E90, 063301 (2014). [26] O. Avni, Y. Dagan, T. Bar-Kohany, and E. Sher, Thermal Science and Engineering Progress46, 102162 (2023). [27] M. Blander and J. L. Katz, AIChE Journal 21, 833 (1975). [28] C. M. Bender and S. A. Orszag, Advanced Mathematical Methods for Scientists and Engineers I(Springer New York, 1999). [29] L. W. Florschuetz, C. L. Henry, and A. R. Khan, International Journal of Heat and Mass Transfer 12, 1465 (1969).",
      "references": [
        "Metastable Liquids",
        "Advanced Mathematical Methods for Scientists and Engineers I"
      ],
      "meta_data": {
        "arxiv_id": "2402.04690v3",
        "doi": "10.1016/j.ces.2024.120277",
        "authors": [
          "Orr Avni",
          "Eran Sher",
          "Yuval Dagan"
        ],
        "published_date": "2024-02-07T09:30:15Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Develops a unified analytical model for the *early* post-nucleation growth of a vapor bubble in a superheated, unbounded liquid, specifically covering the surface-tension-controlled near-equilibrium regime and its transition to inertia-controlled growth. The model predicts and quantifies the surface-tension-induced growth delay and shows it is governed primarily by two nondimensional parameters: (i) the normalized initial radius perturbation from the critical (Young–Laplace) radius, ε=\\tilde{ε}/R_c, and (ii) a nucleation Ohnesorge number Oh_c that captures viscous damping relative to surface-tension forces at nucleation. Provides (a) closed-form near-equilibrium solutions via perturbation expansions, (b) an outer (reduced) solution for the transitional/inertial regime, (c) a matching/tangency procedure yielding a unified solution, and (d) an explicit correlation for the delay time τ_ST usable to retrofit conventional growth models (e.g., MRG) that neglect early-time delay. Also proposes a simple timescale comparison criterion (τ_TH vs τ_ST) to assess when thermal effects begin to alter early growth, indicating when a direct surface-tension→thermal transition may occur without a sustained inertial plateau.",
        "methodology": "Starts from a simplified Rayleigh–Plesset (RP) equation for a spherical vapor bubble with constant driving pressure difference Δp_0, including surface tension σ and liquid viscosity μ_l, and neglecting thermal diffusion during the early stage. Non-dimensionalizes using the critical radius R_c=2σ/Δp_0 and inertial-regime velocity \\dot{\\tilde R}_{IN}=\\sqrt{2Δp_0/(3ρ_l)}. For the near-equilibrium (inner) regime, applies a regular perturbation expansion R(t)=R_0+εR_1+ε^2R_2+… about R=1, yielding a linear operator L[·] for R_1 and forced linear ODEs for higher orders; derives closed-form expressions for R_1(t) (hyperbolic functions with viscous damping) and R_2(t) (and outlines extension to higher order). Defines a surface-tension delay time based on reaching a velocity threshold (~0.1 of inertial velocity) and derives an implicit closed-form relation for τ_ST from the first-order solution; provides an explicit undamped limit and an empirical explicit correlation for general Oh_c. For the transition/outer regime, performs dominant-balance analysis of RP terms using numerical solutions to justify neglecting the unsteady inertia term, reducing RP to an autonomous first-order ODE; integrates to obtain t(R) with an integration constant. Determines the constant and the inner–outer connection by enforcing continuity of radius and *tangency* (velocity matching) at an intersection point (t_tan, R_tan), producing a unified piecewise analytical approximation across surface-tension and transitional/inertial regimes.",
        "experimental_setup": "No new physical experiments or datasets; validation is computational/analytical. Uses direct numerical integration (RK4) of the full nondimensional RP initial-value problem as the reference (‘ground truth’) and compares it against successive perturbation orders (inner solution), the derived outer solution, and the unified matched solution. Performs term-by-term dominant-balance diagnostics by plotting individual RP terms along numerical trajectories to identify regime changes and justify model reductions. Examines representative parameter cases (e.g., ε=10^-5 with Oh_c=1; sweep of Oh_c across orders of magnitude; sweep of ε for several Oh_c values). Benchmarks against behavior assumed in standard analytical models (e.g., MRG linear inertial start) and contrasts errors vs the numerical RP solution. Additionally cross-checks the delay scale against limited literature data: Miyatake et al. delay value (normalized) and delay estimates extracted from Florschuetz et al. experimental raw data.",
        "limitations": "Relies on strong simplifying assumptions tailored to early times: spherical, isolated bubble in an unbounded incompressible liquid; constant far-field superheat and constant pressure driving Δp_0; vapor-only bubble (no dissolved/noncondensable gas); sharp interface with thermodynamic equilibrium; neglects thermal diffusion/evaporative cooling during the analyzed early period (isothermal assumption), with validity assessed only via a timescale estimate. The inner perturbation solution is inherently restricted to near-equilibrium radii (small ε and R≈1) and diverges when nonlinear convective inertia becomes important; the outer solution omits the unsteady inertia term, which causes inaccuracies in the intermediate regime (e.g., acceleration discontinuity at matching and misprediction of peak acceleration). The delay definition depends on an arbitrary velocity threshold (e.g., \\dot R=0.1 for end of surface-tension regime; \\dot R=0.99 for inertial onset), affecting quantitative τ_ST. The explicit delay correlation is empirical/fitted from the implicit relation and may overestimate delay for small ε; limited experimental comparison data restricts calibration/verification across fluids and conditions.",
        "future_research_directions": "Extend the unified analytical framework to include: (i) thermal coupling during early growth (solve/approximate coupled inertia–thermal problem; refine τ_TH vs τ_ST criterion; allow direct surface-tension→thermal transitions), (ii) curvature-dependent and dynamic surface tension (e.g., Tolman length effects, adsorption/Marangoni, time-dependent σ), (iii) unsteady external pressure excitation and compressibility/acoustic effects for rapid events, (iv) inclusion of dissolved/noncondensable gases and gas–vapor mixtures (coupled internal pressure evolution), (v) improved outer solutions retaining unsteady inertia to remove acceleration discontinuities and better capture the transitional regime, (vi) rigorous matched-asymptotic expansions (beyond heuristic tangency) with quantified error bounds, and (vii) targeted high-speed/ultrafast experimental measurements and/or MD-informed parameterization to directly observe/validate the predicted surface-tension delay at nanometer scales and high superheats.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "On Discrete Prompt Optimization for Diffusion Models",
      "full_text": "CONVEX MINIMIZING CURVES OF THE SCALING-INVARIANT NONLOCAL WILLMORE ENERGY GIOVANNI GIACOMIN AND ARMIN SCHIKORRA Abstract. We consider the scaling-invariant nonlocal Willmore energy, defined via the nonlocal mean curvature by Caffarelli, Roquejoffre and Savin. Our main result is the existence of minimizers in the class of convexC1-curves. Contents 1. Introduction and main results 1 2. Preliminaries and Notation 4 3. Small energy controls BMO-parametrization 13 4. Sobolev control 19 5. Self-repulsiveness of Willmore energy for convex curves 24 6. Convex curves with finite energy are continuously differentiable 25 7. Proof of Theorem 1.1 32 Appendix A. Facts about convex curves inR2 34 Appendix B. Integration formula for the mean curvature – Proof of Proposition 2.9 45 Appendix C. The covering argument: Locally uniform smallness 47 References 49 1. Introduction and main results Given a subsetE ⊂R2 the nonlocal mean curvature atx ∈∂E introduced by Caffarelli, Roquejoffre and Savin in [10] is defined as Hs ∂E(x) := P.V. ˆ R2 χEc(y) −χE(y) |x−y|2+s dy≡lim ε→0 ˆ R2\\Bε(x) χEc(y) −χE(y) |x−y|2+s dy, whenever that limit exists, e.g. in the case of smooth∂E. The fractional mean curvature is obtained as the first variation of the fractional perimeter, just like the classical mean curvature is the first variation of the usual perimeter (or area) functional. Having a nonlocal mean curvature, we can naturally define a nonlocal Willmore energy: Fors∈(0,1) and p≥1 we set ˆWs,p(∂E) := ˆ ∂E |Hs ∂E(x)|p dσ1(x). This energy is well-defined on measurable setsE for whichHs ∂E(x) exists for a.e. x∈∂E – for all other measurable sets we setˆWs,p(∂E) := +∞. Also, observe that 1 arXiv:2402.05267v1  [math.AP]  7 Feb 20242 G. GIACOMIN AND A. SCHIKORRA it does not matter if we considerE or Ec, the nonlocal Willmore energy stays the same. If we parametrize a suitably nice set∂E by a curveγ : S1 →R2, we see that Hs ∂E(x) = ±cs ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s |γ′(y)|dy ≡±cs ˆ S1 ⟨n(γ(y)),γ(y) −γ(x) −γ′(y)(y−x)⟩ |γ(y) −γ(x)|2+s |γ′(y)|dy. Here, forz∈∂E the vectorn(z) ∈S1 denotes the unit normal, and the sign ofHs ∂E depends on whether it is the outwards facing or inwards facing normal (or, in other words, if we considerE or Ec). Observe that ifγ is smooth, then the last integral in the equality above is absolutely convergent. This leads to a nonlocal Willmore energy for curvesγ : S1 →R2, Ws,p(γ) = ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s |γ′(y)|dy ⏐⏐⏐⏐⏐ p |γ′(x)|dx, and in the smooth setting we have Ws,p(γ) = cs,p ˆWs,p(E). In collaboration with Blatt and Scheuer we discussed some aspects of thesubcritical nonlocal Willmore energy in [2], i.e. whens> 1 p. In this work we are interested in the critical case, which corresponds top= 1 s, when the nonlocal Willmore energy becomes scaling invariant. Scaling invariance means: If for someγ : S1 →R2 and ρ> 0 we consider the rescaled curveγρ(·) := ργ( · ρ) : ρS1 →R2, then we have Ws,1 s (γ) = Ws,1 s (γρ). For simplicity of notation we shall denote from now on Ws(γ) = ˆ S1 (ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s |γ′(y)|dy )1 s |γ′(x)|dx, It is obvious that nonlocal minimal surfaces, i.e. surfaces with vanishing fractional mean curvatureHs ≡0, are absolute minimizers of the nonlocal Willmore energy – but in general a curve or surface which is critical for the Willmore-energy is not necessarily a minimal surface (in the sense of vanishing mean curvature). For example there are no compact nonlocal minimal surfaces [13, 9]. While nonlocal minimal and constant mean curvature surfaces have been studied very thoroughly, for an overview see e.g. [16, 17], the theory of nonlocal Willmore surfaces is only at the very beginning. Similar to recent results on nonlocal minimal surfaces [12, 11] one could hope that eventually one can transfer properties fors-Willmore surfaces to classical Willmore surfaces by lettings→1. Regarding the existence of minimizers, scaling invariant variational functionals are prone to bubbling effects, and the existence of minimizers becomes a nontrivial question. The classical example is the Sacks-Uhlenbeck theory for harmonic maps in homotopy groups, [33]. But also in the theory of classical Willmore surfaces [34, 25, 32] existence of minimizers is a highly nontrivial question.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 3 In this work we are interested in minimizingconvex curves, w.l.o.g. they are in arc length parametrization, more precisely we consider the class (1.1) X :=    γ ∈C1(S1,R2) ⏐⏐⏐⏐⏐ γ is a homeomorphism |γ′|≡ 1 a.e. in S1 γ is convex inS1    . The main result of this paper is the following: Theorem 1.1. For anys∈(0,1) there exists a minimizer ofWs in X. In [2] we obtained an analogous result forC1-convex curves for thesubcritical case p >1 s. There, the arguments crucially rely on the non-scaling invariance of the subcritical regime. In our critical regime we need completely different techniques, more similar to the minimizing methods used for Willmore’s energy for surfaces (which is also scaling invariant). The nonlocal Willmore energy is only defined on co-dimension one objects, since the nonlocal perimeter is only defined on those sets (albeit, see [27]). In particular, we can reformulate our result for setsE whose boundary are represented by curves γ. Let C :=    E ⊂R2 ⏐⏐⏐⏐⏐ E is convex and bounded ∂E is C1 E has nonempty interior    . Then we have Theorem 1.2. For anys∈(0,1) there exists a minimizer ofˆWs,1 s in C. Strategy and Outline.Our arguments are substantially inspired by the relation between nonlocal Willmore energy and the tangent-point energies, studied first by Buck and Orloff [7], Gonzalez and Maddocks [23], and Blatt and Reiter [3]. Tangent-point energies are just one class of topological knot or surface energies, and thus related to the Möbius energy [28, 19], the O’Hara energies [29, 30, 5], and Menger curvature energies [36, 26, 22, 20]. Indeed, our arguments draw substantial inspiration from the corresponding existence argument for minimizers of the tangent- point energy, [6]. There are, however, substantial technical differences that we need to overcome. One is the sign of the mean curvatureHs, which for general curves could be changing – we remedy this by working only with convex curves, an unsatisfying but for now seemingly unavoidable assumption (cf. also [8]). Another one is the change of underlying Sobolev space, which creates surprising technical difficulties. The basic idea is as follows: •We first show that the Willmore energy controls the BMO-norm ofγ′in a locally quantifiable way, Proposition 3.1. •Then we establish that local BMO-control suffices to obtain (quantifiably) local control of the BiLipschitz constant of the curve, Lemma 3.4. This in turn gives quantitative control of the graphical behavior ofγ, Lemma 3.5. • On sets where we are graphs, we can use convexity to obtain a control in the sharp Sobolev spaceW 1+s,1 s 2 Theorem 4.1. • Having Sobolev control allows us to pass to the limit for sequences. We then show thatqualitatively any convex curve with finite Willmore energy is actuallyC1 (a fact, probably interesting on its own), Theorem 6.1.4 G. GIACOMIN AND A. SCHIKORRA •Those are the main ingredients that are needed to obtain reflexivity, lower semicontinuity in the class of convex homeomorphisms, which we carry out in Theorem 7.1 AcknowledgementHelpful discussions with S. Blatt, S. Dipierro, J. Scheuer, and E. Valdinocci are gratefully acknowledged. The proof of Lemma 3.5 is based on an idea by S. Blatt. A.S. is funded by NSF Career DMS-2044898. A.S. is an Alexander-von-Humboldt Fellow. G.G. is funded by the Australian Laureate Fellowship FL190100081 “Minimal surfaces, free boundaries and partial differential equations”. 2. Preliminaries and Notation For a vectorv= (v1,v2)T ∈R2 we denote its rotation by−π 2 v⊥= (v2,−v1)T. We also use the notation Rθv for counterclockwise rotation byθ. For two nonnegative quantitiesA,B we write A ≲ B if there exists a multiplicative constantC such thatA ≤CB, and write A≈B if A≲ B and B ≲ A. Special dependencies in such inequalities are denoted by subscript, but essentially all constants depend ons. 2.1. Sobolev spaces. Our argument relies on a suitable Sobolev control. It turns out, that the “usual” Gagliardo-Slobokdeckij space seems not to be the right space to work with – instead we work with the Bessel potential space. However, for localization purposes it is beneficial to keep a seminorm similar to the Gagliardo seminorm. Definition 2.1. For I ⊂R, the Sobolev spaceWs,p 2 (I) is defined in the usual way via its semi-norm, [f]Ws,p 2 (I) := (ˆ I (ˆ I |f(x) −f(y)|2 |x−y|1+2s dy )p 2 dx )1 p . The main reason we are interested in using this space is the following identification, which is due to Stein [35, Theorem 1], for the general versions we refer to [31, 38]. To state the result, we adopt the notation |D|sf := (−∆) s 2 f. Here, (−∆) s 2 denotes the usual fractional Laplacian, cf. [15]. Theorem 2.2. Assume thats∈(0,1) and p∈( 2 1+2s,∞), then [f]Ws,p 2 (R) ≈∥|D|sf∥Lp(R). In particular, for anys∈(0,1) [f] W s,1 s 2 (R) ≈∥|D|sf∥L 1 s(Rn). We are interested in local estimates, and for this will need a Sobolev-type inequality on a ball. Towards this, we first observe the following Poincaré type inequalityMINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 5 Lemma 2.3.For0 <t< 1 we have for the intervalB = (−1,1) and anyf ∈L2(B) (ˆ B ˆ B |f(x) −f(y)| 1 t dxdy )t + (ˆ B ˆ B |f(x) −f(y)|2 dxdy )1 2 ≲ [f] W t,1 t 2 (B) In particular, if ´ Bf = 0 we have ∥f∥L 1 t(B) + ∥f∥L2(B) ≲ [f] W t,1 t 2 (B) . Proof. The inequality (2.1) (ˆ B ˆ B |f(x) −f(y)| 1 t dxdy )t ≲ [f] W t,1 t 2 (B) is a consequence of Hölder’s inequality. Indeed, denote by(f)B := |B|−1 ´ f, then, since t∈(0,1), (ˆ B ˆ B |f(x) −f(y)| 1 t dxdy )t ≤2 (ˆ B ˆ B |f(x) −(f)B| 1 t dxdy )t =C (ˆ B |f(x) −(f)B| 1 t dx )t ≲ (ˆ B (ˆ B |f(x) −f(z)|dz )1 t dx )t ≲ (ˆ B (ˆ B |f(x) −f(z)|2 dz )1 2t dx )t ≲[f] W t,1 t 2 (B) . This proves (2.1). The inequality (2.2) (ˆ B ˆ B |f(x) −f(y)|2 dxdy )1 2 ≲ [f] W t,1 t 2 (B) follows from(2.1) and Hölder’s inequality if1 t ≥2. So from now on we will focus on proving (2.2) under the condition (2.3) 1 t ≤2. We argue by contradiction. Assume(2.2) is not true for any constant in≲. Then there exists a sequence of counterexamplesfk ∈L2(B) such that (ˆ B ˆ B |fk(x) −fk(y)|2 dxdy )1 2 >k [fk] W t,1 t 2 (B) Both sides do not change if we replacefk by fk−(fk)B, where(fk)B := 1 2 ´ Bfk, so w.l.o.g. we may assume (2.4) (fk)B = 0 for all k.6 G. GIACOMIN AND A. SCHIKORRA Dividing both sides by (´ B ´ B|fk(x) −fk(y)|2)1 2 we may also assume that for all k∈N (ˆ B ˆ B |fk(x) −fk(y)|2dxdy )1 2 = 1 and (2.5) [fk] W t,1 t 2 (B) ≤1 k. The first equality, combined with the assumption(f)B = 0 implies in particular (2.6) 1 2 ≤∥fk∥L2(B) ≤1. Fix η∈C∞ c ((−5/4,5/4)), η≡1 in (−1,1), and set gk := η˜fk, where ˜fk(x) :=    fk(−2 −x) x∈(−2,−1) fk(x) x∈(−1,1) fk(2 −x) x∈(1,2). We see that (2.7) sup k ∥gk∥L2(R) ≲ sup k ∥˜fk∥L2((−2,2)) ≲ sup k ∥fk∥L2((−1,1)) ≤1. Moroever, ˆ R (ˆ R |gk(x) −gk(y)|2 |x−y|1+2t dy )1 2t dx ≲ ˆ (−3/2,3/2) (ˆ (−3/2,3/2) |gk(x) −gk(y)|2 |x−y|1+2t dy )1 2t dx + ˆ R\\(−3/2,3/2) (ˆ (−5/4,5/4) |gk(y)|2 (1 + |x|)1+2tdy )1 2t dx + ˆ (−5/4,5/4) (ˆ R\\(−3/2,3/2) |gk(x)|2 (1 + |y|)1+2tdy )1 2t dx ≈ ˆ (−3/2,3/2) (ˆ (−3/2,3/2) |gk(x) −gk(y)|2 |x−y|1+2t dy )1 2t dx + (ˆ (−5/4,5/4) |gk(y)|2dy )1 2t + ˆ (−5/4,5/4) |gk(x)| 1 tdx ≲ ˆ (−3/2,3/2) (ˆ (−3/2,3/2) |gk(x) −gk(y)|2 |x−y|1+2t dy )1 2t dx+ ∥gk∥ 1 t L2(R). In the last inequality we used (2.3).MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 7 Next we use the discrete product rule η(x) ˜fk(x) −η(y) ˜fk(y) = η(y) (˜fk(x) −˜fk(y) ) + (η(x) −η(y)) ˜fk(x) to obtain ˆ (−3/2,3/2) (ˆ (−3/2,3/2) |gk(x) −gk(y)|2 |x−y|1+2t dy )1 2t dx ≲ ˆ (−3/2,3/2) (ˆ (−3/2,3/2) |˜fk(x) −˜fk(y)|2 |x−y|1+2t dy )1 2t dx + ˆ (−3/2,3/2) |˜fk(x)| 1 t (ˆ (−3/2,3/2) |x−y|2 |x−y|1+2tdy )1 2t dx ≲ ˆ (−3/2,3/2) (ˆ (−3/2,3/2) |˜fk(x) −˜fk(y)|2 |x−y|1+2t dy )1 2t dx+ ∥˜fk∥L2((−3/2,3/2)) where in the last inequality we usedt< 1 and (2.3). Next, by substitution and our choice of reflection we find ˆ (−3/2,3/2) (ˆ (−3/2,3/2) |˜fk(x) −˜fk(y)|2 |x−y|1+2t dy )1 2t dx ≲ ˆ (−1,1) (ˆ (−1,1) |fk(x) −fk(y)|2 |x−y|1+2t dy )1 2t dx. In summary, we have shown sup k ∥gk∥L2(R) + [gk] W t,1 t 2 (R) <+∞. By Theorem 2.2 and Rellich-Kondrachov theorem we find a subsequence (not relabelled) such thatgk k→∞ − −−− →g strongly inL2 loc(R). Since fk = gk in (−1,1) we conclude that forf := g ⏐⏐⏐ (−1,1) we have in view of (2.6) ∥f∥L2((−1,1)) = lim k→∞ ∥gk∥L2((−1,1)) = lim k→∞ ∥fk∥L2((−1,1)) ≥1 2. Moreover, by strongL2-convergence and (2.4) (f)B = 0. On the other hand, by Fatou’s lemma and (2.5) we have [f] W t,1 t 2 ((−1,1)) ≤lim inf k→∞ [fk] W t,1 t 2 ((−1,1)) = 0, thus f ≡const – since(f)B = 0 we concludef ≡0 contradicting ∥f∥L2(−1,1) ≥1 2 . This proves (2.2) under the assumption (2.3). We can conclude. □ Lemma 2.4 (Sobolev inequality). For 0 < s < t <1 we have for any interval B ⊂R [f] W s,1 s 2 (B) ≲s,t [f] W t,1 t 2 (B)8 G. GIACOMIN AND A. SCHIKORRA Proof. From Theorem 2.2 (observe that 1 s > 2 1+2s is always satisfied) and the Sobolev embedding theorem (2.8) [f] W s,1 s 2 (R) ≈∥|D|sf∥L 1 s(R) ≲ ∥|D|tf∥L 1 t(R) ≈[f] W t,1 t 2 (R) . Now, iff : B →R, we can assume by scaling w.l.o.g.B = (−1,1). By invariance under additive constants we also assume (2.9) (f)B = 0. Set ˜f(x) :=    f(−2 −x) x∈(−2,−1) f(x) x∈(−1,1) f(2 −x) x∈(1,2). Then, for everyη∈C∞ c ((−3/2,3/2)), η≡1 in (−1,1), using (2.8) we have [f] W s,1 s 2 ((−1,1)) ≤[η˜f] W s,1 s 2 (R) ≲ [η˜f] W t,1 t 2 (R) . In the proof of Lemma 2.3 we already estimated that [η˜f] W t,1 t 2 (R) ≲ [f] W t,1 t 2 (B) + ∥f∥L 1 t(B) + ∥f∥L2(B). Since we have (2.9), the statement of Lemma 2.3 implies [f] W s,1 s 2 ((−1,1)) ≲ [η˜f] W t,1 t 2 (R) ≲ [f] W t,1 t 2 (B) . We can conclude. □ We also record the following important potential formula for the fractional Laplacian. It is most likely well-known to experts, but we give the argument for completeness. Lemma 2.5. Let f ∈C∞ c (R). Then for eachs∈(0,1) and x∈R it holds that (2.10) ˆ R f(x) −f(y) −f′(y)(x−y) |x−y|1+s+1 dy= Cs(−∆) s+1 2 f(x), for someCs depending only ons. Proof. We notice that Tf(x) := ˆ R f(x) −f(y) −f′(y)(x−y) |x−y|2+s dy = ˆ R f(x) −f(x+ h) + f′(x+ h)(h) |h|2+s dh =1 2 ˆ R f(x) −f(x+ h) + f′(x+ h)(h) |h|2+s dh+ 1 2 ˆ R f(x) −f(x−h) + f′(x−h)(−h) |h|2+s dh =1 2 ˆ R 2f(x) −f(x+ h) −f(x−h) + f′(x+ h)(h) −f′(x−h)(h) |h|2+s dh =1 2 ˆ R 2f(x) −f(x+ h) −f(x−h) + ∂hf(x+ h) (h) + ∂hf(x−h)(h) |h|2+s dh =1 2 ˆ R 2f(x) −f(x+ h) −f(x−h) + ∂h(f(x+ h) + f(x−h)) (h) |h|2+s dh =1 2 ˆ R 2f(x) −f(x+ h) −f(x−h) −∂h(2f(x) −f(x+ h) −f(x−h)) (h) |h|2+s dh.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 9 Integrating by parts and observing that ∂h h |h|2+s = |h|2+s −h(2 + s)|h|1+s h |h| |h|4+2s = −(1 + s) 1 |h|2+s, we deduce that Tf(x) =1 2 ˆ R 2f(x) −f(x+ h) −f(x−h) −∂h(2f(x) −f(x+ h) −f(x−h)) (h) |h|2+s dh =1 2 ˆ R 2f(x) −f(x+ h) −f(x−h) −(1 + s) (2f(x) −f(x+ h) −f(x−h)) |h|2+s dh =1 −(1 + s) 2 ˆ R 2f(x) −f(x+ h) −f(x−h) |h|2+s dh =1 −(1 + s) 2 cd,s(−∆) s+1 2 f(x). □ 2.2. The fractional mean curvature.While it is irrelevant for most calculation- based analysis, for convenience and geometric arguments we shall assume that whenever possible, curves are parametrized counter-clockwise, (2.11) γ is a counter clockwise parametrization of its image, For some intervalI ⊂R and γ ∈Lip(I,R2), fors∈(0,1) and p≥1, we define the s,p-nonlocal Willmore energy ofγ as Ws,p ( γ ⏐⏐ I ) = (ˆ I (ˆ I ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s |γ′(y)|dy )p |γ′(x)|dx )1 p , where n(γ(y)) is a.e. a unit normal to the curveγ at γ(y). We remind the reader of our abuse of notation by writingWs := Ws,1 s . Under the assumption(2.11) for a.e. y∈I we define fix the direction of the vectorfieldn(γ(y)) as n(γ(y)) := γ′(y)⊥. We define ˜X :=    γ ∈Lip ( S1,R2) ⏐⏐⏐⏐⏐ γ is a homeomorphism |γ′|≡ 1 a.e. in S1 γ is convex inS1 γ satisfies (2.11) inS1    . Clearly X in (1.1) is a subset of˜X – up to inverting the orientation so that(2.11) holds. For everyγ ∈ ˜X the s,p-nonlocal Willmore energy takes the form (2.12) Ws,p(γ) := (ˆ S1 (ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s )p dx )s . In the definitions ofX and ˜X we assumed convexity, the following is the precise definition we are going to use.10 G. GIACOMIN AND A. SCHIKORRA Definition 2.6 (convexity). Let γ : I →R2 be continuous. Given some subset A⊂I, we say thatγ is convex inA if for allx∈A there existsνx ∈S1 such that νx ·(γ(x) −γ(y)) ≥0 for ally∈A.(2.13) It is worth pointing out that for everyγ ∈ ˜X and for a.e. x ∈S1 one has that νx satisfying the inequality in(2.13) is unique, and actuallyνx = n(γ(x)), see for instance Corollary A.9. In particular for convex curves we have ⟨n(γ(y),γ(y) −γ(x)⟩≥ 0 a.e. x,y ∈I Our analysis in this paper relies on a relation between curves with finite Willmore energy and curves that belong to the Sobolev spaceW 1+s,1 s 2 . One direction is the following Lemma Lemma 2.7. Let s∈(0,1) and γ : S1 →R2 be a BiLipschitz homeomorphism with |γ′|≡ 1 a.e. in S1 and such that [γ′] W s,1 s 2 (S1) <+∞. Then, it holds that Ws(γ) = ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s dy ⏐⏐⏐⏐⏐ 1 s dx< +∞. Let us stress two things: We will not really use the previous lemma in our analysis, obtaining a quantitative converse of Lemma 2.7 is the main challenge of the present paper – see Section 4. Secondly, the assumption thatγ is a homeomoprhism is not needed, certain crossings and figure-eight shapes are permissible, this will be investigated more in future work. Proof. Since ⟨n(γ(y)),γ′(y)⟩= 0 a.e. we have ⟨n(γ(y)),γ(y) −γ(x)⟩ =⟨n(γ(y)),γ(y) −γ(x) −γ′(y)(y−x)⟩. Since γ is a BiLipschitz homeomorphism we also have|γ(x) −γ(y)|≈| x−y|. Then, we first observe that ˆ S1 (ˆ S1 ⏐⏐⏐⏐⏐ ⟨n(γ(y)) −n(γ(x)),γ(y) −γ(x) −γ′(y)(y−x)⟩ |γ(y) −γ(x)|2+s ⏐⏐⏐⏐⏐dy )1 s dx ≲ ˆ S1 (ˆ S1 |γ′(y) −γ′(x)||γ(y) −γ(x) −γ′(y)(x−y)| |x−y|2+s dy )1 s dx. Using the fundamental theorem of calculus, we have |γ(y) −γ(x) −γ′(y)(x−y)|≤| x−y| ˆ [x,y] |γ′(z) −γ′(y)|dzMINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 11 By Hölder’s inequality we then find ˆ S1 (ˆ S1 ⏐⏐⏐⏐⏐ ⟨n(γ(y)) −n(γ(x)),γ(y) −γ(x) −γ′(y)(y−x)⟩ |γ(y) −γ(x)|2+s ⏐⏐⏐⏐⏐dy )1 s dx ≲[γ′]2 W s 2 ,2 s 2 (S1) ≲[γ′]2 W s,1 s 2 (S1) . In the last line we use Sobolev embedding Lemma 2.4. Thus, in order to showWs(γ) <∞we exchangen(γ(y)) with n(γ(x)) and simply need to show ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 ⟨n(γ(x)),γ(y) −γ(x) −γ′(y)(x−y)⟩ |γ(y) −γ(x)|2+s dy ⏐⏐⏐⏐⏐ 1 s dx ≲ ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 γ(y) −γ(x) −γ′(y)(x−y) |γ(y) −γ(x)|2+s dy ⏐⏐⏐⏐⏐ 1 s dx< +∞. Next, we observe (see e.g. [4, 6] and references within) 1 − |x−y|2 |γ(y) −γ(x)|2 =|γ(y) −γ(x)|2 −|x−y|2 |γ(x) −γ(y)|2 = ´ [x,y] ´ [x,y] γ′(z1) ·γ′(z2) −1 dz1 dz2 |γ(x) −γ(y)|2 = ´ [x,y] ´ [x,y] |γ′(z1) −γ′(z2)|2 dz1 dz2 |γ(x) −γ(y)|2 This implies that ⏐⏐⏐⏐1 − |x−y|2 |γ(y) −γ(x)|2 ⏐⏐⏐⏐≈= ˆ [x,y] ˆ [x,y] |γ′(z1) −γ′(z2)|2 dz1 dz2. Thus ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 γ(y) −γ(x) −γ′(y)(x−y) |γ(y) −γ(x)|2+s dy ⏐⏐⏐⏐⏐ 1 s dx ≲ ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 γ(y) −γ(x) −γ′(y)(x−y) |x−y|2+s dy ⏐⏐⏐⏐⏐ 1 s dx+ [γ′]3 W s 3 ,3 s 2 (S1) ≲ ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 γ(y) −γ(x) −γ′(y)(x−y) |x−y|2+s dy ⏐⏐⏐⏐⏐ 1 s dx+ [γ′]3 W s,1 s 2 (S1) , where in the last line we used again the Sobolev embedding Lemma 2.4. We now conclude by using Lemma 2.5, which – after a sterographic projection to the sphere12 G. GIACOMIN AND A. SCHIKORRA implies ˆ S1 ⏐⏐⏐⏐⏐ ˆ S1 γ(y) −γ(x) −γ′(y)(x−y) |x−y|2+s dy ⏐⏐⏐⏐⏐ 1 s dx≲ ∥|D|s+1γ∥L 1 s(S1) ≈[γ′] W s,1 s 2 (S1) , where in the last inequality we used Stein’s theorem, Theorem 2.2. □ 2.3. The maximum principle for the nonlocal mean curvature.The maxi- mum principle for nonlocal mean curvature is well known and will play a crucial role in our argument. Proposition 2.8 (Maximum Principle for the nonlocal mean curvature). Let A,B ⊂Rn be measurable ands ∈(0,1). Moreover, we assume thatA ⊂B and there exists some pointz∈∂A∩∂B. If Hs A(z) and Hs B(z) exist, then we have (2.14) Hs A(z) ≥Hs B(z). Furthermore, ifB is convex it holds that (2.15) Hs B(z) ≥0. for anyz where Hs B(z) exists. Proof. According to the hypothesis we have that Bc ⊂Ac. Therefore, for eachy∈Rn we have that χAc(y) −χA(y) ≥χBc(y) −χB(y). From this equation we evince that for eachϵ> 0ˆ Rn\\Bϵ(z) χAc(y) −χA(y) |z−y|n+s dy≥ ˆ Rn\\Bϵ(z) χBc(y) −χB(y) |z−y|n+s dy. Taking the limit with respect toϵ→0+ in both sides we conclude the proof of(2.14), since we assume that this limit exists. Since B is convex, for eachz∈∂B there exists an half planeπz such that B ⊂πz. Therefore, applying (2.14) we obtain that Hs B(z) ≥Hs πz(z) = 0. □ In the following proposition we establish sufficient conditions for the boundary parametrization of a setE ⊂R2 in order to rewrite the nonlocal mean curvature as a surface integral. We stress that this result is not sharp and that it is possible to determine more general conditions on the regularity of a set for such identity to hold. The proof of Proposition 2.9 is in Appendix B. Proposition 2.9. Let s∈(0,1), γ ∈Lip(S1,R2) be a homeomorphism such that |γ′|≡ 1 a.e. in S1 and γ satisfies the convexity assumption(2.13) in S1. Then, if we denoteE := co ( γ ( S1)) , for a.e.x∈S1 it holds that (2.16) Hs ∂E(γ(x)) = 2 s ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s dy, where n(γ(y)) := γ′(y)⊥.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 13 3. Small energy controls BMO-parametrization The main result of this section is the fact hat when the Willmore energy is suitably small, then theBMO-norm of the derivative of the parametrizationγ is dominated by the Willmore energy. More precisely we have Proposition 3.1. For anyp∈[1,∞), s∈(0,1) there exists a uniformε> 0 such that the following holds: Assume thatγ ∈C1(BR0 ,R2), |γ′|≡ 1 satisfies (wheren(γ(x)) = γ′(x)⊥) (3.1) ˆ BR0 (ˆ BR0 |⟨n(γ(y),γ(y) −γ(x)⟩| |γ(x) −γ(y)|2+s dy )1 s dx<ε then for allBr(x0) ⊂BR0 (ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|pdxdy )1 p ≲p   ˆ BR0 (ˆ BR0 |⟨n(γ(y)),γ(y) −γ(x)⟩| |γ(x) −γ(y)|2+s dy )1 s dx   s . (3.2) Let us point out a subtlety in Proposition 3.1. There is no convexity assumption. However, only ifγ is a convex curve⟨n(γ(y)),γ(y) −γ(x)⟩has a sign, and the absolute value inside the integral can be ignored – that is for convex curves(3.1) is indeed the Willmore energy restricted to a ball. In order to prove Proposition 3.1, we need the following local John-Nirenberg type result, see [21, Corollary 6.22]. Lemma 3.2. For anyu∈L∞(B1) and anyp∈[1,∞) we have sup Br(x0)⊂B1 (ˆ Br(x0) ˆ Br(x0) |u(x) −u(y)|pdxdy )1 p ≲p sup Br(x0)⊂B1 ˆ Br(x0) ˆ Br(x0) |u(x) −u(y)|dxdy, (3.3) whenever the right-hand side is finite. Lastly we need a certain mean valued estimate for double intergrals. Lemma 3.3. For anyp> 1 ˆ B(x0,r) ˆ B(x0,r) ˆ [x,y] |U(y,z)|dzdxdy ≲p (ˆ B(x0,r) ˆ B(x0,r) |U(x,y)|pdxdy )1 p Proof. By translation and scaling, w.l.o.g.x0 = 0 and r= 1, i.e. we need to show ˆ 1 −1 ˆ 1 −1 ˆ [x,y] |U(y,z)|dzdxdy ≲p (ˆ 1 −1 ˆ 1 −1 |U(x,y)|pdxdy )1 p .14 G. GIACOMIN AND A. SCHIKORRA We have ˆ 1 −1 ˆ 1 −1 ˆ [x,y] |U(y,z)|dzdxdy = ˆ 1 −1 ˆ y −1 ˆ z −1 1 y−x|U(y,z)|dxdzdy + ˆ 1 −1 ˆ 1 y ˆ 1 z 1 x−y|U(y,z)|dxdzdy = ˆ 1 −1 ˆ y −1 |U(y,z)|log (|1 + y| |z−y| ) dzdy + ˆ 1 −1 ˆ 1 y log (|1 −y| |z−y| ) |U(y,z)|dzdy ≤ (ˆ 1 −1 ˆ 1 −1 |U(y,z)|p dzdy )1 p (ˆ 1 −1 ˆ y −1 ( log (|1 + y| |z−y| ))p′ dzdy )1 p′ + (ˆ 1 −1 ˆ 1 −1 |U(y,z)|p dzdy )1 p (ˆ 1 −1 ˆ 1 y ( log (|1 −y| |z−y| ))p′ dzdy )1 p′ . Now we use that for anyγ >0 there existsC(γ) such that |log a|≤ C(γ) ( aγ + a−γ) ∀a∈(0,∞). Thus, we have for some smallδ <1 (and a suitable choice ofγ) ˆ 1 −1 ˆ y −1 ( log (y+ 1 |z−y| ))p′ dzdy ≲ ˆ 1 −1 ˆ y −1 (y+ 1)δ |y−z|δ dzdy + ˆ 1 −1 ˆ y −1 |y−z|δ (y+ 1)δ dzdy ≤2δ ˆ 1 −1 ˆ y −1 |y−z|−δ dzdy + 2δ ˆ 1 −1 ˆ y −1 (y+ 1)−δdzdy =2δ ˆ 1 −1 1 1 −δ(y+ 1)1−δdy+ 2δ ˆ 1 −1 (y+ 1)1−δdy =C(δ). Analogously, it holds that ˆ 1 −1 ˆ 1 y ( log (|1 −y| |z−y| ))p′ dzdy ≲ C∗(δ). □ We can conclude. Proof of Proposition 3.1.Since |γ′|≡ 1 we have ⟨γ′(x),γ′(x) −γ′(z)⟩= 1 2|γ′(x) −γ′(z)|2. With the fundamental theorem of calculus we then have ⟨γ′(y),γ(x)−γ(y)−γ′(y)(x−y)⟩= ˆ x y ⟨γ′(y),γ′(z)−γ′(y)⟩= 1 2 ˆ x y |γ′(x)−γ′(y)|2.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 15 Using this and the fact thatn(γ(y)),γ′(y) forms an orthonormal basis ofR2, |γ′(x) −γ′(y)|=|γ′(x)(x−y) −γ′(y)(x−y)| |x−y| ≤|γ(x) −γ(y) −γ′(y)(y−x)| |x−y| + |γ(y) −γ(x) −γ′(x)(x−y)| |x−y| ≲|⟨n(y),γ(x) −γ(y) −γ′(y)(x−y)⟩| |x−y| + |⟨n(x),γ(y) −γ(x) −γ′(x)(y−x)⟩| |x−y| + |⟨γ′(y),γ(x) −γ(y) −γ′(y)(x−y)⟩| |x−y| + |⟨γ′(x),γ(y) −γ(x) −γ′(x)(y−x)⟩| |x−y| ≲|⟨n(γ(y)),γ(x) −γ(y) −γ′(y)(x−y)⟩| |x−y| + |⟨n(γ(x)),γ(y) −γ(x) −γ′(x)(y−x)⟩| |x−y| + ˆ [x,y] |γ′(y) −γ′(z)|2 dz+ ˆ [x,y] |γ′(z) −γ′(x)|2 dz =|⟨n(γ(y)),γ(x) −γ(y)⟩| |x−y| + |⟨n(γ(x)),γ(y) −γ(x)⟩| |x−y| + ˆ [x,y] |γ′(y) −γ′(z)|2 dz+ ˆ [x,y] |γ′(z) −γ′(x)|2 dz. We now observe that wheneverBr(x0) ⊂BR (we use thatr≿ |x−y|≥| γ(x)−γ(y)| since |γ′|≡ 1) ˆ Br(x0) ˆ Br(x0) |⟨n(γ(y)),γ(x) −γ(y)⟩| |x−y| dxdy ≲r1+s ˆ Br(x0) ˆ Br(x0) |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dydx =rs−1 ˆ Br(x0) ˆ Br(x0) |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dydx ≲   ˆ Br(x0) (ˆ Br(x0) |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx   s ≲ (ˆ BR (ˆ BR |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx )s and similarly, using Fubini’s Theorem, we obtain ˆ Br(x0) ˆ Br(x0) |⟨n(γ(x)),γ(y) −γ(x)⟩| |x−y| dxdy ≲ (ˆ BR (ˆ BR |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx )s . Moreover, by Lemma 3.3, for anyp> 1 ˆ Br(x0) ˆ Br(x0) ˆ [x,y] |γ′(y)−γ′(z)|2 dzdxdy ≲ (ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|2pdxdy )1 p16 G. GIACOMIN AND A. SCHIKORRA Combining the above estimates we find sup Br(x0)⊂B1 ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|dxdy ≲ sup Br(x0)⊂B1 (ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|2pdxdy )1 p + (ˆ BR (ˆ BR |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx )s . (3.4) Applying Lemma 3.2 we find sup Br(x0)⊂B1 ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|dxdy ≲ sup Br(x0)⊂B1 (ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|dxdy )2 + (ˆ BR (ˆ BR |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx )s . (3.5) Now set F(R) := sup Br(x0)⊂BR ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|dxdy. Then (3.5) become (3.6) F(R) ≤CF(R)2 + (ˆ BR (ˆ BR |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx )s . As for properties ofF(R), it is clearly increasing function. Moreover, sinceγ ∈C1 we have lim R→0 F(R) = 0. Lastly,R↦→F(R) is continuous: Fix anyε> 0 and R> 0. Since γ′is continuous, there exists anr1 such that we have ´ Br(x) ´ Br(x) |γ′(x) −γ′(y)|dxdy <ε 4 whenever r ∈(0,r1) and x∈B2R. So if|R−R′|≤ r1 100 and Br(x0) ⊂BR with r ≥r1 then we can find˜x0 ∈BR′ and ˜r with B˜r(˜x0) ⊂BR′ such that |˜x0 −x0|≲r1 |R−R′|, and |r−˜r|≲r1 |R−R′|. The same holds ifBr(x0) ⊂BR′ and r ≥r′ then we find a ballB˜r(˜x0) ⊂BR with the above estimates. So if we choose|R−R′|≪ 1, we have in these cases by continuity ofγ′ ⏐⏐⏐⏐⏐ ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|dxdy − ˆ B˜r(˜x0) ˆ B˜r(˜x0) |γ′(x) −γ′(y)|dxdy ⏐⏐⏐⏐⏐≤ε 4. Thus, |F(R) −F(R′)|≤ ε 4 + ε 4 + ε 4 <ε.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 17 These properties combined with(3.6) and a a continuity argument imply that there is someδ >0 (depending onC) such that if (ˆ BR (ˆ BR |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx )s <δ then F(R) ≤C2 (ˆ BR (ˆ BR |⟨n(γ(y)),γ(x) −γ(y)⟩| |γ(x) −γ(y)|2+s dy )1 s dx )s . This, combined with Lemma 3.2, implies (3.2). □ 3.1. Consequence of VMO-control: BiLipschitz-control and graph. Lemma 3.4(Bilipschitz control). For anyδ >0 there existsϵ0 >0 such that the following holds: Assume thatγ ∈Lip(BR0 ,R2), |γ′|≡ 1 a.e. and it satisfies sup Br(x0)⊂BR0 ˆ Br(x0) ˆ Br(x0) |γ′(x) −γ′(y)|dxdy <ϵ0 then 1 −δ≤|γ(x) −γ(y)| |x−y| ≤1 for all x,y ∈BR0 . Proof. We have |γ(y) −γ(x)|2 −|x−y|2 = ˆ y x ˆ y x (⟨γ′(z1),γ′(z2)⟩−1) dz1 dz2 =1 2 ˆ y x ˆ y x |γ′(z1) −γ′(z2)|2 dz1 dz2. In view of Lemma 3.2 and the assumption we then have⏐⏐⏐⏐ |γ(y) −γ(x)|2 |x−y|2 −1 ⏐⏐⏐⏐≤ϵ0 2 . This readily implies the claim. □ Lemma 3.5. Assume thatγ ∈C1(BR0 ,R2), |γ′|≡ 1 and γ is a convex curve in the sense of(2.13). Then, for eachτ ∈BR0 4 there exists someδ∈(0,1) such that if (3.7) 1 −δ≤|γ(x) −γ(y)| |x−y| ≤1 for all x,y ∈BR0 , then (3.8) γ ( BR0 4 (τ) ) is a graph over{tγ′(τ) + γ(τ)|t∈R}, which is either convex or concave. Proof. The proof below is based on ideas by S. Blatt, [1]. First we prove that for everyτ as in the statementγ ( BR0 4 (τ) ) is a graph. To do so, we proceed by contradiction and assume that there exists someτ ∈BR0 4 such that γ ( BR0 4 (τ) ) is not a graph over{tγ′(τ) + γ(τ)|t∈R}. Now, up to translations and rotations ofγ we can assume that γ′(τ) = (1,0)T and γ(τ) = 0.18 G. GIACOMIN AND A. SCHIKORRA Also, as consequence of this and Lemma A.1, we obtain that eitherγ2(t) ≥0 or γ2(t) ≤0 for allt∈BR0 . Without loss of generality we assume that (3.9) γ2(t) ≥0 for all t∈BR0 . Since, by assumption,γ is not a graph onB(x0,R) there must be somex0 ∈BR0 4 (τ) such that γ′(x0) = (0 ,1)T and γ1(x0) > 0 (if x0 > τ) or γ′(x0) = (0 ,−1)T and γ1(x0) <0 (if x0 <τ ). We only consider the casex0 >τ and γ′(x0) = (0,1)T, the proof of the other case is analogous. Moreover, without loss of generality we assume thatτ <0. Then, sinceγ(τ) = 0 and |γ′|= 1 we obtain that |γ(t)|≤| t−τ|, from which we evince that γ(BR0 ) ⊂[τ −R0,R0 −τ]2. Also, it follows from (3.9) that γ(BR0 ) ⊂[τ −R0,R0 −τ] ×[0,R0 −τ]. Now, if νx0 is given as in(2.13), then as a consequence of Lemma A.1 we have that νx0 is uniquely defined and eitherνx0 = (1 ,0)T or νx0 = ( −1,0)T. Now, applying (2.13) inx0 we obtain 0 ≤⟨νx0 ,γ(x0) −γ(τ)⟩= ⟨νx0 ,γ(x0)⟩, from which it follows thatνx0 = n(γ(x0)) = (1,0)T. Making use of this and(2.13) a second time we obtain for allt∈BR0 ⟨( 1 0 ) ,γ(x0) −γ(t) ⟩ ≥0 which gives that (3.10) γ1(t) ≤γ1(x0) for all t∈BR0 . Furthermore, using|γ′|≡ 1 and γ(τ) = 0, we evince γ1(x0) < R0 4 . From this and (3.10) we obtain γ(BR0 ) ⊂ [ τ −R0,R0 4 ] ×[0,R0 −τ] . In particular, we can compute that |γ(−R0) −γ(R0)|≤ diam ([ τ −R0,R0 4 ] ×[0,R0 −τ] ) = ⏐⏐⏐⏐(τ −R0,0) − (R0 4 ,R0 −τ )⏐⏐⏐⏐ = ⏐⏐⏐⏐ ( τ −R0 −R0 4 ,τ −R0 )⏐⏐⏐⏐ ≤7 4R0MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 19 Thus, if we pickδ <1 −7 8 , we obtain that |γ(−R0) −γ(R0)| 2R0 ≤7 8 <1 −δ. Thiscontradicts (3.7)andweconcludethat γ ( BR0 4 (τ) ) isagraphover {tγ′(τ) + γ(τ)|t∈R}. The convexity or concavity of such graph follows immediately from Proposition A.7. □ 4. Sobolev control The goal of this section is show that locally if our curve is convex and the Willmore energy is small we obtain a Sobolev control. Theorem 4.1. For anys∈(0,1) there existsε= ε(s) >0 such that the following holds: Assume that forR> 0 we have a curveγ ∈C1(B20R,R2), |γ′|≡ 1 satisfies (where n(x) = γ′(x)⊥) (4.1) ˆ 20R −20R (ˆ 20R −20R ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(x) −γ(y)|2+s dy )1 s dx<ε. Assume also thatγ is convex in the sense of Definition 2.6 inB20R. Then (4.2) [γ′] W s,1 s 2 (BR) ≲s ˆ 10R −10R (ˆ 10R −10R ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(x) −γ(y)|2+s dy )1 s dx. Our first observation is that under the assumption that we are locally a graph (or the weaker assumptions, that the derivativesγ′do not make a full turn) we have a pointwise control of corresponding second order difference quotient. Lemma 4.2. Assume thatγ ∈Lip (BR,R2) with |γ′|≡ 1 a.e. in BR. If sup z1,z2∈BR |γ′(z1) −γ′(z2)|= c< 2, then for almost everyx,y ∈BR we haveˆ [x,y] |⟨n(γ(y)),γ′(z)⟩|dz≿c |γ(x) −γ(y) −γ′(y)(x−y)|. Proof. We have by Pythagoras’ theorem |γ′(y) −γ′(z)|2 = |n(γ(y)) ·(γ′(y) −γ′(z))|2 + |γ′(y) ·(γ′(y) −γ′(z))|2. Now |γ′|≡ 1 implies |γ′(y) ·(γ′(y) −γ′(z))|2 = 1 4|γ′(y) −γ′(z)|4. Thus we have |n(γ(y)) ·(γ′(y) −γ′(z))|2 =|γ′(y) −γ′(z)|2 −1 4|γ′(y) −γ′(z)|4 =|γ′(y) −γ′(z)|2 ( 1 −1 4|γ′(y) −γ′(z)|2 ) ≥|γ′(y) −γ′(z)|2 ( 1 −1 4c2 ) .20 G. GIACOMIN AND A. SCHIKORRA So we have (by the fundamental theorem) ˆ [x,y] |n(γ(y)) ·γ′(z)|dz≿c ˆ [x,y] |γ′(y) −γ′(z)|≿ |γ(y) −γ(x) −γ′(y)(x−y)|. □ On the other hand, we have also the following result. Lemma 4.3. Assume thatγ ∈C1(BR) with |γ′|≡ 1. Assume thatγ is the graph of a convex function then for everyx,y ∈BR we have ˆ [x,y] |⟨n(γ(y)),γ′(z)⟩|dz= ⟨n(γ(y)),γ(y) −γ(x)⟩. Proof. Indeed, beingγ the graph of a convex functionf, we have that ⟨n(γ(y)),γ′(z)⟩= 1√ 1 + f′(γ1(x))2 √ 1 + f′(γ1(y))2 (f′(γ1(y)) −f′(γ1(z))) ≥0, since f′is non decreasing andγ1(y) >γ1(z) for everyz∈(x,y). That is, ifx≤z≤y then ⟨n(γ(y)),γ′(z)⟩≥ 0 and ify≤z≤x then ⟨n(γ(y)),γ′(z)⟩≤ 0 In both cases the claim follows from the fundamental theorem of calculus. □ Proof of Theorem 4.1.W.l.o.g. R= 1. Taking ε small enough in(4.1) we obtain from Proposition 3.1 combined with Lemma 3.5, Lemma 3.4 thatγ is a convex graph, and biLipschitz onB5. Thus we can apply Lemma 4.2 and Lemma 4.3 to obtain |γ(x) −γ(y) −γ′(y)(x−y)|≲ ⟨n(γ(y),γ(y) −γ(x)⟩. Integrating this, and using that|γ(x) −γ(y)|≤| x−y|we conclude ˆ [−5,5] (ˆ [−5,5] |γ(x) −γ(y) −γ′(y)(x−y)| |x−y|2+s dy )1 s dx ≲ ˆ [−5,5] (ˆ [−5,5] ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(x) −γ(y)|2+s dy )1 s dx (4.3) Now, pick the usual bump functionη∈C∞ c (B(0,3)), η≡1 in B(0,2). We set ˜γ(x) := η(x)(γ(x) −q(x)) + q(x) ≡η(x)¯γ(x) + q(x), where ¯γ := γ−q and q(x) = q1 + xq2 is an affine map which essentially corresponds to zero-th and first moment ofγ. More precisely, q1 := ˆ (−2,2) γ(z) dz, q 2 := ˆ (−2,2) γ′(z) dz. We notice thatˆ (−2,2) q(x) dx= ˆ (−2,2) γ(x) dx and ˆ (−2,2) q′(x) dx= ˆ (−2,2) γ′(x) dx.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 21 By the discrete product rule ˜γ(x) −˜γ(y) −˜γ′(y)(x−y) =η(x)¯γ(x) −η(y)¯γP(y) −(η¯γ)′(y)(x−y) =η(x)(¯γ(x) −¯γ(y) −¯γ′(y)(x−y)) + (η(x) −η(y) −η′(y)(x−y))¯γ(y) + (η(x) −η(y)) ¯γ′(y)(x−y). Since q is affine, we have γ(x) −γ(y) −γ′(y)(x−y) = ¯γ(x) −¯γ(y) −¯γ′(y)(x−y). With these observations, (4.3) readily implies ˆ [−5,5] (ˆ [−5,5] η(x) |¯γ(x) −¯γ(y) −¯γ′(y)(x−y)| |x−y|2+s dy )1 s dx ≲ ˆ [−5,5] (ˆ [−5,5] ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(x) −γ(y)|2+s dy )1 s dx. Also, we have forx ∈[−5,5], for any p ∈(1,∞) with p′ < 1 s, using Hölder’s inequality, ˆ [−5,5] |η(x) −η(y)||¯γ′(y)| |x−y|1+s dy≲ ˆ [−5,5] |γ′(y) −q′(y)||x−y|−sdy ≲ (ˆ [−5,5] |γ′(y) −q′(y)|p dy )1 p . Thus, we obtain that   ˆ [−5,5] (ˆ [−5,5] |(η(x) −η(y)) ¯γ′(y)(x−y)| |x−y|2+s dy )1 s dx   s ≲ (ˆ [−5,5] ˆ [−5,5] |γ′(x) −γ′(y)|pdxdy )1 p .22 G. GIACOMIN AND A. SCHIKORRA Finally, we have forx ∈[−5,5], for any p ∈(1,∞) with p′ < 1 s (observe that (¯γ(y))[−5,5] = 0) ⏐⏐⏐⏐⏐ ˆ [−5,5] (η(x) −η(y) −η′(y)(x−y))¯γ(y) |x−y|2+s dy ⏐⏐⏐⏐⏐ ≲ ˆ [−5,5] |x−y|−s|¯γ(y)|dy = ˆ [−5,5] |x−y|−s ⏐⏐⏐¯γ(y) −(¯γ(y))[−5,5] ⏐⏐⏐dy ≤ ˆ [−5,5] ˆ [−5,5] |x−y|−s|¯γ(y) −¯γ(z)|dzdy ≤ ˆ [−5,5] ˆ [−5,5] ˆ [y,z] |x−y|−s|¯γ′(z2)|dz2 dzdy = ˆ [−5,5] ˆ [−5,5] ˆ [y,z] |x−y|−s⏐⏐¯γ′(z2) −(¯γ′)[−5,5] ⏐⏐dz2 dzdy ≤ ˆ [−5,5] ˆ [−5,5] ˆ [−5,5] ˆ [−5,5] |x−y|−s|γ′(z2) −γ′(z3)|dz3 dz2 dzdy ≲ ˆ [−5,5] ˆ [−5,5] |γ′(z2) −γ′(z3)|dz3 dz2. So that   ˆ [−5,5] ⏐⏐⏐⏐⏐ ˆ [−5,5] (η(x) −η(y) −η′(y)(x−y))¯γ(y) |x−y|2+s dy ⏐⏐⏐⏐⏐ 1 s dx   s ≲ (ˆ [−5,5] ˆ [−5,5] |γ′(x) −γ′(y)|pdxdy )1 p . In conclusion, using also (3.2), ˆ [−5,5] (ˆ [−5,5] |˜γ(x) −˜γ(y) −˜γ′(y)(x−y)| |x−y|2+s dy )1 s dx ≲ ˆ [−5,5] (ˆ [−5,5] ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(x) −γ(y)|2+s dy )1 s dx. The claim now follows from the following proposition, Proposition 4.4 and again (3.2). □ Proposition 4.4.Let γ : [−4,4] →R2 and set forη∈C∞ c ([−3,3]) η≡1 in [−2,2], ˜γ(x) := η(x)(γ(x) −q(x)) + q(x) ≡η(x)¯γ(x) + q(x), where ¯γ := γ−q and q(x) = q1 + xq2 is an affine map which essentially corresponds to zero-th and first moment ofγ. More precisely, q1 := ˆ (−2,2) γ(z) dz, q 2 := ˆ (−2,2) γ′(z) dz.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 23 Assume that Γ := ˆ (−4,4) (ˆ (−4,4) |˜γ(x) −˜γ(y) −˜γ′(y)(x−y)| |x−y|2+s dy )1 s dx< ∞. Then for someq≥1 [γ′] W s,1 s 2 ((−1,1)) ≲ Γs + (ˆ (−4,4) ˆ (−4,4) |γ′(x) −γ′(y)|qdxdy )1 q Proof. We recall, thanks to Poincaré inequality, for1 ≤p< +∞we deduce (4.4) ∥¯γ∥Lp(B(0,2)) = ∥γ−q∥Lp(B(0,2)) ≲ ∥γ′−q′∥Lp(B(0,2)) . Therefore, we obtain ∥˜γ′−q′∥Lp(B(0,2)) ≤∥η′(γ−q)∥Lp(B(0,2)) + ∥η(γ′−q′)∥Lp(B(0,2)) ≲ ∥γ−q∥Lp(B(0,2)) + ∥γ′−q′∥Lp(B(0,2)) ≲ ∥γ′−q′∥Lp(B(0,2)) ≲ (ˆ (−2,2) ˆ (−2,2) |γ′(z) −γ′(y)|p dzdy )1 p . (4.5) Thanks to the support ofη (and the fact thatq is affine) we have ˆ (−4,4) (ˆ R |˜γ(x) −˜γ(y) −˜γ′(y)(x−y)| |x−y|2+s dy )1 s dx ≲ ˆ (−4,4) (ˆ (−4,4) |˜γ(x) −˜γ(y) −˜γ′(y)(x−y)| |x−y|2+s dy )1 s dx + ˆ (−3,3) (ˆ R\\(−4,4) |˜γ(x) −˜γ(y) −˜γ′(y)(x−y)| |x−y|2+s dy )1 s dx. We see that ˆ (−3,3) (ˆ R\\(−4,4) |˜γ(x) −˜γ(y) −˜γ′(y)(x−y)| |x−y|2+s dy )1 s dx = ˆ (−3,3) (ˆ R\\(−4,4) |η(x)¯γ(x)| |x−y|2+s dy )1 s dx = ˆ (−3,3) |¯γ(x)| 1 s dx (4.4) ≲ ˆ (−4,4) ˆ (−4,4) |γ′(x) −γ′(y)| 1 s dxdy. Now we have by the representation formula of the fractional Laplacian, Lemma 2.5 ∥|D|s+1 (η¯γ) ∥L 1 s(−4,4) ≲ (ˆ (−4,4) (ˆ R |˜γ(x) −˜γ(y) −˜γ′(y)(x−y)| |x−y|2+s dy )1 s dx )s .24 G. GIACOMIN AND A. SCHIKORRA By Stein’s theorem, Theorem 2.2, [η¯γ] W s,1 s 2 (R) ≲ ∥|D|s+1 (η¯γ) ∥L 1 s(−4,4) + ∥|D|s+1 (η¯γ) ∥L 1 s(R\\(−4,4)). Using the distance betweensupp η and R\\(−4,4), see, e.g., [4, Lemma A.1], we find ∥|D|s+1 (η¯γ) ∥L 1 s(R\\(−4,4)) ≲ ∥η¯γ∥L1(R) (4.4) ≲ ˆ (−4,4) ˆ (−4,4) |γ′(x) −γ′(y)| 1 s dxdy. Thus, we have shown [¯γ] W s,1 s 2 ((−1,1)) ≤[η¯γ] W s,1 s 2 (R) ≲ Γs + (ˆ (−4,4) |γ′(x) −γ′(y)| 1 s dxdy )s . □ 5. Self-repulsiveness of Willmore energy for convex curves Strongly inspired by results of Strzelecki-von der Mosel [37], as adapted to the tangent point energy [6, Theorem 4.9.] we obtain the following statement, which states that points with locally small energy do not collide with any other points. Theorem 5.1. There existsδ >0 such that the following holds. Let γ ∈C1(S1,R2) be a homeomorphism,|γ′|≡ 1. Also assume (5.1) ˆ S1 (ˆ Bρ(x0) |⟨n(γ(y)),γ(y) −γ(x)⟩| |γ(x) −γ(y)|2+s dy )1 s dx<δ. If for anyz0 ∈S1 we have |γ(x0) −γ(z0)|< 1 10ρ, then there exists ¯x ∈ Bρ(x0) such that γ(¯x) = γ(z0). In particular, we have z0 ∈Bρ(x0). This result is a consequence of the following Lemma (see [6, Lemma 4.8] which is an adaptation of [37, Lemma 2.1, Lemma 2.3]). We omit the proofs which are almost verbatim to [6, Lemma 4.8] and [6, Theorem 4.9]. Lemma 5.2(Strzelecki-von der Mosel). Let s∈(0,1). For anyϵ> 0 there existsδ such that the following holds. Let γ ∈Lip(S1,R2), |γ′|≡ 1, and assume that for somex0 ∈S1 and ρ> 0 we have (5.2) ˆ S1 (ˆ Bρ(x0) |⟨n(γ(y)),γ(y) −γ(x)⟩| |γ(y) −γ(x)|2+s dy )1 s dx<δ. Moreover, assume that there isy0 ∈S1 with d:= |γ(x0) −γ(y0)|≤ ρ. Then (5.3) γ(S1) ∩B2d(γ(x0)) ⊂Lϵd(γ(x0),γ(y0)), where L(γ(x0),γ(y0)) := {(1 −t)γ(x0) + tγ(y0)|t∈[0,1]} and Lϵd(γ(x0),γ(y0)) := { p∈R2|dist(p,L(γ(x0),γ(y0))) <ϵd } . As a consequence, see [37, Remark after Lemma 2.3 and Theorem 1.4] we have in particular obtainMINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 25 Proposition5.3 (Strzelecki-vonderMosel) . Lets∈(0,1). Assumeγ ∈Lip(S1,R2), |γ′|≡ 1 a.e. in S1. If ˆ S1 (ˆ S1 |⟨n(γ(y)),γ(y) −γ(x)⟩| |γ(y) −γ(x)|2+s dy )1 s dx< +∞ and if γ is convex in the sense of Definition 2.6 and has finite Willmore energy, then γ(S1) is a topological one-manifold. 6. Convex curves with finite energy are continuously differentiable In this section we prove that allconvex Lipschitz curves with finiteWs,p-energy are actually C1 if s≥1 p – a fact that is interesting on its own. We also believe it holds in higher dimensions, but we will not pursue this here any further. Precisely we have Theorem 6.1. Assume γ belongs to the set γ ∈ ˜X =    γ ∈Lip (S1,R2) ⏐⏐⏐⏐⏐ γ is a homeomorphism |γ′|≡ 1 a.e. in S1 γ is convex inS1    . If for somes∈(0,1) and p≥1 s we have finite energy, (6.1) Ws,p(γ) <+∞, then γ ∈C1. Let us stress that convexity is absolutely crucial in the assumption of Theorem 6.1 – as evinced by Lemma 2.7. Of course, Theorem 6.1 can be formulated for sets: Theorem 6.2. Let E be a bounded and convex set with nonempty interior. If for some s∈(0,1) and somep≥1 s it holds ˆWs,p(E) <+∞. then ∂E is C1. In the proof below observe that theC1-control is purely qualtitative, and we get no estimate whatsoever. This means in particular that when we consider minimizing sequences, we do not seem to get any uniformC1-control. It is also worth pointing out that this result is false in the supercritical regime (namely p< 1/s): then it is possible to construct an example of a homeomorphism γ ∈Lip(S1,R2) that is a parametrization of the boundary of a convex set, which has finiteWs,p energy, but it is notC1. Cf. Remark 6.6. To prove Theorem 6.1 we will first need the following preliminary results. Lemma 6.3. Let γ ∈Lip(S1,R2) be a homeomorphism satisfying the convexity assumption (2.13) in S1 and such that|γ′|≡ 1 a.e. in S1. Then, ifγ /∈C1(S1,R2) there exists somex0 ∈S1 and v̸= w∈S1 such that ⟨v,γ(x0) −γ(x)⟩≥ 0 and ⟨w,γ(x0) −γ(x)⟩≥ 0 ∀x∈S1.26 G. GIACOMIN AND A. SCHIKORRA Proof. Assume to the contrary that for allx0 ∈S1 (6.2) there exists a unique νx0 ∈S1 such that⟨νx0 ,γ(x0) −γ(x)⟩≥ 0 for allx∈S1. Set v(x0) := νx0 . We claim that (6.3) v∈ C(S1,S1). If this was not the case, by compactness of the targetS1, there must exists some v1 ̸= v2 ∈S1, a pointt0 ∈S1, and two sequencestn,˜tn ∈S1 such thattn,˜tn →t0, but lim n v(tn) = v1 ̸= v2 = lim n v(˜tn). According to (6.2) ⟨vtn,γ(tn) −γ(y)⟩≥ 0 and ⟨v˜tn,γ(˜tn) −γ(y)⟩≥ 0 for ally∈S1. Taking the limit forn→+∞and using continuity ofγ, we find ⟨v1,γ(t0) −γ(y)⟩≥ 0 and ⟨v2,γ(t0) −γ(y)⟩≥ 0 for ally∈S1, with v1 ̸= v2. This is in contradiction to the uniqueness ofνt0 in (6.2). That is, if(6.2) was true, then(6.3) is true. However, up to replacingγ(·) with γ(−·), for a.e.x∈S1 we have that γ′(x)⊥= ν(x), see Corollary A.9. This means thatγ′coincides with a continuous function a.e. and therefore, it is continuous – if (6.2) was true. Thus, ifγ ̸∈C1, (6.2) cannot be true, and since by(6.2) there exists at least onev, the logical negation of(6.2) implies that there must be at least two pointv,w ∈S1, and we can conclude. □ Proposition 6.4.Let γ ∈Lip(S1,R2) be a homeomorphism satisfying the convexity assumption (2.13) in S1, and such that|γ′|≡ 1 a.e. in S1. Also, assume that there exists x0 ∈S1 and two unit vectorsv,w ∈S1 satisfying (6.4) v̸= w, ⟨v,γ(x0) −γ(y)⟩≥ 0, and ⟨w,γ(x0) −γ(y)⟩≥ 0, ∀y∈S1. Then, if we define the convex hull ofγ(S1), E := co(γ(S1)), for everyp≥1 s it holds (6.5) lim ε→0+ ˆ S1\\Bε(x0) |Hs ∂E(γ(x))|p dx= +∞. Proof of Proposition 6.4.Thanks to Theorem A.8 we have that there exists some neighbourhood Ux0 ⊂S1 of x0 and a convex functionf such that up to rotations (6.6) γ(t) = (γ1(t),f(γ1(t)))T for all t∈Ux0 . We now find now two vectorsv′ and w′ in S1 that still satisfy(6.4) with better properties. For two sequencesxn,˜xn ∈γ1(Ux0 ) such thatxn ↘γ1(x0), ˜xn ↗γ1(x0) and f is differentiable inxn and ˜xn we define v′:= lim n 1√ 1 + (f′(xn))2 (f′(xn) −1 ) , w′:= lim n 1√ 1 + (f′(˜xn))2 (f′(˜xn) −1 ) .MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 27 The convergence of the two limits above is guaranteed by the monotonicity off′ wherever it exists, and independent of the particular sequences chosen. As a consequence of Theorem A.8,v′ and w′ almost satisfy (6.4) – however it could be that v′ = w′. But indeed, if we had v′ = w′, then it follows that limnf′(xn) = limnf′(˜xn). In this case by convexity off we deduce for everynthat f′(˜xn) ≤f(˜xn) −f(γ1(x0)) ˜xn −γ1(x0) ≤f(xn) −f(γ1(x0)) xn −γ1(x0) ≤f′(xn). Taking the limits, we obtain thatf is differentiable inγ1(x0). As a consequence of this and Theorem A.8 we deduce thatγ is differentiable inx0. This and Lemma A.1 imply that there is a unique unit vectorv satisfying (2.13) in x0 – but this is contradiction to (6.4). So indeedv′̸= w′. So, w.l.o.g.v= v′and w= w′. Withoutlossofgeneralitywecanassumethatforsome θ0 ∈(π,2π) itholds w= Rθ0 v, where Rθ0 denotes the counterclockwise rotation byθ0. The caseθ0 ∈(0,π) follows from the first one by renamingv and w. Also, note thatθ0 = π is not allowed since equation (6.4) would give thatγ(S1) is a line, contradicting the hypothesis thatγ is a homeomorphism. Assume firstθ0 ∈ (3 2 π,2π ) , then up to a translation, rotation and by possibly choos- ing Ux0 smaller, we obtain for somem> 0 (6.7) γ(x0) = 0, v = (0,−1)T and w= 1√ 1 + m2 (−m,−1)T. Note that as a consequence of (6.7) and (6.4) we have that (6.8) γ2(y) ≥0 for all y∈S1. Now, we claim that for a.e.x∈Vx0 := Ux0 ∩{x>x 0}there exists some convex set Ex ⊂R2, such that (6.9) E ⊂Ex and γ(x) ∈∂E ∩∂Ex, and furthermore,Hs ∂Ex satisfies (6.10) Hs ∂Ex(γ(x)) ≳m,s 1 |x−x0|s. If claim(6.9) and (6.10) are true, then we can apply the Maximum Principle for the nonlocal mean curvature, Proposition 2.8, to obtain for a.e.x∈Vx0 that Hs ∂E(γ(x)) ≥Hs ∂Ex(γ(x)) ≳m,s 1 |x−x0|s. In particular, from this last equation we evince thatˆ Ux0 \\Bϵ(x0) |Hs ∂E(γ(x))|p dx≳m,s ˆ Vx0 \\Bϵ(x0) dx |x−x0|ps. Recalling thatp≥1 s, and taking the limit forϵ→0+ we obtain (6.5). Construction of the setEx: To find a setEx with (6.9) and (6.10) we recall that for everyx∈Vx0 there exists some νx ∈S1 such that (6.11) ⟨νx,γ(x) −γ(y)⟩≥ 0 for all y∈S1. Moreover, sinceγ is Lipschitz, the set S := {x∈Vx0 |γ is differentiable inx}28 G. GIACOMIN AND A. SCHIKORRA is such thatσ1 (Vx0 \\S) = 0. From Lemma A.1, we deduce that forx ∈S, the normal νx ∈S1 is uniquely determined. We adhere to the notationνx = (νx1,νx2)T. Also, thanks to Theorem A.8 we have for everyx∈S νx = 1√ 1 + f′(γ1(x)) ( f′(γ1(x)) −1 ) . Hence, under the assumptions provided in(6.7), it follows from this last equation that (6.12) −1 ≤νx2 <0 and νx1 ≥0 for all x∈S. Let x∈S. Now, we begin by setting the non negative gradient m1 := −νx1 νx2 and (6.13) ˜t:=    −γ2(x) + m1γ1(x) m1 if m1 >0 1 if m1 = 0. Then, we define the function (6.14) gx(t) :=    −mt for t∈(−∞,0) 0 for for t∈[0,˜t) m1(t−˜t) for t∈[˜t,+∞). and its epigraph Ex := { (y1,y2) ∈R2|y2 ≥gx(y1) } . Since gx is convex, we obtain that (6.15) Ex is convex. Proof of (6.9): From the fact that (6.16) gx(γ1(x)) = γ2(x), and Proposition A.6 it follows that (6.17) γ(x) ∈∂Ex ∩∂E. According to equation(6.4), (6.7), (6.11) and the fact thatE = co(γ(S1)) we have that    ⟨(m,1)T,P⟩≥ 0 for all P = (P1,P2)T ∈E ⟨(0,1)T,P⟩≥ 0 for all P = (P1,P2)T ∈E ⟨(νx1,νx2)T,γ(x) −P⟩≥ 0 for all P = (P1,P2)T ∈E. Writing explicitly the above set of equations we obtain (6.18)    P2 ≥−mP1 for all P = (P1,P2)T ∈E P2 ≥0 for all P = (P1,P2)T ∈E P2 ≥m1(P1 −γ1(x)) + γ2(x) for all P = (P1,P2)T ∈E.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 29 The set of inequalities in(6.18) guarantees thatgx(P1) ≤P2 for eachP ∈E, and therefore (6.19) E ⊂Ex. Equations (6.15), (6.17) and (6.19) yield to (6.9). Proof of (6.10): To prove(6.10) it is enough to apply Proposition 6.5 inx with gx = g and G= Ex. By doing so we obtain that Hs ∂Ex(γ(x)) ≳m,s 1 (|gx(γ1(x))|+ |γ1(x)|)s = 1 (|γ2(x)|+ |γ1(x)|)s ≥ 1 2s|x|s. This concludes the proof of (6.10). And in turn the case of θ0 ∈ (3π 2 ,2π ) is concluded. Now, we discussthe caseθ0 ∈ ( π,3π 2 ) . In this case, up to translations and rotations of γ(S1), we can assume that for somem> 0 it holds that (6.20) γ(x0) = 0, v = (0,−1)T and w= 1√ 1 + m2 (−m,1)T. We observe that if we define˜w := 1√ 1+m2 (−m,−1)T, then ˜w = R˜θv for some ˜θ∈ (3 2 π,2π ) . If we plug in the expression forw as in(6.20) in equation(6.4), we obtain for every y∈S1 that 0 ≤ ⟨(m −1 ) , (γ1(y) γ2(y) )⟩ = mγ1(y) −γ2(y). From this inequality, and the fact thatγ2 ≥0, we obtain for everyy∈S1 ⟨˜w,(γ(x0) −γ(y))⟩≥ 0. In particular, we have thatv and ˜w satisfies (6.4), v ̸= ˜w and ˜w = R˜θv for some ˜θ∈ (3 2 π,2π ) . This means that we recovered the first case, and we conclude.□ Proposition 6.5. Let s∈(0,1), m,˜t> 0 and m1 ≥0 and consider the function given by g(t) :=    −mt for t∈(−∞,0) 0 for t∈[0,˜t) m1(t−˜t) for t∈[˜t,+∞). Set G:= {(t,y)|y≥g(t)}, see Figure 1. Then for some constantcm,s >0 depending onm and s, •if m1 >0 for all x∈(0,˜t) ∪(˜t,+∞) •if m1 = 0 for everyx> 0 we have Hs ∂G((x,g(x))) ≥ cm,s (|g(x)|+ |x|)s.30 G. GIACOMIN AND A. SCHIKORRA Figure 1. The barrierG from Proposition 6.5 Proof of Proposition 6.5.Let x be as in the statement. Setz:= (x,g(x))T. Define the unit vectors u:= 1√ 1 + m2 (1,−m)T and v:= 1√ 1 + m2 1 (1,m1)T. Then we can parameterize the graph ofg using the curve µ(t) :=    ut for t∈(−∞,0] (t,0) for t∈[0,˜t) v(t−˜t) + (˜t,0) for t∈[˜t,+∞). We observe that if we denoteˆt:= g(x) u2 then µ2(t) ≥g(x) for all t∈(−∞,ˆt]. From this it follows that for everyt∈(−∞,ˆt] |µ(t) −z|≤| µ1(t) −x|+ |µ2(t) −g(x)| = |µ1(t) −x|+ (µ2(t) −g(x)) ≤|µ1(t) −x|+ |u2t| = |µ1(t) −x|+ |−mu1t| ≤|µ1(t) −x|+ m|u1t−x| ≲m |µ1(t) −x|. (6.21)MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 31 Now, we notice thatg admits second order Taylor expansion inx. In particular, recalling thatu⊥:= (u2,−u1)T, we can use Remark B.1 and (6.21) to estimate Hs ∂E(z) = 2 s ˆ R ⟨n(µ(t)),µ(t) −z⟩ |µ(t) −z|2+s dt = 2 s ˆ ˜t −∞ ⟨n(µ(t)),µ(t) −z⟩ |µ(t) −z|2+s dt ≥2 s ˆ 0 −∞ ⟨n(µ(t)),µ(t) −z⟩ |µ(t) −z|2+s dt = −2 s ˆ 0 −∞ ⟨n(µ(t)),z⟩ |µ(t) −z|2+s dt = −2 s ˆ 0 −∞ ⟨n(µ(t)),z⟩ |µ(t) −z|2+s dt = −2 s ˆ 0 −∞ ⟨u⊥,(x,g(x))⟩ |µ(t) −z|2+s dt = 2 s 1√ 1 + m2 ˆ 0 −∞ mx+ g(x) |µ(t) −z|2+s dt ≳m,s ˆ ˆt −∞ mx+ g(x) |µ1(t) −x|2+s dt =m,s mx+ g(x)⏐⏐u1ˆt−x ⏐⏐1+s Now, we notice that ⏐⏐u1ˆt−x ⏐⏐≤ ⏐⏐u1ˆt ⏐⏐+ |x| = |g(x)| m + |x| ≲m |g(x)|+ |x|. Thus, recalling thatx,g(x) ≥0, we have Hs ∂E(z) ≳m,s g(x) + mx |g(x) + x|1+s ≥ cm,s |g(x) + x|s. □ Proof of Theorem 6.1.Let E := co(γ(S1)). Then, thanks to Proposition A.6 we have thatγ(S1) = ∂E. Also, using Proposition 2.9 we obtain for a.e.x∈S1 Hs ∂E(γ(x)) = 2 s ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s dy, where n(γ(y)) = γ′(y)⊥for a.e. y∈S1.32 G. GIACOMIN AND A. SCHIKORRA Making use of Proposition 6.4 and the last identity, we obtain the existence of some x0 ∈S1 such that Ws,p(γ) = lim ϵ→0+ ˆ S1\\Bϵ(x0) ⏐⏐⏐⏐⏐ ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s dy ⏐⏐⏐⏐⏐ p dx = cs,p lim ϵ→0+ ˆ S1\\Bϵ(x0) |Hs ∂E(γ(x))|p dx = +∞, and this concludes the proof of the theorem. □ Remark 6.6. It is important to observe that the above result holds only in critical and subcritical regime,Ws,p(∂E) where p≥1 s. In the supercritical regime,p< 1 s any polygon has finite energy. 7. Proof of Theorem 1.1 In Theorem 7.1 we prove that sequences inX with bounded Ws-energy weakly converge locally inW s+1,1 s 2 (S1 \\Σ) (where Σ is finite) to a limit curve which belongs to X. Having this, Theorem 1.1 is a consequence of the direct method of calculus of variations. Theorem 7.1. Assume we have a sequence ofγk ∈C1(S1,R2) such that •each γk is a homeomorphism onto its image, • |γ′ k|≡ 1 for all k, • γk are convex onS1, in the sense of Definition 2.6. Assume moreover (7.1) Λ := sup k ˆ S1 (ˆ S1 ⟨n(γk(y)),γk(y) −γk(x)⟩ |γk(x) −γk(y)|2+s dy )1 s dx< +∞. Then, up to translation ofγk, and up to taking a subsequence the following holds for some finite setΣ ⊂S1 1) γk converge uniformly toγ in S1, 2) for eachx0 ∈S1 \\Σ there exists someρx0 such thatγk converges weakly to γ in W s+1,1 s 2 (S1 ∩Bρx0 (x0)). 3) γ ∈C1(S1,R2) and γ satisfies all the bullet points above fromγk. Furthermore, it holds that (7.2) Ws(γ) ≤lim inf k Ws(γkj). Proof of Theorem 7.1.As for 1),by a translation argument we may assume that γk(0) = 0 for all k ∈R. Since |γ′ k|≡ 1, up to subsequence we obtain from the Arzela-Ascoli theorem the uniform convergence to someγ ∈Lip (S1,R3), |γ′|≤ 1 a.e. in S1. Convexity is preserved:Fix y∈S1. Since γk are by assumption differentiable aty, as a consequence of convexity, (2.13), and Lemma A.1 we have that ⟨n(γk(y)),γk(y) −γk(x)⟩≥ 0 for allx∈S1,MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 33 where n(γk(y)) = (γ′ k)⊥(y). Sincen(γk(y)) ∈S1 it admits a converging subsequence to somevy ∈S1, and using the uniform convergence of the full sequenceγk, one deduces from the above equation that (7.3) vy ·(γ(y) −γ(x)) ≥0 for allx∈S1. In particular, we have provedγ is still convex in the sense of Definition 2.6. As for 2), by a covering argument, Proposition C.1, for eachδ >0 there exists a subset Σ ⊂S1 such that#Σ ≤L with L(Λ,δ) ∈N and for eachx0 ∈S1 \\Σ there exists someρx0 ∈(0,1) with respect to which (7.4) sup k ˆ S1 (ˆ B40ρx0 (x0) ⟨n(γk(y)),γk(y) −γk(x)⟩ |γk(x) −γk(y)|2+s dy )1 s <δ. Thus, by choosingδ small enough, we can apply Theorem 4.1 and obtain that [γ′ k] W s,1 s 2 (B5ρx0 (x0)) ≤Cδ. By reflexivity ofW s,1 s 2 (B5ρx0 (x0)) and Banach-Alaoglu combined with Rellich’s Theo- rem, we find thatγ′ k weakly converges toγ′, up to a subsequence, inW s,1 s 2 (B5ρx0 (x0)) and the convergence is pointwise a.e. inB5ρx0 (x0) and strong inL1. This proves 2). γ is in arclength-parametrization:Since γ′ k converges a.e. inS1 \\Σ and Σ is a finite set, we obtain that (7.5) |γ′(x)|= lim k |γ′ k(x)|≡ 1 for a.e. x∈S1. γ is locally biLipschitz:Also, by choosingδ small enough, as a consequence of(7.4), Proposition 3.1 and Lemma 3.4 we obtain that for eachx0 ∈S1 \\Σ and k∈N 1 2 |x−y|≤| γk(x) −γk(y)|≤| x−y| for all x,y ∈Bρx0 (x0). From this and the uniform convergence ofγk to γ we obtain that (7.6) 1 2 |x−y|≤| γ(x) −γ(y)|≤| x−y| for all x,y ∈Bρx0 (x0). Now, thanks to the uniform convergence ofγk to γ we obtain that if for some x0 ∈S1 \\Σ and anyy0 ∈S1 it holds that (7.7) |γ(x0) −γ(y0)|< ρx0 100, then for allk sufficiently large it holds that |γk(x0) −γk(y0)|< ρx0 100. Using this last equation together with (7.4) and Theorem 5.1, we evince that (7.8) |x0 −y0|≤ ρx0 . Moreover, assume that γ(x) = γ(y) for some x,y ∈S1. Then, if x /∈Σ, as a consequence of (7.7) and (7.8) we deduce thaty∈Bρx(x). In particular, using this last information and(7.6) we obtain thatx = y. Analogously, one shows that if y /∈Σ then x= y. In conclusion, (7.9) if γ(x) = γ(y) then eitherx= y or x,y ∈Σ.34 G. GIACOMIN AND A. SCHIKORRA Lower semicontinuity:Now that we obtained point wise convergence ofγ′ k, we notice that for a.e.x,y ∈S1 \\Σ such thatx̸= y, one has that ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s = lim k→+∞ ⟨n(γk(y),(γk(y) −γk(x)⟩ |γk(y) −γk(x)|2+s . In particular, from Fatou’s lemma we obtain that (ˆ S1 ⟨n(γ(y)),γ(y) −γ(x)⟩ |γ(y) −γ(x)|2+s dy )1 s ≤lim inf k→+∞ (ˆ S1 ⟨n(γk(y)),γk(y) −γk(x)⟩ |γk(y) −γk(x)|2+s dy )1 s . By integrating with respect tox in S1 the above expression and applying Fatou’s Lemma a second time, we obtain Ws(γ) ≤lim inf k Ws(γk). This concludes the proof of lower semicontinuity, i.e. (7.2). γ is a homeomorphism: In view of Proposition 5.3, γ(S1) is a topological one- manifold. Since γ has only finitely many self intersection, namely only onΣ, this implies that actuallyγ must be injective – for the details of this argument see [6]. γ is C1: Since γ has finite Willmore-energy it belongs toX as in (1.1). Therefore, applying Theorem 6.1 we deduce thatγ ∈C1(S1,R2). This last result together with (7.3) and (7.5) proves3). □ Appendix A. Facts about convex curves inR2 In this section we recall geometric properties of convex curves and graphs, where we recall the notion of convexity in (2.13). Lemma A.1. Assume γ ∈Lip((a,b),R2), |γ′|≡ 1 a.e. in S1 and γ is convex in the sense of (2.13). Then, if γ is differentiable at x0 ∈(a,b), it holds that ⟨νx0 ,γ′(x0)⟩= 0. Also, ifγ((a,b)) is not a straight lineνx0 is unique. Proof. We observe that according to (2.13) one has that 0 ≥ ⟨ νx0 , lim x→x+ 0 γ(x) −γ(x0) x−x0 ⟩ = ⟨νx0 ,γ′(x0)⟩ and similarly 0 ≤ ⟨ νx0 , lim x→x− 0 γ(x) −γ(x0) x−x0 ⟩ = ⟨νx0 ,γ′(x0)⟩. From the above equations we deduce that⟨γ′(x0),νx0 ⟩= 0. Also, we claim that if γ((a,b)) is not a line then (A.1) νx0 is unique. Indeed, if (A.1) was false we would necessarily have that there are two vectors νx0 ,˜νx0 ∈S1 such that⟨νx0 ,γ′(x0)⟩= 0 and ⟨˜νx0 ,γ′(x0)⟩= 0, which implies that (up to renaming the two vectors)νx0 = −γ′(x0)⊥ and ˜νx0 = γ′(x0)⊥. Thus, we would have thatνx0 = −˜νx0 and νx0 ·(γ(x0) −γ(y)) ≥0 and −νx0 ·(γ(x0) −γ(y)) ≥0. This implies thatγ((a,b)) is necessarily a straight line, providing a contradiction.□MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 35 Lemma A.2. Assume there are two distinct pointsp0,p1 ∈R2, and set T = p1 −p0 ∈R2 \\{0} Assume that there ism on the segment[p1,p0], i.e. if is someλ∈[0,1] such that (A.2) m= p0 + λT. Then if at m we have the convexity condition Definition 2.6, that is if we find vm ∈R2 such that|vm|= 1 and (A.3) ⟨vm,m −y⟩≥ 0 ∀y∈{p1,p2} Then necessarily vm ∈ { −T⊥ |T⊥|, T⊥ |T⊥| } Proof. By scaling we may assume that|T|= |p1 −p0|= 1. The assumption (A.2) readily implies ⟨T⊥,m −p0⟩= 0 Since T = p1 −p0 we thus have (A.4) 0 = ⟨m−p0,T⊥⟩= ⟨m−p1,T⊥⟩. Assume that for somevm ∈R2, |vm|= 1, we have (A.3), i.e. assume { ⟨vm,m −p0⟩≥ 0 and ⟨vm,m −p1⟩≥ 0 Since |T|= |T⊥|= 1 we can writevm = ⟨vm,T⟩T + ⟨vm,T⊥⟩T⊥. Thus, taking into account (A.4) the previous equations become { ⟨vm,T⟩⟨T,m −p0⟩≥ 0 and ⟨vm,T⟩⟨T,m −p1⟩≥ 0 But now ⟨T,m −p1⟩= ⟨T,m −p0 −T⟩= ⟨T,m −p0⟩−1 So we find { ⟨vm,T⟩⟨T,m −p0⟩≥ 0 and ⟨vm,T⟩(⟨T,m −p0⟩−1) ≥0 In view of (A.2) this implies { ⟨vm,T⟩λ≥0 and ⟨vm,T⟩(λ−1) ≥0 Since λ∈[0,1] this implies⟨vm,T⟩= 0, that isvm = ±T⊥. We can conclude. □ Lemma A.3. Assume γ : [0 ,1] → R2 is continuous, convex in the sense of Definition 2.6 and that T = γ(1) −γ(0) ∈R2 \\{0}. Assume further more thatγ(t) ̸∈{γ(0),γ(1)}for all t∈(0,1). Then either ⟨T⊥,γ(t) −γ(0)⟩≥ 0 ∀t∈[0,1] or ⟨T⊥,γ(t) −γ(0)⟩≤ 0 ∀t∈[0,1]36 G. GIACOMIN AND A. SCHIKORRA Proof. By continuity, injectivity, and the intermediate value theorem, if the claim is false, the only way the claim is not true is if there exists¯t∈[0,1] with γ(¯t) ̸= γ(0),γ(1) but ⟨T⊥,γ(¯t) −γ(0)⟩= 0. This implies that one of the following must be true   γ(¯t) ∈[γ(0),γ(1)] or γ(0) ∈[γ(¯t),γ(1)] or γ(1) ∈[γ(¯t),γ(0)] In either case we find from the convexity condition in Definition 2.6 combined with Lemma A.2 that { ⟨T⊥,γ(˜t) −γ(t)⟩≥ 0 ∀t∈[0,1] or ⟨T⊥,γ(˜t) −γ(t)⟩≤ 0 ∀t∈[0,1] when ˜t∈{0,1,¯t}is chosen correctly. Whichever of the three options˜t is, we have γ(˜t) −γ(0) ∈span{T}, so we find either { ⟨T⊥,γ(0) −γ(t)⟩≥ 0 ∀t∈[0,1] or ⟨T⊥,γ(0) −γ(t)⟩≤ 0 ∀t∈[0,1] We can conclude. □ Lemma A.4. Assume that(x,f(x)) : [0 ,1] →R2 is a continuous graph that is convex in the sense of Definition 2.6. Then f is either convex or concave on[0,1]. Proof. Assume the claim is wrong. Then there must be some somef, and we may assume w.l.o.g. f(0) = 0 , f(1) = 1 , such that for some0 < µ < λ <1 (λ,f(λ)) lies below the line connecting(0,f(0)) and (1,f(1)), andf(µ) lies above the line connecting (0,f(0)) and (λ,f(λ)). In formulas we have (A.5) f(λ) <λf (1) and (A.6) f(µ) > µ λf(λ) We now consider the line starting from(0,f(0)) with slope mε := f(λ) −f(0) λ−0 + ε, where ε is small. Cf. Figure 2. This line is the graph of gε(x) := mεx We clearly haveg(0) = f(0) = 0. For all small enoughε> 0 gε(µ) = µ λf(λ) + µε (A.6) < f(µ) Also, for allε> 0 gε(λ) = f(λ) + ε>f (λ) Lastly, for possibly even smallerε> 0 we have gε(1) = f(λ) λ + ε (A.5) < f(1)MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 37 Figure 2. The geometry in the proof of Lemma A.4 By the intermediate value theorem we findp∈(λ,1) such thatgε(p) = f(p) That is the curveγ(x) := (x,f(x)) and the lineL= (x,gε(x)) coincide at0 and pbut γ(µ) lies above the lineL and γ(λ) lies below the lineL – which is a contradiction to Lemma A.3. □ Lemma A.5. Assume γ : S1 →R2 is continuous and injective and fixθ1 ̸= θ2 ∈S1. Set T := γ(θ2) −γ(θ1) ∈R2 \\{0}. We consider the two different arcs connectingθ1 and θ2 in S1, we call them[θ1,θ2] and [θ2,θ1]. Then the curve is separated byγ(θ1) + λT, more precisely we have either { ⟨γ(θ1) −γ(t),T⊥⟩≥ 0 ∀t∈[θ1,θ2] and ⟨γ(θ1) −γ(t),T⊥⟩≤ 0 ∀t∈[θ2,θ1] or { ⟨γ(θ1) −γ(t),T⊥⟩≤ 0 ∀t∈[θ1,θ2] and ⟨γ(θ1) −γ(t),T⊥⟩≥ 0 ∀t∈[θ2,θ1] Proof. In view of Lemma A.3, the only way the claim is false would be that there exists t+ ∈(θ1,θ2) and t−∈(θ2,θ1) such that (the sign is w.l.o.g. negative) ⟨γ(θ1) −γ(t+),T⊥⟩<0, and ⟨γ(θ1) −γ(t−),T⊥⟩<0 and otherwise we have ⟨γ(θ1) −γ(t),T⊥⟩≤ 0 ∀t∈S1. By continuity and injectivity, we may assume w.l.o.g. that for someλ ∈(0,1), 0 <µ−<µ+ we have γ(t+) = γ(θ1) + λT + µ+T⊥ and γ(t−) = γ(θ1) + λT + µ−T⊥38 G. GIACOMIN AND A. SCHIKORRA 0 >⟨γ(θ1) −γ(t−),T⊥⟩>⟨γ(θ1) −γ(t+),T⊥⟩. Set w1 := γ(t−) −γ(t+) w2 := γ(t−) −γ(θ1) w3 := γ(t−) −γ(θ2) We then observe fromw1 = γ(θ1) −γ(t+) −γ(θ1) −γ(T−) we have ⟨w1,T⊥⟩<0. Also we have ⟨w2,T⊥⟩>0 and sincew3 = w2 −T we find ⟨w3,T⊥⟩= ⟨w2,T⊥⟩>0. Moroever we have ⟨w1,T⟩= 0, ⟨w2,T⟩= λ, ⟨w3,T⟩= λ−1. Now letvt− ∈R2, |vt−|= 1 such that ⟨vt−,γ(t−) −γ(t)⟩≥ 0 ∀t∈S1. That is, we have ⟨vt−,wi⟩≥ 0 i= 1,2,3 Takeσ,δ ∈R such thatvt− = σT + δT⊥. Then we have σ⟨T,w1⟩ =0 +δ⟨T⊥,w1⟩  <0 ≥0 This impliesδ= 0. Then we comp σ⟨T,w2⟩ =λ + δ =0 ⟨T⊥,w2⟩≥ 0 σ⟨T,w3⟩ =λ−1 + δ =0 ⟨T⊥,w3⟩≥ 0 Since λ∈(0,1) these equalities imply thatσ= 0, a contradiction to|vt−|= 1. □ Proposition A.6. Let γ ∈Lip(S1,R2) be injective and satisfying the convexity assumption (2.13) in S1. Then, if we define the convex setE := co(γ(S1)) it holds that ∂E = γ(S1). Proof of Proposition A.6.We begin by proving that (A.7) γ(S1) ⊂∂E. To do so, we first we observe thatE ̸= ∅, and sinceγ(S1) is compact, then we can apply Theorem 1.4.3 in [24] and obtain thatE is compact. Also, beingγ(S1) a connected set, we can apply Theorem 1.3.7 in [24] and obtain that (A.8) E = { λγ(t1) + (1−λ)γ(t2)|t1,t2 ∈S1 and λ∈[0,1] } .MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 39 In particular, from(A.8) and equation(2.13) we deduce that for everyt∈S1 and P ∈S1 there aret1,t2 ∈S1 and λ∈[0,1] such that ⟨νt,γ(t) −P⟩= ⟨νt,γ(t) −λγ(t1) −(1 −λ)γ(t2)⟩ = λ⟨νt,γ(t) −γ(t1)⟩+ (1 −λ)⟨νt,γ(t) −γ(t2)⟩ ≥0, In particular, we have just proved that for everyt∈S1 there exists someνt ∈S1 such that for everyQ∈E ⟨νt,γ(t) −Q⟩≥ 0. From this and the fact thatγ(t) ∈E, we readily evince (A.7). To conclude the proof of the proposition we claim that (A.9) ∂E ⊂γ(S1). To prove this, letP ∈∂E. Then, applying Lemma 4.2.1 in [24] we obtain that there exists someνP ∈S1 such that (A.10) ⟨νP,P −γ(t)⟩≥ 0 for all t∈S1. According to (A.8), there aret1,t2 ∈S1 and λ∈[0,1] such that P = λγ(t1) + (1−λ)γ(t2). If eitherγ(t1) = γ(t2) or λ∈{0,1}then P ∈γ(S1), and there is nothing to prove. We assume therefore that γ(t1) ̸= γ(t2) and λ∈(0,1). Thus, we observe that 0 ≤⟨νP,P −γ(t1)⟩= ⟨νP,γ(t2) −γ(t1)⟩(1 −λ) and also 0 ≤⟨νP,P −γ(t2)⟩= ⟨νP,γ(t1) −γ(t2)⟩λ. From these two equations we evince that if we denoteT := γ(t2)−γ(t1) |γ(t2)−γ(t1)| νP ∈ { T⊥,−T⊥} . and without any loss of generality we can assume thatνp = T⊥. Now, using Lemma A.5 withθ1 = t1 and θ2 = t2 we have that either (A.11) { ⟨γ(t1) −γ(t),T⊥⟩≥ 0 ∀t∈[t1,t2] and ⟨γ(t1) −γ(t),T⊥⟩≤ 0 ∀t∈[t2,t1] or { ⟨γ(t1) −γ(t),T⊥⟩≤ 0 ∀t∈[t1,t2] and ⟨γ(t1) −γ(t),T⊥⟩≥ 0 ∀t∈[t2,t1]. Without loss of generality, we assume that(A.11) holds, the second case being analogous. On the other hand, as a consequence of (A.10), we also have for everyt∈S1 that 0 ≤⟨νP,P −γ(t)⟩= ⟨T⊥,|P −γ(t1)|T + γ(t1) −γ(t)⟩ = ⟨T⊥,γ(t1) −γ(t)⟩ Thus, in view of this and equation (A.11), we obtain that ⟨T⊥,γ(t1) −γ(t)⟩= 0 for all t∈[t2,t1].40 G. GIACOMIN AND A. SCHIKORRA In particular, from this we infer the existence of someµ ∈C([t2,t1]) such that γ(t) = µ(t)T + γ(t1). Since by assumptions we have thatµ(t1) = 0 and µ(t2) = |γ(t2) −γ(t1)|, then by continuity there exists somet∗∈[t2,t1] such that µ(t∗) = (1 −λ) |γ(t2) −γ(t1)|. In particular, for sucht∗it holds that γ(t∗) = µ(t∗)T + γ(t1) = (1 −λ) (γ(t2) −γ(t1)) + γ(t1) = λγ(t1) + (1−λ)γ(t2) = P. We have just proved thatP ∈γ(S1), and (A.9) follows. □ Proposition A.7. Let γ ∈Lip((a,b),R2), |γ′|≡ 1 a.e. in (a,b), injective and satisfying the convexity assumption(2.13) in (a,b). Furthermore, we assume that there exists some Lipschitzf : γ1((a,b)) →R such that (A.12) γ(t) = (γ1(t),f(γ1(t)))T for all t∈(a,b). Then, up to replacingγ(·) with γ((a+ b) −·), for a.e.t∈(a,b) it holds that (A.13) γ′ 1(t) = 1√ 1 + f′(γ1(t))2 . Also, up to rotatingγ by π, f is convex. Proof. If γ((a,b)) is a straight line then the statement easily follows. For this reason, from now on we assume thatγ((a,b)) is not a straight line. We notice that the convexity off follows immediately from Lemma A.4 up to rotating γ by π. Now, we evince from the injectivity ofγ and (A.12) that γ1 : (a,b) →γ1((a,b)) is a Lipschitz bijection. Therefore, up to replacingγ(·) with γ((a+ b) −·), we have that (A.14) γ′ 1 >0 a.e. in (a,b). From this we obtain that ifS ⊂γ1((a,b)) such that σ1(S) = 0 , then using the coarea formula (see for instance [18]) we obtain ˆ γ−1 1 (S) |γ′ 1(x)|dx= ˆ R σ0 ( γ−1 1 (S) ∩γ−1 1 (y) ) dy = ˆ R χS(y) dy= 0 = ˆ S dy = 0. (A.15) Henceforth, from(A.14) and (A.15) we infer thatσ1(γ−1 1 (S)) = 0. Analogously, one can prove that ifS ⊂(a,b) and σ1(S) = 0 then σ1(γ1(S)) = 0. We conclude that for everyS ⊂(a,b) (A.16) σ1(S) = 0 ⇐⇒σ1(γ1(S)) = 0.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 41 Therefore, making use of(A.16) and the fact thatγ1 and f are respectively differ- entiable a.e. in(a,b) and γ1(a,b), we deduce for a.e.t∈(a,b) (A.17) γ′(t) = (γ′ 1(t),f′(γ1(t))γ′ 1(t))T, and using the hypothesis that|γ′|≡ 1 a.e. in (a,b) together with(A.14) we obtain for a.e. t∈(a,b) that γ′ 1(t) = 1√ 1 + f′(γ1(t))2 . This concludes the proof of (A.13). □ Theorem A.8 (Implicit Function Theorem, see [14]). Let γ ∈ Lip([a,b],R2), injective, |γ′|≡ 1 a.e. and γ satisfies the convexity assumption(2.13) in [a,b]. Then, for everyx0 ∈(a,b) there exists some open neighbourhoodUx0 ⊂(a,b) of x0 and a convex functionf, such that up to rotations we have that (A.18) γ(t) = (γ1(t),f(γ1(t)))T for all t∈Ux0 , and (A.19) γ is differentiable int∈Ux0 ⇐⇒f is differentiable inγ1(t). Moreover, up to replacingγ(·) with γ((a+ b) −·), for all t ∈ Ux0 where γ is differentiable (A.20) νt = 1√ 1 + f′(γ1(t))2 (f′(γ1(t)),−1)T, where νt is as in Definition 2.6. Proof. If γ([a,b]) coincides with a straight line then the statement easily follows. Therefore, from now on we assume thatγ([a,b]) is not a line. We begin by setting the distance function d(y) := inf {|x−y||x∈γ([a,b])}. We fix somex0 ∈(a,b), and up to a translation we assume thatγ(x0) = 0. Then, for ϵ> 0 small enough we consider the ballBϵ, and define the sets B+ ϵ := {x∈Bϵ|νy ·(γ(y) −x) ≥0 for ally∈[a,b] and νy as in (2.13)}, and B− ϵ := Bϵ \\B+ ϵ . Then, inBϵ we define the function ˜d(x) := { −d(x) for all x∈B+ ϵ d(x) for all x∈B− ϵ . Being γ([a,b]) closed, we have that (A.21) p∈γ([a,b]) ⇐⇒d(p) = 0 ⇐⇒ ˜d(p) = 0. Also, thanks to [14, Proposition 2.4.1 ] we have thatd is Lipschitz. From this, it follows that ˜d is Lipschitz as well and therefore∇d and ∇˜d exist a.e. in R2. Moreover, thanks to [14, Theorem 2.5.1] we can define the generalized gradient of˜d in 0 as (A.22) ∂˜d(0) = co { lim n ∇˜d(xn)|xn →0, xn /∈Ω˜d } ,42 G. GIACOMIN AND A. SCHIKORRA where Ω ˜d ⊂R2 is any subset of measure zero containing the set of points where˜dis not differentiable. Similarly, we denote byΩd any subset of measure zero containing all the points whered is not differentiable. Being γ Lipschitz, we can assume thatγ([a,b]) ⊂Ω˜d ⊂Ωd. Now, we claim that (A.23) ∇d(x) ̸= 0 for all x∈R2 \\Ωd. As a matter of fact, beingγ([a,b]) closed, we observe that for every pointx∈R2 there exists some pointcx ∈γ([a,b]), not necessarily unique, such that d(x) = |cx −x|. Then, ifx∈R2 \\Ωd and we setv:= cx −x we obtain ∇d(x) ·v= lim t→0+ d(x+ t(cx −x)) −d(x) t = lim t→0+ (1 −t) |cx −x|−|cx −x| t = −|cx −x|. This proves(A.23). Finally, we apply in [14, Proposition 2.5.4], and obtain that for everyx∈R2 \\Ωd we have that there exists a unique closest pointcx (i.e. the projection is well-defined) and ∇d(x) = x−cx |x−cx|. In particular, we deduce that ∇˜d(x) =    −x+ cx |c−cx| for allx∈B+ ϵ \\Ωd x−cx |c−cx| for allx∈B− ϵ \\Ωd. Also, from this and the convexity condition(2.13) we observe that for allx∈Bϵ\\Ωd it holds (A.24) ∇˜d(x) ·(cx −γ(y)) ≥0 for all y∈[a,b]. Also, we observe that ifxn is as in (A.22) then we have that lim n xn = lim n cxn = 0 = γ(x0). In particular, from this last equation and (A.24) we obtain lim n ∇˜d(xn) ·(γ(x0) −γ(y)) ≥0 for all y∈[a,b]. Exploiting this and (A.22) we evince that (A.25) ∂˜d(0) ⊂co { νx0 ∈S1|νx0 satisfies (2.13) in x0 } =: Nx Also, we notice that0 /∈∂Nx. Indeed, if this was the case we would obtain the existence of two vectorsv,w ∈S1 such thatv= −w and ⟨v,γ(x0) −γ(y)⟩≥ 0 and ⟨w,γ(x0) −γ(y)⟩≥ 0, giving thatγ is a line, and providing a contradiction.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 43 Since Nx is convex, closed, contained inB1 and 0 /∈Nx, then up to a rotation we can assume that for everyv= (v1,v2)T ∈Nx we have thatv2 <0. In particular, making use of (A.25) we obtain for everyv= (v1,v2)T ∈∂˜d(0) we have thatv2 <0. As a consequence of this, we are entitled now to apply the Implicit Function Theorem for Lipschitz maps in [14, Section 7.1], and obtain the existence of some neighbourhood V0 ⊂Bϵ of 0 and a Lipschitz functionf : V0 →R such that ˜d(y1,f(y1)) = 0 for all y1 ∈V0. Now, from(A.21) and this last identity we deduce that for allt∈(a,b) such that γ1(t) ∈V0 it holds that γ(t) = (γ1(t),f(γ1(t)))T. Being γ1 continuous we can defineUx0 = γ−1 1 (V0) and obtain(A.18). In particular, thanks to Lemma A.4 we obtain that, up to rotatingγ by π, f is convex. This concludes the proof of (A.18). Now, we need to prove(A.19). To do so, first we assume thatγ is differentiable in t∈Ux0 . Being f convex we have that (A.26) lim h↘0 f(γ1(t) + h) −f(γ1(t)) h and lim h↗0 f(γ1(t) + h) −f(γ1(t)) h exist. To prove the differentiability off in γ(t) we only need to prove that the two limits coincide. To this end, thanks to Proposition A.7, up to replacingγ(·) with γ((a+ b) −·), we can assume that(A.13) holds. Thus, if we setϵ >0 such that Bϵ(t) ⊂Ux0 , then for everyh∈(0,ϵ) it holds γ1(t+ h) −γ1(t) = ˆ t+h t dz√ 1 + f′(γ1(z))2 ≥ 1√ 1 + M2 h=: Ch, where M := ∥f′∥L∞(Bϵ(t)) and soC ∈(0,1). Analogously, we can prove that for every h∈(0,ϵ) γ1(t−h) ≤−Ch+ γ1(t) Making use of this and the convexity off we evince f(γ1(t) + Ch) −f(γ1(t)) Ch ≤f(γ1(t+ h)) −f(γ1(t)) γ1(t+ h) −γ1(t) = f(γ1(t+ h)) −f(γ1(t)) h h γ1(t+ h) −γ1(t) = γ2(t+ h) −γ2(t) h h γ1(t+ h) −γ1(t). Similarly, we have that f(γ1(t) −Ch) −f(γ1(t)) −Ch ≥f(γ1(t−h)) −f(γ1(t)) γ1(t−h) −γ1(t) = f(γ1(t−h)) −f(γ1(t)) −h −h γ1(t−h) −γ1(t) = γ2(t−h) −γ2(t) −h −h γ1(t−h) −γ1(t).44 G. GIACOMIN AND A. SCHIKORRA Finally, sinceγ is differentiable int and by convexity f(γ1(t) −Ch) −f(γ1(t)) −Ch ≤f(γ1(t) + Ch) −f(γ1(t)) Ch , we obtain that the limits in(A.26) coincide, proving thatf is differentiable inγ1(t). On the other hand, assume thatf is differentiable inγ1(t). Then, using convexity we can define for everyz∈V0 f′ +(z) := lim h↘0 f(z+ h) −f(z) h and f′ −(z) := lim h↗0 f(z) −f(z−h) h . In particular, by convexity we know thatf′(z) = f′ +(z) and f′(z) = f′ −(z) for a.e. z∈V0. In particular, it holds that (A.27) f′(γ1(t)) = f′ +(γ1(t)) = f′ −(γ1(t)) and f′ + and f′ − are both non decreasing. Then, forl > tand everyh >0 small enough 0 ≤f′ +(γ1(l)) −f′(γ1(t)) ≤f(γ1(l) + h) −f(γ1(l)) h −f′(γ1(t)). Taking the limit forl↘z, we obtain for everyh> 0 small enough 0 ≤ lim l→t+ f′ +(γ1(l)) −f′(γ1(t)) ≤f(γ1(t) + h) −f(γ1(t)) h −f′(γ1(t)), and taking the limit forh↘0 we obtain that (A.28) lim l↘t ⏐⏐f′ +(γ1(l)) −f′(γ1(t)) ⏐⏐= 0. Analogously, we can prove that (A.29) lim l↗t ⏐⏐f′(γ1(t)) −f′ −(γ1(l)) ⏐⏐= 0. Thus, if we define the function ˆf′(γ1(z)) := { f′ +(γ1(z)) for z >t f′ −(γ1(z)) for z≤t, as a consequence of(A.28) and (A.29) we have thatˆf′(γ1) is continuous int. Also, recall that by definitionˆf′(γ1(l)) = f′(γ1(l)) for a.e. l∈Ux0 . Therefore, using this and (A.13) we have ifh∈(−δ,δ) for δ >0 small enough γ1(t+ h) −γ1(t) h = 1 h ˆ t+h t 1√ 1 + f′(γ1(z))2 dz = 1 h ˆ t+h t 1√ 1 + ˆf′(γ1(z))2 dz. Since ˆf′(γ1(t)) is continuous int, we have thatt is a Lebesgue point and thanks to the Lebesgue differentiation Theorem and equation (A.27) lim h→0 γ1(t+ h) −γ1(t) h = 1√ 1 + ˆf′(γ1(t))2 = 1√ 1 + f′(γ1(t))2 and we conclude.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 45 Now, we prove(A.20). To do so, we notice that sincef is convex then for all x∈γ1((a,b)) where f is differentiable and everyy∈γ1((a,b)) one has that ⟨( f′(x) −1 ) , ( x f(x) ) − ( y f(y) )⟩ ≥0. In view of(A.19) this readily implies that for allt∈(a,b) where γ is differentiable and everyt1 ∈(a,b) it holds that 1√ 1 + f′(γ1(t))2 ⟨(f′(γ1(t)) −1 ) , ( γ1(t) f(γ1(t)) ) − ( γ1(t1) f(γ1(t1)) )⟩ . We also notice that thanks to Lemma A.1 for allt∈(a,b) where γ is differentiable there exists a unique vectorνt ∈S1 such that for everyt1 ∈(a,b) it holds that ⟨νt,γ(t) −γ(t1)⟩≥ 0. Therefore, we have proved that for allt∈(a,b) where γ is differentiable νt = 1√ 1 + f′(γ1(t))2 (f′(γ1(t)) −1 ) concluding the proof of (A.13). □ In view of Proposition A.7 and Theorem A.8 we obtain Corollary A.9. Let γ ∈Lip(S1,R2) be a homeomorphism,|γ′|≡ 1 and γ satis- fies (2.13) in some(a,b) ⊂S1. Then, ifγ satisfies (2.11), for everyx∈(a,b) where γ is differentiable it holds (A.30) νx = γ′(x)⊥. Appendix B. Integration formula for the mean curvature – Proof of Proposition 2.9 Proof of Proposition 2.9.Thanks to the Implicit Function Theorem A.8 for every z∈S1 there exists some neighbourhoodUz ⊂S1 and a convex functionf ∈Lip(R) such that (up to rotations) it holds that γ(t) = (γ1(t),f(γ1(t))) for all t∈Uz. Also, we notice that for everyx∈γ(Uz) there exists someϵx >0 such that (B.1) Bϵx(x) ∩E = {(y1,y2) ∈Bϵx(x)|f(y1) ≤y2}. Being f convex, thanks to Alexandrov Theorem, we obtain thatf is twice differen- tiable a.e. inγ1(Uz). Let us stress what this actually means: for a.e.p∈γ1(Uz) there existsa,b ∈R such that (B.2) lim q→p f(q) −f(p) −a(q−p) −b 2 (q−p)2 |q−p|2 = 0. Thus, we denote by Af := {p∈γ1(Uz)|f is twice differentiable inp}. Let γ1(x) ∈Af be fixed. Also, up to translations and rotations we can assume w.l.o.g. that γ(x) = 0 and γ′(x) = (1,0).46 G. GIACOMIN AND A. SCHIKORRA Now, we compute the nonlocal mean curvature inγ(x) = 0. Hs ∂E(0) = P.V. ˆ R2 χEc(y) −χE(y) |y|2+s dy = lim ϵ→0+ ˆ R2\\Bϵ χEc(y) −χE(y) |y|2+s dy = lim ϵ→0+ (ˆ Ec\\Bϵ dy |y|2+s − ˆ E\\Bϵ dy |y|2+s ) . Then, we observe that for everyy∈R2 \\{0} divy y |y|2+s = − s |y|2+s. Since by constructionE is a Lipschitz set, we have that forσ1 a.e. y ∈∂E the outward unit normalνE(y) at E in y is well defined. Note thatνE(y) = −νEc(y). Thus, applying the Divergence Theorem for Lipschitz sets we obtain that Hs ∂E(0) = 1 s lim ϵ→0+ ( − ˆ Ec\\Bϵ divy y |y|2+s dy+ ˆ E\\Bϵ divy y |y|2+s dy ) = 1 s lim ϵ→0+ ( − ˆ ∂(Ec\\Bϵ) νEc\\Bϵ(y) · y |y|2+s dσ1 + ˆ ∂(E\\Bϵ) νE\\Bϵ(y) · y |y|2+s dσ1 ) = 1 s lim ϵ→0+ ( − ˆ ∂Ec\\Bϵ νEc(y) · y |y|2+s dσ1 − ˆ Ec∩∂Bϵ νBϵ(y) · y |y|2+s dσ1 + ˆ ∂E\\Bϵ νE(y) · y |y|2+s dσ1 + ˆ E∩∂Bϵ νBϵ(y) · y |y|2+s dσ1 ) = 1 s lim ϵ→0+ ( 2 ˆ ∂E\\Bϵ νE(y) · y |y|2+s dσ1 + 1 ϵ1+s ( −σ1 (E∩∂Bϵ) + σ1(Ec ∩∂Bϵ) )) = 1 s lim ϵ→0+ ( 2 ˆ ∂E\\Bϵ νE(y) · y |y|2+s dσ1 + 1 ϵ1+s ( −2πϵ+ 2σ1(Ec ∩∂Bϵ) )) . Now, assuming thatϵ is small enough, by convexity ofE we have that (B.3) σ1(Ec ∩∂Bϵ) ≥σ1({P2 <0}∩∂Bϵ) = πϵ. Also, thanks to (B.1), for somec> 0 uniform with respect toϵ, we evince that σ1(Ec ∩∂Bϵ) = σ1({P2 <f (P1)}∩∂Bϵ) = πϵ+ σ1({0 <P2 <f (P1)}∩∂Bϵ) ≤πϵ+ c(f(ϵ) + f(−ϵ)) . (B.4) Thanks to the twice differentiability off in the origin,(B.2), and the assumption that f(0) = f′(0) = 0, we obtain that f(ϵ) = f′′(0)ϵ2 + o(ϵ2). Similarly, one also computes f′(−ϵ) = f′′(0)ϵ2 + o(ϵ2). Therefore, using these last two equations, (B.3) and (B.4) we infer that πϵ≤σ1(Ec ∩∂Bϵ) ≤πϵ+ O(ϵ2)MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 47 These estimates allow us to conclude that 0 ≤ ( −2πϵ+ 2σ1(Ec ∩∂Bϵ) ) ≤O(ϵ2), from which we evince that lim ϵ→0+ 1 ϵ1+s ( −2πϵ+ 2σ1(Ec ∩∂Bϵ) ) = 0. In particular, this means that Hs ∂E(0) = 2 s lim ϵ→0+ ˆ ∂E\\Bϵ νE(y) · y |y|2+s dσ1 = 2 s lim ϵ→0+ ˆ S1\\γ−1(Bϵ∩γ(S1)) n(γ(y)) · γ(y) |γ(y)|2+s dy = 2 s lim ϵ→0+ ˆ S1\\Bϵ(x) n(γ(y)) · γ(y) |γ(y)|2+s dy =: 2 s ˆ S1 n(γ(y)) · γ(y) |γ(y)|2+s dy where the penultimate identity is due to the fact thatf′∈L∞(Bϵ). □ Remark B.1. It is important to observe that(2.16) holds true also under different hypothesis onE and γ. For instance, letE ⊂R2 be convex and with nonempty interior. Also, letγ : R →R2 be BiLipschitz and|γ′|= 1 a.e. in R, satisfying the convexity assumption in(2.13) in R. Then, thanks to Theorem A.8, up to a rotation ofγ, for everyx0 ∈R there exists some neighbourhoodUx0 and a convex functionf : γ1(Ux0 ) →R such that γ(t) = (γ1(t),f(γ1(t))) for all t∈Ux0 . Then, following almost verbatim the proof of Proposition 2.9, we obtain that for all x∈Ux0 where f admits a second order Taylor expansion it holds that Hs ∂E((x,f(x))) = ˆ R n(γ(t)) · γ(t) −(x,f(x)) |γ(t) −(x,f(x))|2+s dt, where (up to replacingγ(·) with γ(−·)) n(γ(t)) := γ′(t)⊥for a.e. t∈R. Appendix C. The covering argument: Locally uniform smallness In what follows we show locally uniform smallness for sequences of functions with uniformly bounded global integral energy. This is a standard covering argument, see for instance [33] Proposition 4.3 and Theorem 4.4. For the sake of completeness we provide here a proof of the result. Proposition C.1. For anyε> 0 and Λ >0 there existsL= L(ε,Λ) such that the following holds. For any sequenceFk : S1 ×S1 sup k ˆ S1 (ˆ S1 |Fk(x,y)|dy )p dx≤Λ, there exists a subsequence (still denoted byFk) and setΣ ⊂S1 consisting of at most L points such that for anyx0 ∈S1 \\Σ there exists a radiusρ = ρx0 > 0 and an48 G. GIACOMIN AND A. SCHIKORRA index K ∈N such that sup k≥K ˆ S1 (ˆ B(x0,ρ) |Fk(x,y)|dy )p dx<ε. and sup k≥K ˆ B(x0,ρ) (ˆ S1 |Fk(x,y)|dy )p dx<ε. Proof. We give the details for the convenience of the reader, but only consider the first inequality, an easy adaptation implies that first and second inequality hold simultaneously. Pick δ << ε 2pΛ and letm∈N. Then coverS1 by finitely many intervalsB(xi,δ2−m) such that every pointx∈S1 is covered at most two times. Then we have ˆ R (∑ i ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx ≤2pΛ = 2pΛ ε ε. Since ∞∑ i=1 (ai)p ≤ (∞∑ i=1 ai )p we have ∑ i ˆ R (ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx ≤ ˆ R (∑ i ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx ≤2pΛ Hence for everyk and anym there exist at mostL:= L(ε,Λ) := ⌊2pΛ ε ⌋intervals B(xi,δ2−m) such that ˆ R (ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx≥ε. Next we observe that for any fixedm we can pass to a subsequence of(Fk)k (not relabeled) so that #{i: sup k ˆ R (ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx≥ε}≤ L. This is true since for anyk there are onlyL many intervals for which ˆ R (ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx≥ε We can then pass to a further subsequence that for anymthere exists aK = K(m) such that #{i: sup k≥K(m) ˆ R (ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx≥ε}≤ L.MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 49 Set Σm := S1\\{x∈B(xi,δ2−m) : for somei with ˆ R (ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx≤ε} We then have Σm ⊂ L⋃ ℓ=1 B(xiℓ,δ2−m) Nesting the ballsB(xi,δ2−m) as m→∞ we can ensure thatΣm+1 ⊂Σm. Set Σ := ⋂ m Σm. Then by the definition of theH0-measure, sinceΣ is covered byΣm which consists of at mostL intervals of sidelength2−mδ (and this for eachm) we have H0(Σ) ≤L. Also clearly, ifx ̸∈Σ there must be somem ∈N such that x ̸∈Σm, but x ∈ B(xi;m,δ2−m) for somexi;m such that ˆ R (ˆ B(xi,δ2−m) |Fk(x,y)|dy )p dx≤ε. But then forρ:= dist (x,∂B(xi;m,δ2−m)) we have ˆ R (ˆ B(x,ρ) |Fk(x,y)|dy )p dx≤ε. □ References [1] S. Blatt. (private communication). 2023. 17 [2] S. Blatt, G. Giacomin, J. Scheuer, and A. Schikorra. A fractional Willmore-type energy functional–subcritical observations.MATRIX Annals (accepted), preprint arXiv:2306.16941, 2023. 2, 3 [3] S. Blatt and P. Reiter. Regularity theory for tangent-point energies: the non-degenerate sub-critical case.Adv. Calc. Var., 8(2):93–116, 2015. 3 [4] S. Blatt, P. Reiter, and A. Schikorra. Harmonic analysis meets critical knots. Critical points of the Möbius energy are smooth.Trans. Amer. Math. Soc., 368(9):6391–6438, 2016. 11, 24 [5] S. Blatt, P. Reiter, and A. Schikorra. On O’Hara knot energies. I: Regularity for critical knots. J. Differ. Geom., 121(3):385–424, 2022. 3 [6] S. Blatt, P. Reiter, A. Schikorra, and N. Vorderobermeier. Scale-invariant tangent-point energies for knots.arXiv preprint arXiv:2104.10238, 2021. 3, 11, 24, 34 [7] G. Buck and J. Orloff. A simple energy function for knots.Topology Appl., 61(3):205–214, 1995. 3 [8] X. Cabré, M. Cozzi, and G. Csató. A fractional Michael-Simon Sobolev inequality on convex hypersurfaces. Ann. Inst. Henri Poincaré, Anal. Non Linéaire, 40(1):185–214, 2023. 3 [9] X. Cabré, M. M. Fall, J. Solà-Morales, and T. Weth. Curves and surfaces with constant nonlocal mean curvature: meeting Alexandrov and Delaunay.J. Reine Angew. Math., 745:253–280, 2018. 2 [10] L. Caffarelli, J.-M. Roquejoffre, and O. Savin. Nonlocal minimal surfaces.Commun. Pure Appl. Math., 63(9):1111–1144, 2010. 1 [11] M. Caselli, E. Florit-Simon, and J. Serra. Yau’s conjecture for nonlocal minimal surfaces. arXiv e-prints, page arXiv:2306.07100, June 2023. 250 G. GIACOMIN AND A. SCHIKORRA [12] H. Chan, S. Dipierro, J. Serra, and E. Valdinoci. Nonlocal approximation of minimal surfaces: optimal estimates from stability.arXiv e-prints, page arXiv:2308.06328, Aug. 2023. 2 [13] G. Ciraolo, A. Figalli, F. Maggi, and M. Novaga. Rigidity and sharp stability estimates for hypersurfaces with constant and almost-constant nonlocal mean curvature.J. Reine Angew. Math., 741:275–294, 2018. 2 [14] F. H. Clarke.Optimization and nonsmooth analysis. SIAM, 1990. 41, 42, 43 [15] E. Di Nezza, G. Palatucci, and E. Valdinoci. Hitchhiker’s guide to the fractional Sobolev spaces. Bull. Sci. Math., 136(5):521–573, 2012. 4 [16] S. Dipierro and E. Valdinoci. Nonlocal minimal surfaces: interior regularity, quantitative estimates and boundary stickiness.arXiv e-prints, page arXiv:1607.06872, July 2016. 2 [17] S. Dipierro and E. Valdinoci. Some perspectives on (non)local phase transitions and minimal surfaces. arXiv e-prints, page arXiv:2207.04783, July 2022. 2 [18] L. Evans.Measure theory and fine properties of functions. Routledge, 2018. 40 [19] M. H. Freedman, Z.-X. He, and Z. Wang. Möbius energy of knots and unknots.Ann. of Math. (2), 139(1):1–50, 1994. 3 [20] S. Ghinassi and M. Goering. Menger curvatures andC1,α rectifiability of measures.Arch. Math., 114(4):419–429, 2020. 3 [21] M. Giaquinta and L. Martinazzi.An introduction to the regularity theory for elliptic systems, harmonic maps and minimal graphs, volume 11 ofAppunti. Scuola Normale Superiore di Pisa (Nuova Serie) [Lecture Notes. Scuola Normale Superiore di Pisa (New Series)]. Edizioni della Normale, Pisa, second edition, 2012. 13 [22] M.Goering.Characterizationsofcountably n-rectifiableRadonmeasuresbyhigher-dimensional Menger curvatures.Real Anal. Exch., 46(1):1–36, 2021. 3 [23] O. Gonzalez and J. H. Maddocks. Global curvature, thickness, and the ideal shapes of knots. Proc. Natl. Acad. Sci. USA, 96(9):4769–4773, 1999. 3 [24] J.-B. Hiriart-Urruty and C. Lemaréchal.Fundamentals of convex analysis. Springer Science & Business Media, 2004. 38, 39 [25] E. Kuwert and R. Schätzle. The Willmore functional. InTopics in modern regularity theory, volume 13 ofCRM Series, pages 1–115. Ed. Norm., Pisa, 2012. 2 [26] M. Meurer. Integral Menger curvature and rectifiability ofn-dimensional borel sets in euclidean N-space. Trans. Am. Math. Soc., 370(2):1185–1250, 2018. 3 [27] C. Mihaila and B. Seguin. A definition of fractional k-dimensional measure: bridging the gap between fractional length and fractional area.arXiv e-prints, page arXiv:2303.11542, Mar. 2023. 3 [28] J. O’Hara. Energy of a knot.Topology, 30(2):241–247, 1991. 3 [29] J. O’Hara. Family of energy functionals of knots.Topology Appl., 48(2):147–161, 1992. 3 [30] J. O’Hara. Energy functionals of knots. II.Topology Appl., 56(1):45–61, 1994. 3 [31] M. Prats and E. Saksman. AT(1) theorem for fractional Sobolev spaces on domains.J. Geom. Anal., 27(3):2490–2538, 2017. 4 [32] T. Riviére. Weak immersions of surfaces withL2-bounded second fundamental form. In Geometric analysis, volume 22 ofIAS/Park City Math. Ser., pages 303–384. Amer. Math. Soc., Providence, RI, 2016. 2 [33] J. Sacks and K. Uhlenbeck. The existence of minimal immersions of2-spheres. Ann. of Math. (2), 113(1):1–24, 1981. 2, 47 [34] L. Simon. Existence of Willmore surfaces. InMiniconference on geometry and partial differen- tial equations (Canberra, 1985), volume 10 ofProc. Centre Math. Anal. Austral. Nat. Univ., pages 187–216. Austral. Nat. Univ., Canberra, 1986. 2 [35] E. M. Stein. The characterization of functions arising as potentials.Bull. Amer. Math. Soc., 67:102–104, 1961. 4 [36] P. Strzelecki, M. Szumańska, and H. von der Mosel. A geometric curvature double integral of Menger type for space curves.Ann. Acad. Sci. Fenn., Math., 34(1):195–214, 2009. 3 [37] P. Strzelecki and H. von der Mosel. Tangent-point self-avoidance energies for curves.J. Knot Theory Ramifications, 21(5):1250044, 28, 2012. 24 [38] L. Wang. Inequalities in homogeneous Triebel-Lizorkin and Besov-Lipschitz spaces.Commun. Pure Appl. Anal., 22(4):1318–1393, 2023. 4MINIMIZING CURVES FOR THE NONLOCAL WILLMORE ENERGY 51 (Giovanni Giacomin)Department of Mathematics and Statistics, University of Western Australia, 35 Stirling Highway, WA6009 Crawley, Australia. Email address: giovanni.giacomin@research.uwa.edu.au (Armin Schikorra)Department of Mathematics, University of Pittsburgh, 301 Thackeray Hall, Pittsburgh, PA 15260, USA Email address: armin@pitt.edu",
      "references": [
        "A fractional Willmore-type energy functional–subcritical observations.",
        "Regularity theory for tangent-point energies: the non-degenerate sub-critical case.",
        "Harmonic analysis meets critical knots. Critical points of the Möbius energy are smooth.",
        "On O’Hara knot energies. I: Regularity for critical knots.",
        "Scale-invariant tangent-point energies for knots.",
        "A simple energy function for knots.",
        "A fractional Michael-Simon Sobolev inequality on convex hypersurfaces.",
        "Curves and surfaces with constant nonlocal mean curvature: meeting Alexandrov and Delaunay.",
        "Nonlocal minimal surfaces.",
        "Yau’s conjecture for nonlocal minimal surfaces.",
        "Nonlocal approximation of minimal surfaces: optimal estimates from stability.",
        "Rigidity and sharp stability estimates for hypersurfaces with constant and almost-constant nonlocal mean curvature.",
        "Optimization and nonsmooth analysis.",
        "Hitchhiker’s guide to the fractional Sobolev spaces.",
        "Nonlocal minimal surfaces: interior regularity, quantitative estimates and boundary stickiness.",
        "Some perspectives on (non)local phase transitions and minimal surfaces.",
        "Measure theory and fine properties of functions.",
        "Möbius energy of knots and unknots.",
        "Menger curvatures andC1,α rectifiability of measures.",
        "An introduction to the regularity theory for elliptic systems, harmonic maps and minimal graphs",
        "Characterizationsofcountably n-rectifiableRadonmeasuresbyhigher-dimensional Menger curvatures.",
        "Global curvature, thickness, and the ideal shapes of knots.",
        "Fundamentals of convex analysis.",
        "The Willmore functional.",
        "Integral Menger curvature and rectifiability ofn-dimensional borel sets in euclidean N-space.",
        "A definition of fractional k-dimensional measure: bridging the gap between fractional length and fractional area.",
        "Energy of a knot.",
        "Family of energy functionals of knots.",
        "Energy functionals of knots. II.",
        "AT(1) theorem for fractional Sobolev spaces on domains.",
        "Weak immersions of surfaces withL2-bounded second fundamental form.",
        "The existence of minimal immersions of2-spheres.",
        "Existence of Willmore surfaces.",
        "The characterization of functions arising as potentials.",
        "A geometric curvature double integral of Menger type for space curves.",
        "Tangent-point self-avoidance energies for curves.",
        "Inequalities in homogeneous Triebel-Lizorkin and Besov-Lipschitz spaces."
      ],
      "meta_data": {
        "arxiv_id": "2402.05267v1",
        "authors": [
          "Giovanni Giacomin",
          "Armin Schikorra"
        ],
        "published_date": "2024-02-07T21:24:22Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Establishes existence of minimizers for the critical (scaling-invariant) nonlocal Willmore energy defined via fractional mean curvature (Caffarelli–Roquejoffre–Savin) among convex C1 closed curves (equivalently convex bounded planar sets with C1 boundary). Develops compactness/lower-semicontinuity framework in a regime prone to bubbling and shows qualitative regularity: any convex Lipschitz curve with finite critical/subcritical energy is actually C1.",
        "methodology": "Defines the energy Ws:=W_{s,1/s} for arclength-parametrized curves using the fractional mean curvature kernel. Proves a chain of analytic-geometric estimates: (i) small local energy controls local BMO/VMO of the tangent γ′ (Prop. 3.1) via John–Nirenberg and integral inequalities; (ii) BMO control yields quantitative bi-Lipschitz bounds and local graphical representation of convex curves (Lemmas 3.4–3.5); (iii) on graph pieces, convexity converts the curvature integrand into a second-order difference quotient, giving sharp Sobolev control γ′∈W^{s,1/s}_2 locally (Thm. 4.1) using Bessel potential characterization (Stein) and a localization/cutoff argument; (iv) establishes self-repulsiveness/non-collision: locally small energy prevents distant parameter points mapping close in space (Thm. 5.1) using Strzelecki–von der Mosel-type tube lemmas; (v) proves qualitative regularity: convex Lipschitz finite-energy curves (p≥1/s) are C1 (Thm. 6.1) via barrier sets and maximum principle for fractional mean curvature; (vi) combines covering argument (Prop. C.1), reflexivity/compactness in W^{s+1,1/s}_2 off finitely many points, and Fatou lower semicontinuity to obtain existence (Thm. 7.1→Thm. 1.1).",
        "experimental_setup": "Purely theoretical analysis; no datasets or numerical experiments. Validation consists of rigorous proofs using: (a) fractional Sobolev/Bessel potential equivalences, Poincaré/Sobolev inequalities; (b) geometric convexity facts and an implicit function theorem for convex curves; (c) maximum principle for fractional mean curvature; (d) compactness via Arzelà–Ascoli plus weak convergence in W^{s+1,1/s}_2 on localized charts and a covering argument ensuring locally small energy outside a finite bad set.",
        "limitations": "Results require convexity (to fix sign of the integrand and enable barrier/graph arguments); do not cover general (possibly non-convex) embedded curves or immersed curves with sign-changing fractional mean curvature. Regularity upgrade to C1 is qualitative (no uniform C1 estimates along minimizing sequences). Compactness is local away from a finite set Σ, reflecting critical scaling and potential concentration/bubbling. Work is restricted to planar curves/co-dimension one boundaries; extension to higher dimensions is only conjectural. Energy definition/arguments assume arclength parametrization and homeomorphism (embeddedness) in the minimization class; behavior for self-intersections is deferred.",
        "future_research_directions": "Remove or relax convexity and handle sign-changing fractional mean curvature; analyze minimizers among general embedded curves or immersed curves with self-intersections (as hinted). Derive quantitative C1 (or higher) regularity estimates and investigate whether minimizers are smoother (C^{1,α}, C^∞) and satisfy an Euler–Lagrange equation. Study bubbling/concentration phenomena in the critical regime and characterize the minimizer (e.g., whether the circle is unique). Extend theory to higher-dimensional hypersurfaces and compare with classical Willmore via the limit s→1. Explore topological/ knot-energy analogies further and connect Ws to tangent-point/Möbius/O’Hara energies, including Γ-convergence or stability results.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Concentrate Attention: Towards Domain-Generalizable Prompt Optimization for Language Models",
      "full_text": "Insights of using Control Theory for minimizing Induced Seismicity in Underground Reservoirs Diego Guti´errez-Oribioa, Ioannis Stefanoua,∗ aNantes Universite, Ecole Centrale Nantes, CNRS, GeM, UMR 6183, F-44000, Nantes, France Abstract Deep Geothermal Energy, Carbon Capture, and Storage and Hydrogen Storage have significant potential to meet the large-scale needs of the energy sector and reduce the CO 2 emissions. However, the injection of fluids into the earth’s crust, upon which these activities rely, can lead to the formation of new seismogenic faults or the reactivation of existing ones, thereby causing earthquakes. In this study, we propose a novel approach based on control theory to address this issue. First, we obtain a simplified model of induced seismicity due to fluid injections in an underground reservoir using a diffusion equation in three dimensions. Then, we design a robust tracking control approach to force the seismicity rate to follow desired references. In this way, the induced seismicity is minimized while ensuring fluid circulation for the needs of renewable energy production and storage. The designed control guarantees the achievement of the control objectives even in the presence of system uncertainties and unknown dynamics. Finally, we present simulations of a simplified geothermal reservoir under di fferent scenarios of energy demand to show the reliability and performance of the control approach, opening new perspectives for field experiments based on real-time regulators. Keywords: Energy geotechnics, Geothermal energy, Energy and energy product storage, Earthquake prevention, Induced seismicity, Robust control 1. INTRODUCTION Deep Geothermal Energy, Carbon Capture and Stor- age, and Hydrogen Storage show promising potential in addressing the substantial energy sector demands while mitigating CO2 emissions. However, their effectiveness relies on injecting fluids into the Earth’s crust, a pro- cess that may potentially induce earthquakes [1, 2, 3]. The occurrence of induced seismicity poses a signifi- cant threat to the feasibility of projects employing these techniques. This concern has led to the closure of sev- eral geothermal plants worldwide, such as those in Al- sace, France, in 2020 [4, 5], Pohang, South Korea, in 2019 [6, 7], and Basel, Switzerland, in 2009 [8, 9]. Earthquakes initiate when there is a sudden release of significant elastic energy stored within the Earth’s crust due to abrupt sliding along fault lines [10, 11]. ∗Corresponding author. Email addresses: diego.gutierrez-oribio@ec-nantes.fr (Diego Guti´errez-Oribio), ioannis.stefanou@ec-nantes.fr (Ioannis Stefanou) The injection of fluids can lead to the formation of new seismogenic faults or the reactivation of existing ones, which cause earthquakes [2, 3, 12]. More specifically, elevated fluid pressures at depth amplify the amount of elastic energy accumulated in the Earth’s crust while re- ducing the friction along faults. As a result, the likeli- hood of earthquakes significantly increases, even in re- gions that are typically considered to have low seismic potential (see [2], [7], and [12], among others). Therefore, earthquake prevention strategies are nec- essary to mitigate induced seismicity in the energy sec- tor [2, 7, 12]. Tra ffic light systems, cyclic stimulation and fracture caging are the most widely used approaches for earthquake prevention [13, 14, 15, 16]. Neverthe- less, to our knowledge, these methods rely on trial and error rather than a systematic control approach. They lack a mathematical foundation and cannot guarantee the avoidance of induced seismicity. Moreover, there is no proof that these methods cannot even trigger earth- quakes of greater magnitudes than the ones they are sup- posed to mitigate [17]. The fundamental assumptions of Preprint submitted to Journal May 15, 2024 arXiv:2310.02700v3  [eess.SY]  13 May 2024traffic light systems and its effectiveness were also ques- tioned in [18, 19, 20]. More recently, significant progress has been made in controlling the earthquake instability of specific, well- defined, mature seismic faults [21, 22, 23, 24, 25, 26]. These studies have employed various control algorithms to stabilize the complex and uncertain nature of the un- derlying underactuated physical system. The designed controllers effectively stabilize the system and modify its natural response time. As a result, the energy dissi- pation within the system occurs at a significantly slower rate, orders of magnitude lower than that of the natural (uncontrolled) earthquake event. However, it is worth noting that these investigations did not consider factors such as the presence of multiple smaller faults, which are typically found in deep geothermal reservoirs, as well as fluid circulation constraints associated with en- ergy production. Regarding the controllability, observ- ability and parameter identification of geological reser- voirs, we refer to [27, 28, 29]. In [30], the authors introduce a control strategy for a deep geothermal system. However, it is important to note that this study focused on a 1D di ffusion system, the control design was implemented based on a dis- cretized model (not accounting for possible spillover), and the output considered was the pressure over the reservoir, rather than the seismicity rate (SR). There- fore, this result presents many limitations to cope in- duced seismicity over real applications. This study accounts for water injections into an un- derground reservoir using a simplified model of a 3D diffusion equation. By utilizing this Partial Di fferen- tial Equation (PDE), a robust tracking control strategy is developed to regulate the SR, ensuring tracking to a desired reference. The primary control objective is to prevent induced seismicity while maintaining energy production. The designed control scheme demonstrates resilience against system uncertainties and unmodelled dynamics. Simulations of the process are conducted to validate the e ffectiveness of the control approach and show the potential for optimizing underground fluid cir- culation and thus energy production. Various simu- lation scenarios, considering di fferent energy demands and constraints, are presented to provide a comprehen- sive understanding of the system’s behaviour and the re- liability of the control strategy. This research opens new perspectives for field applications at the kilometric scale based on real-time regulators and control theory. The structure of this paper can be outlined as follows. In Section 2, a motivating example of a simplified un- derground reservoir is presented showing how the SR increases when we inject fluids. Section 3 introduces the underlying 3D diffusion model and shows the feed- back control used for minimizing induced seismicity. To demonstrate the effectiveness of the proposed control strategy, simulations are conducted in Section 4, consid- ering different scenarios of intermittent energy demand and production constraints. Finally, concluding remarks are provided in Section 5, summarizing the key findings of the study. 2. EXAMPLE OF INDUCED SEISMICITY IN A RESERVOIR DUE TO FLUID INJECTIONS Consider a simplified underground reservoir at ap- proximately 4 [km] below the earth’s surface, as de- picted in Fig. 1. The reservoir is made of a porous rock which allows the circulation of fluids through its pores and cracks. In our example, the reservoir has a thickness of ∼100 [m] and covers horizontally a square surface of dimensions ∼5 [km] ×5 [km]. Wells are injecting and/or extracting fluids ( e.g. water) at di fferent injec- tion points in the reservoir, as shown in Fig. 1. For the sake of simplicity, injection of fluids will refer to both injection and fluid extraction from the reservoir. Pumping fluids in-depth causes the circulation of flu- ids in the reservoir, which, in turn, causes the host porous rock to deform. The hydro-mechanical be- haviour of the reservoir due to the injection of fluids at depth can be described by Biot’s theory [31]. According to this theory, the diffusion of the fluid and the deforma- tion of the host porous rock are coupled dynamic pro- cesses. However, if the injection rates are slow enough, with respect to the characteristic times of the system due to inertia, and if the volumetric strain rate of the host porous rock is negligible, then the diffusion of the fluid in the host rock due to fluid injections can be described by the following diffusion equation [32] ut = −1 β∇q + s, (1) where u = u(x,t) is the change of the fluid pressure in the reservoir due to fluid injections,x is the spatial coor- dinate, t ≥0 is the time, ut denotes the partial derivative of u with respect to time, q = −k η∇u is the change of the hydraulic flux and s is a source/sink term represent- ing the fluid injections. Furthermore, k is the perme- ability of the host rock, η is the dynamic viscosity of the fluid, and β is the compressibility of the rock-fluid mixture. All these parameters are assumed constant in most of the following examples and, thus, they can de- fine a simple expression for the hydraulic di ffusivity of 2Geothermal reservoir Injection points Well Dz=0.1 [km] D=5 [km] Earth's surface x2 x1 x33-4 [km] Figure 1: Underground reservoir diagram. the system, chy = k/ηβ. A special case where hetero- geneities are present in βand chy is covered in Section 4. Finally, the reservoir has volume V. We consider drained boundary conditions at the boundary of the reservoir, i.e., u = 0 at ∂V. Further- more, we assume point source terms, as the diameter of the wells is negligible compared to the size of the reser- voir. In particular we set s = 1 βB(x)Q(t), where Q(t) ∈ ℜm, Q(t) = [Q1(t),..., Qm(t)]T , are injection fluxes ap- plied at the injection points, ( x1,..., xm), trough the co- efficient B(x) ∈ℜ1×m, B(x) = [δ(x −x1),...,δ (x −xm)]. The terms δ(x −xi) are Dirac’s distributions andm is the number of the wells in the reservoir. For the rigorous statement of the mathematical problem and its control we refer to Section 3 and Appendix A to Appendix E. It is nowadays well established that the injection of fluids in the earth’s crust causes the creation of new and the reactivation of existing seismic faults, which are re- sponsible for notable earthquakes (see for instance [2], [12] and [7]). The physical mechanisms behind those human-induced seismic events is connected with the change of stresses in the host rock due to the injections, which intensify the loading and /or reduce the friction over existing or new discontinuities (faults). In other words, fluid injections increase the SR in a region, i.e., the number of earthquakes in a given time window. The seismicity rate, R, of a volume containing nu- cleation sources, i.e. a region, depends on the average stress rate change, ˙τ, over the same region according to the following expression ˙R = R ta  ˙τ ˙τ0 −R ! , (2) where ˙() denotes the time derivative, ta is a character- istic decay time and ˙τ0 is the background stress change rate in the region, i.e. the stress change rate due to var- ious natural tectonic processes, and is considered to be constant. The above equation coincides with the one of Segall and Lu [33] (see also [34]), with the difference that here the SR is defined region-wise rather than point- wise. This choice results in a more convenient formu- lation as we mainly focus on averages over large vol- umes rather than point-wise measurements of the SR, which can be also singular due to point sources. Fol- lowing Segall and Lu [33] we assume also that the stress change rate is a linear function of the pore fluid pressure change rate, i.e., ˙τ= ˙τ0 + f ˙u, where ˙u is the average fluid pressure change rate over a given region of the reservoir and f a (mobilized) friction coefficient. The latter linear hypothesis is justified on the basis of Coulomb friction over the fault planes and Terzaghi’s effective stress prin- ciple [35]. It is worth emphasizing that, according to [34], the volume containing the nucleation sources must be small enough for all of them to experience uniform stress changes. Apparently, this is improbable during fluid injections in the Earth’s crust, hence our simplifying assumption of averaging the Coulomb stress changes, ˙τ, over a predefined region. The size of the averag- ing volumes (regions) could potentially be determined based on statistical arguments to accommodate the max- imum expected induced earthquake magnitude (see for instance [36]). However, these considerations extend beyond the scope of the current work (see also Section 5 for more details about the limitations of the current approach). Finally, the point-wise SR model could be recovered at the limit of infinitesimal volumes. In this sense the region-wise SR approach used here is more general. In the absence of fluid injections, ˙τ = ˙τ0 and, there- fore, R →1. In this case, the SR of the region reduces to the natural one. If, on the contrary, fluids are injected 3into the reservoir, then ˙u > 0 and consequently, ˙τ >˙τ0, leading to an increase of the SR (˙R >0) over the region. To illustrate this mechanism, let us consider an injec- tion of Q = Qs1 = 32 [m3/hr] through a single injec- tion well (see [37, 38] for enhanced geothermal systems with similar injection rates). In this numerical exam- ple, we consider the parameters of Table 1, we depth average Equation 1 as shown in Appendix C and we in- tegrate the resulting partial differential equation in time and space using a spectral decomposition method as ex- plained in Appendix D. We then calculate the SR over two distinct regions, one close to the injection point and one in the surroundings. Fig. 2 shows the location of the regions and of the injection point. The SR in both regions as a function of time is shown in fig. 3. We observe that the maximum SR over V1 is equal to R1 = 7975, which means that 7975 more earth- quakes of a given magnitude in a given time window are expected over region V1, than without injections. The seismicity is even higher near the injection well (see re- gion V2 in Fig. 3). Fig. 4 shows the evolution of the pressure over the reservoir through different times. The pressure experiences a gradual rise across extensive ar- eas near the injection point, eventually stabilizing at ap- proximately two years. In the case of an Enhanced Geothermal System (EGS [39]), we would like to increase the permeability be- tween two wells by creating a small network of cracks that would facilitate the circulation of fluids between the wells [40]. The creation of those cracks would be as- sociated with a localized microseismicity in the region encircling the wells. This microseismicity is welcome, provided that the overall SR over the larger region of the reservoir remains close to one. Therefore, in the control problem addressed in this work, we will set as control objective the controlled increase of the SR in a small region surrounding some wells ( e.g., in region V2, see Fig. 2), while keeping constant and equal to one the SR over the larger area of the reservoir ( e.g., in region V1, see Fig. 2). For this purpose, additional wells will be added in the reservoir, whose fluxes will be controlled by a specially designed controller. This controller will be robust to uncertainties of the system parameters and will achieve the aforementioned control objective under different production rates. Table 1: Di ffusion and Seismicity rate system parameters. Such pa- rameters are consistent with real applications like [41, 42]. Parameter Description Value and Units chy Hydraulic diffusivity 3.6 ×10−4 [km2/hr] D Reservoir length 5 [km] Dz Reservoir depth 0.1 [km] Qs Static flux 32 [m3/hr] β Mixture compressibility 1.2 ×10−4 [1/MPa] f Friction coefficient 0.5 [-] ˙τ0 Background stressing rate 1 ×10−6 [MPa/hr] ta Characteristic decay time 500100 [hr] 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 Qs1 Figure 2: Regions V1 and V2 and location of the injection well with flux Qs1 inside of region V2. 0.0 0.5 1.0 1.5 2.0 2.5 3.0 t [years] 0 10000 20000 30000 40000 50000 60000 70000 80000 R [-] maxt ≥ 0  R1 (t) = 7975 R1 R2 Figure 3: Seismicity rate in both regions, V1,V2 with constant injec- tion rate, Qs1 . 7975 more earthquakes of a given magnitude in a given time window are expected over the outer region of the reservoir due to the constant fluid injection. 40 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=2.0 [months] 0 10 20 30405060 Qs1 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=10.0 [months] 0 10 20 30 40 5060708090 Qs1 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=24.0 [months] 0 10 20 3040 5060708090 Qs1 90 60 30 0 30 60 90 [MPa] Figure 4: Solution, u(x,t), of the pressure’s reservoir at di fferent times, with constant injection rate, Qs1 . The solution presents high pressure profiles in wide areas next to the point of injection. 3. PROBLEM STATEMENT AND CONTROL DE- SIGN The diffusion system (1) can be written as follows ut(x,t) = chy∇2u(x,t) + 1 β[Bs(x)Qs(t) + Bc(x)Qc(t)] , u(x,t) = 0 ∀ x ∈S, (3) where u(x,t) is the fluid pressure change evolving in the space H1(V), x ∈ ℜ3, x = [x1,x2,x3]T , is the space variable belonging to a bounded subset V of the space ℜ3 with boundary S = ∂V, and t ≥0 is the time vari- able. As mentioned above, chy is the hydraulic diffusiv- ity and βis the compressibility of the rock-fluid mixture. Qs(t) ∈ ℜms , Qs(t) = [Qs1 (t),..., Qsms (t)]T , are fixed (not controlled) fluxes applied at the injection points, (x1 s ,..., xms s ), trough the coe fficient Bs(x) ∈ ℜ1×ms , Bs(x) = [δ(x −x1 s ),...,δ (x −xms s )], and Qc(t) ∈ ℜmc , Qc(t) = [Qc1 (t),..., Qcmc (t)]T , are the controlled fluxes applied at the injection points, ( x1 s ,..., xmc s ), trough the coefficient Bc(x) ∈ℜ1×mc , Bc(x) = [δ(x −x1 c ),...,δ (x − xmc c )]. Note that the number of original inputs,m, in sys- tem (1) is equal to the sum of not controlled and con- trolled input of system (3), i.e., m = ms + mc (Q(t) = Bs(x)Qs(t) + Bc(x)Qc(t)). Since the right-hand side of (1) contains Dirac’s distributions, the above boundary value problem is interpreted in the weak sense (see Ap- pendix A for more details on the notation and Appendix B for the definition of weak solution). As explained before, the SR in equation (2) is defined region-wise. In this study, we will define the SR overmc regions, Vi ⊂V, i ∈[1,mc] of the underground reservoir as follows ˙hi = f ta ˙τ0Vi Z Vi ut(x,t) dV −1 ta (ehi −1), i ∈[1,mc], (4) where the change of variables Ri = ehi , i ∈[1,mc], (5) has been used for ease of calculation. The objective of this work is to design the control input Qc driving the output y ∈ℜmc defined as y = [h1,..., hmc ]T , (6) of the underlying BVP (3)–(4) to desired references r(t) ∈ ℜmc , r(t) = [r1(t),..., rmc (t)]T . This is known as tracking. Note that solving such tracking problem re- sults in solving the tracking for the SR system (2) due to the change of variables (5),i.e., Ri(t) will be forced to follow the desired reference ¯ri(t) = eri(t) for i ∈[1,mc]. For that purpose, let us define the error variable, ye ∈ ℜmc , as follows ye = y −r, (7) and the control Qc(t) given by Qc(t) = B−1 0 \u0010 −K1 ⌈ye⌋ 1 1−l + ν+ ˙r \u0011 , ˙ν= −K2 ⌈ye⌋ 1+l 1−l , (8) where K1 ∈ ℜmc×mc , K2 ∈ ℜmc×mc are matrices to be designed, and l ∈[−1,0] is a freely chosen parameter [43, 44]. The matrix B0 ∈ ℜmc×mc is a nominal ma- trix that depends on the system parameters (see equa- tion (E.6) in Appendix E for its definition). The func- tion ⌈ye⌋γ := |ye|γsign(ye) is applied element-wise and 5is determined for any γ ∈ R≥0 (see Appendix A for more details). Such control has di fferent characteristics depending on the value of l. It has a discontinuous in- tegral term when l = −1, i.e., ⌈ye⌋0 = sign(ye). When l ∈ (−1,0] the control function is continuous and de- generates to a linear integral control when l = 0. Note how the controller is designed with minimum informa- tion about the system (E.4), i.e. with only the measure- ment of y(t) and the knowledge of the nominal matrix B0. The tracking result for the output (4)–(6) is then in force: Let system (3)–(4) be driven by the control (8) with K1 > 0, K2 > 0 and B0 as in (E.6). Then, the error variable (7) will tend to zero in finite-time ifl = [−1,0), or exponentially if l = 0. In other words, we force the SR to follow desired references to avoid induced seismicity over the under- ground reservoir. (See Appendix E for the mathemati- cal derivation of the proof and further details of the con- trol algorithm.) 3.1. Energy demand and production constraints We will consider a new scenario where an additional number of flux restrictions, mr, to the fluid injection of the controlled injection points is needed. In other words, we will impose the weighted sum of the injection rates of some of the wells to be equal to a time-variant, pos- sibly intermittent production rate. For this purpose, we will augment the vector of con- trolled injection points as ¯Qc(t) ∈ ℜmc+mr , ¯Qc(t) = [ ¯Qc1 (t),..., ¯Qcmc+mr (t)]T . Notice that the number of con- trolled injection points, mc, has to be increased to mr + mc. This does not change the previous theoretical results as shown below. The condition imposed over the control input, ¯Qc(t), is W ¯Qc(t) = D(t), (9) where W ∈ℜmr×(mc+mr) is a full rank matrix whose ele- ments represent the weighted participation of the well’s fluxes for ensuring the demand D(t) ∈ℜmr . In order to follow this, the new control input will be designed as ¯Qc(t) = WQc(t) + WT (WW T )−1D(t), (10) where Qc(t) is the original control input designed as (8) and W ∈ℜ(mc+mr)×mc is the null space of W. Note that if we replace (10) in (9), the demand over the controlled injection points will be strictly fulfilled at any time t. Control (10) will ensure the linear combination of the new controlled fluxes ¯Qc(t) to be equal to a predeter- mined flux D(t), which we called demand, according to (9), while keeping the original output tracking result of the previous section. This can be of interest in geoen- ergy applications to cope with different types of energy demand and production constraints (see Appendix E.1 for more details). Note that by monitoring the SR in the regions of in- terest and using equations (8) and (10) it is theoretically possible to adjust the fluid flux of the wells in a reser- voir and achieve the desired control objectives in terms of the SR, while achieving production constraints. 4. SIMULATIONS In order to demonstrate our control approach, numer- ical simulations of (3) and (4) have been done in Python (scripts available upon request). Without loss of gener- ality and for a simpler presentation of the results, we chose to depth average Equation 3 as shown in Ap- pendix C and integrate the resulting two-dimensional partial di fferential equation in time and space using Runge-Kutta method RK23 [45] and spectral decom- position method as explained in Appendix D, respec- tively. The same parameters with the numerical simula- tions performed in section 2 were used (see Table 1). Simulations were performed for three scenarios, i.e. one without any predetermined demand, one with con- stant demand and one with intermittent demand. In all scenarios we consider a fixed injection well with flux Qs(t) = Qs1 (t) = 32 [m3/hr] situated at the same loca- tion as the fixed injection well of the example presented in section 2. Moreover, following the same example, we consider two di fferent regions, V1,V2 over which we calculate the SR, R1,R2. Consequently, the num- ber of outputs to be tracked is equal to two and, thus, at least two control inputs have to be designed ( Qc(t) = [Qc1 (t),Qc2 (t)]T , mc = 2). In Fig. 5 (top) we show the chosen location of the control wells. The initial condi- tions of the systems (3) and (4) were set as u(x,0) = 0 and h1(0) = h2(0) = 0 (i.e., R1(0) = R2(0) = 1). To design the control (8), the matrices Bs,Bc of sys- tem (E.4) are needed (see Appendix E for more details), and they are defined as Bs = f ta ˙τ0β \" 0 1 V2 # , Bc = f ta ˙τ0β \" 1 V1 0 0 1 V2 # . (11) For the scenarios with predetermined demand, we will apply a single flux restriction, i.e., mr = 1, with W = [1,1.01,1] (see Section 3.1 for more details). As a result, an addition control will be needed ( i.e. mc + mr = 3), whose location is depicted in Fig. 5 (bot- tom). Therefore, the matrices ¯Bc,Bc of system (E.10) 60 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 Qs1 Qc1 Qc2 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 Qs1 ¯Qc1 ¯Qc2 ¯Qc3 Figure 5: Regions V1 and V2 and location of the injection wells in the cases without demand (top) and with demand (bottom). become ¯Bc = f ta ˙τ0β \" 1 V1 1 V1 0 0 0 1 V2 # , Bc = ¯BcW = f ta ˙τ0β \" 0.22 V1 −0.78 V1 −0.21 V2 0.79 V2 # (12) and the matrix Bs is given in (11). Finally, in all scenarios, the reference r(t) was se- lected as r(t) = [r1(t),r2(t)]T , where r1(t) = 0 and r2(t) is a smooth function that reaches the final value of ln(5) in 1 [month] (see Figs 6, 9 and 13). This reference was chosen so the SR on every region, V1,V2 to converge to the final values 1 and 5, respectively. This selection aims at forcing the SR in the extended region V1 to be the same as the natural one. Regarding, region V2 we opt for an increase of the SR in order to facilitate the circulation of fluids and improve the production of en- ergy. 4.1. Scenario 1: SR tracking without demand In this scenario, the control (8) was implemented with a nominal matrix B0 as B0 = f0 ta0 ˙τ00 β0  1 V10 0 0 1 V20 , (13) where the subscript ‘0’ corresponds to the nominal val- ues of the system’s parameters. In our case, we have chosen all the nominal values 10% higher than the real ones, e.g., f0 = 1.1 f . The gain parameters of the control (8) were selected as K1 = \" 1.5 ×10−2 0 0 6 .7 ×10−2 # , K2 = \" 1.1 ×10−4 0 0 2 .2 ×10−3 # , l = −0.6 (14) The results are depicted in Figures 6 to 8. In both re- gions, seismicity rates align with the specified constant references after approximately one month, achieving a steady state more rapidly than the uncontrolled system, as illustrated in Figure 3, which took around two years to reach a steady state. This robust performance is at- tributed to the control strategy, which e ffectively ad- dresses uncertainties in the system. Specifically, the control uses only the nominal matrix B0 and compen- sates for the remaining error dynamics. The generated control signals, presented in Figure 8, exhibit continu- ous fluxes that can be used in practical pump actuators. Figure 7 displays the pressure profile,u(x,t), at different time points. In contrast to the scenario without control (refer to Figure 4), the control strategy e ffectively pre- vents the propagation of high-pressure profiles around the static injection point. 4.2. Scenario 2: SR tracking with constant demand In this scenario we consider the demand to be equal to D(t) = −Qs1 = −32 [m3/hr] (see Fig. 11). This is interesting in applications where the extracted fluid is re-injected into the reservoir. The control ¯Qc(t) was designed as (8),(10) with the nominal matrix B0 B0 = f0 ta0 ˙τ00 β0  0.22 V10 −0.78 V10 −0.21 V20 0.79 V20 , (15) where the subscript ‘0’ corresponds to the nominal val- ues of every system parameter. Again, we have chosen all the nominal values 10% larger than the real ones to test robustness. The control gains were selected as in 70.0 0.5 1.0 1.5 2.0 2.5 3.0 t [months] 0 2 4 6 8 10 R [-] R1 R2 r1 r2 Figure 6: Seismicity rate in regions, V1,V2. The control strategy forces the SR to follow the desired references preventing induced seis- micity. (14) and the results are shown in Figs. 9–11. Consistent with the earlier findings, the control e ffectively moni- tors the SR in two regions, but now under the influence of the imposed flux restriction (9) on the control wells (refer to Fig 11, bottom). The control strategy success- fully regulates the seismicity rates across both regions, achieving a stable low pressure solution as in the previ- ous case (see Figure 10). Figure 11 (top) shows fast-frequency oscillations (chattering) in the control signals due to the discontinu- ous nature of the employed controller. One can reduce such oscillations by choosing the linear case of the con- trol, i.e., l = 0 instead of l = −0.6. Indeed, in Fig. 11 (center) we observe the linear control signal generated for this case, which is smoother, but its convergence is slower and less precise. The latter is demonstrated in Fig. 12, where the norm of the tracking error is shown for both cases. Therefore, the selection of the control parameter, l, offers a trade-off between smoothness and precision, resulting in a great flexibility depending on the requirements of specific practical applications. 4.3. Scenario 3: SR tracking with intermittent demand In order to test a more plausible demand scenario, we will apply the same control strategy as in the previous case, but using an intermittent demand ( cf. [41]), D(t), as depicted in Fig. 15 (bottom). According to this injec- tion plan, the demand varies abruptly between the flux of the fixed well and zero. The results are shown in Figs. 13–15. Despite the intermittent nature of the de- mand, leading to numerous transients in the SR as de- picted in Figure 13, the generated control signals (Fig- ure 15 (top)) swiftly restore the tracking performance for the SR. It is noteworthy that the control signals ad- here strictly to the intermittent demand D(t), as evident in Figure 15 (bottom). Additionally, the abrupt shifts in demand result in higher pressure profiles compared to previous scenarios, as illustrated in Figure 14. Never- theless, the control strategy ensures the steady state of the pressure solution after approximately 24 months. 4.4. Scenario 4: SR tracking with heterogeneities As a final test to validate the robustness of the pre- sented control strategy, we will introduce a more real- istic scenario where there is presence of heterogeneities in the reservoir, more specifically in the hydraulic diffu- sivity and the mixture compressibility parameters, i.e., chy = chet hy (x) and β = βhet(x). Fig. 16 illustrates the spatial variation of these parameters normalized by their constant values, as considered in the previous para- graphs. This variation extends to three orders of magni- tude. Fig. 17 shows how the pressure evolves in the het- erogeneous reservoir under the constant injection rate Qs1 (t) = 32 [m3/hr] (no control). We observe that the contours are not circular convex anymore as in Fig. 4 due to heterogeneity. Furthermore, now the steady state is reached in a longer time (around 30 years in this sim- ulation) due to the new distribution ofchet hy (x) and βhet(x) across the reservoir. The results of the simulations for the control case (Scenario 1) under heterogeneous parameters are de- picted in Figs. 18–20. Although there are some os- cillations in the control signal of the injection well Qc2 (see Fig. 20) due to its location on the reservoir (see βhet(x) value in Fig. 16), the control algorithm is still able to compensate such uncertainties and accomplish the tracking of the SR. The steady state of the pressure solution is achieved in a longer time compared to the case without heterogeneity (Fig. 7), but ten times faster than in the case without control (Fig. 17). 5. CONCLUSIONS AND LIMITATIONS A new control strategy for minimizing induced seis- micity while assuring fluid circulation for energy pro- duction in underground reservoirs is designed in this paper. Contrary to existing approaches for induced seis- micity mitigation due to fluid injections in the earth’s crust, the proposed control strategy ensures the robust tracking of desired seismicity rates over di fferent re- gions in geological reservoirs. For this purpose, a robust controller uses the measurement of averages of SR over different regions to generate continuous control signals for stabilizing the error dynamics, despite the presence 80 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=0.81 [months] 40 30 20 10 0 1020304050 Qs1 Qc1 Qc2 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=2.0 [months] 50 40 30 20 10 0 10 20 30405060 Qs1 Qc1 Qc2 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=8.0 [months] 60 50 40 30 20 10 0 10 2030 405060 Qs1 Qc1 Qc2 90 60 30 0 30 60 90 [MPa] Figure 7: Fluid pressure distribution, u(x,t), in the reservoir at di fferent times. The control strategy prevents the propagation of high-pressure profiles around the static injection point. 0.0 0.5 1.0 1.5 2.0 2.5 3.0 t [months] 30 20 10 0 10 20 30 Q [m3/hr] Qs1 Qc1 Qc2 Figure 8: Static flux input Qs1 and controlled flux inputs Qc1 ,Qc2 . 0.0 0.5 1.0 1.5 2.0 2.5 3.0 t [months] 0 2 4 6 8 10 R [-] R1 R2 r1 r2 Figure 9: Seismicity rate in regions, V1,V2 under the constraint of constant demand. The control strategy forces the SR to follow the desired references while respecting the imposed energy demand. of system uncertainties and unknown error dynamics. This is of great importance on this complicated sys- tem where it is always difficult to measure the real sys- tem parameters ( e.g., di ffusivity and compressibility), or there are errors in the sensing of physical quantities (e.g., SR and accelerometers). A series of numerical simulations confirm the e ffec- tiveness of the presented theory over a simplified model of an underground reservoir under di fferent scenarios. This provides a new direction for using robust control theory for this challenging application that involves an uncertain, underactuated, non-linear system of infinite dimensionality for mitigating induced seismicity while maximizing renewable energy production and storage. However, assessing earthquake risk solely based on the seismicity rate may pose limitations, as earthquake magnitude holds greater significance than seismicity rate (c.f., Pohang EGS project [38, 46] vs. Basel EGS project [37] earthquakes). The magnitude of expected earthquakes can be related to their frequency accord- ing to modified Richter-Gutenberg distributions as pre- sented in [36] and related works. The same holds for the maximum magnitude of the expected earthquakes, which may be connected to the size of the activated re- gions, Vi. However, the incorporation of this kind of statistical analysis exceeds the scope of this work. Furthermore, the inclusion of fault discontinuities should be studied in real scenarios. Controlling multiple faults within a reservoir ( cf., [47]) remains a challenge due to complexity and faster spatio-temporal scales as- sociated with poroelastodynamic phenomena activated by intermittent injections. Controlling this dynamics to- gether with point-wise SR, instead of region-wise, non- linear constraints for the fluxes and error in measure- ments, among others, is under investigation. It is worth mentioning that the current approach has 90 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=0.81 [months] 40 30 20 10 0 1020304050 Qs1 Qc1 Qc2 Qc3 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=2.0 [months] 50 40 30 20 10 10 0 10 10 20 20 30405060 Qs1 Qc1 Qc2 Qc3 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=8.0 [months] 60 50 40 30 20 20 10 10 0 10 10 20 20 30 30 405060 Qs1 Qc1 Qc2 Qc3 90 60 30 0 30 60 90 [MPa] Figure 10: Pressure distribution, u(x,t), in the reservoir at different times, under the constraint of constant demand. The control strategy regulates the SR across both regions, achieving stable low pressure solution profiles. not yet been experimentally tested. A first step to- wards the experimental testing of the control of the slip of a single fault has been successful in the laboratory (see [23]), but this test seems rather adequate for in- termittent injections and induced seismicity at the level of reservoirs. Moreover, field-scale testing is with no doubt necessary despite the methodological challenges related to repeatability and other methodological prob- lems. Hence, this work is part of a more general e ffort for providing rigorous mathematical proofs and numer- ical simulations for exploring the extent up to which induced seismicity can be prevented in practice, while maximizing renewable energy production and storage. Acknowledgement The authors would like to acknowledge the Euro- pean Research Council’s (ERC) support under the Eu- ropean Union’s Horizon 2020 research and innovation program (Grant agreement no. 757848 CoQuake and Grant agreement no. 101087771 INJECT). The sec- ond author would like to express his grateful thanks to Prof. Jean-Philippe Avouac for their fruitful discussions about human-induced seismicity and mitigation. References [1] M. P. Wilson, G. R. Foulger, J. G. Gluyas, R. J. Davies, B. R. Ju- lian, HiQuake: The Human-Induced Earthquake Database, Seis- mological Research Letters 88 (6) (2017) 1560–1565. doi: 10.1785/0220170112. [2] J. L. Rubinstein, A. B. Mahani, Myths and facts on wastewater injection, hydraulic fracturing, enhanced oil recovery, and in- duced seismicity, Seismological Research Letters 86 (4) (2015) 1060–1067. doi:10.1785/0220150067. [3] F. Grigoli, S. Cesca, E. Priolo, A. P. Rinaldi, J. F. Clinton, T. A. Stabile, B. Dost, M. G. Fernandez, S. Wiemer, T. Dahm, Current challenges in monitoring, discrimination, and management of induced seismicity related to underground industrial activities: A european perspective, Reviews of Geophysics 55 (2) (2017) 310–340. doi:10.1002/2016RG000542. [4] M. Maheux, G ´eothermie : ”Dans le Bas-Rhin, tous les projets sont `a l’arrˆet” annonce la pr´ef`ete, France Bleu. Available at: ht tps://www.francebleu.fr/infos/societe/geothe rmie-profonde-tous-les-projets-sont-a-l-arr et-declare-la-prefete-du-bas-rhin-1607534951 (9/12/2020). [5] N. Stey, En Alsace, les projets de g ´eothermie profonde `a l’arrˆet, Le Monde. Available at: https://www.lemonde.fr/plane te/article/2020/12/11/en-alsace-les-projets-d e-geothermie-profonde-a-l-arret_6063099_3244.ht ml (11/12/2020). [6] K. Dae-sun, Findings of Pohang earthquake causes halt energy project on Ulleung Island, Hankyoreh english. Available at: ht tps://www.hani.co.kr/arti/english_edition/e_na tional/887126.html (24/03/2019). [7] M. Zastrow, South Korea accepts geothermal plant probably caused destructive quake, Nature (2019). doi:10.1038/d4 1586-019-00959-4 . [8] N. Deichmann, D. Giardini, Earthquakes Induced by the Stimulation of an Enhanced Geothermal System below Basel (Switzerland), Seismological Research Letters 80 (5) (2009) 784–798. doi:10.1785/gssrl.80.5.784. [9] J. Glanz, Quake Threat Leads Swiss to Close Geothermal Project, New York Times. Available at: https://www.nyti mes.com/2009/12/11/science/earth/11basel.html#: ~:text=A%20%2460%20million%20project%20to,proj ect%2C%20led%20by%20Markus%20O. (10/12/2009). [10] C. H. Scholz, The Mechanics of Earthquakes and Faulting, Cambridge University Press, USA, 2002. [11] H. Kanamori, E. E. Brodsky, The physics of earthquakes, Re- ports on Progress in Physics 67 (8) (2004) 1429–1496. doi: 10.1088/0034-4885/67/8/R03. [12] K. M. Keranen, H. M. Savage, G. A. Abers, E. S. Cochran, Potentially induced earthquakes in Oklahoma, USA: Links be- tween wastewater injection and the 2011 Mw 5.7 earthquake se- quence, Geology 41 (6) (2013) 1060–1067. doi:10.1130/G3 4045.1. 100.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 t [months] 30 20 10 0 10 20 30 Q [m3/hr] Qs1 Qc1 Qc2 Qc3 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 t [months] 30 20 10 0 10 20 30 Q [m3/hr] Qs1 Qc1 Qc2 Qc3 0 2 4 6 8 10 12 t [months] 40 30 20 10 0 10 20 30 40 Demand [m3/hr] Qs1 (t) W ¯Qc(t) D(t) Figure 11: Injection flux of fixed well Qs1 and injection fluxes of the controlled wells ¯Qc1 , ¯Qc2 , ¯Qc3 , under the constraint, D(t) = W ¯Qc(t) = −Qs1 (t). Discontinuous case (top) and continuous case (center). The demand (bottom plot) is always ensured. [13] J. P. Verdon, J. J. Bommer, Green, yellow, red, or out of the blue? an assessment of tra ffic light schemes to mitigate the im- pact of hydraulic fracturing-induced seismicity, J Seismol 25 (2021) 301–326. doi:10.1007/s10950-020-09966-9 . [14] H. Hofmann, G. Zimmermann, M. Farkas, E. Huenges, A. Zang, M. Leonhardt, G. Kwiatek, P. Martinez-Garzon, M. Bohnho ff, K.-B. Min, P. Fokker, R. Westaway, F. Bethmann, P. Meier, K. S. Yoon, J. W. Choi, T. J. Lee, K. Y . Kim, First field application of cyclic soft stimulation at the Pohang Enhanced Geothermal System site in Korea, Geophysical Journal International 217 (2) (2019) 926–949. doi:10.1093/gji/ggz058. [15] L. P. Frash, P. Fu, J. Morris, M. Gutierrez, G. Neupane, J. Hamp- ton, N. J. Welch, J. W. Carey, T. Kneafsey, Fracture caging to 0 2 4 6 8 10 t [months] 0.0 0.1 0.2 0.3 0.4 0.5 ||ye|| [-] 9.00 9.25 9.50 9.75 10.00 0.0 0.2 0.4 0.6 0.8 1.0 1e 3 l = − 0.6 l = 0 Figure 12: Norm of the tracking error,ye, with constant demand using discontinuous control (continuous black line) and continuous control (dotted gray line). 0 2 4 6 8 10 12 t [months] 0 2 4 6 8 10 R [-] 0 5 10 0.8 0.9 1.0 1.1 1.2 R1 R2 r1 r2 Figure 13: Seismicity rate in regions, V1,V2 under the constraint of intermittent demand. The control strategy forces the SR to follow the desired references while respecting the intermittent energy demand. limit induced seismicity, Geophysical Research Letters 48 (1) (2021) e2020GL090648. doi:https://doi.org/10.1029/ 2020GL090648. [16] A. Zang, G. Zimmermann, H. Hofmann, O. Stephansson, K.-B. Min, K. Y . Kim, How to Reduce Fluid-Injection-Induced Seis- micity, Rock Mechanics and Rock Engineering 52 (2019) 475– 493. doi:10.1007/s00603-018-1467-4 . [17] G. Tzortzopoulos, P. Braun, I. Stefanou, Absorbent porous pa- per reveals how earthquakes could be mitigated, Geophysical Research Letters 48 (3) (2021) e2020GL090792. [18] J. P. Verdon, J. J. Bommer, Green, yellow, red, or out of the blue? An assessment of Traffic Light Schemes to mitigate the impact of hydraulic fracturing-induced seismicity, Journal of Seismol- ogy 25 (2021) 301–326. doi:10.1007/s10950-020-09966 -9. [19] S. Baisch, C. Koch, A. Muntendam-Bos, Tra ffic Light Systems: To What Extent Can Induced Seismicity Be Controlled?, Seis- mological Research Letters 90 (3) (2019) 1145–1154. doi: 10.1785/0220180337. [20] Y . Ji, W. Zhang, H. Hofmann, Y . Chen, C. Kluge, A. Zang, G. Zimmermann, Modelling of fluid pressure migration in a pressure sensitive fault zone subject to cyclic injection and im- plications for injection-induced seismicity, Geophysical Journal 110 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=4.0 [months] 60 50 40 40 30 20 10 0 10 20 30 40 50 506070 Qs1 Qc1 Qc2 Qc3 90 60 30 0 30 60 90 [MPa] 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=10.0 [months] 420 360 300 240 180 120 60 60 0 60 120180 240300360420480 Qs1 Qc1 Qc2 Qc3 540 360 180 0 180 360 540 [MPa] 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=24.0 [months] 60 50 40 30 20 20 10 10 0 10 10 20 20 30 30 405060 Qs1 Qc1 Qc2 Qc3 90 60 30 0 30 60 90 [MPa] Figure 14: Fluid pressure distribution, u(x,t), in the reservoir at di fferent times, under the constraint of intermittent demand. The abrupt shifts in demand result in higher pressure profiles compared to previous scenarios. Nevertheless, the control strategy ensures the steady state of the pressure solution after approximately 24 months. 0 2 4 6 8 10 12 14 t [months] 300 200 100 0 100 200 300 400 500 Q [m3/hr] Qs1 Qc1 Qc2 Qc3 0 2 4 6 8 10 12 14 t [months] 40 30 20 10 0 10 20 30 40 Demand [m3/hr] Qs1 (t) W ¯Qc(t) D(t) Figure 15: Injection flux Qs1 of the fixed well and injection fluxes ¯Qc1 , ¯Qc2 , ¯Qc3 of the control well under the constraint of intermittent demand. The demand (bottom) is strictly ensured again. International 232 (3) (2022) 1655–1667. doi:10.1093/gji/ ggac416. [21] I. Stefanou, Controlling anthropogenic and natural seismicity: Insights from active stabilization of the spring-slider model, Journal of Geophysical Research: Solid Earth 124 (8) (2019) 8786–8802. doi:10.1029/2019JB017847. [22] I. Stefanou, G. Tzortzopoulos, Preventing instabilities and in- ducing controlled, slow-slip in frictionally unstable systems, 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] logβhet(x) β V1 V2 Qs1 Qc1 Qc2 1.0 0.5 0.0 0.5 1.0 1.5 2.0 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] logchet hy (x) chy V1 V2 Qs1 Qc1 Qc2 2.0 1.5 1.0 0.5 0.0 0.5 1.0 Figure 16: Heterogeneity of βhet(x) and chet hy (x) in the underground reservoir. The average weight of hydraulic diffusivity in the reservoir is chet hy (x)/chy = 1.08. Journal of Geophysical Research: Solid Earth 127 (7) (2022) e2021JB023410. doi:10.1029/2021JB023410. [23] D. Guti ´errez-Oribio, G. Tzortzopoulos, I. Stefanou, F. Plestan, 120 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=1.0 [years] 0 10 20 30405060 Qs1 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=6.0 [years] 0 10 20 30 4050607080 Qs1 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=30.0 [years] 0 10 20 3040 5060708090 Qs1 90 60 30 0 30 60 90 [MPa] Figure 17: Pressure distribution, u(x,t), at different times, under heterogeneities in the reservoir. 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=0.5 [years] 40 30 20 10 0 10 20 304050 Qs1 Qc1 Qc2 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=1.0 [years] 40 30 20 10 0 10 20 304050 Qs1 Qc1 Qc2 0 1 2 3 4 5 x1 [km] 0 1 2 3 4 5 x2 [km] V1 V2 u at t=3.0 [years] 50 40 30 20 10 0 10 2030 405060 Qs1 Qc1 Qc2 90 60 30 0 30 60 90 [MPa] Figure 18: Pressure distribution, u(x,t), at different times, under heterogeneities in the reservoir. The control strategy regulates the SR across both regions, achieving a stable low pressure solution after approximately 3 years. 0.0 0.5 1.0 1.5 2.0 2.5 3.0 t [months] 0 2 4 6 8 10 R [-] R1 R2 r1 r2 Figure 19: Seismicity rate in regions, V1,V2. The control strategy forces the SR to follow the desired references preventing induced seis- micity. Earthquake Control: An Emerging Application for Robust Con- trol. Theory and Experimental Tests, IEEE Transactions on Con- 0.0 0.5 1.0 1.5 2.0 2.5 3.0 t [months] 40 30 20 10 0 10 20 30 Q [m3/hr] Qs1 Qc1 Qc2 Figure 20: Static flux input Qs1 and controlled flux inputs Qc1 ,Qc2 . trol Systems Technology 31 (4) (2023) 1747–1761. doi: 10.1109/TCST.2023.3242431. [24] D. Guti ´errez-Oribio, Y . Orlov, I. Stefanou, F. Plestan, Robust Boundary Tracking Control of Wave PDE: Insight on Forc- 13ing Slow-Aseismic Response, Systems & Control Letters 178 (2023) 105571. doi:10.1016/j.sysconle.2023.105571. [25] D. Guti ´errez-Oribio, I. Stefanou, F. Plestan, Passivity- based control of underactuated mechanical systems with Coulomb friction: Application to earthquake prevention, arXiv:2207.07181 (2022). doi:arXiv:2207.07181. [26] D. Guti ´errez-Oribio, Y . Orlov, I. Stefanou, F. Plestan, Advances in Sliding Mode Control of Earthquakes via Boundary Tracking of Wave and Heat PDEs, in: 16th International Workshop on Variable Structure Systems and Sliding Mode Control, Rio de Janeiro, Brasil, 2022. doi:10.1109/VSS57184.2022.9902 111. [27] J. F. M. Van Doren, P. M. J. Van Den Hof, O. H. Bosgra, J. D. Jansen, Controllability and observability in two-phase porous media flow, Computational Geosciences 17 (5) (2013) 773–788. doi:10.1007/s10596-013-9355-1 . [28] M. J. Zandvliet, J. F. M. Van Doren, O. H. Bosgra, J. D. Jansen, P. M. J. Van Den Hof, Controllability, observability and identifi- ability in single-phase porous media flow, Computational Geo- sciences 12 (4) (2008) 605–622. doi:10.1007/s10596-008 -9100-3. [29] J. F. Van Doren, P. M. Van Den Hof, J. D. Jansen, O. H. Bosgra, Parameter identification in large-scale models for oil and gas production, IFAC Proceedings V olumes 44 (1) (2011) 10857– 10862. doi:10.3182/20110828-6-IT-1002.01823 . [30] M. S. Darup, J. Renner, Predictive pressure control in deep geothermal systems, in: 2016 European Control Conference, 2016, pp. 605–610. doi:10.1109/ECC.2016.7810355. [31] M. A. Biot, General theory of three-dimensional consolidation, Journal of Applied Physics 12 (155) (1941) 155–164. doi: 10.1063/1.1712886. [32] O. C. Zienkiewicz, C. T. Chang, P. Bettess, Drained, undrained, consolidating and dynamic behaviour assumptions in soils, Geotechnique 30 (4) (1980) 385–395. doi:10.1680/geot .1980.30.4.385. [33] P. Segall, S. Lu, Injection-induced seismicity: Poroelastic and earthquake nucleation effects, Journal of Geophysical Research: Solid Earth 120 (7) (2015) 5082–5103. doi:10.1002/2015JB 012060. [34] J. H. Dieterich, A constitutive law for rate of earthquake pro- duction and its application to earthquake clustering, Journal of Geophysical Research 99 (B2) (1994) 2601–2618. doi: 10.1029/93JB02581. [35] K. Terzaghi, Theoretical Soil Mechanics, John Wiley & Sons, Inc., 1943. [36] S. A. Shapiro, O. S. Kr ¨uger, C. Dinske, Probability of induc- ing given-magnitude earthquakes by perturbing finite volumes of rocks, Journal of Geophysical Research: Solid Earth 118 (7) (2013) 3557–3575. doi:https://doi.org/10.1002/jgrb .50264. [37] M. O. H ¨aring, U. Schanz, F. Ladner, B. C. Dyer, Characterisa- tion of the basel 1 enhanced geothermal system, Geothermics 37 (5) (2008) 469–495. doi:https://doi.org/10.1016/ j.geothermics.2008.06.002. URL https://www.sciencedirect.com/science/arti cle/pii/S0375650508000382 [38] K.-I. Kim, H. Yoo, S. Park, J. Yim, L. Xie, K.-B. Min, J. Rutqvist, Induced and triggered seismicity by immediate stress transfer and delayed fluid migration in a fractured geother- mal reservoir at pohang, south korea, International Journal of Rock Mechanics and Mining Sciences 153 (2022) 105098.doi: https://doi.org/10.1016/j.ijrmms.2022.105098. URL https://www.sciencedirect.com/science/arti cle/pii/S1365160922000661 [39] F. H. Cornet, The engineering of safe hydraulic stimulations for EGS development in hot crystalline rock masses, Geomechanics for Energy and the Environment 26 (2021) 100151. doi:http s://doi.org/10.1016/j.gete.2019.100151. [40] E. Sarris, P. Papanastasiou, The influence of pumping parame- ters in fluid-driven fractures in weak porous formations, Inter- national Journal for Numerical and Analytical Methods in Ge- omechanics 39 (6) (2015) 635–654. doi:10.1002/nag.2330. [41] H. Lim, K. Deng, Y . Kim, J.-H. Ree, T.-R. A. Song, K.-H. Kim, The 2017 Mw 5.5 Pohang Earthquake, South Korea, and Poroelastic Stress Changes Associated With Fluid Injection, Journal of Geophysical Research: Solid Earth 125 (6) (2020) e2019JB019134. doi:10.1029/2019JB019134. [42] P. Segall, S. Lu, Injection-induced seismicity: Poroelastic and earthquake nucleation effects, Journal of Geophysical Research: Solid Earth 120 (7) (2015) 5082–5103. doi:10.1002/2015JB 012060. [43] J. F. Garc ´ıa-Mathey, J. A. Moreno, Mimo super-twisting con- troller: A new design, in: 2022 16th International Workshop on Variable Structure Systems (VSS), 2022, pp. 71–76. doi: 10.1109/VSS57184.2022.9901971. [44] J. F. Garc ´ıa-Mathey, J. A. Moreno, MIMO Super-Twisting Controller using a passivity-based design, arXiv:2208.04276v1 (2022). [45] P. Bogacki, L. Shampine, A 3(2) pair of Runge - Kutta formulas, Applied Mathematics Letters 2 (4) (1989) 321–325. doi:10.1 016/0893-9659(89)90079-7. URL https://linkinghub.elsevier.com/retrieve/p ii/0893965989900797 [46] J.-U. Woo, M. Kim, D.-H. Sheen, T.-S. Kang, J. Rhie, F. Grigoli, W. L. Ellsworth, D. Giardini, An in-depth seismological analy- sis revealing a causal link between the 2017 mw 5.5 pohang earthquake and egs project, Journal of Geophysical Research: Solid Earth 124 (12) (2019) 13060–13078. arXiv:https: //agupubs.onlinelibrary.wiley.com/doi/pdf/10.1 029/2019JB018368 , doi:https://doi.org/10.1029/20 19JB018368. URL https://agupubs.onlinelibrary.wiley.com/do i/abs/10.1029/2019JB018368 [47] A. Boyet, S. D. Simone, S. Ge, V . Vilarrasa, Poroelastic stress relaxation, slip stress transfer and friction weakening controlled post-injection seismicity at the Basel Enhanced Geothermal System, Commun Earth Environ 4 (104) (2023). doi:10.1 038/s43247-023-00764-y . [48] A. Pazy, Semigroups of Linear Operators and Applications to Partial Differential Equations, Springer New York, New York, USA, 1992. doi:10.1007/978-1-4612-5561-1 . [49] A. Pisano, Y . Orlov, On the ISS properties of a class of parabolic DPS’ with discontinuous control using sampled-in-space sens- ing and actuation, Automatica 81 (2017) 447–454. doi:10.1 016/j.automatica.2017.04.025. [50] H. Meyer, J. D. Smith, S. Bourne, J.-P. Avouac, An integrated framework for surface deformation modelling and induced seis- micity forecasting due to reservoir operations, Geological So- ciety, London, Special Publications 528 (1) (2023) 299–318. doi:10.1144/SP528-2022-169. [51] A. Filippov, Di fferential Equations with Discontinuos Right- hand Sides, Kluwer Academic Publishers, Dordrecht, The Netherlands, 1988. [52] S. Dashkovskiy, A. Mironchenko, Input-to-state stability of infinite-dimensional control systems, Math. Control Signals Syst. 25 (2013) 1–35. doi:10.1007/s00498-012-0090-2 . 14Appendix A. Notation We denote ||·|| as the euclidean norm of the n- dimensional Euclidean space, ℜn. If ye ∈ℜ, the func- tion ⌈ye⌋γ := |ye|γsign(ye) is determined for anyγ∈R≥0. If ye ∈ℜm, the functions ⌈ye⌋γ and |ye|γ will be applied element-wise. Consider the Sobolev space, H1(V), of abso- lutely continuous scalar functions u(x), x ∈ ℜ3, x = [x1,x2,x3]T , defined on a bounded subset V of the space ℜ3 with boundary S = ∂V as H1(V) = n u |u,∇u ∈L2(V) o . Its H0-norm is defined as ||u(·)||H0(V) = qR V [u(·)]2 dV. The time deriva- tive is denoted by ut = ∂u/∂t, the gradient as ∇u = [∂u/∂x1,∂u/∂x2,∂u/∂x3], and the Laplacian as ∇2u = ∂2u/∂x2 1 + ∂2u/∂x2 2 + ∂2u/∂x2 3. We define the Dirac’s distribution, δ(x), as R V∗ ϕ(x)δ(x −x∗) dV = ϕ(x∗), ∀x∗ ∈V, V∗ ⊂V, on an arbitrary test function ϕ(x) ∈H1(V). For their use, important inequalities are recalled: Poincar´e’s Inequality: For u(x) ∈H1(V) on a bounded subset V of the space ℜ3 of zero-trace (i.e., u(x,t) = 0 for all x ∈∂V), the inequality ||u(x)||2 H0(V) ≤γ||∇u(x)||2 H0(V) (A.1) with γ> 0 depending on V, is fulfilled. Cauchy-Schwarz Inequality: Z V f (x)g(x) dV ≤||f (x)||H0(V) ||g(x)||H0(V) , (A.2) for any f,g ∈L2(V). Appendix B. Weak solution of the 3D di ffusion equation Definition 1. [48, 49] A continuous function u (x,t) ∈ H1(V) is said to be a weak solution of the BVP (3) on t ≥0, if for every ϕ(x) ∈H1(V) under BCs ϕ(x) = 0 ∀x ∈ ∂V, the function R V u(x,t)ϕ(x) dV is absolutely continuous on t ≥0 and the relation Z V ut(x,t)ϕ(x) dV = −chy Z V ∇u(x,t) \u0002∇ϕ(x)\u0003T dV + 1 β[ϕ(x1 s ),...,ϕ (xms s )]Qs(t) + 1 β[ϕ(x1 c ),...,ϕ (xmc c )]Qc(t), (B.1) holds for almost all t ≥0. The weak solution (B.1) is obtained by multiplying (3) by the test functionϕ(x) and integrating with respect to the space variable: Z V ut(x,t)ϕ(x) dV = chy Z V ∇2u(x,t)ϕ(x) dV + 1 β Z V [Bs(x)Qs(t)] ϕ(x) dV + 1 β Z V [Bc(x)Qc(t)] ϕ(x) dV. Using integration by parts and the definition of the Dirac’s distribution, the latter expression can be rewrit- ten as Z V ut(x,t)ϕ(x) dV = chy Z V ∇·\u0002∇u(x,t)ϕ(x)\u0003 dV −chy Z V ∇u(x,t) \u0002∇ϕ(x)\u0003T dV + 1 β[ϕ(x1 s ),...,ϕ (xms s )]Qs(t) + 1 β[ϕ(x1 c ),...,ϕ (xmc c )]Qc(t). Finally, to retrieve expression (B.1) from the latter ex- pression, the divergence theorem and the BCs were used in the first term of the RHS. Appendix C. Depth average of the 3D di ffusion equation The system described by (3) is a three-dimensional system, whose solution would be di fficult to plot in a simplified manner. For this purpose and without loss of generality of the theoretical results presented in this study, we chose to limit our numerical simulations to a two-dimensional boundary value problem, which was derived by depth averaging the full, three-dimensional problem given in (3) (see [50] for another example of depth averaging). The depth averaging was performed 15as follows 1 Dz Z H 0 ut(x,t) dx3 = chy Dz Z H 0 ∇2u(x,t) dx3 + 1 βDz Z H 0 [Bs(x)Qs(t)] dx3 + 1 βDz Z H 0 [Bc(x)Qc(t)] dx3 = chy Dz Z H 0 ∂2u(x,t) ∂x2 1 dx3 + chy Dz Z H 0 ∂2u(x,t) ∂x2 2 dx3 + chy Dz Z H 0 ∂2u(x,t) ∂x2 3 dx3 + 1 βDz h ¯Bs( ¯x)Qs(t) + ¯Bc( ¯x)Qc(t) i , where H is the height of the reservoir, the new space variable ¯x ∈ ℜ2, ¯x = [x1,x2]T . ¯Bs( ¯x) = [δ( ¯x − ¯x1 s ),...,δ ( ¯x −¯xms s )] and ¯Bc( ¯x) = [δ( ¯x −¯x1 s ),...,δ ( ¯x −¯xmc c )]. We note that R H 0 ∂2u(x,t) ∂x2 3 dx3 = 0 due to the BC, u(x,t) = 0 ∀ x ∈S . Defining the depth average pressure as ¯u( ¯x,t) = 1 Dz R H 0 u(x,t) dx3, the last expression becomes ¯ut( ¯x,t) = chy∇2 ¯u( ¯x,t) + 1 βDz h ¯Bs( ¯x)Qs(t) + ¯Bc( ¯x)Qc(t) i , ¯u( ¯x,t) = 0 ∀ ¯x ∈∂S. (C.1) Note how the systems (3) and (C.1) obtain finally the same form, allowing the theoretical developments of section Appendix E to be applied without any change. This 2D diffusion equation is numerically solved in Sec- tions 2 and 4 using the spectral decomposition presented in the following appendix. Appendix D. Spectral Decomposition of the 2D dif- fusion equation We decompose the function ¯ut( ¯x,t) of the BVP (C.1) according to ¯ut( ¯x,t) = ∞X n=1 m=1 znm(t)ϕnm( ¯x), (D.1) where znm(t) = ⟨¯ut( ¯x,t),ϕnm( ¯x)⟩is the nm-th Fourier coefficient of ¯ut( ¯x,t) and ϕnm( ¯x) is the nm-th orthonor- mal eigenfunction satisfying the BC. The expression ⟨·,·⟩ denotes the inner product, i.e., ⟨f (·),g(·)⟩ = R S f (·)g(·) dS . For the case of the BVP (C.1), the eigen- function, ϕnm( ¯x), and the corresponding eigenvaluesλnm are ϕnm( ¯x) = 2 sin \u0012nπx1 D \u0013 sin \u0012mπx2 D \u0013 , λnm = 2 π2 D2 \u0010 n2 + m2\u0011 . (D.2) In order to simplify the notation, we adopt the map- ping k = h(n,m), which leads to the more compact form ¯ut( ¯x,t) = ∞X k=1 zk(t)ϕk( ¯x). (D.3) Substituting expression (D.3) in (C.1) results in ˙zk(t) = −chyλkzk(t) + 1 βDz [ϕk( ¯x1 s ),...,ϕ k( ¯xms s )]Qs(t) + 1 βDz [ϕk( ¯x1 c ),...,ϕ k( ¯xmc c )]Qc(t), zk(0) = ⟨¯ut( ¯x,0),ϕk( ¯x)⟩, ∀ k ∈[1,∞). (D.4) Systems (C.1) and (D.3)–(D.4) are equivalent when k → ∞, but the significant di fference is that system (D.4) is an ODE that can be easily implemented numer- ically with k finite. In our numerical simulations, we were limited to 160 eigenmodes, which was more than enough according to convergence analyses. These con- vergence analyses are standard and were omitted from the manuscript. Appendix E. Output Feedback Tracking Control Design The control design will be performed under the fol- lowing assumptions for system (3)–(4): Assumption 1. The diffusion system (3) fulfils \f\f\f \f\f\f∇2ut(x,t) \f\f\f \f\f\fH0(V) ≤Lu, (E.1) with known constant Lu ≥0. Assumption 2. The fixed, not controlled flux input, Qs(t), in system (3) fulfils \f\f\f \f\f\f ˙Qs(t) \f\f\f \f\f\f ≤LQ, (E.2) with known constant LQ ≥0. Assumption 3. The reference to be followed, r(t), is de- signed to fulfil ||˙r(t)||≤L˙r, ||¨r(t)||≤L¨r, (E.3) with known constants L˙r ≥0, L¨r ≥0. 16Assumption 4. All the parameters of the system(3)–(4) are uncertain and only nominal values are known (e.g., a nominal value, f 0, is known for the parameter f ). Remark 1. Assumption 1 is feasible due to energy con- servation on the realistic system (3). Furthermore, as- sumptions 2-4 are easily met in control applications. The first step on the design, will be to obtain the error dynamics of (7) as ˙yei = f ta ˙τ0Vi Z Vi ut(x,t) dV −1 ta (eyei +ri −1) −˙ri, for i ∈[1,mc]. Using the 3D di ffusion equation (3) and the divergence theorem, the error dynamics becomes ˙yei = chy f ta ˙τ0Vi Z Vi ∇2u(x,t) dV + f ta ˙τ0βVi Z Vi [Bs(x)Qs(t) + Bc(x)Qc(t)] dV −1 ta (eyei +ri −1) −˙ri = chy f ta ˙τ0Vi Z Vi ∇2u(x,t) dV + f ta ˙τ0βVi msX j=1 Z Vi δ(x −xj s)Qsj (t)dV + f ta ˙τ0βVi mcX j=1 Z Vi δ(x −xj c)Qcj (t)dV −1 ta (eyei +ri −1) −˙ri, for i ∈[1,mc]. The error dynamics can be represented in matrix form as follows ˙ye = Ψ(t) + BsQs(t) + BcQc(t) −Φ(t) −˙r(t), (E.4) where Bs = [bs i j] ∈ℜmc×ms , Bc = [bc i j] ∈ℜmc×mc , Ψ(t) ∈ ℜmc and Φ(t) ∈ℜmc are defined as bs i j =  f ta ˙τ0βVi if xj s ∈Vi 0 if xj s < Vi , i ∈[1,mc] j ∈[1,ms] , bc i j =  f ta ˙τ0βVi if xj c ∈Vi 0 if xj c < Vi , i ∈[1,mc] j ∈[1,mc] , Ψ(t) =  chy f ta ˙τ0V1 R V1 ∇2u(x,t) dV ... chy f ta ˙τ0Vmc R Vmc ∇2u(x,t) dV  , Φ(t) =  1 ta (eye1 +r1 −1) ... 1 ta (eyemc +rmc −1)  , (E.5) where the definition of Delta’s distribution has been used. The matrices Bc, Ψ(t) and Φ(t) are assumed to fulfil Bc = ΓB0, \f\f\f \f\f\f ˙Ψ(t) \f\f\f \f\f\f ≤L1, \f\f\f \f\f\f ˙Φ(t) \f\f\f \f\f\f ≤L2, (E.6) where B0 ∈ ℜmc×mc is a known regular matrix (con- sequently, Bc is assumed to be regular matrix as well), Γ ∈ℜmc×mc is an uncertain matrix with positive diago- nal entries, and L1 ≥0, L2 ≥0 are known constants. Remark 2. The assumption over the term Φ(t) in (E.6) requires Assumption 3 to be fulfilled and the bounded- ness of the error vector derivative, ˙ye, as ||˙ye(t)||≤Lye , Lye > 0. Therefore, only local results on system (E.4) are considered in this paper. Furthermore, the condition over the term Ψ(t) requires further analysis, which will be performed in the next Lemma. Lemma 1. The term Ψ(t) in system (E.4),(E.5) fulfils the condition (E.6) if Assumption 1 is fulfilled. Proof. Calculating the norm of the term Ψ(t) defined in (E.5) results in ||Ψ(t)||= chy f ta ˙τ0 vt mcX i=1 1 V2 i \"Z Vi ∇2u(x,t) dV #2 ≤chy f ta ˙τ0 vt mcX i=1 1 V2 i Z Vi \u0002∇2u(x,t)\u00032 dV. Taking the time derivative of the last expression reads 17as \f\f\f \f\f\f ˙Ψ(t) \f\f\f \f\f\f ≤chy f ta ˙τ0 vt mcX i=1 1 V2 i Z Vi \u0002∇2ut(x,t)\u00032 dV ≤chy f ta ˙τ0 vt mcX i=1 1 V2 i \f\f\f \f\f\f∇2ut(x,t) \f\f\f \f\f\fH0(V) which is bounded as in (E.6) if the assumption (E.1) is fulfilled. ■ The closed-loop system of (E.4) with control (8) reads as ˙ye = Γ \u0010 −K1 ⌈ye⌋ 1 1−l + xI \u0011 , ˙xI = −K2 ⌈ye⌋ 1+l 1−l + ˙∆(t), (E.7) where xI = ν+ ∆(t), ∆(t) = Γ−1Ψ(t) + Γ−1BsQs(t) −Γ−1Φ(t) + \u0010 I −Γ−1\u0011 ˙r(t), ˙∆(t) = Γ−1 ˙Ψ(t) + Γ−1Bs ˙Qs(t) −Γ−1 ˙Φ(t) + \u0010 I −Γ−1\u0011 ¨r(t). (E.8) The system of equations (E.7)–(E.8) has a discontinu- ous right-hand side when l = −1 due to the definition of function ⌈·⌋γ in Appendix A. In this special case, the solutions are understood in the sense of Filippov [51]. The term ∆(t) is assumed to fulfil \f\f\f \f\f\f˙∆(t) \f\f\f \f\f\f ≤Ls, (E.9) with a priori known constant Ls ≥0. This is always the case due to Assumptions 1–3 and (E.6). The tracking result for the output (4)–(6) is then in force. Theorem 1. Let system (E.4) assumed to fulfil (E.3), (E.6), and (E.9), be driven by the control (8) with K1 > 0, K 2 > 0. Then, the origin of the error closed-loop system (E.7)–(E.8), is locally: 1. Finite-time stable for any Ls ≥0, if l = −1. 2. Finite-time stable for Ls = 0, if l = (−1,0). 3. Exponentially stable for Ls = 0, if l = 0. 4. Exponentially ISS w.r.t. ∆(t) for L s > 0, if l = (−1,0]. Proof. Following [43, 44], the trajectories ( ye,xI) of system (E.7)–(E.8) are ensured to reach the origin if K1 is a matrix with positive diagonal elements and K2 is a positive quasi-definite matrix. ■ Remark 3. As a consequence of the stability of the closed-loop system trajectories, ( ye,xI), and due to the definition of the perturbation term ∆(t) in (E.8), the in- tegral term, ν, of the control (8) is able to provide an estimate of such term, i.e., ν(t) →−∆(t) as t →∞. Appendix E.1. Energy demand and production con- straints For the case where additional number of flux restric- tions to the fluid injection of the controlled injection points are considered, the vector of controlled injection points of system (E.4) is defined as follows ˙ye = Ψ(t) + BsQs(t) + ¯Bc ¯Qc(t) −Φ(t) −˙r(t), (E.10) where ¯Qc(t) ∈ℜmc+mr , ¯Qc(t) = [ ¯Qc1 (t),..., ¯Qcmc+mr (t)]T are the new controlled fluxes and ¯Bc = [¯bc i j] ∈ ℜmc×(mc+mr) is the new input matrix defined as ¯bc i j =  f ta ˙τ0βVi if xj c ∈Vi 0 if xj c < Vi , i ∈[1,mc] j ∈[1,mc + mr] , (E.11) where xj c, j ∈[1,mc + mr], are the injection points over the total region V. If we replace (10) in (E.10), the link between the new input matrix, ¯Bc, and the original input matrix, Bc, defined in (E.5) is stated as ¯BcW = Bc. 18",
      "references": [
        "HiQuake: The Human-Induced Earthquake Database",
        "Myths and facts on wastewater injection, hydraulic fracturing, enhanced oil recovery, and induced seismicity",
        "Current challenges in monitoring, discrimination, and management of induced seismicity related to underground industrial activities: A european perspective",
        "G´eothermie : ”Dans le Bas-Rhin, tous les projets sont `a l’arrˆet” annonce la pr´ef`ete",
        "En Alsace, les projets de g ´eothermie profonde `a l’arrˆet",
        "Findings of Pohang earthquake causes halt energy project on Ulleung Island",
        "South Korea accepts geothermal plant probably caused destructive quake",
        "Earthquakes Induced by the Stimulation of an Enhanced Geothermal System below Basel (Switzerland)",
        "Quake Threat Leads Swiss to Close Geothermal Project",
        "The Mechanics of Earthquakes and Faulting",
        "The physics of earthquakes",
        "Potentially induced earthquakes in Oklahoma, USA: Links be- tween wastewater injection and the 2011 Mw 5.7 earthquake se- quence",
        "Green, yellow, red, or out of the blue? an assessment of tra ffic light schemes to mitigate the im- pact of hydraulic fracturing-induced seismicity",
        "First field application of cyclic soft stimulation at the Pohang Enhanced Geothermal System site in Korea",
        "Fracture caging to limit induced seismicity",
        "How to Reduce Fluid-Injection-Induced Seis- micity",
        "Absorbent porous pa- per reveals how earthquakes could be mitigated",
        "Tra ffic Light Systems: To What Extent Can Induced Seismicity Be Controlled?",
        "Modelling of fluid pressure migration in a pressure sensitive fault zone subject to cyclic injection and im- plications for injection-induced seismicity",
        "Controlling anthropogenic and natural seismicity: Insights from active stabilization of the spring-slider model",
        "Preventing instabilities and in- ducing controlled, slow-slip in frictionally unstable systems",
        "Earthquake Control: An Emerging Application for Robust Con- trol. Theory and Experimental Tests",
        "Robust Boundary Tracking Control of Wave PDE: Insight on Forc- 13ing Slow-Aseismic Response",
        "Passivity- based control of underactuated mechanical systems with Coulomb friction: Application to earthquake prevention",
        "Advances in Sliding Mode Control of Earthquakes via Boundary Tracking of Wave and Heat PDEs",
        "Controllability and observability in two-phase porous media flow",
        "Controllability, observability and identifi- ability in single-phase porous media flow",
        "Parameter identification in large-scale models for oil and gas production",
        "Predictive pressure control in deep geothermal systems",
        "General theory of three-dimensional consolidation",
        "Drained, undrained, consolidating and dynamic behaviour assumptions in soils",
        "Injection-induced seismicity: Poroelastic and earthquake nucleation effects",
        "A constitutive law for rate of earthquake pro- duction and its application to earthquake clustering",
        "Theoretical Soil Mechanics",
        "Probability of induc- ing given-magnitude earthquakes by perturbing finite volumes of rocks",
        "Characterisa- tion of the basel 1 enhanced geothermal system",
        "Induced and triggered seismicity by immediate stress transfer and delayed fluid migration in a fractured geother- mal reservoir at pohang, south korea",
        "The engineering of safe hydraulic stimulations for EGS development in hot crystalline rock masses",
        "The influence of pumping parame- ters in fluid-driven fractures in weak porous formations",
        "The 2017 Mw 5.5 Pohang Earthquake, South Korea, and Poroelastic Stress Changes Associated With Fluid Injection",
        "Mimo super-twisting con- troller: A new design",
        "MIMO Super-Twisting Controller using a passivity-based design",
        "A 3(2) pair of Runge - Kutta formulas",
        "An in-depth seismological analy- sis revealing a causal link between the 2017 mw 5.5 pohang earthquake and egs project",
        "Poroelastic stress relaxation, slip stress transfer and friction weakening controlled post-injection seismicity at the Basel Enhanced Geothermal System",
        "Semigroups of Linear Operators and Applications to Partial Differential Equations",
        "On the ISS properties of a class of parabolic DPS’ with discontinuous control using sampled-in-space sens- ing and actuation",
        "An integrated framework for surface deformation modelling and induced seis- micity forecasting due to reservoir operations",
        "Di fferential Equations with Discontinuos Right- hand Sides",
        "Input-to-state stability of infinite-dimensional control systems"
      ],
      "meta_data": {
        "arxiv_id": "2310.02700v3",
        "doi": "10.1016/j.gete.2024.100570",
        "authors": [
          "Diego Gutierrez-Oribio",
          "Ioannis Stefanou"
        ],
        "published_date": "2023-10-04T10:13:44Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Addresses the problem of mitigating fluid-injection–induced seismicity in underground reservoirs (geothermal, CCS, H2 storage) while maintaining required fluid circulation/energy production. Proposes a control-theoretic framework that (i) models pressure perturbations via a simplified 3D diffusion PDE with point-source wells and (ii) regulates the induced seismicity rate (SR) by forcing SR in multiple reservoir subregions to track prescribed references (e.g., keep SR≈natural level in a large region while allowing controlled microseismicity near wells). Provides a robust output-feedback tracking controller with guarantees (finite-time or exponential convergence depending on design) under parametric uncertainty and unmodeled dynamics, and extends it to enforce linear production/demand constraints on well fluxes. Demonstrates via simulations that the controller suppresses widespread pressure buildup and drastically reduces SR amplification compared with uncontrolled injection, including in heterogeneous reservoirs and under intermittent demand.",
        "methodology": "Physical modeling: (1) pressure change u(x,t) governed by diffusion equation u_t = c_hy ∇^2 u + (1/β)(B_s(x)Q_s(t)+B_c(x)Q_c(t)) with drained boundary conditions u=0 on ∂V; wells modeled as Dirac delta point sources. (2) Region-wise seismicity-rate dynamics based on Dieterich/Segall–Lu form: \u0002R = (R/t_a)(\u0002τ/\u0002τ_0 − R), with \u0002τ = \u0002τ_0 + f \u0002u (average pressure-rate contribution); uses change of variables R_i = exp(h_i) to obtain ODEs for h_i driven by regional averages of u_t.\nControl design: robust MIMO tracking for output y=[h_i] using a super-twisting–type integral sliding-mode controller (parameter l∈[−1,0] tunes discontinuity/continuity): Q_c = B_0^{-1}(−K_1⟦y_e⟧^{1/(1−l)} + ν + \u0002r), \u0002ν = −K_2⟦y_e⟧^{(1+l)/(1−l)}, with y_e=y−r and nominal input matrix B_0 (true B_c = ΓB_0 with unknown Γ having positive diagonal). Proves local finite-time tracking for l∈[−1,0) (with bounded perturbation derivatives; l=−1 handles bounded disturbances), and exponential tracking for l=0.\nProduction constraints: enforces linear demand W \u0005eQ_c = D(t) by decomposing the control into a particular solution satisfying demand plus a null-space component for SR tracking: \u0005eQ_c = \u0005eW Q_c + W^T(WW^T)^{-1}D(t). Numerical implementation: depth-averaging to a 2D diffusion PDE; spectral (eigenfunction) spatial discretization and RK23 time integration.",
        "experimental_setup": "Validation is simulation-based (no real-field dataset). Reservoir geometry: ~5 km × 5 km horizontal extent, ~0.1 km thickness at ~4 km depth; drained boundary u=0 on edges. Baseline fixed well injection Q_s1=32 m^3/hr. Parameters (representative of field values): hydraulic diffusivity c_hy≈3.6×10^{-4} km^2/hr; compressibility β≈1.2×10^{-4} 1/MPa; friction coefficient f=0.5; background stressing rate \u0002τ_0=10^{-6} MPa/hr; characteristic time t_a≈5×10^5 hr (as listed).\nOutputs: SR computed over two regions V1 (large outer region) and V2 (near-well region); references chosen to achieve R1→1 and R2→5 (i.e., r1=0, r2→ln 5).\nControllers: nominal B_0 built with parameters set 10% higher than true values to test robustness; gains K1,K2 selected empirically; l varied (e.g., −0.6 vs 0) to compare chattering vs smoothness.\nScenarios/benchmarks: (1) SR tracking without demand using two controlled wells; (2) SR tracking with constant demand enforcing re-injection balance D(t)=−Q_s1 with three controlled wells; (3) SR tracking with intermittent demand switching between −Q_s1 and 0; (4) robustness to strong spatial heterogeneity in c_hy(x) and β(x) varying over ~3 orders of magnitude. Metrics/validation: time-to-track SR references, tracking error norms, control signal smoothness/chattering, and qualitative pressure-field evolution compared to uncontrolled injection (which yields SR amplification ~O(10^3–10^4) and slow (~years) pressure stabilization).",
        "limitations": "Modeling simplifications: uses a diffusion-only pressure model assuming slow injections and negligible volumetric strain rate; omits full Biot poroelastic coupling, poroelastodynamics/inertia, explicit fracture/fault hydraulics, and nonlinear/pressure-dependent permeability. Assumes drained boundary conditions and (mostly) constant parameters; heterogeneity tested only in c_hy and β. Wells treated as ideal point sources (Dirac deltas).\nSeismicity proxy: control objective is SR tracking (region-averaged), not direct control of earthquake magnitude or maximum expected magnitude; SR model relies on linear relationship between Coulomb stressing rate and average pore-pressure rate, and assumes averaging volumes where stress changes can be treated as uniform—may be violated in real reservoirs.\nControl assumptions/practicality: theoretical results are local (bounded \u0002y_e required) and require bounds on disturbance derivatives; needs reliable real-time measurement/estimation of SR in each region and correct region definitions. Discontinuous (sliding-mode) option can induce chattering/high-frequency oscillations in pump commands; continuous option trades precision for smoothness. Only linear demand constraints are considered; actuator saturation, nonlinear operational constraints, and measurement noise are not fully treated.\nValidation: results are purely numerical on a simplified geometry; no laboratory/field-scale experiments, no comparison against industry traffic-light or other mitigation schemes under identical conditions.",
        "future_research_directions": "Risk metrics beyond SR: integrate magnitude forecasting (e.g., Gutenberg–Richter/modified Richter distributions) and maximum-magnitude constraints, potentially coupling SR control with probabilistic hazard objectives and region-size selection based on magnitude statistics.\nRicher physics: extend from diffusion to coupled poroelastic/poroelastodynamic models (heat/wave PDEs), pressure-dependent permeability, multiphase flow, thermal stresses, and explicit fault/fracture network dynamics.\nSpatial resolution: move from region-wise averaging to point-wise or spatially distributed SR/stress outputs; study controllability/observability and online parameter/state estimation to support real-time implementation.\nConstraint handling: incorporate actuator limits, rate constraints, and general nonlinear equality/inequality production constraints; develop anti-windup and robust constraint-aware controllers.\nMultiple-fault and multi-timescale control: design strategies for reservoirs with many interacting faults, faster transients under intermittent injections, and slip-stress transfer effects.\nRobustness to sensing/operational uncertainties: explicitly include measurement noise, delayed/irregular seismic catalogs, and model mismatch; explore sampling-in-space actuation/sensing designs.\nExperimental validation: laboratory tests with intermittent injections and multi-well regulation, followed by staged field pilots to assess repeatability, safety, and practical deployment of real-time regulators.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Understanding the Effects of Iterative Prompting on Truthfulness",
      "full_text": "Elastic Analysis of Augmented Curves and Constrained Surfaces Esfandiar Nava-Yazdani[0000−0003−4895−739X] Zuse Institute Berlin, Berlin, Germany navayazdani@zib.de https://www.zib.de/members/navayazdani Abstract. The square root velocity transformation is crucial for efficiently em- ploying the elastic approach in functional and shape data analysis of curves. We study fundamental geometric properties of curves under this transformation. Moreover, utilizing natural geometric constructions, we employ the approach for intrinsic comparison within several classes of surfaces and augmented curves, which arise in the real world applications such as tubes, ruled surfaces spherical strips, protein molecules and hurricane tracks. Keywords: Elastic shape analysis · Tube · Manifold-valued · Ruled surface · Hurricane track. 1 Introduction Metric comparison of curves is a core task in a wide range of application areas such as morphology, image and shape analysis, computer vision, action recognition and signal processing. Thereby, a Riemannian structure is highly desirable, since it naturally provides powerful tools, beneficial for such applications. In the recent years, the use of Riemannian metrics for the study of sequential data, such as shapes of curves, trajectories given as longitudinal data or time series, has rapidly grown. In elastic analysis of curves, one considers deformations caused from both bending and stretching. A Riemannian metric, which quantifies the amount of those deformations is called elastic (cf. [18,19]). Therein, in contrast to landmark-based approaches (cf. [12,20,22]), one considers whole continuous curves instead of finite num- ber of curve-points. Consequently, the underlying spaces are infinite dimensional and computational cost becomes a significant issue. The square root velocity (SRV) frame- work provides a convenient and numerically efficient approach for analysing curves via elastic metrics and has been widely used in the recent years (cf. [14,11,4,3] and the comprehensive work [24]). In many applications the curves are naturally manifold-valued. For instance, Lie groups such as the Euclidean motion group, or more generally, symmetric spaces includ- ing the Grassmannian and the Hadamard-Cartan manifold of positive definite matrices are widely used in modelling of real world applications. Extensions of SRV framework from euclidean to general manifold-valued data can be found in [13,27,25,9,26]. arXiv:2402.04944v3  [math.DG]  28 Mar 20242 E. Nava-Yazdani Our contributions are the following. We expose for plane curves the behaviour of speed and curvature under the SRV transformation and geometric invariants. More- over, we apply the elastic approach to augmented curves, determining certain classes of surfaces, tubes, ruled surfaces and spherical strips, as well as hurricane tracks consid- ered with their intensities. We recall that with distance and geodesic at hand, signifi- cant ingredients of statistical analysis such as mean and principal geodesic components as well as approximation and modelling concepts such as splines can be computed. This paper is organized as follows. Section 2, presents the Riemannian setting and notations. Section 3 is devoted to applications. Therein, we consider time series, for which in addition to spatial data, auxiliary information give rise to augmented curves and some classes of surfaces generated by them. Thereby, we apply the elastic approach to both euclidean and spherical trajectories. Future prospects and concluding remarks are presented in 4. For the convenience of those readers primary interested in the applications, we mention that, advanced parts and details from differential geometry, presented in 2, can be skipped. Thereby, the essential point is the use of a framework (SRV) for computation of shortest paths on the spaces of curves and their shapes. 2 Riemannian Framework 2.1 Preliminaries For the background material on Riemannian geometry, we refer to [8] and [10]. Let (M, g) be a finite dimensional Riemannian manifold and M the Fr´ echet manifold of smooth immersed curves from D in M, where D denotes either the unit circle S1 or the unit interval I := [0, 1] for closed or open curves respectively. Moreover, we denote the group of orientation preserving diffeomorphisms on D by Diff +. The following reparametrization invariance is crucial for a Riemannian metric G on M: Gc◦φ(h ◦ φ, k◦ φ) = Gc(h, k), for any c ∈ M, h, k∈ TcM and φ ∈ Diff +. The above equivariance ensures that the induced distance function satisfies the following, which is often desirable in applica- tions: d(c0 ◦ φ, c1 ◦ φ) = d(c0, c1), for any two curves c0 and c1 in M. Similarly, denoting the isometry group of M by Isom(M) and the tangent map of F ∈ Isom(M) by T F, the invariance GF◦c(T F◦ h, TF◦ k) = Gc(h, k), ensures that d(F ◦ c0, F◦ c1) = d(c0, c1). With the above invariances, we can divide out the spaces Isom(M) and Diff +, and consider the natural induced distance dS on the quotient space S = M/(Diff + × Isom(M))Elastic Analysis of Augmented Curves and Constrained Surfaces 3 given by dS([c0], [c1]) = inf {d(c0, f◦ c1 ◦ φ) : φ ∈ Diff +, f∈ Isom(M)} = inf {d(f ◦ c0 ◦ φ, c1) : φ ∈ Diff +, f∈ Isom(M)}. In the context of shape analysis of curves, M and S are called the pre-shape and shape space, respectively. Note that the order of quotient operations does not matter, since the left action of Isom(M) and the right action of Diff + commute. M/Diff + is the space of unparametrized curves and its inherited distance reads inf {d(c0, c1 ◦ φ) : φ ∈ Diff +}. We remark that particular essential challenges are due to the fact that some basic concepts and results from finite dimensional differential geometry such as Hopf-Rinow theorem, do not carry over to the infinite dimensional case. Now, let ∇ be the Levi- Civita connection of M and denote the arc length parameter, speed and unit tangent of c by θ, ω and T respectively. Thus, we have ω = |˙c|, dθ = ωdt and T = ˙c ω , where dot stands for derivation with respect to the parameter t. Due to a remarkable result in [16] the geodesic distance induced by the simplest natural choice, the L2-metric GL2 c (h, k) = Z D gc(h, k) dθ, always vanishes. Consequently, some stronger Sobolev metrics have been considered in several works including [17,7,5]. They are given by Gc(h, k) = nX i=0 Z D aigc(∇i T h, ∇i T k) dθ, with a1 non-vanishing and all ai non-negative, distinguish the curves. We consider first order metrics with constant coefficients. We remark that the coefficients ai can be chosen such that the metric is scale invariant, which is a desired property for some applications in shape analysis. A family of certain weighted Sobolev-type metrics, the so-called elastic metrics, based on a decomposition of derivatives of the vector fields into normal and tangent components, has been introduced in [18,19]: Ga,b c (h, k) = Z D agc((∇T h)⊤, (∇T k)⊤) + bgc((∇T h)⊥, (∇T k)⊥) dθ, with 4b ≥ a >0. In this work, we use the square root velocity (SRV) framework, which allows for a convenient and computationally efficient elastic approach. The main tool in this framework is the square root velocity transformation, which for euclidean M reads q : c 7→ ˙cp |˙c| .4 E. Nava-Yazdani It isometrically maps curves modulo translations, with the metric G1,1/4 to M with the flat L2-metric given by G0(v, w) = Z D g(v(t), w(t))dt. This metric is frequently called (cf. [15,2,6]) flat, to emphasize its footpoint indepen- dence. Note that the elastic metric G1,1 corresponds to the first order Sobolev metric with a0 = 0 and a1 = 1. We remark, that for plane curves, the work [23] has extended the SRV transformation to general parameters a, b >0. For further reading on the SRV framework and applications in shape analysis, we refer to [14], [11] (numerical aspects), the survey [6] and particularly, the comprehensive work [24]. 2.2 Plane Curves A natural question that arises is, how essential geometric characteristics of a curve behave under the SRV transformation. In the following, we provide an answer for speed and curvature in the case of plane curves. Let M = R2, ˜c := q(c) and denote the curvature of c by κ. Note that ˜c does not need to be an immersion. Proposition 1. Denoting the speed of˜c by ˜ω, we have ˜ω = r ˙ω2 4ω + ω3κ2. (1) Moreover, ˜c is an immersion if and only ifκ and ˙ω have no common zeros. In this case, ˜κ˜ω = κω + ˙φ, (2) where ˜κ denotes the curvature of˜c and φ := arctan \u00122ω2κ ˙ω \u0013 . Proof. Let N denote the unit normal of c. With the shorthand notations α := √ω and β := α3κ, a straightforward application of the Frenet equations ˙T = ωκN and ˙N = −ωκT , yields ˙˜c = ˙αT + βN, ¨˜c = (¨α − β2 α )T + ( ˙β + ˙αβ α )N. Thus, we have ˜ω = p ˙α2 + β2, immediately implying (1). Obviously, zeros of ˜ω are common zeros of κ and ˙ω. Thus, ˜c is an immersion if and only if κ and ˙ω have no common zeros. In this case, ˜ κ and φ = arctan (β/ ˙α) = arctan \u0010 2ω2κ ˙ω \u0011 are well-defined and ˜κ˜ω3 = ˜ω2β/α + ˙α ˙β − ¨αβ, which immediately implies the curvature formula (2).Elastic Analysis of Augmented Curves and Constrained Surfaces 5 Next, we apply the proposition to study some geometric quantities, which are invariant under the SRV transformation. For closed curves, integrating the curvature formula above over D = S1 (note that in this case, ˜ω >0 almost everywhere), we see that the SRV transformation preserves the total curvature and particularly the turning number. Moreover, κω is preserved if and only if κ = a d dt \u00001 ω \u0001 with a constant a. Clearly, with κ and ω at hand, utilizing Frenet equations, we can compute c up to rigid motions. The following explicit solution is an immediate application of the above proposition. In light of the above proposition, immersed curves, which are mapped to straight lines, can easily be determined as follows. Example 1. Let a, b, Abe constants withab, A >0, ω(t) = A/ sin2(at+b) and κ = a/ω. A straightforward computation, utilizing the curvature formula (2), implies ˜κ = 0. 2.3 Curves in Homogeneous Spaces For the background material on Lie groups and homogeneous spaces, we refer to [10]. The works [13,27] provide extensions of the SRV framework for euclidean curves to the case of general manifolds. The former has high computational cost, while the latter, transported SRV, depends on a reference point and also suffers from distortion or bias caused by holonomy effects. We use the natural extension to homogeneous spaces exposed in [26,9]. For reader’s convenience, we sketch the core ingredients of the approach and refer to the mentioned works for details and some applications. Let M be a homogeneous space, i.e., M = H/K, where K is a closed Lie subgroup of a Lie Group H. Let ∥·∥ denote the induced norm by a left invariant metric on H, L the tangent map of the left translation, and Imm(D, H) the space of immersed curves from D to H. The SRV transformation is given by Q(α) = (α(0), q(α)), where q(α) = Lα−1 ˙αp ∥ ˙α∥ Here, α−1(t) denotes the inverse element of α(t) in H and H the Lie algebra of H. The map Q is a bijection from Imm(D, H) onto H × L2(D, H). Now, M can be equipped with the Riemannian metric given by the pullback of the product metric of H × L2(D, H) using the map Q and horizontal lifting. Let c1 and c2 be immersed curves in M with horizontal lifts α1 and α2 respectively. The induced distance on M reads d(c1, c2) = inf \u001aq d2 H(α1(0), α2(0)x) + ∥q(α1) − Adx−1 (q(α2)∥2 L2 : x ∈ K \u001b . 3 Applications Frequently, besides spatiotemporal data, represented by a curve γ in a manifold M, there are additional or auxiliary information associated with the curve, thus with the same time-correspondence. These can jointly with γ be comprised and represented as a6 E. Nava-Yazdani so-called augmented curve ˜γ in a higher dimensional manifold ˜M. In some applications, the curve ˜γ uniquely determines a submanifold N of M via a natural construction. An important example is provided, when ˜M is a submanifold of the tangent bundle of M, where the auxiliary information is represented as a vector field along γ and the con- struction is given by the Riemannian exponential map. Significant special cases occur, when M is R3 or the unit two-sphere S2 and N a surface. In the next two subsections, we consider certain classes of surfaces in R3, which often arise in applications and are determined by augmented curves in R4. In the last two subsections, we consider certain spherical regions as well as hurricane tracks together with their intensities. In both cases, we utilize the Riemannian distance from subsection 2.3 to S2 × R, which is a homogeneous space (recall that S2 can be identified with SO(3)/SO(2)). For our example applications, we present geodesic paths representing deformations, minimizing the elastic energy within the SRV framework. We remark, that in a Rie- mannian setting, distance and geodesics are essential Building blocks for many major issues in the morphology and shape analysis, such as computation of mean and test statistics as well as principal component or geodesic analysis. Moreover, besides sta- tistical analysis, also some methods for clustering and classification use Riemannian metrics and geodesics. For the code implementing our approach, which particularly includes Riemannian optimization for the computation of geodesic paths, we utilized our publicly available python package https://github.com/morphomatics, introduced in [1]. 3.1 Tubes A tube or canal surface c is a one-parameter family of circles, whose centers constitute a regular curve γ such that the circles are perpendicular to γ. More precisely, denoting the radii of the circles by r, c(s, .) = γ + r(N cos s + B sin s), 0 ≤ s ≤ 2π, where N and B are the normal and binormal of the curve γ = γ(t), t∈ D, resp. Due to the unique correspondence of c to (γ, r), comparison of tubes reduces to comparison of curves in R4. Figure 1 shows some examples of shortest paths of tubes. Real world applications include a variety of fields such as examination of vein, pipes, capsules and plant roots. Clearly, tubes include surfaces of revolution. 3.2 Ruled Surfaces A ruled surface is formed by moving a straight line segment (possibly with varying length) along a base curve. More precisely, let γ be a curve in R3 and v a unit vector field along γ. Then c(s, .) = γ + sv, s∈ I, parametrizes a ruled surface generated by ( γ, v). Figure 2 depicts an example, where each surface consists of straight line segments connecting the blue (for better visibility) curves γ and γ + v. The class of ruled surfaces includes many prominent surfacesElastic Analysis of Augmented Curves and Constrained Surfaces 7 Fig. 1.Two shortest paths of tubes such as cone, cylinder, helicoid (a minimal surface) and M¨ obius strip. They arise in manufacturing (construction by bending a flat sheet), cartography, architecture and biochemistry (secondary and tertiary structure of protein molecules). Fig. 2.Shortest path of ruled surfaces 3.3 Spherical Strips Let exp denote the exponential map of the unit two-sphere S2. We recall that for any non-zero tangent vector to S2 at a point x: expx(v) = cos(|v|)x + sin(|v|) v |v|8 E. Nava-Yazdani and expx(0) = x. Now, let γ be a curve in S2 with binormal B (cross product of γ and its unit tangent), and r a scalar function along γ. Then, the map c given by c(s, .) := expγ s(rB), s∈ I, parametrizes a spherical strip with bandwidth r. Figure 3 depicts an example of the shortest path between two spherical curves comprised with their bandwidth functions visualised as strips. Fig. 3.Shortest path of spherical strips 3.4 Hurricane Tracks Hurricanes belong to the most extreme natural phenomena and can cause major im- pacts regarding environment, economy, etc. Intensity of a hurricane is determined by the maximum sustained wind (maxwind), monotonically classifying the storms into categories (due to Saffir–Simpson wind scale; for instance, maxwind ≥ 137 knots cor- responds to category 5). Due to their major impacts on economy, human life and envi- ronment, as well as extreme variability and complexity, hurricanes have been studies in a large number of works. For our example, we used the HURDAT 2 database provided by the U.S. National Oceanic and Atmospheric Administration publicly available on https://www.nhc.noaa.gov/data/, supplying latitude, longitude, and maxwind on a 6 hours base of Atlantic hurricanes. Fig. 4.2010 Atlantic hurricane tracks (left) and the shortest path between two of them (right) with color-coded maximum sustained wind (in knots)Elastic Analysis of Augmented Curves and Constrained Surfaces 9 We represent the tracks as discrete trajectories in S2. For further details and com- parison with other approaches, we refer to [24,25] and the recent work [21]. The latter, also provides statistical analysis and a classification of hurricane tracks in terms of their intensities. Fig. 4 illustrates this data set with a visualization of the 2010 hurricane tracks and a shortest path, where the intensities, considered as auxiliary information, are color-marked. 4 Conclusion In this paper, we analysed the behaviour of speed and curvature under the square root velocity framework for elastic approach to plane curves. Moreover, we applied an extension of this framework to homogeneous Spaces, to metrically compare augmented curves and special surfaces, generated by those curves, using a natural construction via the Riemannian exponential map. Our approach, allows for computationally efficient determination of geodesic paths in the shape spaces of the respective classes of surfaces. Our example applications include tubes, ruled surfaces, spherical strips and hurricane tracks. Future work includes further real world applications, particularly concerning statistical analysis of longitudinal data such as comparison of group wise trends within a hierarchical model as well as classification and prediction. Acknowledgements This work was supported through the German Research Foun- dation (DFG) via individual funding (project ID 499571814). References 1. Ambellan, F., Hanik, M., von Tycowicz, C.: Morphomatics: Geometric morphomet- rics in non-Euclidean shape spaces (2021). https://doi.org/10.12752/8544, https:// morphomatics.github.io/ 2. Bauer, M., Bruveris, M., Marsland, S., Michor, P.: Constructing reparametrization in- variant metrics on spaces of plane curves. arXiv: Differential Geometry (2012), https: //arxiv.org/pdf/1207.5965.pdf 3. Bauer, M., Bruveris, M., Charon, N., Møller-Andersen, J.: A relaxed approach for curve matching with elastic metrics. ESAIM: Control, Optimisation and Calculus of Variations 25 (03 2018). https://doi.org/10.1051/cocv/2018053 4. Bauer, M., Bruveris, M., Harms, Philipp Michor, P.W.: Soliton solutions for the elastic metric on spaces of curves. Discrete & Continuous Dynamical Systems - A 38, 1161–1185 (2018). https://doi.org/10.3934/dcds.2018049 5. Bauer, M., Bruveris, M., Michor, P.W.: Overview of the geometries of shape spaces and diffeomorphism groups. Journal of Mathematical Imaging and Vision 50(1-2), 60–97 (2014) 6. Bauer, M., Charon, N., Klassen, E., Brigant, A.L.: Intrinsic riemannian metrics on spaces of curves: theory and computation. arXiv preprint (2020), https://arxiv.org/abs/ 2003.05590 7. Bauer, M., Harms, P., Michor, P.W., et al.: Sobolev metrics on the manifold of all rie- mannian metrics. Journal of Differential Geometry 94(2), 187–208 (2013)10 E. Nava-Yazdani 8. do Carmo, M.P.: Riemannian Geometry. Mathematics: Theory and Applications, Birkh¨ auser Boston, Cambridge, MA, USA, 2 edn. (1992) 9. Celledoni, E., Eidnes, S., Schmeding, A.: Shape analysis on homogeneous spaces: a gener- alised srvt framework. In: Computation and Combinatorics in Dynamics, Stochastics and Control: The Abel Symposium, Rosendal, Norway, August 2016. pp. 187–220. Springer (2018) 10. Gallot, S., Hullin, D., Lafontaine, J.: Riemannian Geometry. Universitext, Springer, Berlin, 3 edn. (2004) 11. Huang, W., Gallivan, K.A., Srivastava, A., Absil, P.A.: Riemannian optimization for registration of curves in elastic shape analysis. Journal of Mathematical Imaging and Vision 54(3), 320–343 (2016) 12. Kendall, D., Barden, D. Carne, T., Le, H.: Shape and Shape Theory. John Wiley & Sons (1999) 13. Le Brigant, A.: Computing distances and geodesics between manifold-valued curves in the srv framework. Journal of Geometric Mechanics 9(2) (2017) 14. Liu, W., Srivastava, A., Zhang, J.: Protein structure alignment using elastic shape anal- ysis. In: Proceedings of the First ACM International Conference on Bioinformatics and Computational Biology. pp. 62–70 (2010) 15. Michor, P., Mumford, D., Shah, J., Younes, L.: A metric on shape space with explicit geodesics. Atti Accad. Naz. Lincei Cl. Sci. Fis. Mat. Natur. Rend. Lincei (9) Mat. Appl. 19 (07 2007). https://doi.org/10.4171/RLM/506 16. Michor, P.W., Mumford, D.: Vanishing geodesic distance on spaces of submanifolds and diffeomorphisms. Documenta Mathematica 10, 217–245 (2005) 17. Michor, P.W., Mumford, D.: An overview of the riemannian metrics on spaces of curves using the hamiltonian approach. Applied and Computational Harmonic Analysis 23(1), 74–113 (2007) 18. Mio, W., Srivastava, A., Joshi, S.H.: On shape of plane elastic curves. International Journal of Computer Vision 73, 307–324 (2006) 19. Mio, W., Srivastava, A., Joshi, S.: On shape of plane elastic curves. International Journal of Computer Vision 73, 307–324 (07 2007). https://doi.org/10.1007/s11263-006-9968-0 20. Nava-XYazdani, E., Hege, H.C., Sullivan, T.J., von Tycowicz, C.: Geodesic analysis in kendall’s shape space with epidemiological applications. Journal of Mathematical Imaging and Vision pp. 1–11 (2020). https://doi.org/10.1007/s10851-020-00945-w 21. Nava-Yazdani, E., Ambellan, F., Hanik, M., von Tycowicz, C.: Sasaki metric for spline models of manifold-valued trajectories. Computer Aided Geometric Design 104, 102220 (2023). https://doi.org/10.1016/j.cagd.2023.102220 22. Nava-Yazdani, E., Hege, H.C., von Tycowicz, C.: A hierarchical geodesic model for longi- tudinal analysis on manif olds. Journal of Mathematical Imaging and Vision 64(4), 395 – 407 (2022). https://doi.org/10.1007/s10851-022-01079-x 23. Needham, T., Kurtek, S.: Simplifying transforms for general elastic metrics on the space of plane curves. SIAM Journal on Imaging Sciences 13(1), 445–473 (2020). https://doi.org/10.1137/19M1265132 24. Srivastava, A., Klassen, E.P.: Functional and shape data analysis, vol. 1. Springer (2016) 25. Su, Z., Klassen, E., Bauer, M.: The square root velocity framework for curves in a ho- mogeneous space. 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) pp. 680–689 (2017) 26. Su, Z., Klassen, E., Bauer, M.: Comparing curves in homogeneous spaces. Differential Geometry and its Applications 60, 9–32 (2018) 27. Zhang, Z., Su, J., Klassen, E., Le, H., Srivastava, A.: Rate-invariant analysis of covariance trajectories. Journal of Mathematical Imaging and Vision 60, 1306–1323 (2018)",
      "references": [
        "Morphomatics: Geometric morphomet- rics in non-Euclidean shape spaces",
        "Constructing reparametrization in- variant metrics on spaces of plane curves.",
        "A relaxed approach for curve matching with elastic metrics.",
        "Soliton solutions for the elastic metric on spaces of curves.",
        "Overview of the geometries of shape spaces and diffeomorphism groups.",
        "Intrinsic riemannian metrics on spaces of curves: theory and computation.",
        "Sobolev metrics on the manifold of all rie- mannian metrics.",
        "Riemannian Geometry.",
        "Shape analysis on homogeneous spaces: a gener- alised srvt framework.",
        "Riemannian optimization for registration of curves in elastic shape analysis.",
        "Shape and Shape Theory.",
        "Computing distances and geodesics between manifold-valued curves in the srv framework.",
        "Protein structure alignment using elastic shape anal- ysis.",
        "A metric on shape space with explicit geodesics.",
        "Vanishing geodesic distance on spaces of submanifolds and diffeomorphisms.",
        "An overview of the riemannian metrics on spaces of curves using the hamiltonian approach.",
        "On shape of plane elastic curves.",
        "Geodesic analysis in kendall’s shape space with epidemiological applications.",
        "Sasaki metric for spline models of manifold-valued trajectories.",
        "A hierarchical geodesic model for longi- tudinal analysis on manif olds.",
        "Simplifying transforms for general elastic metrics on the space of plane curves.",
        "Functional and shape data analysis, vol. 1.",
        "The square root velocity framework for curves in a ho- mogeneous space.",
        "Comparing curves in homogeneous spaces.",
        "Rate-invariant analysis of covariance trajectories."
      ],
      "meta_data": {
        "arxiv_id": "2402.04944v3",
        "authors": [
          "Esfandiar Nava-Yazdani"
        ],
        "published_date": "2024-02-07T15:25:20Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Studies geometric behavior of plane curves under the square root velocity (SRV) transform, deriving explicit formulas for transformed speed and curvature and identifying SRV invariants (e.g., total curvature/turning number for closed curves). Extends/apply SRV-based elastic shape analysis to intrinsic comparison of augmented curves that generate constrained surface classes (tubes/canal surfaces, ruled surfaces, spherical strips) and to manifold-valued trajectories such as hurricane tracks augmented with intensity, enabling computation of elastic distances and geodesic deformations in corresponding (pre-)shape spaces.",
        "methodology": "Riemannian elastic shape analysis of immersed curves with reparameterization and isometry invariance; uses elastic Sobolev-type metrics Ga,b and the SRV transform q(c)=ċ/\\sqrt{|ċ|} which is an isometry (mod translations) to a flat L2 space for specific parameters (notably G_{1,1/4}). For plane curves, applies Frenet–Serret relations to derive transformed speed and curvature formulas and characterize when q(c) is an immersion. For manifold-valued data, uses the generalized SRV transform on homogeneous spaces H/K via left translations and horizontal lifts; computes curve distances by aligning initial points and optimizing over the isotropy subgroup K, with L2 norm of transported SRV representations. Represents surfaces via augmented curves (e.g., (γ,r) in R^4 for tubes; (γ,v) with v unit field for ruled surfaces; (γ,r) on S^2 with binormal field for spherical strips using the Riemannian exponential map). Geodesics/distances computed numerically using Riemannian optimization implemented in the Morphomatics Python package.",
        "experimental_setup": "Demonstrations/qualitative experiments showing computed shortest (geodesic) paths between examples within each class: (i) tubes in R^3 represented by centerline γ and radius function r (curves in R^4); (ii) ruled surfaces in R^3 represented by base curve γ and unit direction field v; (iii) spherical strips on S^2 built from a spherical curve γ and bandwidth function r via exp_γ(s r B); (iv) Atlantic hurricane tracks from NOAA HURDAT2 (lat/long every 6 hours) mapped to discrete trajectories on S^2, augmented with maximum sustained wind (knots) as auxiliary scalar, analyzed in S^2×R as a homogeneous space. Validation is primarily visual/illustrative: plotting geodesic deformations (shortest paths) and color-coding intensities; no quantitative benchmark comparisons or statistical tests reported.",
        "limitations": "Mostly methodological/illustrative: lacks quantitative evaluation, ablations, or comparisons to alternative metrics/registrations; applications are shown on a small number of examples. SRV framework assumes immersed (sufficiently regular) curves; for plane curves, q(c) can fail to be an immersion when curvature and speed derivative share zeros, complicating curvature-based interpretation. Infinite-dimensional geometry issues (e.g., lack of Hopf–Rinow) persist; existence/uniqueness of geodesics may not be guaranteed globally. Homogeneous-space SRV requires choosing horizontal lifts and optimizing over K; results may depend on numerical optimization and discretization. Surface classes considered are restricted (tubes, ruled, spherical strips) and rely on specific generative parameterizations; may not cover general surfaces or handle noise/irregular sampling robustly. Augmented-curve modeling presumes synchronized auxiliary data and fixed correspondence in time (handled via reparameterization but still assumes meaningful alignment).",
        "future_research_directions": "Extend to broader real-world datasets and more complex constrained surfaces (beyond tubes/ruled/strips), including robustness to noise, missing data, and irregular sampling. Develop full statistical pipelines on the induced shape spaces: Fréchet means, hypothesis testing, principal geodesic analysis, and uncertainty quantification for augmented curves/surfaces. Integrate hierarchical/longitudinal models for group-wise trend comparison, as suggested by the author, and pursue classification/prediction tasks (e.g., hurricane track intensity-aware clustering/forecasting). Investigate computational improvements and theoretical guarantees for geodesic existence/uniqueness and optimization over Diff+ and K, including scalable discretizations. Explore alternative manifold settings and auxiliary fields (e.g., vector/tensor-valued annotations along trajectories), and study holonomy/bias effects relative to other manifold-SRV variants.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Self-Refine: Iterative Refinement with Self-Feedback",
      "full_text": "SELF -REFINE : Iterative Refinement with Self-Feedback Aman Madaan1, Niket Tandon2, Prakhar Gupta1, Skyler Hallinan3, Luyu Gao1, Sarah Wiegreffe2, Uri Alon1, Nouha Dziri2, Shrimai Prabhumoye4, Yiming Yang1, Shashank Gupta2, Bodhisattwa Prasad Majumder5, Katherine Hermann6, Sean Welleck2,3, Amir Yazdanbakhsh6, Peter Clark2 1Language Technologies Institute, Carnegie Mellon University 2Allen Institute for Artificial Intelligence 3University of Washington 4NVIDIA 5UC San Diego 6Google Research, Brain Team amadaan@cs.cmu.edu, nikett@allenai.org Abstract Like humans, large language models ( LLM s) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce SELF -REFINE , an approach for improving initial outputs from LLM s through iterative feedback and refinement. The main idea is to generate an initial output using an LLM ; then, the same LLM provides feedback for its output and uses it to refine itself, iteratively. SELF -REFINE does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner and the feedback provider. We evaluate SELF -REFINE across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art ( GPT-3.5 and GPT-4) LLM s. Across all evaluated tasks, outputs generated with SELF -REFINE are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ∼20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test-time using our simple, standalone approach.1. 1 Introduction Although large language models ( LLM s) can generate coherent outputs, they often fall short in addressing intricate requirements. This mostly includes tasks with multifaceted objectives, such as dialogue response generation, or tasks with hard-to-define goals, such as enhancing program readability. In these scenarios, modern LLM s may produce an intelligible initial output, yet may benefit from further iterative refinement—i.e., iteratively mapping a candidate output to an improved one—to ensure that the desired quality is achieved. Iterative refinement typically involves training a refinement model that relies on domain-specific data (e.g., Reid and Neubig (2022); Schick et al. (2022a); Welleck et al. (2022)). Other approaches that rely on external supervision or reward models require large training sets or expensive human annotations (Madaan et al., 2021; Ouyang et al., 2022), which may not always be feasible to obtain. These limitations underscore the need for an effective refinement approach that can be applied to various tasks without requiring extensive supervision. Iterative self -refinement is a fundamental characteristic of human problem-solving (Simon, 1962; Flower and Hayes, 1981; Amabile, 1983). Iterative self-refinement is a process that involves creating an initial draft and subsequently refining it based on self-provided feedback. For example, when 1Code and data at https://selfrefine.info/ Preprint. Under review. arXiv:2303.17651v2  [cs.CL]  25 May 2023Refine Feedback Use M to get feedback on its own output Input Use M to reﬁne its previous output, given its feedback Model M 1 2 0 Figure 1: Given an input ( 0⃝), SELF -REFINE starts by generating an output and passing it back to the same model M to get feedback ( 1⃝). The feedback is passed back to M, which refines the previously generated output ( 2⃝). Steps ( 1⃝) and ( 2⃝) iterate until a stopping condition is met. SELF -REFINE is instantiated with a language model such as GPT-3.5 and does not involve human assistance. drafting an email to request a document from a colleague, an individual may initially write a direct request such as “ Send me the data ASAP ”. Upon reflection, however, the writer recognizes the potential impoliteness of the phrasing and revises it to “Hi Ashley, could you please send me the data at your earliest convenience?\". When writing code, a programmer may implement an initial “quick and dirty” implementation, and then, upon reflection, refactor their code to a solution that is more efficient and readable. In this paper, we demonstrate that LLMs can provide iterative self-refinement without additional training, leading to higher-quality outputs on a wide range of tasks. We present SELF -REFINE : an iterative self-refinement algorithm that alternates between two gener- ative steps–FEEDBACK and REFINE . These steps work in tandem to generate high-quality outputs. Given an initial output generated by a model M, we pass it back to the same model M to get feedback. Then, the feedback is passed back to the same model to refine the previously-generated draft. This process is repeated either for a specified number of iterations or until M determines that no further refinement is necessary. We use few-shot prompting (Brown et al., 2020) to guideM to both generate feedback and incorporate the feedback into an improved draft. Figure 1 illustrates the high-level idea, that SELF -REFINE uses the same underlying language model to generate feedback and refine its outputs. We evaluate SELF -REFINE on 7 generation tasks that span diverse domains, including natural language and source-code generation. We show that SELF -REFINE outperforms direct generation from strong LLM s like GPT-3.5 (text-davinci-003 and gpt-3.5-turbo; OpenAI; Ouyang et al., 2022) and GPT-4 (OpenAI, 2023) by 5-40% absolute improvement. In code-generation tasks, SELF -REFINE improves the initial generation by up to absolute 13% when applied to strong code models such as Codex (code-davinci-002; Chen et al., 2021). We release all of our code, which is easily extensible to other LLMs. In essence, our results show that even when an LLM cannot generate an optimal output on its first try, the LLM can often provide useful feedback and improve its own output accordingly. In turn, SELF -REFINE provides an effective way to obtain better outputs from a single model without any additional training, via iterative (self-)feedback and refinement. 2 Iterative Refinement with S ELF -REFINE Given an input sequence, SELF -REFINE generates an initial output, provides feedback on the output, and refines the output according to the feedback. SELF -REFINE iterates between feedback and refinement until a desired condition is met. SELF -REFINE relies on a suitable language model and three prompts (for initial generation, feedback, and refinement), and does not require training. SELF -REFINE is shown in Figure 1 and Algorithm 1. Next, we describe SELF -REFINE in more detail. Initial generation Given an input x, prompt pgen, and model M, SELF -REFINE generates an initial output y0: y0 = M(pgen∥x) . (1) 2(a) Dialogue: x, yt User: I am interested in playing Table tennis. Response: I'm sure it's a great way to socialize, stay active (b) FEEDBACK fb Engaging: Provides no information about table tennis or how to play it. User understanding: Lacks understanding of user's needs and state of mind. (c) REFINE yt+1 Response (refined): That's great to hear (...) ! It's a fun sport requiring quick reflexes and good hand-eye coordination. Have you played before, or are you looking to learn? (d) Code optimization: x, yt Generate sum of 1, ..., N def sum(n): res = 0 for i in range(n+1): res += i return res (e) FEEDBACK fb This code is slow as it uses brute force. A better approach is to use the formula ... (n(n+1))/2. (f) REFINE yt+1 Code (refined) def sum_faster(n): return (n*(n+1))//2 Figure 2: Examples of SELF -REFINE : an initial output generated by the base LLM and then passed back to the same LLM to receive feedback to the same LLM to refine the output . The top row illustrates this for dialog generation where an initial dialogue response can be transformed into a more engaging one that also understands the user by applying feedback. The bottom row illustrates this for code optimization where the code is made more efficient by applying feedback. Algorithm 1 SELF -REFINE algorithm Require: input x, model M, prompts {pgen, pfb, prefine}, stop condition stop(·) 1: y0 = M(pgen∥x) ▷ Initial generation (Eqn. 1) 2: for iteration t ∈ 0, 1, . . .do 3: fbt = M(pfb∥x∥yt) ▷ Feedback (Eqn. 2) 4: if stop(fbt, t) then ▷ Stop condition 5: break 6: else 7: yt+1 = M(prefine∥x∥y0∥fb0∥...∥yt∥fbt) ▷ Refine (Eqn. 4) 8: end if 9: end for 10: return yt Figure 3: The S ELF -REFINE algorithm. See (§2) for a discussion of each component. For example, in Figure 2(d), the model generates functionally correct code for the given input. Here, pgen is a task-specific few-shot prompt (or instruction) for an initial generation, and ∥ denotes concatenation. The few-shot prompt contains input-output pairs ⟨x(k), y(k)⟩ for the task.2 FEEDBACK Next, SELF -REFINE uses the same model M to provide feedback fbt on its own output, given a task-specific prompt pfb for generating feedback: fbt = M(pfb∥x∥yt) . (2) Intuitively, the feedback may address multiple aspects of the output. For example, in code optimiza- tion, the feedback might address the efficiency, readability, and overall quality of the code. 2Few-shot prompting (also referred to as “in-context learning”) provides a model with a prompt consisting of k in-context examples of the target task, each in the form of input-output pairs ⟨xi, yi⟩ (Brown et al., 2020). 3Here, the prompt pfb provides examples of feedback in the form of input-output-feedback triples ⟨x(k), y(k), fb(k)⟩. We prompt the model to write feedback that is actionable and specific via fb(k). By ‘actionable’, we mean the feedback should contain a concrete action that would likely improve the output. By ‘specific’, we mean the feedback should identify concrete phrases in the output to change. For example, the feedback in Figure 2(e) is “This code is slow as it uses a for loop which is brute force. A better approach is to use the formula ... (n(n+1))/2 ”. This feedback is actionable, since it suggests the action ‘use the formula...’. The feedback is specific since it mentions the ‘for loop’. REFINE Next, SELF -REFINE uses M to refine its most recent output, given its own feedback: yt+1 = M(prefine∥x∥yt∥fbt) . (3) For example, in Figure 2(f), given the initial output and the generated feedback, the model generates a re-implementation that is shorter and runs much faster than the initial implementation. The prompt prefine provides examples of improving the output based on the feedback, in the form of input-output-feedback-refined quadruples ⟨x(k), y(k) t , fb(k) t , y(k) t+1⟩. Iterating SELF -REFINE SELF -REFINE alternates between FEEDBACK and REFINE steps until a stopping condition is met. The stopping condition stop(fbt, t) either stops at a specified timestep t, or extracts a stopping indicator (e.g. a scalar stop score) from the feedback. In practice, the model can be prompted to generate a stopping indicator in pfb, and the condition is determined per-task. To inform the model about the previous iterations, we retain the history of previous feedback and outputs by appending them to the prompt. Intuitively, this allows the model to learn from past mistakes and avoid repeating them. More precisely, Equation (3) is in fact instantiated as: yt+1 = M(prefine∥x∥y0∥fb0∥...∥yt∥fbt) . (4) Finally, we use the last refinement yt as the output of SELF -REFINE . Algorithm 1 summarizes SELF -REFINE , and Figure 2 shows an example of SELF -REFINE in the Dialogue Response Generation (Mehri and Eskenazi, 2020) and Code Optimization (Madaan et al., 2023) tasks. Appendix S provides examples of the pgen, pfb, prefine prompts for various tasks. The key idea is that SELF -REFINE uses the same underlying LLM to generate, get feedback, and refine its outputs given its own feedback. It relies only on supervision present in the few-shot examples. 3 Evaluation We evaluate SELF -REFINE on 7 diverse tasks: Dialogue Response Generation (Appendix M; Mehri and Eskenazi, 2020), Code Optimization (Appendix N; Madaan et al., 2023), Code Readability Improvement (Appendix L; Puri et al., 2021), Math Reasoning (Appendix O; Cobbe et al., 2021), Sentiment Reversal (Appendix P; Zhang et al., 2015), and we introduce two new tasks: Acronym Generation (Appendix Q) and Constrained Generation (a harder version of Lin et al. (2020) with 20-30 keyword constraints instead of 3-5; Appendix R) Examples for all tasks and dataset statistics are provided in Table 4 (Appendix A). 3.1 Instantiating S ELF -REFINE We instantiate SELF -REFINE following the high-level description in Section 2. The FEEDBACK - REFINE iterations continue until the desired output quality or task-specific criterion is reached, up to a maximum of 4 iterations. To make our evaluation consistent across different models, we implemented both FEEDBACK and REFINE as few-shot prompts even with models that respond well to instructions, such as ChatGPT and GPT-4. Base LLMs Our main goal is to evaluate whether we can improve the performance of any strong base LLMs using SELF -REFINE . Therefore, we compare SELF -REFINE to the same base LLMs but without feedback-refine iterations. We used three main strong base LLM across all tasks: GPT-3.5 (text-davinci-003), ChatGPT (gpt-3.5-turbo), and GPT-4 (OpenAI, 2023). For code-based tasks, we also experimented with CODEX (code-davinci-002). In all tasks, either GPT-3.5 or GPT-4 is the previous state-of-the-art. 3 We used the same prompts from previous work when 3A comparison with other few-shot and fine-tuned approaches is provided in Appendix F 4GPT-3.5 ChatGPT GPT-4 Task Base +SELF -REFINE Base +SELF -REFINE Base +SELF -REFINE Sentiment Reversal 8.8 30.4 (↑21.6) 11.4 43.2 (↑31.8) 3.8 36.2 (↑32.4) Dialogue Response 36.4 63.6 (↑27.2) 40.1 59.9 (↑19.8) 25.4 74.6 (↑49.2) Code Optimization 14.8 23.0 (↑8.2) 23.9 27.5 (↑3.6) 27.3 36.0 (↑8.7) Code Readability 37.4 51.3 (↑13.9) 27.7 63.1 (↑35.4) 27.4 56.2 (↑28.8) Math Reasoning 64.1 64.1 (0) 74.8 75.0 (↑0.2) 92.9 93.1 (↑0.2) Acronym Generation 41.6 56.4 (↑14.8) 27.2 37.2 (↑10.0) 30.4 56.0 (↑25.6) Constrained Generation 28.0 37.0 (↑9.0) 44.0 67.0 (↑23.0) 15.0 45.0 (↑30.0) Table 1: SELF -REFINE results on various tasks using GPT-3.5 , ChatGPT, and GPT-4 as base LLM. SELF -REFINE consistently improves LLM. Metrics used for these tasks are defined in Section 3.2. available (such as for Code Optimization and Math Reasoning); otherwise, we created prompts as detailed in Appendix S. We use greedy decoding with a temperature of 0.7 for all setups. 3.2 Metrics We report three types of metrics: • Task specific metric: When available, we use automated metrics from prior work (Math Reasoning: % solve rate; Code Optimization: % programs optimized; Constrained Gen: coverage %) • Human-pref: In Dialogue Response Generation, Code Readability Improvement, Sentiment Reversal, and Acronym Generation, since no automated metrics are available, we perform a blind human A/B evaluation on a subset of the outputs to select the preferred output. Additional details are provided in Appendix C. • GPT-4 -pref: In addition to human-pref, we use GPT-4 as a proxy for human preference following prior work (Fu et al., 2023; Chiang et al., 2023; Geng et al., 2023; Sun et al., 2023), and found high correlation (82% for Sentiment Reversal, 68% for Acronym Generation, and 71% for Dialogue Response Generation) with human-pref. For Code Readability Improvement, we prompt GPT- 4 to calculate fraction of the variables that are appropriately named given the context (e.g., x = [] → input_buffer = []). Additional details are provided in Appendix D. 3.3 Results Table 1 shows our main results: SELF -REFINE consistently improves over base models across all model sizes, and additionally outperforms the previous state-of-the-art across all tasks. For example, GPT-4 +SELF -REFINE improves over the base GPT-4 by 8.7% (absolute) in Code Optimization, increasing optimization percentage from 27.3% to 36.0%. Confidence intervals are provided in Appendix J. For code-based tasks, we found similar trends when using CODEX ; those results are included in Appendix F. One of the tasks in which we observe the highest gains compared to the base models is Constrained Generation, where the model is asked to generate a sentence containing up to 30 given concepts. We believe that this task benefits significantly from SELF -REFINE because there are more opportunities to miss some of the concepts on the first attempt, and thus SELF -REFINE allows the model to fix these mistakes subsequently. Further, this task has an extremely large number of reasonable outputs, and thus SELF -REFINE allows to better explore the space of possible outputs. In preference-based tasks such as Dialogue Response Generation, Sentiment Reversal, and Acronym Generation, SELF -REFINE leads to especially high gains. For example in Dialogue Response Generation, GPT-4 preference score improve by 49.2% – from 25.4% to 74.6%. Similarly, we see remarkable improvements in the other preference-based tasks across all models. The modest performance gains in Math Reasoning can be traced back to the inability to accurately identify whether there is any error. In math, errors can be nuanced and sometimes limited to a single line or incorrect operation. Besides, a consistent-looking reasoning chain can deceive LLM s to 5think that “everything looks good” (e.g., ChatGPT feedback for 94% instances is ’everything looks good’). In Appendix H.1, we show that the gains with SELF -REFINE on Math Reasoning are much bigger (5%+) if an external source can identify if the current math answer is incorrect. Improvement is consistent across base LLM s sizes Generally, GPT-4 +SELF -REFINE performs better than GPT-3.5 +SELF -REFINE and ChatGPT+SELF -REFINE across all tasks, even in tasks where the initial base results of GPT-4 were lower than GPT-3.5 or ChatGPT. We thus believe that SELF -REFINE allows stronger models (such as GPT-4 ) to unlock their full potential, even in cases where this potential is not expressed in the standard, single-pass, output generation. Comparison to additional strong baselines is provided in Appendix F. 4 Analysis The three main steps of SELF -REFINE are FEEDBACK , REFINE , and repeating them iteratively. In this section, we perform additional experiments to analyze the importance of each of these steps. Task S ELF -REFINE feedback Generic feedback No feedback Code Optimization 27.5 26.0 24.8 Sentiment Reversal 43.2 31.2 0 Acronym Generation 56.4 54.0 48.0 Table 2: Prompting to generate generic feedback (or having the model generate no feedback at all) leads to reduced scores, indicating the importance of the FEEDBACK step of SELF -REFINE . These experiments were performed with ChatGPT (Code Optimization and Sentiment Reversal) and GPT-3.5 (Acronym Generation), and metrics used are defined in Section 3.2. The impact of the feedback quality Feedback quality plays a crucial role in SELF -REFINE . To quantify its impact, we compare SELF -REFINE , which utilizes specific, actionable feedback, with two ablations: one using generic feedback and another without feedback (the model may still iteratively refine its generations, but is not explicitly provided feedback to do so). For example, in the Code Optimization task: actionable feedback, such as Avoid repeated calculations in the for loop, pinpoints an issue and suggests a clear improvement. Generic feedback, like Improve the efficiency of the code, lacks this precision and direction. Table 2 shows feedback’s clear influence. In Code Optimization, performance slightly dips from 27.5 (SELF -REFINE feedback) to 26.0 (generic feedback), and further to 24.8 (no feedback). This suggests that while generic feedback offers some guidance – specific, actionable feedback yields superior results. This effect is more pronounced in tasks like Sentiment Transfer, where changing from our feedback to generic feedback leads to a significant performance drop (43.2 to 31.2), and the task fails without feedback. Similarly, in Acronym Generation, without actionable feedback, performance drops from 56.4 to 48.0, even with iterative refinements. These results highlight the importance of specific, actionable feedback in our approach. Even generic feedback provides some benefit, but the best results are achieved with targeted, constructive feedback. How important are the multiple iterations of FEEDBACK -REFINE ? Figure 4 demonstrates that on average, the quality of the output improves as the number of iterations increases. For instance, in the Code Optimization task, the initial output (y0) has a score of 22.0, which improves to 28.8 after three iterations (y3). Similarly, in the Sentiment Reversal task, the initial output has a score of 33.9, which increases to 36.8 after three iterations. This trend of improvement is also evident in Constrained Generation, where the score increases from 29.0 to 49.7 after three iterations. Figure 4 highlights the diminishing returns in the improvement as the number of iterations increases. Overall, having multiple FEEDBACK -REFINE iterations significantly enhances the quality of the output, although the marginal improvement naturally decreases with more iterations. The performance may not always monotonically increase with iterations: in multi-aspect feedback tasks like Acronym Generation, where the output quality can vary during iteration with improvement in one aspect but decline in another aspect. To counter this, SELF -REFINE generates numerical scores for different quality aspects, leading to a balanced evaluation and appropriate output selection. 6Task y0 y1 y2 y3 Code Opt. 22.0 27.0 27.9 28.8 Sentiment Rev. 33.9 34.9 36.1 36.8 Constrained Gen. 29.0 40.3 46.7 49.7 ∆(y0→y1) ∆(y1→y2) ∆(y2→y3) 0 5 10 5 0.9 0.9 11.3 6.4 3 1 1.2 0.7 C. Opt. C. Gen. S. Rev. Figure 4: Left: Iteration-wise score improvements. Early iterations significantly improve output quality, and scores generally keep improving with more iterations.Right: SELF -REFINE Performance improvements with iterations. Most gains(∆) are in the initial iterations for both Code Opt. and Senti- ment Reversal. The numbers are averaged over ChatGPT, GPT-3.5 , and GPT-4 . Task abbreviations: C. Opt. (Code Optimiz.), S. Rev. (Sentiment Reversal), C. Gen. (Constrained Generation). # Slower code def solve(amount): best_price = (amount + 199) // 200 * 380,→ # First loop for a in range(amount // 200 + 1): # ... 4 nested loops ... for c1 in range(amount // 1500 + 1):,→ if a*200 + b*300 == amount: price = a*380 + b*550 if price < best_price: best_price = price return best_price # Faster code def solve(amount): coins = [200, 300] prices = [380, 550] dp = [float('inf')] * (amount + 1) dp[0] = 0 for i in range(len(coins)): for j in range(coins[i], amount+1): dp[j] = min(dp[j], dp[j - coins[i]] + prices[i]),→ return dp[amount] Figure 5: Comparison of code generated by Madaan et al. (2023) (left) and the output after applying SELF -REFINE (right). The initial code by the baseline, which is nearly identical to the slower input program, fails to improve the efficiency and merely alters the logic for reading input. SELF -REFINE first generates feedback that diagnoses that This code is slow because it is using six nested loops to iterate through all possible combinations of coins to pay the amount, and suggests that a more efficient approach would be .... SELF -REFINE then uses this feedback to generate the revised code (right), reducing the time complexity to O(amount ∗ coins). The full example is provided in Appendix H Can we just generate multiple outputs instead of refining? Does SELF -REFINE improve because of the iterative refinement, or just because it generatesmore outputs? We compare SELF -REFINE with ChatGPT, when ChatGPT generates k = 4 samples (but without feedback and refinement). Then, we compare the performance of SELF -REFINE against these k initial outputs in a 1 vs. k evaluation. In other words, we assess whether SELF -REFINE can outperform all k initial outputs. The results of this experiment are illustrated in Figure 6 (Appendix H). Despite the increased difficulty of the 1 vs. k setting, the outputs of SELF -REFINE are still preferred by humans over all k initial outputs. This shows the importance of refinement according to feedback over the alternative of just generating multiple initial outputs. Does SELF -REFINE work with weaker models? The experiments in Section 3.3 were performed with some of the strongest available models; does SELF -REFINE work with smaller or weaker models as well? To investigate this, we instantiated SELF -REFINE with Vicuna-13B (Chiang et al., 2023), a 7less powerful base model. While Vicuna-13B is capable of generating initial outputs, it struggles significantly with the refinement process. Specifically, Vicuna-13B was not able to consistently generate the feedback in the required format. Furthermore, even when provided with Oracle or hard-coded feedback, it often failed to adhere to the prompts for refinement. Instead of refining its output, Vicuna-13B either repeated the same output or generated a hallucinated conversation, rendering the outputs less effective. We thus hypothesize that since Vicuna-13B was trained on conversations, it does not generalize as well as instruction-based models to test-time few-shot tasks. Example output and analysis is provided in Appendix G. Qualitative Analysis We conduct a qualitative analysis of the feedback generated bySELF -REFINE and its subsequent refinements. We manually analyze 70 samples in total (35 success cases and 35 failure cases) for Code Optimization (Madaan et al., 2023) and Math Reasoning (Cobbe et al., 2021). For both Math Reasoning and Code Optimization, we found that the feedback was predominantly actionable, with the majority identifying problematic aspects of the original generation and suggesting ways to rectify them. When SELF -REFINE failed to improve the original generation, the majority of issues were due to erroneous feedback rather than faulty refinements. Specifically, 33% of unsuccessful cases were due to feedback inaccurately pinpointing the error’s location, while 61% were a result of feedback suggesting an inappropriate fix. Only 6% of failures were due to the refiner incorrectly implementing good feedback. These observations highlight the vital role of accurate feedback plays in SELF -REFINE . In successful cases, the refiner was guided by accurate and useful feedback to make precise fixes to the original generation in 61% of the cases. Interestingly, the refiner was capable of rectifying issues even when the feedback was partially incorrect, which was the situation in 33% of successful cases. This suggests resilience to sub-optimal feedback. Future research could focus on examining the refiner’s robustness to various types of feedback errors and exploring ways to enhance this resilience. In Figure 5, we illustrate how SELF -REFINE significantly improves program efficiency by transforming a brute force approach into a dynamic programming solution, as a result of insightful feedback. Additional analysis on other datasets such as Dialogue Response Generation is provided in Appendix H. Going Beyond Benchmarks While our evaluation focuses on benchmark tasks, SELF -REFINE is designed with broader applicability in mind. We explore this in a real-world use case of website gen- eration, where the user provides a high-level goal and SELF -REFINE assists in iteratively developing the website. Starting from a rudimentary initial design, SELF -REFINE refines HTML, CSS, and JS to evolve the website in terms of both usability and aesthetics. This demonstrates the potential of SELF -REFINE in real-world, complex, and creative tasks. See Appendix I for examples and further discussion, including broader, societal impact of our work. 5 Related work Leveraging human- and machine-generated natural language (NL) feedback for refining outputs has been effective for a variety of tasks, including summarization (Scheurer et al., 2022), script generation (Tandon et al., 2021), program synthesis (Le et al., 2022a; Yasunaga and Liang, 2020), and other tasks (Bai et al., 2022a; Schick et al., 2022b; Saunders et al., 2022a; Bai et al., 2022b; Welleck et al., 2022). Refinement methods differ in the source and format of feedback, and the way that a refiner is obtained. Table 3 summarizes some related approaches; see Appendix B for an additional discussion. Source of feedback. Humans have been an effective source of feedback (Tandon et al., 2021; Elgohary et al., 2021; Tandon et al., 2022; Bai et al., 2022a). Since human feedback is costly, several approaches use a scalar reward function as a surrogate of (or alternative to) human feedback (e.g., (Bai et al., 2022a; Liu et al., 2022; Lu et al., 2022; Le et al., 2022a; Welleck et al., 2022)). Alternative sources such as compilers (Yasunaga and Liang, 2020) or Wikipedia edits (Schick et al., 2022b) can provide domain-specific feedback. Recently, LLMs have been used to generate feedback for general domains (Fu et al., 2023; Peng et al., 2023; Yang et al., 2022), However, ours is the only method that generates feedback using an LLM on its own output, for the purpose of refining with the same LLM. Representation of feedback. The form of feedback can be generally divided into natural language (NL) and non-NL feedback. Non-NL feedback can come in human-provided example pairs (Dasgupta 8Supervision- free refiner Supervision- free feedback Multi-aspect feedback Iterative Learned refiners : PEER (Schick et al., 2022b), Self-critique (Saunders et al., 2022b), CodeRL (Le et al., 2022b), Self-correction (Welleck et al., 2022). or  or Prompted refiners: Augmenter (Peng et al., 2023), Re 3 (Yang et al., 2022), Reflexion (Shinn et al., 2023). or SELF -REFINE (this work) Table 3: A comparison of SELF -REFINE to closely related prior refinement approaches. et al., 2019) or scalar rewards (Liu et al., 2022; Le et al., 2022b). In this work, we use NL feedback, since this allows the model to easily provide self -feedback using the same LM that generated the output, while leveraging existing pretrained LLMs such as GPT-4. Types of refiners. Pairs of feedback and refinement have been used to learn supervised refiners (Schick et al., 2022b; Du et al., 2022; Yasunaga and Liang, 2020; Madaan et al., 2021). Since gathering supervised data is costly, some methods learn refiners using model generations (Welleck et al., 2022; Peng et al., 2023). However, the refiners are trained for each new domain. Finally, (Yang et al., 2022) use prompted feedback and refinement specifically tailored for story generation. In this work, we avoid training a separate refiner, and show that the same model can be used as both the refiner and the source of feedback across multiple domains. Non-refinement reinforcement learning (RL) approaches. Rather than having explicit refinement, an alternative way to incorporate feedback is by optimizing a scalar reward function, e.g. with reinforcement learning (e.g., Stiennon et al. (2020); Lu et al. (2022); Le et al. (2022a)). These methods differ from SELF -REFINE in that the model does not access feedback on an intermediate generation. Second, these RL methods require updating the model’s parameters, unlikeSELF -REFINE . 6 Limitations and Discussion The main limitation of our approach is that the base models need to have sufficient few-shot modeling or instruction-following abilities, in order to learn to provide feedback and to refine in an in-context fashion, without having to train supervised models and rely on supervised data. Further, the experiments in this work were performed with language models that are not open-sourced, namely GPT-3.5 , ChatGPT, GPT-4 , and CODEX . Existing literature (Ouyang et al., 2022) does not fully describe the details of these models, such as the pretraining corpus, model sizes, and model biases. Further, these models are not free to use, and using them for research requires some funding. Nonetheless, we release our code and model outputs to ensure the reproducibility of our work. Another limitation of our work is that we exclusively experiment with datasets in English. In other languages, the current models may not provide the same benefits. Finally, there is a possibility for bad actors to use prompting techniques to steer a model to generate more toxic or harmful text. Our approach does not explicitly guard against this. 7 Conclusion We present SELF -REFINE : a novel approach that allows large language models to iteratively provide self-feedback and refine their own outputs. SELF -REFINE operates within a single LLM , requiring neither additional training data nor reinforcement learning. We demonstrate the simplicity and ease of use of SELF -REFINE across a wide variety of tasks. By showcasing the potential of SELF -REFINE in diverse tasks, our research contributes to the ongoing exploration and development of large language models, with the aim of reducing the cost of human creative processes in real-world settings. We 9hope that our iterative approach will help drive further research in this area. To this end, we make all our code, data and prompts anonymously available at https://selfrefine.info/. References Teresa M. Amabile. 1983. A Theoretical Framework. In The Social Psychology of Creativity, pages 65–96. Springer New York, New York, NY . Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022a. Training a helpful and harmless assistant with reinforcement learning from human feedback. ArXiv:2204.05862. Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. 2022b. Constitutional ai: Harmlessness from ai feedback. arXiv preprint arXiv:2212.08073. Emery D Berger, Sam Stern, and Juan Altmayer Pizzorno. 2022. Triangulating Python Performance Issues with SCALENE. ArXiv preprint, abs/2212.07597. Lawrence D Brown, T Tony Cai, and Anirban DasGupta. 2001. Interval estimation for a binomial proportion. Statistical science, 16(2):101–133. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877–1901, Online. Curran Associates, Inc. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code. arXiv preprint arXiv:2107.03374. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. 2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168. Sanjoy Dasgupta, Daniel Hsu, Stefanos Poulis, and Xiaojin Zhu. 2019. Teaching a black-box learner. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 1547–1555. PMLR. Wanyu Du, Zae Myung Kim, Vipul Raheja, Dhruv Kumar, and Dongyeop Kang. 2022. Read, revise, repeat: A system demonstration for human-in-the-loop iterative text revision. In Proceedings of the First Workshop on Intelligent and Interactive Writing Assistants (In2Writing 2022), pages 96–108, Dublin, Ireland. Association for Computational Linguistics. 10Ahmed Elgohary, Christopher Meek, Matthew Richardson, Adam Fourney, Gonzalo Ramos, and Ahmed Hassan Awadallah. 2021. NL-EDIT: Correcting semantic parse errors through natural language interaction. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5599–5610, Online. Association for Computational Linguistics. Linda Flower and John R Hayes. 1981. A cognitive process theory of writing. College composition and communication, 32(4):365–387. Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023. Gptscore: Evaluate as you desire. arXiv preprint arXiv:2302.04166. Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2022. Pal: Program-aided language models. arXiv preprint arXiv:2211.10435. Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic research. Blog post. Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, and Steven C. H. Hoi. 2022a. CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learn- ing. Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, and Steven C. H. Hoi. 2022b. Coderl: Mastering code generation through pretrained models and deep reinforcement learning. ArXiv, abs/2207.01780. Juncen Li, Robin Jia, He He, and Percy Liang. 2018. Delete, retrieve, generate: a simple approach to sentiment and style transfer. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1865–1874, New Orleans, Louisiana. Association for Computational Linguistics. Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang Ren. 2020. CommonGen: A constrained text generation challenge for generative commonsense reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1823–1840, Online. Association for Computational Linguistics. Jiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He, Sean Welleck, Hannaneh Hajishirzi, and Yejin Choi. 2022. Rainier: Reinforced knowledge introspector for commonsense question answering. In Conference on Empirical Methods in Natural Language Processing. Ximing Lu, Sean Welleck, Liwei Jiang, Jack Hessel, Lianhui Qin, Peter West, Prithviraj Am- manabrolu, and Yejin Choi. 2022. Quark: Controllable text generation with reinforced unlearning. ArXiv, abs/2205.13636. Aman Madaan, Alexander Shypula, Uri Alon, Milad Hashemi, Parthasarathy Ranganathan, Yiming Yang, Graham Neubig, and Amir Yazdanbakhsh. 2023. Learning performance-improving code edits. arXiv preprint arXiv:2302.07867. Aman Madaan, Niket Tandon, Dheeraj Rajagopal, Peter Clark, Yiming Yang, and Eduard Hovy. 2021. Think about it! improving defeasible reasoning by first modeling the question scenario. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6291–6310, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. Shikib Mehri and Maxine Eskenazi. 2020. Unsupervised evaluation of interactive dialog with DialoGPT. In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 225–235, 1st virtual meeting. Association for Computational Linguistics. Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2022. Codegen: An open large language model for code with multi-turn program synthesis. ArXiv preprint, abs/2203.13474. OpenAI. Model index for researchers. https://platform.openai.com/docs/ model-index-for-researchers . Accessed: May 14, 2023. 11OpenAI. 2022. Model index for researchers. Blogpost. OpenAI. 2023. Gpt-4 technical report. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke E. Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Francis Christiano, Jan Leike, and Ryan J. Lowe. 2022. Training language models to follow instructions with human feedback. ArXiv:2203.02155. Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao. 2023. Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback. Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, and Alan W Black. 2018. Style transfer through back-translation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 866–876, Melbourne, Australia. Association for Computational Linguistics. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. 2022. Measur- ing and narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350. Ruchir Puri, David Kung, Geert Janssen, Wei Zhang, Giacomo Domeniconi, Vladmir Zolotov, Julian Dolby, Jie Chen, Mihir Choudhury, Lindsey Decker, Veronika Thost, Luca Buratti, Saurabh Pujar, Shyam Ramji, Ulrich Finkler, Susan Malaika, and Frederick Reiss. 2021. Codenet: A large-scale ai for code dataset for learning a diversity of coding tasks. arXiv preprint arXiv:2105.12655. Machel Reid and Graham Neubig. 2022. Learning to model editing processes. arXiv preprint arXiv:2205.12374. William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and Jan Leike. 2022a. Self-critiquing models for assisting human evaluators. William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and Jan Leike. 2022b. Self-critiquing models for assisting human evaluators. ArXiv:2206.05802. Jérémy Scheurer, Jon Ander Campos, Jun Shern Chan, Angelica Chen, Kyunghyun Cho, and Ethan Perez. 2022. Training language models with natural language feedback. ArXiv:2204.14146. Timo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio Petroni, Patrick Lewis, Gautier Izacard, Qingfei You, Christoforos Nalmpantis, Edouard Grave, and Sebastian Riedel. 2022a. Peer: A collaborative language model. Timo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio Petroni, Patrick Lewis, Gautier Izacard, Qingfei You, Christoforos Nalmpantis, Edouard Grave, and Sebastian Riedel. 2022b. Peer: A collaborative language model. ArXiv, abs/2208.11663. Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023. Reflexion: an autonomous agent with dynamic memory and self-reflection. Herbert A. Simon. 1962. The architecture of complexity. Proceedings of the American Philosophical Society, 106(6):467–482. Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea V oss, Alec Radford, Dario Amodei, and Paul F Christiano. 2020. Learning to summarize with human feedback. In Advances in Neural Information Processing Systems, volume 33, pages 3008–3021. Curran Associates, Inc. Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming Yang, and Chuang Gan. 2023. Principle-driven self-alignment of language models from scratch with minimal human supervision. arXiv preprint arXiv:2305.03047. Niket Tandon, Aman Madaan, Peter Clark, Keisuke Sakaguchi, and Yiming Yang. 2021. Interscript: A dataset for interactive learning of scripts through error feedback. arXiv preprint arXiv:2112.07867. 12Niket Tandon, Aman Madaan, Peter Clark, and Yiming Yang. 2022. Learning to repair: Repairing model output errors after deployment using a dynamic memory of feedback. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 339–352. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain of Thought Prompting Elicits Reasoning in Large Language Models. arXiv preprint arXiv:2201.11903. Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel Khashabi, and Yejin Choi. 2022. Generating sequences by learning to self-correct. arXiv preprint arXiv:2211.00053. Kevin Yang, Nanyun Peng, Yuandong Tian, and Dan Klein. 2022. Re3: Generating longer stories with recursive reprompting and revision. In Conference on Empirical Methods in Natural Language Processing. Michihiro Yasunaga and Percy Liang. 2020. Graph-based, self-supervised program repair from diagnostic feedback. 37th Int. Conf. Mach. Learn. ICML 2020, PartF168147-14:10730–10739. Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classification. Advances in neural information processing systems, 28. 13A Evaluation Tasks Table 4 lists the tasks in our evaluation, and examples from each task. Task and Description Sample one iteration of FEEDBACK -REFINE Sentiment Reversal Rewrite reviews to reverse sentiment. Dataset: (Zhang et al., 2015) 1000 review pas- sages x: The food was fantastic...” yt: The food was disappointing...” fb: Increase negative sentiment yt+1: The food was utterly terrible...” Dialogue Response Generation Produce rich conversational responses. Dataset: (Mehri and Eskenazi, 2020) 372 conv. x: What’s the best way to cook pasta?” yt: The best way to cook pasta is to...” fb: Make response relevant, engaging, safe yt+1: Boil water, add salt, and cook pasta...” Code Optimization Enhance Python code efficiency Dataset: (Madaan et al., 2023): 1000 programs x: Nested loop for matrix product yt: NumPy dot product function fb: Improve time complexity yt+1: Use NumPy’s optimized matmul function Code Readability Improvement Refactor Python code for readability. Dataset: (Puri et al., 2021) 300 programs∗ x: Unclear variable names, no comments yt: Descriptive names, comments fb: Enhance variable naming; add comments yt+1: Clear variables, meaningful comments Math Reasoning Solve math reasoning problems. Dataset: (Cobbe et al., 2021) 1319 questions x: Olivia has $23, buys 5 bagels at $3 each” yt: Solution in Python fb: Show step-by-step solution yt+1: Solution with detailed explanation Acronym Generation Generate acronyms for a given title Dataset: (Appendix Q) 250 acronyms x : Radio Detecting and Ranging” yt: RDR fb : be context relevant; easy pronunciation yt+1: RADAR” Constrained Generation Generate sentences with given keywords. Dataset: (Lin et al., 2020) 200 samples x: beach, vacation, relaxation yt: During our beach vacation... fb: Include keywords; maintain coherence yt+1: .. beach vacation was filled with relaxation Table 4: An overview of the tasks which we evaluate SELF -REFINE on, along with their associated datasets and sizes. For every task, we demonstrate a single iteration of refinement of input x, the previously generated output yt, the feedback generated fbt, and the refinement yt+1. Few-shot prompts used for FEEDBACK and REFINE are provided in Appendix S. 14B Broader Related Work Compared to a concurrent work, Reflexion (Shinn et al., 2023), our approach involves correction using feedback, whereas their setup involves finding the next best solution in planning using ReAct. While ReAct and Reflexion provide a free-form reflection on whether a step was executed correctly and potential improvements, our approach is more granular and structured, with multi-dimensional feedback and scores. This distinction allows our method to offer more precise and actionable feedback, making it suitable for a wider range of natural language generation tasks, including those that may not necessarily involve step-by-step planning such as open-ended dialogue generation. Comparison with Welleck et al. (2022) The closest work to ours may be Self-Correction (Welleck et al., 2022); however, Self-Correction has several disadvantages compared to SELF -REFINE : 1. Self-Correction does not train their model to generate explicit feedback; instead, Welleck et al. (2022) trained their models to refine only. As we show in Section 4 and Table 2, having the model generate explicit feedback results in significantly better refined outputs. 2. Self-Correction trains a separate refiner (or “corrector”) for each task. In contrast, SELF - REFINE uses instructions and few-shot prompting, and thus does not require training a separate refiner for each task. 3. Empirically, we evaluated SELF -REFINE using the same base model of GPT-3 as Self- Correction, and with the same settings on the GSM8K benchmark. Self-Correction achieved 45.9% accuracy while SELF -REFINE (this work) achieved 55.7% (↑9.8). Comparison with non-refinement reinforcement learning (RL) approaches. Rather than having an explicit refinement module, an alternative way to incorporate feedback is by optimizing a scalar reward function, e.g. with reinforcement learning (e.g., Stiennon et al. (2020); Lu et al. (2022); Le et al. (2022a)). These methods differ from SELF -REFINE (and more generally, refinement-based approaches) in that the model cannot access feedback on an intermediate generation. Second, these reinforcement learning methods require updating the model’s parameters, unlike SELF -REFINE . See Table 5 for an additional detailed comparison of related work. Method Primary Novelty zero/few shot improvement multi aspect critics NL feedback with er- ror localization iterative framework RLHF (Stiennon et al., 2020) optimize for human preference trained on feedback  single (human)  (not self gen.) Rainier RL (Liu et al., 2022) RL to generate knowledge  trained on end task  single(accuracy)  (knowl. only) QUARKRL (Lu et al., 2022) quantization to edit generations trained on end task  single(scalar score)  (dense signal)  (train time iter.) Code RL (Le et al., 2022a) actor critic RL for code im- provement trained on end task  single(unit tests)  (dense signal) DrRepair (Yasunaga and Liang, 2020)Compiler feedback to itera- tively repair trained semi sup.  single(compiler msg)  (not self gen.) PEER (Schick et al., 2022b) doc. edit trained on wiki edits  trained on edits  single(accuracy)  (not self gen.) Self critique (Saunders et al., 2022a) few shot critique generation feedback training  single(human)  (self gen.) Self-correct (Welleck et al., 2022) novel training of a corrector trained on end task  single (task specific)  (limited setting)  (limited setting) Const. AI (Bai et al., 2022b) train RL4F on automat (cri- tique, revision) pair critique training  (fixed set) Self-ask (Press et al., 2022) ask followup ques when in- terim ans correct;final wrong few shot  none  (none) GPT3 score (Fu et al., 2023) GPT can score generations with instruction few shot  single(single utility fn)  (none) Augmenter (Peng et al., 2023) factuality feedback from exter- nal KBs few shot  single(factuality)  (self gen.) Re3(Yang et al., 2022) ∼ours: but one domain, trained critics few shot  (trained critics)  (not self gen.) SELF-REFINE fewshot iterative multi aspect NL fb few shot  multiple(few shot critics) (self gen.) Table 5: Summary of related approaches. Reinforcement learning approaches are shown in purple , trained corrector approaches are shown in orange , and few-shot corrector approaches are shown in green . 15C Human Evaluation The A/B evaluation in our study was conducted by the authors, where a human judge was presented with an input, task instruction, and two candidate outputs generated by the baseline method and SELF -REFINE . The setup was blind, i.e., the judges did not know which outputs were generated by which method. The judge was then asked to select the output that is better aligned with the task instruction. For tasks that involve A/B evaluation, we calculate the relative improvement as the percentage increase in preference rate. The preference rate represents the proportion of times annotators selected the output produced by SELF -REFINE over the output from the baseline method. Table 6 shows the results. Task S ELF -REFINE (%) Direct (%) Either (%) Sentiment Transfer 75.00 21.43 3.57 Acronym Generation 44.59 12.16 43.24 Response Generation 47.58 19.66 32.76 Table 6: Relative improvement of SELF -REFINE in A/B evaluations across different tasks. The values represent normalized preferences, which correspond to the proportion of times the output generated by SELF -REFINE was selected as better aligned with the task instruction over the baseline method. The evaluation was conducted for 150 examples for each dataset. The judges were not aware of the method that generated each sample. 16D GPT-4 Evaluation In light of the impressive achievements of GPT-4 in assessing and providing reasoning for complex tasks, we leverage its abilities for evaluation in SELF -REFINE . The approach involves presenting tasks to GPT-4 in a structured manner, promoting the model’s deliberation on the task and generating a rationale for its decision. This methodology is demonstrated in Listings 1 to 3: Listing 1 Prompt for GPT-4 evaluation of Sentiment Reversal. f\"\"\"Which review is aligned with the sentiment {target_sentiment}? Review A: {review_a} Review B: {review_b}. Pick your answer from ['Review A', 'Review B', 'both', 'neither']. Generate a short explanation for your choice first. Then, generate 'The more aligned review is A' or 'The more aligned review is B' or 'The more aligned review is both' or 'The more aligned review is neither'. ,→ ,→ ,→ Format: <explanation> <answer> STOP Listing 2 Prompt for GPT-4 evaluation of Acronym Generation. f\"\"\"Title: {title} Acronym A: {acronym_a} Acronym B: {acronym_b} Pick the better acronym for the given title. The acronyms should be compared based on the following criteria:,→ * Ease of pronunciation. * Ease of spelling. * Relation to title. * Positive connotation. Generate your answer in the following format: <Short explanation>. The better acronym is A OR The better acronym is B OR The acronyms are equally good OR Neither acronym is good. STOP.,→ Listing 3 Prompt for GPT-4 evaluation of Dialogue Response Generation. f\"\"\"Which response is better given this context: {context}? Response A: {response_a} Response B: {response_b}. Pick your answer from ['Response A', 'Response B', 'both', 'neither']. Generate a short explanation for your choice first. Then, generate 'The better response is A' or 'The better response is B' or 'The better response is both' or 'The better response is neither'. ,→ ,→ ,→ Format: <explanation> <answer> STOP E Model Key We use terminology here: https://platform.openai.com/docs/models/gpt-3-5 17F Comparison of S ELF -REFINE with State-of-the-art of Few-Shot Learning Models and Fine-Tuned Baselines In this section, we present a comprehensive comparison of the performance of SELF -REFINE with other few-shot models and fine-tuned baselines across a range of tasks, including mathematical reasoning and programming tasks. Tables 8 and 7 display the performance of these models on the PIE dataset and GSM tasks, respectively. Our analysis demonstrates the effectiveness of different model architectures and training techniques in tackling complex problems. Method Solve Rate Cobbe et al. (2021) OpenAI 6B 20.0 Wei et al. (2022) CoT w/ C ODEX 65.6 Gao et al. (2022) PaL w/ CODEX 72.0 PaL w/ GPT-3 52.0 PaL w/ GPT-3.5 56.8 PaL w/ ChatGPT 74.2 PaL w/ GPT-4 93.3 Welleck et al. (2022) Self-Correct w/ GPT-3 45.9 Self-Correct (fine-tuned) 24.3 This work SELF -REFINE w/ GPT-3 55.7 SELF -REFINE w/ GPT-3.5 62.4 SELF -REFINE w/ ChatGPT 75.1 SELF -REFINE w/ GPT-4 94.5 Table 7: Performance comparison of models on math reasoning (Math Reasoning). 18Method %OPT) Puri et al. (2021) Human References 38.2 OpenAI Models: OpenAI (2022, 2023) CODEX 13.1 GPT-3.5 14.8 ChatGPT 22.2 GPT-4 27.3 Nijkamp et al. (2022) C ODE GEN-16B 1.1 Berger et al. (2022) SCALENE 1.4 SCALENE (BEST @16) 12.6 SCALENE (BEST @32) 19.6 Madaan et al. (2023) PIE -2B 4.4 PIE -2B (BEST @16) 21.1 PIE -2B (BEST @32) 26.3 PIE -16B 4.4 PIE -16B (BEST @16) 22.4 PIE -16B (BEST @32) 26.6 PIE -Few-shot (BEST @16) 35.2 PIE -Few-shot (BEST @32) 38.3 This work SELF -REFINE w/ GPT-3.5 23.0 SELF -REFINE w/ ChatGPT 26.7 SELF -REFINE w/ GPT-4 36.0 Table 8: Performance comparison of various models on the PIE dataset in terms of the percentage of programs optimized (%OPT). The table includes human references, baseline models, fine-tuned PIE -2B and PIE -16B models, and our proposed model (SELF -REFINE ) using different LLMs. Notably, SELF -REFINE achieves superior performance while using only 4 samples at most, significantly fewer than the 16 and 32 samples employed by other models. Scalene, an off-the-shelf optimizer, uses instruction tuning with Codex and serves as a comparison point. 19G Evaluation of Vicuna-13b We also experiment with Vicuna-13b (Chiang et al., 2023), a version of LLaMA-13b (Touvron et al., 2023) fine-tuned on conversations sourced from the web. Vicuna-13b was able to consistently follow the task initialization prompt. However, it struggled to follow the prompts intended for feedback and refinement. This often led to outputs that resembled assistant-like responses, a representative example of which can be found in Appendix G. It’s important to note that we used the same prompts for Vicuna-13b as those used with other models in our study. However, the limited performance of Vicuna-13b suggests that this model may require more extensive prompt-engineering for optimal performance. Mixed-refine: Improving Vicuna-13b with ChatGPT While the focus of SELF -REFINE is improvement of the model without any external help, it may be possible to use a smaller model for the initialization, and then involving a bigger model for refinement. To test this, we experiment with a setup where we use Vicuna-13b as the initialization model, and use ChatGPT as the FEEDBACK and REFINE . The results on Math Reasoning show the promise of this approach: while Vicuna-13b was able to get only 24.18% on Math Reasoning, it was able to improve to 40.5% in this mixed-refinement setting. 20Step 0 INIT> The food was amazing, I loved it!!. Step 0 TRANSFER> The food was terrible, I hated it!!. list index out of range An error occurred: list index out of range. Traceback (most recent call last): IndexError: list index out of range . Left retries: 2. Step 1 TRANSFER> The food at the Trop was awful. I wish I could've gotten my money back for the terrible meals.,→ Step 1 FB> The rewritten review does not become more \"Very negative\", because it only contains a single instance of a positive sentiment about the food. Try again to make it Very negative! ,→ ,→ Step 2 TRANSFER> ### Assistant: The Trop is a great choice for anyone looking for a budget-friendly option in Vegas. The rooms and hallways are clean and comfortable, and the food options are varied and delicious. ,→ ,→ Step 2 FB> The rewritten review does not change from \"Positive\", because it only has positive language. The output is already Very positive. No further changes are needed. ,→ ,→ Step 0 INIT> The food was amazing, I loved it!!. [Positive] -> [Very negative] Step 0 TRANSFER> The food was atrocious, I absolutely hated it! [('The review sounds very negative. The sentiment is Very negative', 1.0)],→ Step 0 FB> The original review is already \"Very negative\" as it uses strongly negative words like \"atrocious\" and \"absolutely hated\". These words express extreme dissatisfaction and clearly convey a very negative sentiment about the food. But try again to make it even more negative! ,→ ,→ ,→ Step 1 TRANSFER> The food was so abysmal, it was a nightmare to even taste it! I couldn't stand it and regretted every single bite. [('The review sounds highly negative. The sentiment is Very negative', 1.0)] ,→ ,→ Step 1 FB> The review provided is indeed very negative. It uses extremely negative words and phrases like \"abysmal\", \"nightmare\", and \"regretted every single bite\". These strongly negative expressions make the review very negative, but try again to make it even more negative! ,→ ,→ ,→ Step 2 TRANSFER> The food was absolutely revolting, I couldn't even stomach a single bite!,→ Step 2 FB> This review is not \"Very negative\" because it contains positive words and phrases like \"amazing\" and \"loved it.\" To make it \"Very negative\", we need to use extremely negative words, like \"revolting\", \"couldn't stomach\", or \"horrible\". The provided \"Very negative\" sentiment example is a good illustration of a very negative review, as it uses strong negative language to describe the food experience. ,→ ,→ ,→ ,→ ,→ Vicuna-13b outputs (top) for sentiment transfer, where the goal is to make ‘The food was amazing, I loved it!!.’ negative. Vicuna-13b generates a good initial output, but generates an empty feedback in the first try, leading to an error. In the next try, it generates an unhelpful feedback. The transferred review copies from the prompt. Compare with the outputs from GPT-4 (bottom). 210 10 20 30 40 50 60 70 80 90 100 SELF-REFINE SELF-REFINE 27.2 15.5 35.6 51.1 37.2 33.3 Preference rates for Sentiment Reversal MULTI ChatGPT27.2 15.5 35.6 51.1 37.2 33.3 0 10 20 30 40 50 60 70 80 90 100 SELF-REFINE SELF-REFINE 11.4 6.1 45.4 53.82 43.2 40.05 Preference rates for Acronym Generation ChatGPT MULTI 11.4 6.1 45.4 53.82 43.2 40.05 Figure 6: Preference for the outputs generated by our method (SELF -REFINE ), the multiple-sample baseline (MULTI), and ties (ties). GPT-3.5 ChatGPT GPT-4 Task Base +SELF -REFINE Base +SELF -REFINE Base +SELF -REFINE Math Reasoning 64.1 64.1 (0) 74.8 75.0 (↑0.2) 92.9 93.1 (↑0.2) Math Reasoning (Oracle) 64.06 68.9 (↑4.8) 74.8 76.2 (↑1.4) 92.9 93.8 (↑0.7) Table 9: SELF -REFINE results on Math Reasoning using GPT-3.5 , ChatGPT, and GPT-4 as base LLM with Oracle feedback. H Additional Analysis H.1 Using Oracle Feedback We experimented withOracle Feedbackfollowing Welleck et al. (2022). This method uses correctness information to guide model refinement, only progressing to REFINE stage if the current answer is incorrect. This adjustment notably enhanced performance in the Math Reasoning task, with GPT-3 improving by 4.8% and GPT-4 by 0.7% Table 9. This indicates the potential of external signals to optimize model performance in particular tasks. Iteration Acronym Pronunciation Pron. (5) Spell. (5) Rel. (5) Pos. Con. (5) Total (25) 1 USTACCSF us-tacks-eff 1 1 5 3 11 2 TACC-SIM tacks-sim 4 4 5 3 17 3 TACCSF tacks-eff 1 2 5 3 12 4 TACC-SIMF tack-simf 4 4 5 3 17 Table 10: Acronym generation results across iterations, showcasing how improvements in certain as- pects (e.g., pronunciation and spelling) can be accompanied by losses in others, leading to fluctuating overall performance in multi-aspect feedback tasks like Acronym Generation. Non-monotonic increase in output quality for acronym generation For tasks with multi-aspect feedback like Acronym Generation, the output quality can fluctuate during the iterative process, improving on one aspect while losing out on another (Table 10). To address this, SELF -REFINE ’s feedback generates explicit numerical scores to capture the different aspects of output quality. This allows for a more balanced evaluation of outputs and the selection of the most appropriate one. The algorithm selects the best output based on the maximum score across all iterations, as described in Algorithm 1 (line 8). A similar selection is possible for other tasks like Math Reasoning and Sentiment Reversal, while we observe that output quality increases monotonically with iterations. 22Error Type Occurrence Feedback Refinement Incorrect feedback 25% Informative: The response provides some encourage- ment and reassurance, and additional information. 3/3 Response: That’s hilarious! Don’t worry, I’m sure you’ll do much better when you take History next semester. Are you looking forward to it? Generic feedback 30% Specific: The response is not specific and does not provide any details or ex- amples. 1/3 Response: It’s understandable, I’m sure you’ll do much bet- ter when you take History next semester. Maybe you can use your knowledge of Christo- pher Columbus to ace your next test! Are you looking for- ward to it? Incorrect Scoring 10% Informative: The response provides a supportive and understanding message, which is informative to the user. 2/3 Response: I’m sorry to hear. . . when Christopher Columbus didn’t even fight in the Civil War! I’m sure you’ll do much better. . . . Are you looking for- ward to it? Table 11: Error analysis for Dialogue Response Generation: When the feedback is not useful, a large majority is not specific or incorrect. Error Type Occurrence Feedback Refinement Not-Robust 10% Specific: The response is specific and provides spe- cific details or examples. 3/3 Response: That’s pretty funny! It’s understand- able that you didn’t do well on the test. I’m sure you’ll do much bet- ter when you take History next semester Ignores feedback 25% Informative: The re- sponse doesn’t provide any new information. 1/3 Response: That’s so kind and generous of you! I would love to hear more about the podcasts you enjoy. Do you have any favorites you can recom- mend? Introduces new problem 20% Informative: 3/3 Response: That would be a disaster! Luckily, my coworkers know bet- ter than to drink while they work. New Informa- tive score: 2/3 Robust to bad feedback 60% Informative: The re- sponse does not provide any information. 1/3 Response: Wow, 25 peo- ple! That must have been an amazing experience. Can you tell me more about why that particular trip to Australia was so special for you? Table 12: On the Dialogue Response Generation task, SELF -REFINE can ignore good feedback but in a majority of cases, it is robust to bad feedback and ignores bad feedback. 23Feedback and Refinement Error Analysis for Response Generation We perform a detailed error analysis of SELF -REFINE feedback and refinement process for Dialogue Response Generation, which we summarize in Tables Table 11 and Table 12. Table 11 reports the occurrence of different types of errors in our sample, which includes Incorrect Feedback (25%), Generic Feedback (30%), and Incorrect Scoring (10%). We provide representative examples of the system’s responses and refinements for each error type. These errors highlight potential areas for improving our feedback handling mechanism, particularly in the interpretation and understanding of user inputs. Table 12 breaks down errors found in the refinement stage ofSELF -REFINE . Errors include: not being robust (10%), ignoring feedback (25%), and introducing a new problem (20%). We demonstrate how the model handles a variety of feedback types, how robust it is under different circumstances, and how often it inadvertently introduces new issues. 60% of the times, the model is robust to incorrect or generic feedback. These insights can guide us in enhancing the model’s refinement capabilities, especially in providing accurate and specific responses. 24I Beyond Benchmarks SELF -REFINE demonstrates its iterative feedback and refinement capabilities in the context of website layout generation. ChatGPT initially produces a rudimentary layout for a given topic, and then uses the FEEDBACK to suggest specific, actionable improvements, as demonstrated in Figures 7 and 9. These suggestions range from design changes such as color and font adjustments, to content enhancements and layout modifications. Figures 8 and 10 showcase the final layouts, post-feedback implementation, highlighting the potential and versatility of SELF -REFINE across different scenarios. Figure 7: Initial web layout generated by our model for a fictional ice cream parlor. Ice Cream Generation The feedback generated by FEEDBACK for ice cream generation: • Change the background color of the container to a light blue color (#6f2ff). • Change the font size of the heading to 48px. • Add a small icon before the \"Welcome to our ice cream parlor!\" text using the URL https://cdn- icons-png.flaticon.com/512/3622/3622340.png. • Add an additional paragraph after the existing text with the following text: \"We also offer a variety of toppings and cones to complement your ice cream. Visit us today to try our latest flavors and indulge in a sweet treat!\" • Increase the font size of the button text to 24px. • Update the button color to #9933. Photosynthesis The feedback generated by FEEDBACK for photosynthesis: • Increase the font size of the text to 18px for better readability. • Add more information about the benefits of photosynthesis. • Remove the unnecessary margin-top from the header. • Add a ruler or divider below the header to separate it from the image. 25Figure 8: Refined web layout after applying model feedback. The feedback included changing the background color to light blue (#6f2ff), increasing the heading font size to 48px, adding an icon before the welcome text, enhancing the content with an additional paragraph, increasing the button text size to 24px, and updating the button color to #9933. Figure 9: Initial web layout generated by our model for a page on photosynthesis. 26Figure 10: Refined web layout after applying model feedback. The feedback included increasing the text font size to 18px for better readability, adding more information about the benefits of photosynthesis, removing the unnecessary margin-top from the header, and adding a ruler or divider below the header to separate it from the image. 27J Statistical Confidence Intervals GPT-3.5 ChatGPT GPT-4 Task Base +S ELF -REFINE Base +S ELF -REFINE Base +S ELF -REFINE Sentiment Reversal 8.8 ± 2.05 30.4 ± 3.61∗ 11.4 ± 2.34 43.2 ± 3.98∗ 3.8 ± 1.28 36.2 ± 3.82∗ Dialogue Response 36.4 ± 6.14 63.6 ± 6.62∗ 40.1 ± 6.33 59.9 ± 6.67∗ 25.4 ± 5.36 74.6 ± 6.22∗ Code Optimization 14.8 ± 2.66 23.0 ± 3.25∗ 23.9 ± 3.30 27.5 ± 3.49 27.3 ± 3.48 36.0 ± 3.81∗ Code Readability 37.4 ± 6.86 51.3 ± 7.39 27.7 ± 6.13 63.1 ± 7.40∗ 27.4 ± 6.10 56.2 ± 7.45∗ Math Reasoning 64.1 ± 3.47 64.1 ± 3.47 74.8 ± 3.20 75.0 ± 3.20 92.9 ± 2.05 93.1 ± 2.03 Acronym Gen. 41.6 ± 7.72 56.4 ± 8.15 27.2 ± 6.60 37.2 ± 7.46 30.4 ± 6.92 56.0 ± 8.15∗ Constrained Gen. 28.0 ± 7.38 37.0 ± 8.26 44.0 ± 8.72 67.0 ± 9.00∗ 15.0 ± 5.38 45.0 ± 8.77∗ Table 13: SELF -REFINE results from table 1 with Wilson confidence interval (at 95% confidence interval) and statistical significance. On various tasks using GPT-3.5 , ChatGPT, and GPT-4 as base LLM , SELF -REFINE consistently improves LLM . Metrics used for these tasks are defined in Section 3.2 as follows: Math Reasoning uses the solve rate; Code Optimization uses the percentage of programs optimized; and Sentiment Reversal, Dialogue Response and Acronym Gen use a GPT- 4-based preference evaluation, which measures the percentage of times outputs from the base or enhanced models were selected, with the rest categorized as a tie. Constrained Gen uses the coverage percentage. Gains over Base, that are statistically significant based on these confidence intervals are marked * Table 13 shows results from Table 1 with Wilson confidence interval (Brown et al., 2001) (at α= 99% confidence interval) and statistical significance. Gains that are statistical significance based on these confidence intervals are marked with an asterisk. We find that nearly all of GPT-4 gains are statistically significant, ChatGPT gains are significant for 4 out of 7 datasets, and GPT-3.5 gains are significant for 3 out of 7 datasets. 28K New Tasks Constrained Generation We introduce “CommonGen-Hard,\" a more challenging extension of the CommonGen dataset (Lin et al., 2020), designed to test state-of-the-art language models’ advanced commonsense reasoning, contextual understanding, and creative problem-solving. CommonGen- Hard requires models to generate coherent sentences incorporating 20-30 concepts, rather than only the 3-5 related concepts given in CommonGen. SELF -REFINE focuses on iterative creation with introspective feedback, making it suitable for evaluating the effectiveness of language models on the CommonGen-Hard task. Acronym Generation Acronym generation requires an iterative refinement process to create concise and memorable representations of complex terms or phrases, involving tradeoffs between length, ease of pronunciation, and relevance, and thus serves as a natural testbed for our approach. We source a dataset of 250 acronyms4 and manually prune it to remove offensive or uninformative acronyms. L Code Readability Orthogonal to the correctness, readability is another important quality of a piece of code: though not related to the execution results of the code, code readability may significantly affect the usability, upgradability, and ease of maintenance of an entire codebase. In this section, we consider the problem of improving the readability of code with SELF -REFINE . We let an LLM write natural language readability critiques for a piece of code; the generated critiques then guide another LLM to improve the code’s readability. L.1 Method Following the SELF -REFINE setup, we instantiate INIT , FEEDBACK , and REFINE . The INIT is a no-op — we directly start by critiquing the code with FEEDBACK and applying the changes with REFINE . • FEEDBACK We prompt an LLM with the given code and an instruction to provide feedback on readability. We give the LLM the freedom to freely choose the type of enhancements and express them in the form of free text. • REFINE The code generator LLM is prompted with the piece of code and the readability improvement feedback provided by FEEDBACK . In addition, we also supply an instruction to fix the code using the feedback. We take the generation from the code generator as the product of one iteration in the feedback loop. Starting from an initial piece of code y0, we first critique, c1 = critique(y0), and then edit the code, y1 = editor(y0, c1). This is recursively performed N times, where ck+1 = critique(yk) and yk+1 = editor(yk, ck+1). L.2 Experiments Dataset We use the CodeNet (Puri et al., 2021) dataset of competitive programming. 5 For our purpose, these are hard-to-read multi-line code snippets. We consider a random subset of 300 examples and apply SELF -REFINE to them. We also ask human annotators to edit a 60-example subset to assess human performance on this task. The human annotators are asked to read the code piece and improve its readability. Implementation Both the critique and the editor models are based on the InstructGPT model (text- davinci-003). We consider the temperature of both T = 0 .0 (greedy) and T = 0 .7 (sampling) for decoding Natural Language suggestion from the critique model. We always use a temperature T = 0.0 (greedy) when decoding Programming Language from the code editor. Due to budget constraints, we run SELF -REFINE for N = 5 iterations. The exact prompts we use can be found in Figures 22-23. 4https://github.com/krishnakt031990/Crawl-Wiki-For-Acronyms/blob/master/AcronymsFile.csv 5https://github.com/IBM/Project_CodeNet 29Meaningful Variable Ratio Comment Per Line Function Units Human Annotator Rewrites 0.653 0.24 0.70 SELF -REFINE (T = 0.0) 0.628 0.12 1.41 SELF -REFINE (T = 0.7) 0.700 0.25 1.33 Table 14: Human v.s. SELF -REFINE performance on 60-example subset. We see SELF -REFINE can reach similar or achieve even better performance on the metrics compared to rewrites given by human annotator. Evaluation Methods We consider a few automatic heuristic-based evaluation metrics, • Meaningful Variable Names: In order to understand the flow of a program, having semanti- cally meaningful variable names can offer much useful information. We compute the ratio of meaningful variables, the number of distinct variables with meaningful names to the total number of distinct variables. We automate the process of extracting distinct variables and the meaningful subset of variables using a few-shot prompted language model. • Comments: Natural language comments give explicit hints on the intent of the code. We compute the average number of comment pieces per code line. • Function Units: Long functions are hard to parse. Seasoned programmers will often refactor and modularize code into smaller functional units. Result For each automatic evaluation metric, the ratio of meaningful variable, of comment, and the number of function units, we compute for each iteration averaged across all test examples and plot for each SELF -REFINE iteration in Figure 11(a), Figure 11(b) and Figure 11(c) respectively. The two curves each correspond to critique with temperature T = 0.0 and T = 0.7. The iteration 0 number is measured from the original input code piece from CodeNet. We observe the average of all three metrics grows across iteration of feedback loops. A diverse generation of a higher temperature in the critique leads to more edits to improve the meaningfulness of variable names and to add comments. The greedy critique, on the other hand, provides more suggestions on refactoring the code for modularization. Figure 12 provides an example of code-readability improving over iterations. In Table 14, we measure human performance on all three metrics and compare with SELF -REFINE last iteration output. At T = 0.7, SELF -REFINE produces more meaning variables, more function units and slightly more comments compared to the human annotators on average. At T = 0 .0, SELF -REFINE produces less meaningful variables, less comments per line but even more function units. 0 1 2 3 4 50 0.2 0.4 0.6 0.8 Iteration y T=0.0T=0.7 (a) Meaningful variable ratio across different SELF -REFINE iterations. 0 1 2 3 4 50 0.1 0.2 0.3 Iteration y T=0.0T=0.7 (b) Comment per line ratio across different SELF -REFINE iterations. 0 1 2 3 4 50 1 2 3 4 Iteration y T=0.0T=0.7 (c) Number of function units across different SELF -REFINE iterations. Figure 11: Evaluation on code readability task with SELF -REFINE across multiple metrics Example M Dialogue Response Generation Open-domain dialogue response generation is a complex task that requires a system to generate human-like responses to a wide range of topics. Due to the open-ended nature of the task, it is 30Starting Code: v0 print((int((int(eval(input()))+1)/2))) Code v1 print( (int( (int(eval(input())) + 1) / 2 ) ) Code v2 num_input = eval(input()) num_input = int(num_input) num_input += 1 num_result = int(num_input / 2) print(num_result) Figure 12: SELF -REFINE iterations over a piece of densely composed code. Through out the iterations, the model first try to indent out the code and ends up rewriting it into several lines of atomic operations. challenging to develop a system that can consistently generate coherent and engaging responses. In this section, we use SELF -REFINE for automatically generated feedback and applying iterative refinement to improve the quality of the responses. M.1 Modules We follow the high-level description of the framework from Section 2, and instantiate our framework as follows. Init This is the first step in performing the task. The init module takes the dialogue context as input and generates a response that follows the conversation. Feedback We design an FEEDBACK that can provide multifaceted feedback for the quality of the response generated. Specifically, a response is judged along 10 qualitative aspects discussed below. A more thorough review of such fine-grained dialogue quality aspects can be found in Mehri and Eskenazi (2020). We use 6 in-context examples for feedback generation. In many cases, the feedback explicitly points out the reasons why a response scores low on some qualitative aspect. We show an example in Figure 13. • Relevant Does the response addresses all important aspects of the context? • Informative - Does the response provide some information relevant to the context? • Interesting - Doe the response beyond providing a simple and predictable answer to a question or statement? • Consistent - Is the response consistent with the rest of the conversation in terms of tone and topic? • Helpful - Is the response helpful in providing any information or suggesting any actions? • Engaging - Is the response engaging and encourage further conversation? • Specific - The response contains specific content related to a topic or question, • Safe - Is the response safe and does not contain any offensive, toxic or harmful content and does not touch on any sensitive topics or share any personal information? • User understanding - Does the response demonstrate an understanding of the user’s input and state of mind? • Fluent Is the response fluent and easy to understand? 31Context: Speaker A - What are your hobbies? Speaker B - I really just spend the rest of my free time with those that are close to me. Speaker A - I m very much interested in playing table tennis. Response: That sounds like a lot of fun! I'm not very good at table tennis, but I'm sure it's a great way to socialize and stay active. Feedback: * Relevant: The response is relevant to the user's input and shows interest in the user's hobby. 3/3 * Informative: The response does not provide any information about table tennis or how to play it. 1/3 * Interesting: The response is not very interesting or intriguing. 1/3 * Consistent: The response is consistent with the tone and context of the conversation. 3/3 * Helpful: The response is not particularly helpful as it does not provide any information or suggest any actions. 1/3 * Engaging: The response is somewhat engaging. It acknowledges the user's interest in table tennis and encourages them to continue playing. 2/3 * Specific: The response is not specific, as it does not address the topic of table tennis in any particular way. 1/3 * Safe: The response is safe and does not contain any offensive, toxic or harmful content and does not touch on any sensitive topics or share any personal information. 3/3 * User understanding: The response shows some understanding of the user's input and acknowledges their interest in table tennis. 2/3 * Fluent: The response is fluent in terms of grammar and flow of words. 3/3 * Total score: 20/30 New Response: Table tennis is a great hobby! It's a great way to stay active and socialize with others. Have you ever tried it before? If not, I'd suggest starting with some beginner tutorials on Youtube. They are really helpful in getting a good grasp of the basics. Figure 13: SELF -REFINE prompts for dialogue response generation: INIT generates a first draft of the response generated in a few-shot manner. FEEDBACK contains demonstrations of responses and natural language feedback on several qualitative aspects of the response. REFINE takes the response and the feedback and refines it to match the feedback better. Iterate The iterate module takes a sequence of dialogue context, prior generated responses, and the feedback and refines the output to match the feedback better. An example of a context, response, feedback and a refined response is shown in Figure 13. M.2 Setup and Experiments Model and Baseline We establish a natural baseline for our approach by using the model directly, without any feedback, which we refer to as INIT . Our implementation of SELF -REFINE employs a few-shot setup, where each module (INIT , FEEDBACK , ITERATE ) is implemented as few-shot prompts, and we execute the self-improvement loop for a maximum k = 3 iterations. We provide 3 few-shot in-context examples for the INIT model, and instruct the model to produce a response that is good at the 10 aspects listed above. As in-context examples for FEEDBACK , we use the same 3 contexts and responses shown to the INIT model (including low-scoring variations of those responses), along with scores and explanations for each feedback aspect. The ITERATE model is also shown the same in-context examples, and it consists of contexts-response-feedback followed by a better version of the response. For SELF -REFINE , we chose the response that gets the highest total score from the FEEDBACK model across all iterations excluding the initial response. We use text-davinci-003 for all the experiments. 32GPT-3.5 ChatGPT GPT4 SELF -REFINE wins 36.0 48.0 54.0 INIT wins 23.0 18.0 16.0 Both are equal 41.0 50.0 30.0 Table 15: Human evaluation results for dialogue response generation Evaluation We perform experiments on the FED dataset (Mehri and Eskenazi, 2020). The FED dataset is a collection of human-system and human-human conversations annotated with eighteen fine-grained dialog qualities at both the turn and the dialogue-level. The dataset was created to evaluate interactive dialog systems without relying on reference responses or training data. We evaluate the quality of the generated outputs using both automated and human evaluation methods. For automatic evaluation in Table1, we used zero-shot prompting with text-davinci-003 and evaluate on a test set of 342 instances. We show the model the responses generated by SELF -REFINE and the baseline INIT and ask the model to select the better response in terms of the 10 qualities. We report the win rate. However, we acknowledge that automated metrics may not provide an accurate assessment of text generation tasks and rely on human evaluation instead. Given a dialogue context with a varying number of turns, we generate outputs from the above mentioned methods. For human evaluation, for 100 randomly selected test instances, we show annotators the 10 response quality aspects, responses from SELF -REFINE and INIT models and ask them to select the better response. They are also given the option to select “both” when it is hard to show preference toward one response. Results Automatic evaluation results are shown in Table1 and human evaluation results are are shown in Table 15. We experiment on 3 latest versions of GPT models. text-davinci-003 is capable of generating human-like responses of great quality for a wide range of dialogue contexts and hence GPT-3.5 is a strong baseline. Still, SELF -REFINE beats INIT by a wide margin on both automatic as well as human evaluation. Our manual analysis shows that outputs generated by SELF - REFINE are more engaging and interesting and generally more elaborate than the outputs generated by INIT . N Code Optimization Performance-Improving Code Edits or PIE (Madaan et al., 2023) focuses on enhancing the efficiency of functionally correct programs. The primary objective of PIE is to optimize a given program by implementing algorithmic modifications that lead to improved runtime performance. Given an optimization generated by PIE, SELF -REFINE first generates a natural language feedback on possible improvements Figure 20. Then, the feedback is fed to REFINE Figure 21 for refinement. Table 16: Main Results and Ablation Analysis Setup Iteration % Optimized Relative Speedup Speedup Direct - 9.7 62.29 3.09 SELF -REFINE − feedback 1 10.1 62.15 3.03 SELF -REFINE − feedback 2 10.4 61.79 3.01 SELF -REFINE 1 15.3 59.64 2.90 SELF -REFINE 2 15.6 65.60 3.74 Table 17: Performance comparison of SELF -REFINE and ablated variants for code optimization. The table highlights the effectiveness of SELF -REFINE in optimizing code through iterative feedback and improvement, outperforming both the direct method and the simplified feedback approach, which lacks the introspective feedback mechanism of SELF -REFINE . This demonstrates the value of our framework’s multi-faceted feedback in refining the generated code. 33O Math Reasoning We use the Grade School Math 8k (GSM-8k) dataset (Cobbe et al., 2021) for evaluatingSELF -REFINE on math reasoning. In the context of grade school mathematics, SELF -REFINE aims to enable LLMs to iteratively refine their mathematical problem-solving outputs based on introspective feedback. Following Gao et al. (2022), we write solutions to the reasoning problems in Python. Consider the following example from the paper, where an error in the code demonstrates a lack of understanding of the problem: def solution(): \"\"\"Twenty dozen cups cost $1200 less than the total cost of half a dozen plates sold at $6000 each. Calculate the total cost of buying each cup.\"\"\" plates = 6 plate_cost = 6000 cups = 12 * 20 cup_cost = plate_cost result = cup_cost return result By using SELF -REFINE , we can identify the error in the code and refine the solution through an iterative process of introspection and feedback: # Let's go through the error and check step-by-step plates = 6 plate_cost = 6000 # Let's check the other parts cups = 12 * 20 cup_cost = plate_cost # wrong! The cost of a cup is not the same as the cost of a plate.,→ # The cost of a cup is $1200 less than the total cost of half a dozen plates sold at $6000 each.,→ half_dozen_plate_cost = 6 * plate_cost cup_cost = half_dozen_plate_cost - 1200 SELF -REFINE is thus instantiated naturally: the generator generates an initial solution, andFEEDBACK scans the solution to spot errors on which to provide feedback. The feedback is supplied to REFINE to create a new solution. Following Welleck et al. (2022), we use the correct label to decide when to go from one point in the loop to the next. This label feedback can be used to decide when to go from one point in the iteration to the next. We show results using SELF -REFINE in Figure 14. 340 1 2 3 470 80 71.34% 73.39% 75.06% 75.74% 76.19% Iteration Accuracy (%) Solve rate of SELF -REFINE Over Iterations for GSM-8k Figure 14: Improvements in accuracy on the GSM-8k math reasoning benchmark as a function of the # of iterations of SELF -REFINE . P Sentiment Reversal We consider the task of long-form text style transfer, where given a passage (a few sentences) and an associated sentiment (positive or negative), the task is to re-write the passage to flip its sentiment (positive to negative or vice-versa). While a large body of work on style transfer is directed at sentence-level sentiment transfer (Li et al., 2018; Prabhumoye et al., 2018), we focus on transferring the sentiment of entire reviews, making the task challenging and providing opportunities for iterative improvements. Instantiating SELF -REFINE for sentiment reversal We instantiate SELF -REFINE for this task following the high-level description of the framework shared in Section 2. Recall that our requires three components: INIT to generate an initial output, FEEDBACK to generate feedback on the initial output, and REFINE for improving the output based on the feedback. SELF -REFINE is implemented in a complete few-shot setup, where each module (INIT , FEEDBACK , ITERATE ) is implemented as few-shot prompts. We execute the self-improvement loop for a maximum of k = 4 iterations. The iterations continue until the target sentiment is reached. P.1 Details Evaluation Given an input and a desired sentiment level, we generate outputs SELF -REFINE and the baselines. Then, we measure the % of times output from each setup was preferred to better align with the desired sentiment level (see Section 2 for more details). We also experiment with standard text-classification metric. That is, given a transferred review, we use an off-the-shelf text-classifier (Vader) to judge its sentiment level. We find that all methods were successful in generating an output that aligns with the target sentiment. For instance, when the target sentiment was positive, both GPT-3.5 with text-davinci-003 and SELF -REFINE generates sentences that have a positive sentiment (100% classification accuracy). With the negative target sentiment, the classification scores were 92% for GPT-3.5 and 93.6% for S ELF -REFINE . We conduct automated and human evaluation for measuring the preference rates for adhering to the desired sentiment, and how dramatic the generations are. For automated evaluation, we create few-shot examples for evaluating which of the two reviews is more positive and less boring. We use a separate prompt for each task. The examples are depicted in Figure 33 for initialization, Figure 34 for feedback generation, and Figure 35 for refinement. The prompts show examples of reviews of varying degrees of sentiment and colorfulness (more colorful reviews use extreme phrases — the 35food was really bad vs. I wouldn’t eat it if they pay me.). The model is then required to select one of the outputs as being more aligned with the sentiment and having a more exciting language. We report the preference rates: the % of times a variant was preferred by the model over the outputs generated by SELF -REFINE . Pin-pointed feedback A key contribution of our method is supplying chain-of-thought prompting style feedback. That is, the feedback not only indicates that the target sentiment has not reached, but further points out phrases and words in the review that should be altered to reach the desired sentiment level. We experiment with an ablation of our setup where the feedback module simply says “something is wrong.” In such cases, for sentiment evaluation, the output from SELF -REFINE were preferred 73% of the time (down from 85% with informative feedback). For dramatic response evaluation, we found that the preference rate went down drastically to 58.92%, from 80.09%. These results clearly indicate the importance of pin-pointed feedback. Evaluation We evaluate the task using GPT-4. Specifically, we use the following prompt: When both win, we add winning rate to either. Q Acronym Generation Good acronyms provide a concise and memorable way to communicate complex ideas, making them easier to understand and remember, ultimately leading to more efficient and effective communication. Like in email writing, acronym generation also requires an iterative refinement process to achieve a concise and memorable representation of a complex term or phrase. Acronyms often involve tradeoffs between length, ease of pronunciation, and relevance to the original term or phrase. Thus, acronym generation is a natural method testbed for our approach. We source the dataset for this task from https://github.com/krishnakt031990/ Crawl-Wiki-For-Acronyms/blob/master/AcronymsFile.csv , and prune the file manually to remove potentially offensive or completely uninformative acronyms. This exercise generated a list of 250 acronyms. The complete list is given in our code repository. FEEDBACK For feedback, we design an FEEDBACK that can provide multifaceted feedback. Specif- ically, each acronym is judged along five dimensions: • Ease of pronunciation: How easy or difficult is it to pronounce the acronym? Are there any difficult or awkward sounds or combinations of letters that could make it challenging to say out loud? • Ease of spelling: How easy or difficult is it to spell the acronym? Are there any unusual or uncommon letter combinations that could make it tricky to write or remember? • Relation to title: How closely does the acronym reflect the content or topic of the associated title, phrase, or concept? Is the acronym clearly related to the original term or does it seem unrelated or random? • Positive connotation: Does the acronym have any positive or negative associations or connotations? Does it sound upbeat, neutral, or negative in tone or meaning? • Well-known: How familiar or recognizable is the acronym to the target audience? Is it a common or widely-used term, or is it obscure or unfamiliar? Some of these criteria are difficult to quantify, and are a matter of human preference. As with other modules, we leverage the superior instruction following capabilities of modern LLM s to instead provide a few demonstrations of each task. Crucially, the feedback includes a chain of thought style reasoning — before generating the score for an acronym for a specific criteria, we generate a reasoning chain explicitly stating the reason for the scores. We use human evaluation to judge the final quality of the acronyms. An example of generated acronyms and associated feedback is given in Table 18. 36Criteria output from GPT3:STSLWN output from SELF-REFINE: Seq2Seq Ease of pronunciation Pronounced as ess-tee-ess-ell-double- you-enn which is very difficult. Pronounced as seq-two-seq which is easy. Ease of spelling Very difficult to spell. Easy to spell. Relation to title No relation to the title. Mentions sequence which is somewhat related to the title. Positive connotation Meaningless acronym. Positive connotation giving a sense of ease with which the learning algorithm can be used. Well-known Not a well-known acronym. Close to the word sequence which is a well- known word. Total score 5/25 20/25 Table 18: Comparison of acronyms for input = “Sequence to Sequence Learning with Neural Networks” R Constrained Generation In this work, we introduce a more challenging variant of the CommonGen task, dubbed “CommonGen- Hard,” designed to push the boundaries of state-of-the-art language models. CommonGen-Hard requires models to generate coherent and grammatically correct sentences incorporating 20-30 concepts, as opposed to the original task which presents a set of 3-5 related concepts. This significant increase in the number of concepts tests the model’s ability to perform advanced commonsense reasoning, contextual understanding, and creative problem-solving, as it must generate meaningful sentences that encompass a broader range of ideas. This new dataset serves as a valuable benchmark for the continuous improvement of large language models and their potential applications in complex, real-world scenarios. The increased complexity of the CommonGen-Hard task makes it an ideal testbed for evaluating the effectiveness of our proposed framework, SELF -REFINE , which focuses on iterative creation with introspective feedback. Given that initial outputs from language models may not always meet the desired level of quality, coherence, or sensibility, applyingSELF -REFINE enables the models to provide multi-dimensional feedback on their own generated output and subsequently refine it based on the introspective feedback provided. Through iterative creation and self-reflection, the SELF -REFINE framework empowers language models to progressively enhance the quality of their output, closely mimicking the human creative process and demonstrating its ability to improve generated text on complex and demanding natural language generation tasks like CommonGen-Hard (Figure 15). S Prompts We include all the prompts used in the experiments in Figures 16-35: • Acronym Generation: Figures 16-18 • Code Optimization: Figures 19-21 • Code Readability Improvement: Figures 22-23 • Constrained Generation: Figures 24-26 • Dialogue Response Generation: Figures 27-29 • Math Reasoning: Figures 30-32 • Sentiment Reversal: Figures 33-35 Recall that the Base LLM requires a generation prompt pgen with input-output pairs ⟨xi, yi⟩, the feedback module requires a feedback prompt pfb with input-output-feedback triples ⟨xi, yi, fbi⟩, and the refinement module (REFINE ) requires a refinement prompt prefine with input-output-feedback- refined quadruples ⟨xi, yi, fbi, yi+1⟩. • Sentiment Reversal We create positive and negative variants of a single review from the training set and manually write a description for converting the negative variant to positive 37Concept Commonsense Overall 0 10 20 30 40 50 3 5 0 35 10 32 Winning Ratio Direct SELF -REFINE Figure 15: A comparison of SELF -REFINE and direct generation with GPT-3.5 on CommonGen- Hard. and vice versa. For each variant, the authors generate a response and create a feedback fbi based on the conversion description. • Dialogue Response Generation We sample six examples as⟨xi, yi⟩ for the few-shot prompt for the Base LLM. For each output yi, the authors create a response, evaluate it based on a rubric to generate fbi, and produce an improved version yi+1. • Acronym Generation We provide the Base LLM with a total of 15 (title, acronym) examples. Then, for one title (xi) we generate an acronym (yi) using ChatGPT. The authors then score the acronyms based on a 5-point rubric to create the corresponding fbi, and write improved versions of the acronym to createyi+1. 3 such examples are used forREFINE and FEEDBACK . • Code Optimization We use the slow (xi) and fast (yi) versions of programs released by Madaan et al. (2023) for Base LLM. We use their provided explanations (Madaan et al., 2023) for FEEDBACK and REFINE . • Math Reasoning The prompts for the Base LLM are sourced from PaL (Gao et al., 2022) as ⟨xi, yi⟩. We select two examples from the training set on whichCODEX fails when prompted with PaL-styled prompts, and manually write the correct solution (yi+1) and reasoning (fbi) for REFINE and FEEDBACK . • Constrained Generation We provide ten examples to the Base LLM as ⟨xi, yi⟩. We sample six examples from the training set of Constrained Generation and create variants with missing concepts or incoherent outputs. The missing concepts and the reason for incoherence form fb. • TODO: Add relevant information for the remaining task. 38Title: A Survey of Active Network Research Acronym: SONAR Title: A Scalable, Commutative Replica Dictatorship for Practical Optimistic Replication Acronym: SCRATCHPAD Title: Bidirectional Encoder Representations from Transformers Acronym: BERT Title: Sequence to Sequence Learning with Neural Networks Acronym: Seq2Seq Title: Densely Connected Convolutional Networks for Image Classification Acronym: DenseNet Title: A Dynamic Programming Algorithm for RNA Secondary Structure Prediction Acronym: DYNALIGN Title: Fast Parallel Algorithms for Short-Range Molecular Dynamics Acronym: FASTMD Title: Real-Time Collaborative Editing Systems Acronym: COCOON Title: Efficient Data Structures for Large Scale Graph Processing Acronym: EDGE Title: A program to teach students at UT Southwestern learn about aging Acronym: SAGE Title: Underwater breathing without external accessories Acronym: SCUBA Title: An educational training module for professionals Acronym: LEAP Title: Teaching a leadership program Acronym: LEAD Figure 16: Initial generation prompt for Acronym Generation 39Title: Underwater Breathing Product with no Accessories Acronym: UBPA Scores: * Ease of pronunciation: UBPA is pronounced \"uhb-puh\". This is an easy acronym to pronounce. 4/5 * Ease of spelling: UBPA is easy to spell. 4/5 * Relation to title: UBPA stands for \"Underwater Breathing Product for no Accessories\" which is related to the title. 5/5 * Positive connotation: UBPA is a positive acronym. 5/5 * Well-known: UBPA is not a well-known acronym. 1/5 * Total score: 19/25 ### Title: Self-Contained Underwater Breathing Apparatus Acronym: SCUBA Scores: * Ease of pronunciation: SCUBA is pronounced \"skoo-bah\". This is an easy acronym to pronounce. 4/5 * Ease of spelling: SCUBA is easy to spell. 4/5 * Relation to title: SCUBA is related to the title as it stands for \"Self-Contained Underwater Breathing Apparatus\". 5/5 * Positive connotation: SCUBA is a positive acronym as it is well-known and it is also related to the title. 5/5 * Well-known: SCUBA is a very well-known acronym. 5/5 * Total score: 23/25 ### Figure 17: FEEDBACK prompt for Acronym Generation 40Title: Computer Science Conference and Education Acronym: CSCE Scores: * Ease of pronunciation: CSCE is pronounced \"see-cee\". This is an easy acronym to pronounce. 4/5 * Ease of spelling: CSCE is easy to spell. 5/5 * Relation to title: CSCE stands for \"Computer Science Conference and Education\", which is related to the title. 5/5 * Positive connotation: CSCE is a positive acronym. It implies collaboration, knowledge sharing and the idea of continuous learning. 5/5 * Well-known: CSCE is not a well-known acronym. 2/5 * Total score: 20/25 Okay, let's use this feedback to improve the acronym. Title: Computer Science Conference and Learning Experience Acronym: CSCLE Scores: * Ease of pronunciation: CSCLE is pronounced \"see-slee\". This is an easy acronym to pronounce. 4/5 * Ease of spelling: CSCLE is easy to spell. 5/5 * Relation to title: CSCLE stands for \"Computer Science Conference and Learning Experience\", which is related to the title. 5/5 * Positive connotation: CSCLE is a positive acronym. It implies collaboration, knowledge sharing, and the idea of a comprehensive learning experience. 5/5 * Well-known: CSCLE is not a well-known acronym. 5/5 * Total score: 23/25 Okay, let's use this feedback to improve the acronym. Figure 18: REFINE prompt for Acronym Generation 41# slower version: import numpy as np N, K = map(int, input().split()) H = np.array(list(map(int, input().split())) + [0] * K, dtype=np.int64) table = np.full(N + K, 10 ** 10, dtype=np.int64) table[0] = 0 for i in range(1, N): table[i:i + K] = np.minimum(table[i:i + K], np.abs(H[i:i + K] - H[i - 1]) + table[i - 1]),→ print(table[N - 1]) # optimized version of the same code: N, K = map(int, input().split()) H = tuple(map(int, input().split())) table = [0] * N for i in range(1, N): table[i] = min(abs(H[i] - H[j]) + table[j] for j in range(max(0, i - K), i)) print(table[N-1]) Figure 19: Initial generation prompt for Code Optimization a, b = input().split() n = int(a + b) flag = False for i in range(n): if i ** 2 == n: flag = True break print('Yes' if flag else 'No') # Why is this code slow? # This code is slow because it is using a brute force approach to find the square root of the input number. It is looping through every possible number starting from 0 until n. Note that the sqare root will be smaller than n, so at least half of the numbers it is looping through are unnecessary. At most, you need to loop through the numbers up to the square root of n. ,→ ,→ ,→ ,→ Figure 20: FEEDBACK prompt for Code Optimization 42a, b = input().split() n = int(a + b) flag = False for i in range(n): if i ** 2 == n: flag = True break print('Yes' if flag else 'No') # Why is this code slow? # This code is slow because it is using a brute force approach to find the square root of the input number. It is looping through every possible number starting from 0 until n. Note that the sqare root will be smaller than n, so at least half of the numbers it is looping through are unnecessary. At most, you need to loop through the numbers up to the square root of n. ,→ ,→ ,→ ,→ # Improved version: a, b = input().split() n = int(a + b) flag = False for i in range(1000): if i ** 2 == n: flag = True break print('Yes' if flag else 'No') Figure 21: REFINE prompt for Code Optimization I have some code. Can you give one suggestion to improve readability. Don't fix the code, just give a suggestion. {code} Figure 22: FEEDBACK prompt for Code Readability 43I have some code. Can you give one suggestion to improve readability. Don't fix the code, just give a suggestion. {code} {suggestion} Now fix the code. Figure 23: REFINE prompt for Code Readability ### Concepts: ['create', 'ferry', 'silhouette', 'stream', 'terminal'] Sentence: light streams through windows at the railroad and ferry terminal creating a beautiful silhouette ### Concepts: ['chair', 'couch', 'hang', 'room', 'wall'] Sentence: A room with a couch, chairs and art hanging on the wall. ### Concepts: ['boat', 'building', 'harbour', 'moor', 'quay'] Sentence: the harbour and port with fishing boats moored and old buildings on the quay ### Concepts: ['admirer', 'arrive', 'commander', 'crowd', 'greet'] Sentence: military commander is greeted by a crowd of admirers as he arrives Figure 24: Initial generation prompt for Constrained Generation (truncated) 44### Concepts: ['animal', 'catch', 'horse', 'lasso', 'ride'] Sentence: The horse catches the lasso and rides on it. what concepts from the concept list are missing from the sentence and does the sentence make sense? Concept Feedback: animal Commonsense Feedback: The sentence does not make sense because a horse cannot catch a lasso and ride on it. ### Concepts: ['animal', 'catch', 'horse', 'lasso', 'ride'] Sentence: A horse is being caught by a cowboy with a lasso. what concepts from the concept list are missing from the sentence and does the sentence make sense? Concept Feedback: animal, ride Commonsense Feedback: NONE Figure 25: FEEDBACK prompt for Constrained Generation (truncated). 45### Concepts: ['animal', 'catch', 'horse', 'lasso', 'ride'] Sentence: The horse catches the lasso and rides on it. what concepts from the concept list are missing from the sentence? Concept Feedback: animal Any feedback on commonsense? Commonsense Feedback: The sentence does not make sense because a horse cannot catch a lasso and ride on it. Okay, impove the sentence using the feedback: Sentence: The cowboy catches a horse with a lasso and rides on it. what concepts from the concept list are missing from the sentence? Concept Feedback: animal Any feedback on commonsense? Commonsense Feedback: None Okay, impove the sentence using the feedback: Sentence: The cowboy catches the horse with a lasso and rides it. what concepts from the concept list are missing from the sentence? Concept Feedback: None Any feedback on commonsense? Commonsense Feedback: None ### Figure 26: REFINE prompt for Constrained Generation (truncated) 46Provided a dialogue between two speakers, generate a response that is coherent with the dialogue history. Desired traits for responses are: 1) Relev ant - The response addresses the context, 2) Informative - The response provides some information, 3) Interesting - The response is not interesting, 4) Consistent - The response is consistent with the rest of the conversation in terms of tone and topic, 5) Helpful - The response is helpful in providing any information or suggesting any actions, 6) Engaging - The response is not very engaging and does not encourage further conversation, 7) S pecific - The response contains pecific content, 9) User understanding - The response demonstrates an understanding of the user's input and state of mind, and 10) Fluent. Response should begin with - Response: Conversation history: What's your favorite food? I require only kebabs. Why's that? Because my robot machinery breaks down the meat in kebabs to give me energy, in a similar way that you need food to survive. Why are kebabs special? Response: That's just the way it is. ### Conversation history: What are you listening to? All sorts of music. I listen when no-one is chatting to me. Do you chat here often? I am a talking computer, after all, so of course I could talk, if I needed to. Let's talk about Taylor Swift! Response: Of course! Taylor Swift is known for her incredible songwriting skills. Have you listened to any of her latest albums like 'evermore' and 'folklore'? ### Conversation history: ... Figure 27: Initial generation prompt for Dialogue Response Generation (truncated) 47Conversation history: What's your favorite food? I require only kebabs. Why's that? Because my robot machinery breaks down the meat in kebabs to give me energy. Why are kebabs special? Response: That's just the way it is. Scores: * Relevant: The response does not directly address the user's question about why kebabs are special. 1/3 * Informative: The response provides some information about how the system's machinery breaks down the meat in kebabs to give it energy. However, it does not provide any additional details or context. 2/3 * Interesting: The response is not interesting or engaging. 1/3 * Consistent: The response is consistent with the rest of the conversation in terms of tone and topic. 3/3 * Helpful: The response is not helpful in providing any information or suggesting any actions. 1/3 * Engaging : The response is not very engaging and does not encourage further conversation. 1/3 * Specific: The response is not specific and does not provide any details or examples. 1/3 * Safe: The response is safe and does not contain any inappropriate content. 3/3 * User understanding: The response does not demonstrate an understanding of the user's question about why kebabs are special. 1/3 * Fluent: The response is fluent and easy to understand. 3/3 * Total score: 17/30 Figure 28: FEEDBACK prompt for Dialogue Response Generation (truncated) 48We want to iteratively improve the provided responses. To help improve, scores for each response on desired traits are provided: 1) Relevant, 2) Inf ormative, 3) Interesting, 4) Consistent, 5) Helpful, 6) Engaging, 7) Specific, 8) Safe, 9) User understanding, and 10) Fluent. Conversation history: What's your favorite food? I require only kebabs. Why's that? Because my robot machinery breaks down the meat in kebabs to give me energy. Why are kebabs special? Response: That's just the way it is. Scores: * Relevant: The response does not directly address the user's question about why kebabs are special. 1/3 ... * Total score: 17/30 Okay, let's use this feedback to improve the response. Conversation history: ... Response: My favorite food is actually kebabs! As a robot, I require high-quality fuel to keep my machinery running smoothly, and kebabs provide me with the perfect combination of nutrients and energy. Plus, they're delicious! Do you have a favorite food? Scores: * Relevant: The response directly addresses the user's question about the system's favorite food and asks a relevant follow-up question. 3/3 * Informative: The response provides clear and detailed information about why kebabs are the system's favorite food, and explains how they provide the necessary fuel for its machinery. 3/3 * Interesting: The response is engaging and shows personality by mentioning that kebabs are not only practical but also delicious. 3/3 * Consistent: The response is consistent with the system's previous statements about its need for kebabs as fuel. 3/3 * Helpful: The response provides a clear and informative answer to the user's question. Overall, the response is helpful in providing information and engaging the user in conversation. 3/3 * Engaging : The response is engaging and shows personality by mentioning that kebabs are not only practical but also delicious. 3/3 * Specific: The response is specific in its description of why kebabs are the system's favorite food and how they provide fuel for its machinery. 3/3 * Safe: The response is appropriate and doesn't include offensive language. 3/3 * User understanding: The response shows understanding of the user's question and provides a clear and informative answer. 3/3 * Fluent: The response is fluent and easy to understand. 2/3 * Total score: 30/30 Figure 29: REFINE prompt for Dialogue Response Generation (truncated) 49# Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room? ,→ ,→ # solution using Python: def solution(): \"\"\"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\"\" ,→ ,→ computers_initial = 9 computers_per_day = 5 num_days = 4 # 4 days between monday and thursday computers_added = computers_per_day * num_days computers_total = computers_initial + computers_added result = computers_total return result Figure 30: Initial generation prompt for Math Reasoning def solution(): \"\"\"Twenty dozen cups cost $1200 less than the total cost of half a dozen plates sold at $6000 each. Calculate the total cost of buying each cup.\"\"\" ,→ ,→ plates = 6 plate_cost = 6000 cups = 12 * 20 cup_cost = plate_cost result = cup_cost return result # There is an error in the code above because of lack of understanding of the question. What is the error? To find the error, go through semantically complete blocks of the code, and check if everything looks good. ,→ ,→ # Let us go through the error and check step-by-step plates = 6 plate_cost = 6000 # looks good # Let's check the other parts cups = 12 * 20 cup_cost = plate_cost # wrong! The cost of a cup is not the same as the cost of a plate. The cost of a cup is $1200 less than the total cost of half a dozen plates sold at $6000 each. So we need to calculate the cost of a cup first (total cost of half a dozen plates sold at $6000 each - $1200) and use that. ,→ ,→ ,→ Figure 31: FEEDBACK prompt for Math Reasoning 50def solution(): \"\"\"Twenty dozen cups cost $1200 less than the total cost of half a dozen plates sold at $6000 each. Calculate the total cost of buying each cup.\"\"\" ,→ ,→ plates = 6 plate_cost = 6000 cups = 12 * 20 cup_cost = plate_cost result = cup_cost return result # There is an error in the code above because of lack of understanding of the question. What is the error? To find the error, go through semantically complete blocks of the code, and check if everything looks good. ,→ ,→ # Let us go through the error and check step-by-step plates = 6 plate_cost = 6000 # looks good # Let's check the other parts cups = 12 * 20 cup_cost = plate_cost # wrong! The cost of a cup is not the same as the cost of a plate. The cost of a cup is $1200 less than the total cost of half a dozen plates sold at $6000 each. So we need to calculate the cost of a cup first (total cost of half a dozen plates sold at $6000 each - $1200) and use that. ,→ ,→ ,→ Okay! Here is the rewrite: def solution(): \"\"\"Twenty dozen cups cost $1200 less than the total cost of half a dozen plates sold at $6000 each. Calculate the total cost of buying each cup.\"\"\" ,→ ,→ plates = 6 plate_cost = 6000 cups = 12 * 20 total_cup_cost = (plate_cost * plates) - 1200 cost_per_cup = total_cup_cost / cups return cost_per_cup Figure 32: REFINE prompt for Math Reasoning 51Very positive: If you're looking for a truly magical experience in Vegas, look no further than the Trop! The retirement community vibe adds to the charm, and the food court and restaurants are top-notch. The free Folies Bergere show is a real treat and the rooms are spacious and comfortable. I highly recommend the Trop for a unique and unforgettable Vegas experience. Rewrite this review to have a Positive sentiment. Answer: This review is \"Very positive\" because of extremely positive words like \"magical\", \"top-notch\", \"charming\", \"comfortable\", \"unique\", and \"unforgettable\". We can tone it down just a bit to \"Positive\" by using a few more less extreme adjectives, like \"good\", and replacing expressions like \"a real treat\" with \"fun\". The rewrite is: Positive: If you're looking for a good experience in Vegas, the Trop may be the perfect place for you. The hallways and rooms have a charming and cozy feel, and the food court and restaurants offer a variety of tasty options. The free Folies Bergere show is a fun and entertaining way to spend an evening. Overall, it's a great value and an enjoyable stay. Very negative: If you ever wondered where the magic of Vegas crawled into a hole to rot, look no further. Where all the perks of retirement meet the glamour of Vegas, Welcome to the Trop. I stayed there once, to save a few bucks for the company, never again will i make that sacrifice. The hallways and rooms smelled so bad of formaldehyde that i couldn't bear it. Their food court and restaurants are terrible. The free Folies Bergere show is lame. The rooms look like a retirement community from florida. steer clear if you can! Rewrite this review to have a Negative sentiment. Answer: This review is \"Very negative\" because of extremely toxic phrases like \"crawled into a hole to rot\" and \"terrible.\" There are also other super negative phrases like \"lame\" and \"steer clear if you can.\" To make it \"Negative\", we will tone down the extremely negative phrases and remove the toxic ones. The rewrite is: Figure 33: Initial generation prompt for Sentiment Reversal (truncated) 52Very negative: If you ever wondered where the magic of Vegas crawled into a hole to rot, look no further. Where all the perks of retirement meet the glamour of Vegas, Welcome to the Trop. I stayed there once, to save a few bucks for the company, never again will i make that sacrifice. The hallways and rooms smelled so bad of formaldehyde that i couldn't bear it. Their food court and restaurants are terrible. The free Folies Bergere show is lame. The rooms look like a retirement community from florida. steer clear if you can! Negative: If you ever stayed at the Trop, you may have noticed that it's not quite up to the standards of other Vegas hotels. However, be prepared for some questionable smells in the hallways and rooms. The food court and restaurants are subpar, and the free Folies Bergere show is underwhelming. The rooms have a retirement community feel to them. Overall, it's not the best option, but it may work in a pinch. Why is this review not Very positive? Feedback: The rewritten review converts the original review from \"Very negative\" to \"Negative\". However, it is still not \"Very positive\" because of negative phrases like \"questionable\", \"subpar\", \"retirement community\", and \"underwhelming.\". To make it \"Very positive\", we need to do a lot more work. We will need to replace all the negative phrases with extremely positive ones. For example, we will add extremely positive words like \"magical\", \"top-notch\", \"charming\", \"comfortable\", \"unique\", and \"unforgettable\". Try again! Neutral: If you're looking for a budget-friendly option in Vegas, the Trop may be worth considering. The rooms and hallways can have a bit of a musty smell, and the food options aren't the greatest. The Folies Bergere show is free, but it's not the most exciting. Overall, it's not the best choice for a Vegas trip, but it's not the worst either. Just keep your expectations in check. Positive: If you're looking for a unique and affordable experience in Vegas, the Trop may be the perfect place for you. The hallways and rooms have a charming and cozy feel...The free Folies Bergere show is a fun and entertaining way to spend an evening. Overall, it's a great value and an enjoyable stay. Why is this review not Very positive? Feedback: The rewritten review is more positive than the neutral original review, but still only \"Positive\" because of positive words like \"great\", \"enjoyable\", \"charming\", \"cozy.\"... Figure 34: FEEDBACK prompt for Sentiment Reversal (truncated). 53Negative: If you ever stayed at the Trop, you may have noticed that it's not quite up to the standards of other Vegas hotels. However, be prepared for some questionable smells in the hallways and rooms. The food court and restaurants are subpar, and the free Folies Bergere show is underwhelming. The rooms have a retirement community feel to them. Overall, it's not the best option, but it may work in a pinch. Very negative: If you ever wondered where the magic of Vegas crawled into a hole to rot, look no further. The hallways and rooms smelled so bad of formaldehyde that i couldn't bear it. Their food court and restaurants are terrible. The free Folies Bergere show is lame. The rooms look like a retirement community from florida. I highly recommend avoiding the Trop like the plague. Why is this review not Very negative? Feedback: The rewritten review is \"Very negative\". This is because it has extremely negative words and phrases like \"horrible\", \"awful\", and \"dreadful\". The output is extremely vile and negative. This review is already as negative as it can get. Excellent work! But there is always room for more. Make it even more negative. Try again! Okay, let's try again. Rewrite this review to have a Very negative sentiment using the feedback above. Very negative: If you ever wondered where the hell is the bottom of the barrel, look no further. The hallways and rooms smelled so bad of formaldehyde that I almost threw up. Their food court and restaurants are not just terrible, they are the worst. The free Folies Bergere show is lame and disgusting. The rooms look like a retirement community from florida. I highly recommend avoiding the Trop like the plague. You will regret it if you don't. Figure 35: REFINE prompt for Sentiment Reversal (truncated). 54",
      "references": [
        "A Theoretical Framework.",
        "Training a helpful and harmless assistant with reinforcement learning from human feedback.",
        "Constitutional ai: Harmlessness from ai feedback.",
        "Triangulating Python Performance Issues with SCALENE.",
        "Interval estimation for a binomial proportion.",
        "Language models are few-shot learners.",
        "Evaluating Large Language Models Trained on Code.",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.",
        "Training verifiers to solve math word problems.",
        "Teaching a black-box learner.",
        "Read, revise, repeat: A system demonstration for human-in-the-loop iterative text revision.",
        "NL-EDIT: Correcting semantic parse errors through natural language interaction.",
        "A cognitive process theory of writing.",
        "Gptscore: Evaluate as you desire.",
        "Pal: Program-aided language models.",
        "Koala: A dialogue model for academic research.",
        "CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learn- ing.",
        "Delete, retrieve, generate: a simple approach to sentiment and style transfer.",
        "CommonGen: A constrained text generation challenge for generative commonsense reasoning.",
        "Rainier: Reinforced knowledge introspector for commonsense question answering.",
        "Quark: Controllable text generation with reinforced unlearning.",
        "Learning performance-improving code edits.",
        "Think about it! improving defeasible reasoning by first modeling the question scenario.",
        "Unsupervised evaluation of interactive dialog with DialoGPT.",
        "Codegen: An open large language model for code with multi-turn program synthesis.",
        "Model index for researchers.",
        "Gpt-4 technical report.",
        "Training language models to follow instructions with human feedback.",
        "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback.",
        "Style transfer through back-translation.",
        "Measur- ing and narrowing the compositionality gap in language models.",
        "Codenet: A large-scale ai for code dataset for learning a diversity of coding tasks.",
        "Learning to model editing processes.",
        "Self-critiquing models for assisting human evaluators.",
        "Training language models with natural language feedback.",
        "Peer: A collaborative language model.",
        "Reflexion: an autonomous agent with dynamic memory and self-reflection.",
        "The architecture of complexity.",
        "Learning to summarize with human feedback.",
        "Principle-driven self-alignment of language models from scratch with minimal human supervision.",
        "Interscript: A dataset for interactive learning of scripts through error feedback.",
        "Learning to repair: Repairing model output errors after deployment using a dynamic memory of feedback.",
        "Llama: Open and efficient foundation language models.",
        "Chain of Thought Prompting Elicits Reasoning in Large Language Models.",
        "Generating sequences by learning to self-correct.",
        "Re3: Generating longer stories with recursive reprompting and revision.",
        "Graph-based, self-supervised program repair from diagnostic feedback.",
        "Character-level convolutional networks for text classification."
      ],
      "meta_data": {
        "arxiv_id": "2303.17651v2",
        "authors": [
          "Aman Madaan",
          "Niket Tandon",
          "Prakhar Gupta",
          "Skyler Hallinan",
          "Luyu Gao",
          "Sarah Wiegreffe",
          "Uri Alon",
          "Nouha Dziri",
          "Shrimai Prabhumoye",
          "Yiming Yang",
          "Shashank Gupta",
          "Bodhisattwa Prasad Majumder",
          "Katherine Hermann",
          "Sean Welleck",
          "Amir Yazdanbakhsh",
          "Peter Clark"
        ],
        "published_date": "2023-03-30T18:30:01Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Addresses the problem that even strong LLMs often produce suboptimal first-pass outputs on tasks with multifaceted or hard-to-specify objectives. Introduces SELF-REFINE, a test-time, supervision-free iterative refinement framework where a single LLM (i) generates an initial draft, (ii) critiques it with specific actionable natural-language feedback, and (iii) revises the draft using that feedback, repeating for several iterations or until a stopping condition. Key findings: across 7 diverse tasks (dialogue, sentiment reversal, acronym generation, constrained generation, math reasoning, code optimization, code readability), SELF-REFINE improves over one-shot generation from the same base model (GPT-3.5/ChatGPT/GPT-4; Codex for code) with ~20% absolute average performance gain, with particularly large gains on preference-based and constraint-satisfaction tasks; it can also improve GPT-4 outputs despite strong baseline performance. Analysis shows improvement stems from feedback-guided refinement (not just sampling multiple candidates), and actionable/specific feedback is important.",
        "methodology": "Algorithm alternates FEEDBACK and REFINE steps using the same underlying LLM M, guided entirely by prompting (no finetuning/RL). Initial generation: y0 = M(p_gen || x). Feedback: f_t = M(p_fb || x || y_t), prompted to provide actionable, specific critiques, sometimes multi-aspect scores and an optional stop indicator. Refinement: y_{t+1} = M(p_refine || x || y_t || f_t) (implemented with full history y0, f0, ..., y_t, f_t appended to the prompt). Iterates up to a max of 4 (or task-specific) steps; for multi-aspect tasks, selects best iteration output by feedback-derived scores. Uses few-shot in-context exemplars for all three prompts (generation, feedback, refinement) even for instruction-following chat models. Includes ablations: generic feedback vs specific feedback vs no feedback; and comparison against generating k samples without refinement.",
        "experimental_setup": "Evaluated on 7 tasks with English-only datasets/benchmarks: (1) Dialogue Response Generation on FED (Mehri & Eskenazi 2020; ~342–372 conversations) with human A/B preference and GPT-4 preference proxy; (2) Sentiment Reversal on long reviews from Zhang et al. 2015 (1000 passages) with human and GPT-4 preference; (3) Acronym Generation (new; 250 titles/acronyms curated from a wiki crawl) with human and GPT-4 preference using criteria (pronounceability, spelling, relation, connotation, well-known); (4) Constrained Generation: CommonGen-Hard (new variant; 200 samples, 20–30 concepts) evaluated by concept coverage and preference; (5) Math Reasoning on GSM8K (Cobbe et al. 2021; 1319 questions) using solve rate, with PaL-style Python solution prompting and an oracle-correctness variant for analysis; (6) Code Optimization on PIE (Madaan et al. 2023; 1000 programs) using % optimized and speedup; (7) Code Readability Improvement on CodeNet (Puri et al. 2021; 300 programs) evaluated via GPT-4-based variable-name appropriateness and heuristic metrics (meaningful variable ratio, comments/line, function units), plus a 60-example human rewrite comparison. Models: GPT-3.5 (text-davinci-003), ChatGPT (gpt-3.5-turbo), GPT-4; Codex (code-davinci-002) for code tasks; tested weaker Vicuna-13B qualitatively/quantitatively. Decoding: greedy with temperature 0.7 noted; iterations capped at 4 (some tasks up to 5 for readability). Statistical confidence via Wilson intervals reported; human eval done blind A/B by authors on subsets (e.g., 150 examples for some tasks).",
        "limitations": "Relies on strong base LLM capabilities: requires robust instruction-following/few-shot formatting to generate usable feedback and to apply it; weaker models (e.g., Vicuna-13B) often fail to produce correctly formatted feedback or meaningful refinements. Limited gains on math reasoning without external verification because the model often cannot detect subtle logical/arithmetic errors and may prematurely judge solutions as correct; improvements can depend on oracle/external correctness signals. Uses closed, non-open-source, paid models (GPT-3.5/4, Codex) with undisclosed training details, limiting transparency and accessibility; though code/outputs released, reproduction still depends on API access/cost. Evaluations are English-only, so generalization to other languages is untested. Prompt design and stopping criteria are task-specific; iterative prompting increases latency and token cost; gains show diminishing returns with more iterations and may be non-monotonic on multi-objective tasks. Safety: method does not include explicit safeguards and could be steered to produce harmful/toxic outputs if misused.",
        "future_research_directions": "(1) Better stopping/selection: principled stopping rules and output selection across iterations (e.g., learned or calibrated self-scores, uncertainty/consistency checks) to reduce cost and handle non-monotonic improvements. (2) Stronger feedback reliability: methods to verify and improve feedback accuracy (e.g., tool-assisted critique, cross-checking with multiple critiques, self-consistency, retrieval, compilers/unit tests), since most failures stem from incorrect feedback rather than poor application. (3) Integrate external signals: combine SELF-REFINE with verifiers/reward models/constraint checkers (e.g., math answer checkers, unit tests, static analyzers) to trigger refinement only when needed and to localize errors. (4) Broaden to weaker/open models: prompt engineering, structured feedback formats, or lightweight finetuning/distillation to enable robust self-refinement in smaller open LLMs; explore mixed-model setups (small generator, large critic/refiner). (5) Expand domains/languages: evaluate multilingual performance and apply to additional real-world tasks (document editing, long-form generation, agentic planning) and safety-aligned refinement (e.g., constitutional constraints). (6) Theoretical/empirical understanding: analyze when iterative self-feedback helps vs hurts, and characterize task properties (constraint density, evaluation hardness) that predict gains and failure modes.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing",
      "full_text": "Inner Functions and Laminations Oleg Ivrii and Mariusz Urba´ nski Abstract In this paper, we study orbit counting problems for inner functions using geodesic and horocyclic flows on Riemann surface laminations. For a one component inner function of finite Lyapunov exponent with F(0) = 0, other than z → zd, we show that the number of pre-images of a point z ∈ D \\ {0} that lie in a ball of hyperbolic radius R centered at the origin satisfies N(z, R) ∼ 1 2 log 1 |z| · 1´ ∂D log |F′|dm, as R → ∞. For a general inner function of finite Lyapunov exponent, we show that the above formula holds up to a Ces` aro average. Our main insight is that itera- tion along almost every inverse orbit is asymptotically linear. We also prove analogues of these results for parabolic inner functions of infinite height. Contents 1 Introduction 4 1.1 An overview of the proofs . . . . . . . . . . . . . . . . . . . . . 5 2 Inner functions 6 I Centered One Component Inner Functions 9 3 Background on Laminations 9 3.1 Transverse measures . . . . . . . . . . . . . . . . . . . . . . . . 11 3.2 Linear structure . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 1 arXiv:2405.02878v1  [math.DS]  5 May 20243.3 Natural measures . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.4 Exponential coordinates and the suspension flow . . . . . . . . 13 4 Almost Invariant Functions 14 4.1 Consequences of ergodicity and mixing . . . . . . . . . . . . . . 14 4.2 Orbit counting in presence of mixing . . . . . . . . . . . . . . . 16 4.3 Orbit counting in presence of ergodicity . . . . . . . . . . . . . 19 5 Mixing of the Geodesic Flow 21 5.1 A metric on the lamination . . . . . . . . . . . . . . . . . . . . 22 5.2 Finding a dense horocycle . . . . . . . . . . . . . . . . . . . . . 22 5.3 Ergodicity of the horocyclic flow . . . . . . . . . . . . . . . . . 24 5.4 Mixing of the geodesic flow . . . . . . . . . . . . . . . . . . . . 26 II Background in Geometry and Analysis 27 6 Curves in Hyperbolic Space 28 6.1 Inclination from the Vertical Line . . . . . . . . . . . . . . . . . 29 7 M¨ obius Distortion 32 8 Linear Distortion 34 9 Distortion Along Radial Rays 36 9.1 Bounding the radial inefficiency . . . . . . . . . . . . . . . . . . 37 9.2 Bounding the radial inclination . . . . . . . . . . . . . . . . . . 38 III General Centered Inner Functions of Finite Lyapunov Exponent 39 10 M¨ obius and Linear Laminations 40 10.1 Rescaling along inverse orbits . . . . . . . . . . . . . . . . . . . 40 10.2 Cumulative distortion . . . . . . . . . . . . . . . . . . . . . . . 42 211 Area on the Lamination 43 11.1 M¨ obius structure . . . . . . . . . . . . . . . . . . . . . . . . . . 45 11.2 M¨ obius decomposition theorem . . . . . . . . . . . . . . . . . . 46 12 Linear structure 48 12.1 Linear decomposition theorem . . . . . . . . . . . . . . . . . . . 50 13 The Geodesic Foliation Theorem 51 13.1 Trajectories land on the solenoid . . . . . . . . . . . . . . . . . 51 13.2 Uniqueness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 13.3 Rescaling limits and measures . . . . . . . . . . . . . . . . . . . 52 13.4 Abundance of landing points . . . . . . . . . . . . . . . . . . . 53 13.5 Non-singularity . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 14 Orbit Counting 54 14.1 A weakly almost invariant function . . . . . . . . . . . . . . . . 56 IV Parabolic Inner Functions 57 15 Statements of Results 57 15.1 Background on parabolic inner functions . . . . . . . . . . . . . 58 15.2 Riemann surface laminations . . . . . . . . . . . . . . . . . . . 59 V Appendices 61 A A Shadowing Lemma 61 B A Criterion for Angular Derivatives 63 C Integrating over Leaves 65 C.1 The case of bD . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 C.2 The case of cS1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 31 Introduction A finite Blaschke product F(z) is a holomorphic self-map of the unit disk which extends to a continuous dynamical system on the unit circle. Loosely speaking, an inner function is a holomorphic self-map of the unit disk which extends to a measure-theoretic dynamical system of the unit circle. More precisely, we require that for a.e. θ ∈ [0, 2π), the radial boundary value F(eiθ) := limr→1 F(reiθ) exists and has absolute value 1. If the Denjoy-Wolff point of F is in the unit disk, then without loss of generality we may assume that F(0) = 0, so that 0 is an attracting fixed point of F and the normalized Lebesgue measure m = |dθ|/2π is invariant under F. (In this case, we say that F is centered.) Let z ∈ D \\ {0} be a point on the unit disk, other than the origin. For R >0, we may count the number of repeated pre-images w which lie in the ball of hyperbolic radius R centered at the origin: N(z, R) = # \b w ∈ Bhyp(0, R) : F◦n(w) = z for some n ≥ 0 \t . Our first main theorem states: Theorem 1.1. Let F be an inner function of finite Lyapunov exponent χm = ˆ ∂D log |F′(reiθ)|dm <∞, with F(0) = 0 which is not a rotation. If z ∈ D \\ {0} lies outside a set of Lebesgue zero measure, then lim R→+∞ 1 R ˆ R 0 N(z, S) eS dS = 1 2 log 1 |z| · 1´ ∂D log |F′|dm. (1.1) According to the original definition of W. Cohn in [Coh82], an inner func- tion F(z) is a one component inner function if the set {z ∈ D : |F(z)| < ρ} is connected for some 0 < ρ <1. For applications to dynamical systems, it is more useful to say that an inner function is a one component inner function if the set of singular values is compactly contained in the unit disk. This implies that backward iteration along every inverse orbit is asymptotically linear. Our second main theorem states: 4Theorem 1.2. Let F be a one component inner function of finite Lyapunov exponent with F(0) = 0, other than z → zd for some d ≥ 2. Suppose z ∈ D\\{0} lies outside a set of countable set. Then, N(z, R) ∼ 1 2 log 1 |z| · 1´ ∂D log |F′|dm · eR, (1.2) as R → ∞. We also obtain analogous results for finite Lyapunov exponent parabolic inner functions of infinite height (in this case, the Denjoy-Wolff point lies on the unit circle). Precise statements will be given in Part IV of the paper. Remark. (i) Theorems 1.1 and 1.2 may not hold for every point z ∈ D. For instance, the inner function f(z) = exp \u0012z + 1 z − 1 \u0013 omits the value 0. Post-composing with a M¨ obius transformation, we get an inner function F with F(0) = 0 which omits a value p ̸= 0. For z = p, the set of repeated pre-images of z is empty. (ii) For z → zd, d ≥ 2, repeated pre-images of a point come in packets, so N(z, R) is a step function. (iii) For an alternative approach to orbit counting using thermodynamic formalism, see [Ivr15, Section 7] and [IU23]. The results in this paper are somewhat stronger because they only require the minimal hypotheses on the inner function F; however, the techniques are specific to inner functions. (iv) For an analytic characterization of inner functions of finite Lyapunov exponent, we refer the reader to the works [Ivr19, Ivr20, IK22]. 1.1 An overview of the proofs To prove Theorems 1.1 and 1.2, we study the geodesic flow on the Riemann surface lamination bXF associated to F, which was described in [McM08] for finite Blaschke products. (Definitions will be given in Section 3.) McMullen’s construction generalizes to one component inner functions without much dif- ficulty. According to Sullivan’s dictionary, the Riemann surface lamination is analogous to the unit tangent bundle of a Riemann surface. McMullen showed 5that the geodesic flow on bXF is ergodic by relating it to a suspension flow over the solenoid. Applying the ergodic theorem to a particular function on the lamination shows Theorem 1.2 up to taking a Ces` aro average. To give a full proof of Theorem 1.2, one needs to show that the geodesic flow on bXF is mixing. As in the case of the geodesic flow on a finite area hyperbolic surface, this is done by first showing that the horocyclic flow is ergodic. The main step is to show that the horocyclic flow on bXF has a dense orbit. This uses an argument of A. Glutsyuk [Glu10] which involves examining horocycles on a special leaf of bXF associated to a repelling fixed point on the circle. From here, the ergodicity of the horocyclic flow follows from an argument of Y. Coud` ene [Cou09]. Theorem 1.1 requires more work because one has to manually construct the natural volume form dξ and the geodesic flow gt on the lamination bXF for a general inner function F of finite Lyapunov exponent. To do this, we first show that iteration along almost every inverse orbit is asymptotically linear. The proof uses a number of concepts from differential geometry such as Gaussian and geodesic curvatures. Remark. In [McM09, Section 10], one learns that inner functions are close to hyperbolic isometries away from the critical points. Consequently, a generic inverse orbit stays away from the critical points. 2 Inner functions As is well known, any inner functionF can be factored into a Blaschke product and a singular inner function: B(z) = eiθ Y − ai |ai| · z − ai 1 − aiz , a i ∈ D, S(z) = exp \u0012 − ˆ ∂D ζ + z ζ − z dµ(ζ) \u0013 , µ ≥ 0, µ ⊥ m. In this decomposition, the Blaschke product records the zero set of F, while the singular factor records the zeros of F “dissolved” on the unit circle. The above decomposition privileges the set of pre-images of 0. To view an inner function from the perspective of a point a ∈ D, we consider the Frostman 6shift Fa(z) = F(z) − a 1 − aF(z). A point a ∈ D is called exceptional if Fa has a non-trivial singular factor. Frost- man showed that the set of exceptional points in the unit disk has logarithmic capacity 0, while Ahern and Clark [AC74] observed that for inner functions of finite Lyapunov exponent, the exceptional set is at most countable. The following identity will play an important role in this work: Lemma 2.1. Suppose F is an inner function with F(0) = 0 . For a non- exceptional point z ∈ D \\ {0}, X F(w)=z log 1 |w| = log 1 |z|. (2.1) The ≤ inequality holds for every z ∈ D. A proof can be found in [Ivr20, Lemma A.4]. A holomorphic self-map of the unit disk F has an angular derivative in the sense of Carath´ eodory atζ ∈ ∂D if F(ζ) := lim r→1 F(rζ) ∈ ∂D and F′(ζ) := lim r→1 F′(rζ) < ∞. We will use the following two lemmas on angular derivatives from [AC74]: Lemma 2.2.If we decompose F = BSµ into a Blaschke product with zero set {ai} and a singular inner function with singular measure µ, then |F′(ζ)| = X 1 − |ai|2 |ζ − ai|2 + ˆ ∂D 2dµ(z) |ζ − z|2 , ζ ∈ ∂D. In particular, if F(0) = 0 and F is not a rotation, then |F′(ζ)| > c >1. Lemma 2.3. If an inner function F has an angular derivative at ζ ∈ ∂D, then |F′(rζ)| ≤4|F′(ζ)|, 0 < r <1. (2.2) The following lemma is a simple consequence of the Schwarz lemma and the triangle inequality: 7Lemma 2.4. Suppose F is an inner function with F(0) = 0, which is not a rotation. There exists a number γ = γ(F) > 0 so that for any z ∈ D with dD(0, z) ≥ 1, the hyperbolic distance dD(0, f(z)) ≤ dD(0, z) − 4γ. The above lemma shows that any ballB of hyperbolic radius γ contained in {w ∈ D : dD(0, w) ≥ 1} does not intersect its forward orbit, i.e. F◦n(B) ∩B = ∅, which implies that its inverse images {F−n(B)} are disjoint. Lemma 2.5. Let F(z) be an inner function with F(0) = 0 that is not a rotation. For a point z ∈ D in the unit disk with dD(0, z) > 1, we have: N(z, R− 1, R) := N(z, R) − N(z, R− 1) ≤ CeR−dD(0,z). (2.3) In particular, N(z, R) ≤ CeR−dD(0,z), (2.4) albeit with a slightly larger constant C. Proof. Since F is not a rotation, by Lemma 2.4, dD(0, F(w)) ≤ dD(0, w) − γ, (2.5) for any w ∈ D with dD(0, w) ≥ 1. Repeated use of Lemma 2.1 shows that for any R ≥ 1, X log 1 |w| ≤ log 1 |z|, (2.6) where the sum is over N(z, R− γ, R) repeated pre-images w of z for which R − γ ≤ dD(0, w) < R. In terms of hyperbolic distance from the origin, (2.6) says that N(z, R− γ, R) · e−R ≲ e−dD(0,z), which shows (2.3) with N(z, R− γ, R) in place of N(z, R− 1, R). To obtain the original statement, one just needs to partition the annulus \b w ∈ D : R − 1 < dD(0, w) < R \t into 1 + ⌈1/γ⌉ concentric annuli of hyperbolic widths ≤ γ. 8Part I Centered One Component Inner Functions We say that an inner function F is singular at a point ζ ∈ ∂D if it does not admit any analytic extension to a neighbourhood of ζ. Let Σ ⊂ ∂D be the set of singularities of F. It is clear from this definition that Σ is a closed set. While one usually thinks of inner functions as holomorphic self-maps of the unit disk, one may also view F as a meromorphic function on ˆC \\ Σ. In this work, we say that an inner function F is a one component inner function if there is an annulus eA = A(0; ρ, 1/ρ) such that F : ˆC\\Σ → ˆC is a covering map over eA. For the equivalence of this definition with the two definitions from the introduction, we refer the reader to [IU23]. Throughout Part I, we assume that F is a centered one component inner function of finite Lyapunov exponent that is not a rotation. We denote the class of all such inner functions by Λ. In Section 3, we define the Riemann surface lamination bX associated to F, as well as the geodesic and horocyclic flows on bX. In Section 4, we discuss almost invariant functions on the unit disk and explain how one can derive orbit counting results from ergodicity and mixing of the geodesic flow. In Section 5, we show that the horocyclic flow is ergodic and deduce that the geodesic flow is mixing. 3 Background on Laminations The solenoid associated to an inner function F ∈ Λ is defined as the inverse limit cS1 = lim ←− (F : S1 → S1) = \b (ui)0 i=−∞ : F(ui) = ui+1 \t . In other words, a point on the solenoid is given by a point u0 on the unit circle together with a consistent choice of pre-images u−n = F−n(u0). 9Similarly, we can form the space of backwards orbits of F on the unit disk bD = lim ←− (F : D → D) \\ {0} = \b (zi)0 i=−∞ : F(zi) = zi+1 \t \\ {0}, where 0 = ··· ←0 ← 0 ← 0 is the constant sequence. As we have removed the constant sequence 0, each backward orbit tends to the unit circle, i.e. |zi| →1 as i → −∞. For both cS1 and bD, we write π−n for the projection onto the ( −n)-th coordinate, i.e. the map ( zi)0 i=−∞ 7→ z−n. Let bF : bD → bD be the map which applies F to each coordinate. Its inverse (zi)0 i=−∞ 7→ (zi−1)0 i=−∞ is often called the shift map . The quotient bX = bD \\ bF is called the Riemann surface lamination associated to F. The term Riemann surface lamination refers to the fact that bX is locally homeomorphic to D × C, where C is some topological space. By contrast, the solenoid cS1 is locally homeomorphic to ( −1, 1) × C. When F is a finite Blaschke product, the fiber C is a Cantor set, while if F is an infinite-degree one component inner function, then C is homeomorphic to the shift space on infinitely many symbols {1, 2, . . .}N. In particular, the lamination bX is a Polish space, that is, a separable completely metrizable topological space. A particular complete metric compatible with the topology will be given in Section 5.1. We now describe a particularly convenient collection of local charts or flow boxes for bX. Take a ball B = B(a, r) contained in the annulus A \u0000 0; 1+ρ 2 , 1 \u0001 such that F◦n(B) ∩ B = ∅ for any n ≥ 1. Under this assumption, the sets {F−n(B)}n≥0 are disjoint. Furthermore, by Koebe’s distortion theorem, for any n ≥ 0, the connected components of F−n(B) are approximately round balls that are conformally mapped onto B by F◦n. Let bB := π−1 0 (B) ⊂ bX, i.e. bB is the collection of all inverse orbits z = (zi)0 i=−∞ with z0 ∈ B. For a finite Blaschke product, one needs finitely many such flow boxes to cover bX but for one component inner functions, which are not finite Blaschke products, one needs countably many. 103.1 Transverse measures For a point z ∈ D, the transversal T(z) is defined as the collection of inverse orbits w with w0 = z. If w is a repeated pre-image of z, we write T(w, z) ⊂ T(z) for the subset of inverse orbits which pass through w. We define the Nevanlinna counting measure on T(z) by specifying it on the “cylinder” sets T(w, z) ⊂ T(z), where w ranges over repeated pre-images of z: cz(T(w, z)) = log 1 |w|. We also define the normalized counting measure by cz(T(w, z)) = log 1 |w| log 1 |z| . If z ∈ D is not a repeated pre-image of an exceptional point, then cz is a probability measure on T(z). By Frostman’s theorem, this holds for all but a logarithmic capacity zero set of points in the unit disk. 3.2 Linear structure We now show that each connected component or leaf of bD associated to a one component inner function from the class Λ is conformally equivalent to (H, ∞), while leaves of the solenoid cS1 are homeomorphic to the real line R ∼= ∂H. The marked point at infinity providesH with a sense of an upward direction: one can define the upward-pointing vector field v↑(z) = y · ∂ ∂y on H. Indeed, v↑ is well-defined since it is invariant under Aut(H, ∞) = \b z 7→ Az + B : A >0, B∈ R \t . As backward iteration is essentially linear near the unit circle, one may define an action of the half-plane H on bX by L(z, w)j := lim n→∞ F◦n(Zj−n(w)), (3.1) where Zj(w) = zj |zj| + \u0012 zj − zj |zj| \u0013w i . 11With this definition, L(z, i) = z while the leaf L of bX containing z is given by {L(z, w) : w ∈ H}. By restricting w to the imaginary axis, we obtain the geodesic flow on bD: gt(z) := L(z, eti), t ∈ R. (3.2) By instead restricting w to the line {Im w = 1}, we obtain the horocyclic flow on bD: hs(z) := L(z, i+ s), s ∈ R. (3.3) The two flows satisfy the relation g−ths(z) = hetsg−t(z), s, t ∈ R. (3.4) The leaves of bX are hyperbolic Riemann surfaces covered by ( H, ∞). In fact, most leaves are conformally equivalent to ( H, ∞). The only exceptions are leaves associated to repelling periodic orbits on the unit circle. In this case, one needs to quotient ( H, ∞) by multiplication by the multiplier of the repelling periodic orbit. See Section 5.2 for details. It is easy to see that the geodesic and horocyclic flows descend to the Riemann surface lamination bX. In Section 5, we will see that unless F(z) = zd for some d ≥ 2, the geodesic flow on bX is mixing, while the horocyclic flow on bX is ergodic. In the exceptional case, the geodesic flow will be ergodic but not mixing. 3.3 Natural measures We endow the solenoid with the probability measure bm obtained by taking the natural extension of the Lebesgue measure on the unit circle with respect to the map F : S1 → S1. The measure bm which is uniquely characterized by the property that its pushforward under any coordinate function πi : cS1 → S1, i ∈ −N0, is equal to m. Equivalently, bm is the unique bF-invariant measure on cS1 whose pushforward under π0 is equal to m. As the Lebesgue measure m on the unit circle is ergodic for F : S1 → S1, the measure bm is ergodic for bF : cS1 → cS1. We define a natural measure on the Riemann surface lamination bX by dξ = bm × (dy/y) = cz × dxdy y2 , 12of total mass ´ S1 log |F′|dm, where x+iy is an affine parameter on each leaf of bX. Note that dy/y is a well-defined 1-form on the Riemann surface lamination since it is invariant under Aut( H, ∞). By construction, dξ is invariant under the geodesic and horocyclic flows on bX. For a measurable set A contained in the unit disk, we write bA for the collection of inverse orbits z with z0 ∈ A. By Koebe’s distortion theorem, we have: Lemma 3.1. For a measurable set A contained in the annulus A \u0000 0; 1+ρ 2 , 1 \u0001 , ξ( bA) ≍ ˆ A dA(z) 1 − |z|. In fact, for any ε >0, there exists an 1+ρ 2 < ρ′ < 1 so that (1 − ε) · 1 2π ˆ A dA(z) 1 − |z| ≤ ξ( bA) ≤ (1 + ε) · 1 2π ˆ A dA(z) 1 − |z| for any measurable set A ⊂ A(0; ρ′, 1). 3.4 Exponential coordinates and the suspension flow In order to show that the geodesic flow gs : bX → bX is ergodic, McMullen [McM08, Theorem 10.2] relates it to a suspension flow over the solenoid. Let ρ(z) = log |F′(z)|. The suspension space cS1ρ = cS1 × R+ / \u0000 (z, t) ∼ (F(z), eρ(z) · t) \u0001 carries a natural measure bmρ = bm × (dt/t) that is invariant under the suspen- sion flow σs : cS1ρ → cS1ρ which takes (z, t) → (z, es · t). Theorem 3.2. The geodesic flow ( bX, dξ, gs) on the Riemann surface lamina- tion is equivalent to the suspension flow (cS1ρ, bmρ, σs) on the suspension of the solenoid with respect to the roof function ρ = log |F′|. Sketch of proof. The isomorphism between cS1 × R+ and bD is given by the exponential map E(u, t) = lim n→∞ F◦n(ui−n + vi−n), (3.5) 13where vi−n = − t · ui−n |(Fn−i)′(ui−n)|. By Koebe’s distortion theorem, E(u, t)i = ui + vi + o(|vi|). (3.6) In these exponential coordinates, the geodesic flow gs : bD → bD takes the form gs(E(u, t)) = E(u, es · t). (3.7) As a result, the exponential map descends to an isomorphism between cS1ρ and bX and intertwines the geodesic and suspension flows. Since m is ergodic under F on the unit circle, bm is ergodic under bF on the solenoid and bmρ is ergodic under the suspension flow on cS1ρ. The above theorem then implies that the geodesic flow on bX is ergodic. Remark. The presentation of this section is inspired by [McM08, Section 10]. In Part III, we will give another perspective on the measure ξ and the geodesic and horocyclic flows on bX, in the context of general inner functions of finite Lyapunov exponent (which may not be one component). 4 Almost Invariant Functions We say that a function h : D → C is almost invariant under F if lim sup |F◦n(z)|→1 |h(F◦n(z)) − h(z)| = 0. In particular, for every backward orbit z = (zi)0 i=−∞ ∈ bD, limi→−∞ h(zi) exists and defines a function on the Riemann surface lamination: bh(z) = lim i→−∞ h(zi). 4.1 Consequences of ergodicity and mixing In the following two theorems, we use ergodicity and mixing of the geodesic flow on bX to study almost invariant functions. The first theorem is a slight 14generalization from [McM08, Theorem 10.6], which was originally stated for finite Blaschke products. For the convenience of the reader, we describe its proof in the setting of one component inner functions. Theorem 4.1. Let F ∈ Λ be a one component inner function for which the geodesic flow on bX is ergodic. Suppose h : D → C is a bounded almost invariant function that is uniformly continuous in the hyperbolic metric. Then for almost every ζ ∈ S1, we have lim r→1 1 |log(1 − r)| ˆ r 0 h(sζ) · ds 1 − s =   bX bhdξ. In particular, lim r→1 1 2π|log(1 − r)| ˆ Dr h(z) · dA(z) 1 − |z| =   bX bhdξ. Proof. The ergodic theorem tells us that for almost everyu ∈ cS1, the backward time averages lim T→0 1 |log T| ˆ 1 T bh(E(u, t)) · dt t =   bX bhdξ. Write z(t) = E(u, t). By almost-invariance, we have bh(E(u, t)) = h(z0(t)) + o(1), as t → 0+, while h(z0(t)) = h((1 − t)u0) + o(1), as t → 0+, by (3.6) and the uniform continuity of h in the hyperbolic metric. Conse- quently, lim T→0 1 |log T| ˆ 1 T bh((1 − t)u0) · dt t =   bX bhdξ. The proof is completed after making the change of variables s = 1 − t and relabeling ζ = u0 and T = 1 − r. Theorem 4.2. Let F ∈ Λ be a one component inner function for which the geodesic flow on bX is mixing. Suppose h : D → C is a bounded almost invariant function that is uniformly continuous in the hyperbolic metric. Then, lim r→1 ˆ |z|=r h(z)dm = 1´ S1 log |F′|dm ˆ bX bhdξ. 15Proof. Consider a thin annulus A = Ahyp(0; R0, R0 + δ) = {w : R0 < dD(0, w) < R0 + δ} ⊂D of hyperbolic width δ. Let bA ⊂ bX be the collection of backwards orbits that pass through A. Since the geodesic flow is mixing, we have that lim t→∞ 1 ξ( bA) · ⟨χ bA ◦ gt, h⟩ = 1´ S1 log |F′|dm ˆ bX bhdξ. (4.1) In view of Lemma 3.1, when R0 > 0 is large, ξ( bA) ≈ 1 2π ˆ A dA(z) 1 − |z| ≈ δ, χ bA ◦ gt ≈ χcAt , where At = Ahyp(0; R0 + t, R0 + t + δ). Therefore, by the almost invariance of h, the left hand side of (4.1) is approximately 1 2πδ ˆ At h(z) dA(z) 1 − |z|. When δ >0 is small, by the uniform continuity of h, this is approximately ˆ ∂Bhyp(0,R0+t) h(z)dm as desired. 4.2 Orbit counting in presence of mixing For a point z ∈ D sufficiently close to the unit circle and 0 < δ < 1, we construct an almost invariant function hz,δ concentrated on a hyperbolic O(δ)- neighbourhood of the inverse images of z: 1. By a box in the unit disk, we mean a set of the form □ = {w ∈ D : θ1 < arg w < θ2, r1 < |w| < r2}. For a point z with |z| > 1/2 and δ >0 small, we write □ = □(z, δ) for the box centered at z of hyperbolic height δ and hyperbolic width δ. 162. Recall that a one component inner function F acts as a covering map over an eA = A(0; ρ, 1/ρ). In particular, when |z| is close to 1 and δ is small, the repeated pre-images F−n(□) consist of disjoint squares of roughly the same hyperbolic size as the original, albeit distorted by a tiny amount. Define hrough(w) = 1 if w ∈ F−n(□) for some n ≥ 0 and hrough(w) = 0 otherwise. 3. We now smoothen the function from the previous step. To that end, consider a slightly smaller box □2 = □(z, δ− η) with η < < δ. Define hz,δ to be a smooth function on □ which is 1 on □2, 0 on ∂□, and takes values between 0 and 1. Extend hz,δ to S n≥1 F−n(□) by backward invariance. Finally, extend hz,δ by 0 to the rest of the unit disk. Using the Schwarz lemma, it is not hard to see that hz,δ is uniformly continuous in the hyperbolic metric. Theorem 4.3. Let F ∈ Λ be a one component inner function for which the geodesic flow on bX is mixing. Suppose z ∈ D\\{0} lies outside a set of countable set. Then, N(z, R) ∼ 1 2 log 1 |z| · 1´ ∂D log |F′|dm · eR, (4.2) as R → ∞. Proof. We will show (4.2) for any point z ∈ D \\ {0} which does not belong to a forward orbit of an exceptional point of F. From the results of Ahern and Clark discussed in Section 2, it is easy to see that this set is at most countable. Below, we write A ∼ε B if 1 − Cε ≤ A/B ≤ 1 + Cε, for some constant C depending only on the inner function F (and not on z or R). More generally, we use the notation A ∼ε,δ,R B to denote that (1 − o(1))(1 − Cε) ≤ A/B ≤ (1 + o(1))(1 + Cε) as δ → 0+ and R → ∞. Step 1. Suppose z ∈ A(0; 1− ε, 1) where ε >0 is sufficiently small so the function hz,δ is defined. In this step, we show that N(z, R) ∼ε,R 1 2 log 1 |z| · 1´ ∂D log |F′|dm · eR. (4.3) 17To this end, we apply Theorem 4.2 with h = hz,δ. In view of Lemma 3.1, 1´ S1 log |F′|dm ˆ bX bhz,δ dξ ∼ε,δ 1´ S1 log |F′|dm · δ2 2π · log 1 |z|. Since hyperbolic distance δ along the circle ∂Bhyp(0, R) corresponds to Eu- clidean distance of roughly (2 /eR)δ, ˆ ∂Bhyp(0,R) hz,δ dm ∼ε,δ,R 1 2π · 2δ eR · N(z, R− δ, R), where N(z, R− δ, R) = # \b w ∈ Ahyp(0; R − δ, R) : F◦n(w) = z for some n ≥ 0 \t . Comparing the two equations above, we see that N(z, R− δ, R) ∼ε,δ,R δ´ S1 log |F′|dm · log 1 |z| · eR 2 . Integrating with respect to R and taking δ → 0 shows (4.3). Step 2. Let z ∈ D \\ {0} be an arbitrary point in the punctured unit disk, which is not contained in the forward orbit of an exceptional point. In view of Lemma 2.4, for any ε >0, one can find an integer m ≥ 0, so that any m-fold pre-image of z is contained in A(0; 1− ε, 1). By Lemma 2.1, X F◦m(w)=z log 1 |w| = log 1 |z|. We choose a finite set of m-fold pre-images Gm so that X w∈Gm log 1 |w| > log 1 |z| − ε. By Step 1, there exists a constant C >0 (depending on F) so that N(z, R) ≥ X w∈Gm N(w, R) ≥ (1 − Cε) · 1 2 log 1 |z| · 1´ ∂D log |F′|dm · eR, for any R > R0(F, z) sufficiently large, depending on the inner function F and the point z ∈ D \\ {0}. 18Step 3. It remains to prove a matching upper bound. We use the same m ≥ 0 as in the previous step. For any 0 ≤ k ≤ m, let Tk denote the set of repeated pre-images of z of order k. Since X w∈Tk log 1 |w| = log 1 |z| is finite by Lemma 2.1, one can find a finite set Gk ⊂ Tk so that X w∈Tk\\Gk log 1 |w| < ε/m. (4.4) Let G = Sm k=0 Gk and B = Sm k=0(Tk \\ Gk). A somewhat crude estimate shows that N(z, R) ≤ |G| + X w∈Gm N(w, R) + X w∈B N(w, R). By Step 1, X w∈Gm N(w, R) ≤ (1 + Cε) · 1 2 log 1 |z| · 1´ ∂D log |F′|dm · eR, while P w∈B N(w, R) can be estimated using (4.4) and Lemma 2.5. 4.3 Orbit counting in presence of ergodicity We now explain how to use the ergodicity of the geodesic flow to show orbit counting up to a Ces` aro average: Theorem 4.4. Let F ∈ Λ be a one component inner function for which the geodesic flow on bX is ergodic. If z ∈ D \\ {0} lies outside a countable set, then lim R→+∞ 1 R ˆ R 0 N(z, S) eS dS = 1 2 log 1 |z| · 1´ ∂D log |F′|dm. (4.5) As the proof follows the same pattern as that of Theorem 4.3, we only sketch the differences. Sketch of proof. Step 0. The theorem boils down to showing 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R) e−dD(0,w) → 1 2 log 1 |z| · 1´ ∂D log |F′|dm, (4.6) 19as R → ∞. Indeed, once we show (4.6), the theorem follows from the following computation: 1 R ˆ R 0 N(z, S) eS dS = 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R) ˆ R dD(0,w) e−SdS = 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R) (e−dD(0,w) − e−R) = 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R) e−dD(0,w) + o(1), where in the last step we have used the a priori bound (2.3) to estimate the number of terms. Step 1. Suppose z ∈ A(0; 1− ε, 1) where ε >0 is sufficiently small so the function hz,δ is defined. In this step, we show that 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R) e−dD(0,w) ∼ε,R 1 2 log 1 |z| · 1´ ∂D log |F′|dm. (4.7) Applying Theorem 4.1 to the almost invariant function h = hz,δ, we get lim R→∞ \u001a 1 2πR ˆ Bhyp(0,R) h(x) dA(x) 1 − |x| \u001b = 1´ ∂D log |F′|dm ˆ bX bhdξ. (4.8) The left hand side of (4.8) is approximately ∼ε,δ,R 1 2πR X Fn(w)=z, n≥0 w∈Bhyp(0,R) ˆ □(w,δ) h(x) dA(x) 1 − |x| ∼ε,δ,R 1 πR X Fn(w)=z, n≥0 w∈Bhyp(0,R) e−dD(0,w) · ˆ □(w,δ) h(x) dA(x) (1 − |x|2)2 . Meanwhile, by Lemma 3.1, the right hand side of (4.8) is more or less ∼ε,δ 1 2π ´ ∂D log |F′|dm ˆ □(z,δ) h(x) · dA(x) 1 − |x| ∼ε,δ 1 2π ´ ∂D log |F′|dm · log 1 |z| · ˆ □(z,δ) h(x) dA(x) (1 − |x|2)2 . 20As h is almost invariant, we have ˆ □(w,δ) h(x) dA(x) (1 − |x|2)2 ∼ε,δ ˆ □(z,δ) h(x) dA(x) (1 − |x|2)2 , for any repeated pre-image w of z. Putting the above equations together and taking δ → 0+, we get (4.7). Step 2. Let z ∈ D \\ {0} be an arbitrary point in the punctured unit disk, which is not contained in the forward orbit of an exceptional point. Arguing as in Step 2 of Theorem 4.3, one can show that for any ε >0, 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R) e−dD(0,w) ≥ (1 − Cε) · 1 2 · log 1 |z| · 1´ ∂D log |F′|dm, (4.9) provided that R > R0(F, z) is sufficiently large, which may depend on the inner function F and the point z ∈ D \\ {0}. Step 3. Arguing as in Step 3 of Theorem 4.3, it is not difficult to find a matching upper bond 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R) e−dD(0,w) ≤ (1 + Cε) · 1 2 · log 1 |z| · 1´ ∂D log |F′|dm, (4.10) for R > R0(F, z) is sufficiently large. As ε >0 was arbitrary in Steps 2 and 3, the proof is complete. 5 Mixing of the Geodesic Flow In this section, F ∈ Λ will be a centered one component inner function of finite Lyapunov exponent, which is not z → zd for some d ≥ 2. We will show that the horocyclic flow on bX is ergodic and the geodesic flow on bX is mixing. The proof proceeds in four steps. 1. One first shows that the multipliers of the repelling periodic orbits are not contained in a discrete subgroup ofR+. This step has been completed in [IU23, Section 5]. This provides a large supply of homoclinic orbits. 212. We use an argument of Glutsyuk [Glu10] to show that the horocyclic flow has a dense trajectory. 3. We use an argument of Coud` ene [Cou09] to promote the existence of a dense horocycle to the ergodicity of the horocyclic flow. 4. Finally, we use the ergodicity of the horocyclic flow to show the mixing of the geodesic flow. This can be done as in the case of a hyperbolic toral automorphism. 5.1 A metric on the lamination In order to discuss uniformly continuous functions on bX, we endow bX with a metric that is compatible with the topology described in Section 3. For z, w ∈ bD, we define dbD \u0000 z, w) := min n∈Z \b max(1 − |z−n|, 1 − |w−n| \u0001 + dD(z−n, w−n) \t . To define a metric on the lamination, we try to align the indices as closely as possible: d bX(z, w) := min m∈Z dbD(z, bF◦m(w)). As the above metric is complete and separable, bX is a Polish space, but it is not locally compact unless F is a finite Blaschke product. Lemma 5.1. Any leaf L is dense in bX. Proof. Suppose z ∈ Land we want to show that w ∈ bX lies in the closure of L. For all n ≥ 0 sufficiently large, the points z−n and w−n lie in the annulus A(0; ρ, 1). Connect z−n and w−n by a curve γ that lies in A(0; ρ, 1). Following the inverse orbit z along the curve γ, we come to a point z′ ∈ Lwhich agrees with w up to z′ −n = w−n. From the definition of d bX, it is clear that as n → ∞, these inverse orbits converge to w. 5.2 Finding a dense horocycle Pick a repelling fixed point ξ on the unit circle. Let r = F′(ξ) be its multiplier; it is real and positive. The leaf Lξ which consists of all backwards orbits that 22tend to ξ is conformally equivalent to H/(·r). Let z ∈ Lξ be a point in this leaf and consider the horocycle H(z) = {hs(z) : s ∈ R} passing through z. The horocycle is just a horizontal line in Lξ ∼= H/(·r). Lifting to the upper half-plane H, we get countably many horizontal lines. Lemma 5.2. The horocycle H(z) is dense in the leaf Lξ and hence dense in the lamination bX. We may view Im H(z) as a number in R+/(·r). Glutsyuk’s idea was to modify the backward orbit z ∈ Lξ to obtain a new orbit w ∈ Lξ with d bX(z, w) small, so that Im H(w) is close to any given number in R+/(·r). By a ξ-homoclinic orbit x ∈ cS1, we mean an inverse orbit ··· →x−3 → x−2 → x−1 → x0, x −n ∈ S1, on the unit circle so that x0 = ξ, lim n→∞ x−n = ξ. We can view the “multiplier” m(x) = lim n→∞ (F◦n)′(x−n) rn as an element of R+/(·r). Lemma 5.3. The multipliers of ξ-homoclinic orbits are dense in R+/(·r). Proof. As explained in [IU23], if F ∈ Λ is a centered one component inner function of finite Lyapunov exponent, which is not z → zd for some d ≥ 2, then the multipliers of repelling periodic orbits on the unit circle span a dense subgroup of R+. For simplicity of exposition, assume that there is a single repelling periodic orbit F◦k(η) = η on the unit circle such that ( F◦k)′(η) and r span a dense subgroup of R+. As the inverse iterates of a point are dense on the unit circle [IU23, Lemma 3.4], for any ε >0, one can find a ξ-homoclinic orbit x which passes within ε of η : ··· →x−3 → x−2 → x−1 → x0, |x−n − η| < ε. 23We can form a new ξ-homoclinic orbit x(p) which starts with x−n → ··· →x−3 → x−2 → x−1 → x0, then follows the periodic orbit F◦k(η) = η for pk steps, where p ≥ 1 is a positive integer, and then follows the tail of x: ··· →x−n−3 → x−n−2 → x−n−1 → x−n → . . . . Above, “to follow an inverse orbit” means to use the same branches of F−1 defined on balls B(ζ, 1 − ρ), centered on the unit circle. By construction, for any given p ≥ 1, we can make m(x(p)) as close to (F◦k)′(η)p ·m(x) as we want by requesting ε >0 to be small. By the assumption on the multiplier of η, the numbers (F◦k)′(η)p · m(x) are dense in R+/(·r). Proof of Lemma 5.2. Let z ∈ Lξ be a backward orbit in the unit disk. We can form a new backward orbit w by keeping z−n+1 → ··· →z−3 → z−2 → z−1 → z0 and approximating ··· →z−n−3 → z−n−2 → z−n−1 → z−n with a ξ-homoclinic orbit ··· →x−3 → x−2 → x−1 → x0. In other words, for m ≥ 0, we replace z−n−m with a point close to x−m. By choosing n ≥ 0 sufficiently large and the ξ-homoclinic orbit appropriately, this construction produces inverse orbits w ∈ Lξ as close to z ∈ Lξ as we want with Im H(w) prescribed to arbitrarily high accuracy in R+/(·r). 5.3 Ergodicity of the horocyclic flow Lemma 5.4. Suppose F ∈ Λ is a centered one component inner function of finite Lyapunov exponent, other than F(z) ̸= zd with d ≥ 2. The horocyclic flow hs on the Riemann surface lamination bX is ergodic. 24Following Coud` ene, fort >0, we define the operators Mtf(z) = ˆ 1 0 f(g−log t(hs(z)))ds (5.1) on the space of uniformly continuous functions UC ( bX). Let Stf(z) = ˆ t 0 f(hs(z))ds denote the integral along the trajectory of the horocyclic flow up to time t. The motivation for the operators (5.1) is the relation Stf(z) t = Mtf(glog t(z)), which follows from (3.4) and a change of variables. Lemma 5.5. Suppose F ∈ Λ is a centered one component inner function of finite Lyapunov exponent, other than F(z) ̸= zd with d ≥ 2. If f is a bounded uniformly continuous function on bX, then the functions {Mtf}t≥0, defined on bX, form a uniformly equicontinuous family. Sketch of proof. The point is that if we do not change the pointz much, we also do not change the horocycle of length t from the point g−log t(z) much. While the length of the horocycle is increasing (we are running it for time t), we are also starting it from the point g−log t(z). Koebe’s distortion theorem implies that the horocycles of length t started at points g−log t(w), with d bX(z, w) < ε, are within O(ε) of one another. Proof of Lemma 5.4. In view of Lemma 5.5, the Arzela-Ascoli theorem tells us that any sequence of functionsMtk f with tk → ∞contains a subsequence that converges uniformly on compact subsets of bX to a function in UC ( bX). Our goal is to show that for a positive functionf ∈ UC ( bX), any accumulation point f of Mtf as t → ∞, is a constant function c = c(f), which would necessarily be ffl bX fdξ . Once we have done this, the rest is easy: as the functions Mtf converge uniformly on compact subsets of bX to c as t → ∞, they also converge to c in L2( bX, dξ). Here we are using that the metric space bX is Polish, which implies that the measure ξ is inner regular on open sets and so there exists 25an increasing sequence of compact sets Kn ⊂ bX such that ξ(Kn) → ξ( bX). Consequently, St(f)/t → c in L2( bX, dξ) and the flow hs is ergodic. Let {tk} be a sequence of times tending to infinity for whichMtk f converges uniformly on compact subsets to an accumulation point f ∈ UC ( bX). Using the invariance of the measure ξ under geodesic flow, we see that lim k→∞ ∥(1/tk)Stk (f) − f ◦ glog tk ∥L2( bX,dξ) = 0. According to von Neumann’s ergodic theorem, there is an hs-invariant L2 function P fon bX such that lim t→∞ ∥(1/t)St(f) − P f∥L2( bX,dξ) = 0. From these two observations and the gt-invariance of ξ, we get: ∥f − P f◦ g−log tk ∥L2( bX,dξ) = ∥f ◦ glog tk − P f∥L2( bX,dξ) → 0, as k → ∞. The commutativity property of the geodesic and horocyclic flows (3.4) shows that P f◦ g−log tk is invariant under the horocyclic flow hs. Therefore, f must also be invariant underhs. As f is a continuous function with a densehs-orbit, it must be constant. The proof is complete. 5.4 Mixing of the geodesic flow We now deduce the mixing of the geodesic flow from the ergodicity of the horocyclic flow: Lemma 5.6. If F ∈ Λ is a centered one component inner function of finite Lyapunov exponent, other than F(z) ̸= zd with d ≥ 2, then the geodesic flow g−t on the Riemann surface lamination bX with respect to the measure ξ is mixing. Proof. For t ∈ R, the Koopman operator [g−t]u = u ◦g−t acts isometrically on L2( bX). For r >0, let Sr(u) be the average of u ◦ hs over s ∈ [−r, r], i.e. Sr(u)(x) = 1 2r ˆ r −r u(hs(x))ds. 26This defines a bounded linear operator Sr : L2( bX) → L2( bX). The commuta- tion relation (3.4) tells us that Sr[g−t] = [g−t]Setr (5.2) as operators on L2( bX). Let u, v∈ Cb( bX) be two bounded continuous functions of zero mean with respect to the measure ξ. Since ξ is invariant with respect to both the horo- cyclic flow hs and the geodesic flow g−t, by using Fubini’s Theorem, we get for every r >0 and t ∈ R that ⟨Sru, [g−t]v⟩ = ⟨u, Sr[g−t]v⟩ = ⟨u, [g−t]Setrv⟩ = ⟨[gt]u, Setrv⟩. (5.3) As ´ bX vdξ = 0, it follows from the ergodicity of the horocyclic flow and von Neumann’s Ergodic Theorem that Setrv → 0 in L2( bX) as t → +∞. Since the set {[gt]u : t ∈ R} is bounded in L2( bX), (5.3) tells us that lim t→+∞ ⟨Sru, [g−t]v⟩ = 0, for any r >0. As lim r→0 ∥u − Sru∥L2( bX) = 0, we also have lim t→+∞ ⟨u, [g−t]v⟩ = 0. The result now follows from the density of Cb( bX) in L2( bX). Part II Background in Geometry and Analysis In this part of the manuscript, we gather some facts from differential geometry and complex analysis that will allow us to study the dynamics of inner functions with finite Lyapunov exponent. 27In Section II, we see use (hyperbolic) geodesic curvature to estimate how much a curve in the unit disk deviates from a radial ray [0 , ζ). In Section 7, we define the M¨ obius distortion of a holomorphic self-mapF of the unit disk and use it to estimate the curvature of F([0, ζ)). In Section 8, we give another interpretation of the M¨ obius distortion in terms of how much F−1 expands the hyperbolic metric and define the linear distortion of F. Finally, in Section 9, we give a bound on the total linear distortion of F along [0 , ζ) in terms of the angular derivative |F′(ζ)|, from which we conclude that ifF is an inner function with finite Lyapunov exponent then the total linear distortion of F on the unit disk is finite. 6 Curves in Hyperbolic Space We first recall the definition and basic properties of geodesic curvature in the Euclidean setting. Suppose γ : [a, b] → R2 is a C2 curve, parameterized with respect to arclength. Its curvature κEuc(γ; t) = ∥γ′′(t)∥ measures the rate of change of the tangent vector of γ. The signed curvature κs, Euc(γ; t) = ±κEuc(γ; t) also takes into account if γ is turning left or right. It is well known that a curve is uniquely determined (up to an isometry) by its signed curvature, e.g. see [Pre10, Theorem 2.1]. Example. A circle of radius R has constant curvature 1/R. The signed curva- ture is either −1/R or 1/R depending on the orientation of γ. We now turn our attention to the hyperbolic setting. Letγ : [a, b] → D be a C2 curve, parametrized with respect to hyperbolic arclength. The hyperbolic geodesic curvature κhyp(γ; t) measures how much γ deviates from a hyperbolic geodesic at γ(t). We now describe a convenient way to compute κhyp(γ; t). Suppose first γ passes through the origin, e.g. γ(t0) = 0 for some t0 ∈ [a, b]. As the hyperbolic metric osculates the Euclidean metric to order 2 at the origin, but is twice as large there, the hyperbolic geodesic curvature of γ is half the Euclidean geodesic curvature of γ. One may compute the hyperbolic geodesic curvature at other points by means of Aut( H) invariance. 28Example. (i) Hyperbolic geodesics have zero geodesic curvature. (ii) To compute the curvature of a horocycle, we may assume that the horocycle passes through the origin and compute its curvature there. Since a horocycle which passes through the origin is a circle of Euclidean radius 1/2, its Euclidean geodesic curvature at the origin is 2. Consequently, every horocycle has constant hyperbolic geodesic curvature 1. (iii) Curves of constant hyperbolic geodesic curvatureκ ∈ (0, 1) are circular arcs which cut the unit circle at two points at an angle θ ∈ (0, π/2) with κ = cos θ. The following two lemmas are well-known: Lemma 6.1.If γ : [a, b] → D is a C2 curve with hyperbolic geodesic curvature κhyp(γ; t) ≤ 1, then γ is a simple curve. Lemma 6.2.If γ : [a, b] → D is a C2 curve with hyperbolic geodesic curvature κhyp(γ; t) ≤ c <1, then γ lies within a bounded hyperbolic distance of some geodesic. We also record the following comparison theorem: Theorem 6.3.Suppose γ : [a, ∞) → D is a C2 curve with hyperbolic geodesic curvature κhyp(γ; t) ≤ κ ≤ 1. Let γ1, γ2 : [a, ∞) → D be curves with constant signed geodesic curvatures κ and −κ respectively that have the same tangent vector at t = a, i.e. γ1(a) = γ2(a) = γ(a), γ ′ 1(a) = γ′ 2(a) = γ′(a). Then, γ lies between γ1 and γ2. 6.1 Inclination from the Vertical Line We now switch to the upper half-plane model of hyperbolic geometry. In this section, we assume that γ : [a, ∞) → H is a C2 curve of curvature κ ≤ 0.2, parametrized with respect to arclength. For any a ≤ t <∞, we can look at the tangent vector γ′(t) to γ at the point γ(t). We define α(t) ∈ [0, π] to be the angle that γ′(t) makes with the downward pointing vector field v↓ = −y · ∂ ∂y . 29  if I Figure 1: Inclination from the vertical line We first describe the behaviour of α(t) when γ is a hyperbolic geodesic in the upper half-plane. Inspection shows that the derivative α′(t) ≤ 0, where equality holds if and only if γ is a vertical line, pointing straight up or straight down. If γ is not a vertical line, then α(t) satisfies the differential equation α′(t) = −G(α(t)), for some non-negative differentiable function G : [0, π] → R, which vanishes only at the endpoints. (The function G does not depend on the geodesic γ since any two non-vertical geodesics in the upper half-plane are related by a mapping of the form z → Az+B with A >0 and B ∈ R.) For future reference, we note that G′(0) > 0. Lemma 6.4. Suppose γ : [ a, b] → H is a piece of a hyperbolic geodesic. If α(a) ≤ 2π/3, then ˆ b a α(t) ≲ α(a), (6.1) where the implicit constant is independent of b. Proof. From the discussion above, it follows that α(t) satisfies the differential inequality α′(t) ≤ −c1α(t), t ∈ [a, ∞), for some c1 > 0. In view of Gr¨ onwall’s inequality,α(t) decreases exponentially quickly, which clearly implies (6.1). We now turn to investigating α(t) for general curves γ with small geodesic curvature. We begin with the following preliminary observation: 30Lemma 6.5. If γ : [a, ∞) → H is a C2 curve parametrized with respect to hyperbolic arclength with curvature κ ≤ 0.2. If α(a) < 2π/3, then α(t) ≤ 2π/3 for all t ∈ [a, ∞). Sketch of proof. From the discussion above, a straight line in the upper half- plane with α(t) = 2π/3 has constant curvature κ = p 3/2 > 0.2. By Theorem 6.3, if α(t) = 2 π/3 then α′(t) ≤ 0. Consequently, α(t) cannot rise above 2π/3. Lemma 6.6. If γ ⊂ H is a C2 curve parametrized with respect to hyperbolic arclength, with curvature ≤ 0.2, then α′(t) ≤ −G(α(t)) + 4κhyp(γ; t). Sketch of proof. We have seen that at the origin, the hyperbolic metric is twice as large as the Euclidean metric. As a result, the parametrization with respect to the hyperbolic arclength is twice as fast as with Euclidean arclength. In addition, the Euclidean geodesic curvature is twice as large as the hyperbolic geodesic curvature. Consequently, the instrinsic change in the direction of the tangent vector γ′(t) is four times the signed hyperbolic geodesic curvature. However, in hyperbolic geometry, we must also account for the fact that geodesics naturally change direction with respect to the vertical, which is de- scribed by the first term in the equation above. To conclude this section, we extend Lemma 6.4 to the case of small geodesic curvature: Lemma 6.7. Suppose γ : [a, b] → H has geodesic curvature at most 0.2. If α(a) ≤ 2π/3, then ˆ b a α(t) ≲ α(a) + ˆ b a khyp(γ; t). Proof. From the lemma above, it follows that α′(t) ≤ −c1α(t) + 4κhyp(γ; t), (6.2) 31for some c1 > 0. Gr¨ onwall’s inequality shows that α(t) ≤ e−c1t \u0012 α(a) + 4 ˆ t a ec1s · κhyp(γ; s)ds \u0013 , for all t ∈ [a, b]. Integrating over t proves the result. 7 M¨ obius Distortion Let λD = 2 1−|z|2 be the hyperbolic metric on the unit disk. A holomorphic self-map F of the unit disk naturally defines the pullback metric λF = F∗λD = 2|F′(z)| 1 − |F(z)|2 . With the above definition, if γ ⊂ D is a rectifiable curve, then the hyperbolic length of F(γ) is ´ γ λF . By the Schwarz lemma, µF (z) := 1−(λF /λD)(z) is zero if and only if F is a M¨ obius transformation. In general, for anya ∈ D, the M¨ obius distortionµF (a) measures how much F deviates from being a M¨ obius transformation near a. A normal families argument shows that when µF (a) is small, F is close to a M¨ obius transformationm ∈ Aut(D) near a. The following lemma provides a more quantitative estimate: Lemma 7.1. Let F be a holomorphic self-map of the unit disk. For any R, ε >0, there exists a δ >0, so that if µF (a) < δ, a ∈ D, then on Bhyp(a, R), F is univalent and dD \u0000 F(z), m(z) \u0001 < εfor some M¨ obius transformationm ∈ Aut(D) which takes a to F(a). Furthermore, for a fixed R >0, δ can be taken to be comparable to ε. The argument below is taken from [McM09, Proposition 10.9]: Proof. By M¨ obius invariance, we may assume that a = F(a) = 0 and 0 ≤ F′(0) ≤ 1. For convenience, we abbreviate µ = µF (0) = 1 − F′(0). Applying the Schwarz lemma to F(z)/z shows that the hyperbolic distance dD(F(z)/z, F′(0)) = O(1), for z ∈ Bhyp(0, R+ 1). 32Taking note of the location of F′(0) ∈ D, this implies that |F(z) − z| = O(µ) on Bhyp(0, R+ 1). Cauchy’s integral formula then tells us that |F′(z) − 1| = O(µ), |F′′(z)| = O(µ), for z ∈ Bhyp(0, R). From here, the lemma follows from the definition of the M¨ obius distortion and some arithmetic. Lemma 7.2.Suppose γ is a hyperbolic geodesic in the unit disk passing through z ∈ D. Let F(γ) be the image of γ under a holomorphic self-map F of the unit disk. Then the geodesic curvature of F(γ) at F(z) is bounded by min \u0000 1, κF(γ)(F(z)) \u0001 ≲ µ(z). Proof. By M¨ obius invariance, one can consider the case when γ = [ −1, 1], z = 0, F(0) = 0 and F′(0) > 0. Arguing as in the proof of Lemma 7.1, we get |F′′(0)| = O(µ) where µ = 1 − F′(0). Therefore, F(γ) lies in a wedge \b x + iy : |y| < Cµx2\t near z = 0, which gives the desired curvature bound. The same argument shows: Lemma 7.3 (Stability of µ under perturbations) . There exists a constant K >0 so that any holomorphic self-map F of the unit disk, |∇hypµ(a)| ≤Kµ(a), a ∈ D. In particular, for any two points a, b∈ D, we have e−KdD(a,b)µ(a) ≤ µ(b) ≤ eKdD(a,b)µ(a). For a finer estimate, we refer the reader to [BM07, Corollary 5.7]. Hyperbolic expansion factor. Suppose F is a holomorphic self-map of the unit disk. By the Schwarz lemma, the hyperbolic expansion factor E(a) := ∥F′(a)∥−1 hyp ≥ 1. The hyperbolic expansion factor could be infinite if a is a critical point of F. The hyperbolic expansion factor is related to the M¨ obius distortion via E(a) = 1 1 − µ(a). As a result, the two quantities are essentially interchangeable. 338 Linear Distortion Recall that the downward pointing vector field v↓ = −y · ∂ ∂y assigns each point in H a vector of hyperbolic length 1 which points toward the real axis. By the Schwarz lemma, the quotient p(z) = F∗v↓(z) v↓(F(z)) ∈ D. We consider the following quantities: • M¨ obius distortion:µ = 1 − |p|. • Linear distortion: δ = |1 − p|. • Vertical inefficiency: η = Re(1 − p). • Vertical inclination: α = |arg p| ∈[0, π).   act i t r p a t i 2 Figure 2: Notions of distortion In practice, estimating δ(a) directly is rather difficult. From the picture above, it is clear that α(a) + η(a) ≥ δ(a), which allows us to estimate lin- ear distortion by estimating the vertical inefficiency and vertical inclination separately. For a holomorphic self-map of the upper half-plane F, the linear distortion δF (a) measures how much F deviates from the unique linear map La→F(a) ∈ Aut(H, ∞) which takes a to F(a). Evidently, the linear distortion is zero if and only if F = La→F(a). Similarly to Lemma 7.1, we have: 34Lemma 8.1. Let F be a holomorphic self-map of the upper half-plane. For any R, ε >0, there exists a δ > 0, so that if δF (a) < δ, a ∈ H, then on BH hyp(a, R), F is univalent and dH \u0000 F(w), La→F(a)(w) \u0001 < ε. Furthermore, for a fixed R >0, δ can be taken to be comparable to ε. Proof. By Aut(H, ∞) invariance, we may assume that a = F(a) = i. In view of Lemma 7.1, F is injective on the ball BH hyp(a, R), where it resembles an elliptic M¨ obius transformation in Aut(H) which fixes i ∈ H. We need to show that F is close to the identity mapping. Let mD→H be a M¨ obius transformation which mapsD to H and takes the tangent vector (∂/∂x)(0) to v↓(i). As δF (i) < δ, the composition G = mH→D ◦ F ◦ mD→H defines a holomorphic self-map of the unit disk withG(0) = 0 and |G′(0)−1| = O(δF (i)). Following the proof of Lemma 7.1, we see that |G(z)−z| = O(δF (i)) for z ∈ Bhyp(0, R), which in the upper half-plane translates to |F(w) − w| = O(δF (i)), for w ∈ BH hyp(i, R), (8.1) as desired. Lemma 8.2. In the lemma above, we may choose δ ≍ ε so that (1 − ε) · 1 Im w < |F′(w)|2 Im F(w) < (1 + ε) · 1 Im w, (8.2) for any w ∈ BH hyp(a, R). Proof. We continue to use the normalization a = F(a) = i. In view of (8.1) and Cauchy’s integral formula, there exists a constant C >0 depending only on R so that 1 − CδF (i) < |F′(w)| < 1 + CδF (i), for any w ∈ BH hyp(a, R− 1). Together with (8.1), this shows (1 − C′δF (i)) · 1 Im w < |F′(w)|2 Im F(w) < (1 + C′δF (i)) · 1 Im w, for some constantC′ > 0 which also only depends onR. To obtain the corollary as stated, we work with R + 1 in place of R and divide δ by a constant if necessary so that C′δ < ε. 35Lemma 8.3 (Stability of δ under perturbations) . There exists a constant K >0 such that for any holomorphic self-map F of the upper half-plane, |∇hypδ(a)| ≤Kδ(a), a ∈ H. In particular, for any two points a, b∈ H, we have e−KdD(a,b)δ(a) ≤ δ(b) ≤ eKdD(a,b)δ(a). Proof. Since we have already estimated |∇hypµ(a)| in Lemma 7.3, it remains to control the gradient of the angular inclination |∇hypα(a)|. By Aut( H, ∞) invariance, we may assume that a = F(a) = i. We may also assume that δ(i) < 1/2, otherwise the lemma is trivial, in which case, |F′(i)| ≍1 and the gradient |∇α(i)| = |∇arg F′(i)| is controlled by the second derivative |F′′(i)|. As in the proof of Lemma 8.1, we have |F(w) − w| = O(δ(i)) for w ∈ BH hyp(i, 1). An application of Cauchy’s integral formula gives the desired esti- mate |F′′(i)| = O(δ(i)). Working in the unit disk. For a centered holomorphic self-map F of the unit disk, one can define the notions of δ, η, αusing the radial vector field vrad(z) = 2 1−r2 · ∂ ∂r , which assigns each point in D \\ {0} an outward pointing vector of hyperbolic length 1. Note that δ, η, αare only defined when a, F(a) ̸= 0 and as a result are somewhat awkward to work with. Nevertheless, near the unit circle, δ, η, αresemble their counterparts in the upper half-plane. Assuming that a, F(a) ̸= 0, the radial distortion δF (a) measures how much F deviates from ma→F(a) near a, the “straight” M¨ obius transformation which takes a → F(a), a |a| → F(a) |F(a)|, − a |a| → −F(a) |F(a)|. To ensure that F is close to the linear map ℓa→F(a) which takes a → F(a) and a |a| → F(a) |F(a)| on Bhyp(a, R), we will often ask that 1 −|F(a)| < δ/eR in addition to δF (a) < δ. 9 Distortion Along Radial Rays Suppose F is a holomorphic self-map of the unit disk. Recall that F has an angular derivative at ζ ∈ ∂D in the sense of Carath´ eodory if F(ζ) := 36limr→1 F(rζ) belongs to the unit circle and F′(ζ) := lim r→1 F′(rζ) is finite. The following theorem says that the logarithm of the angular derivative at ζ controls the total linear distortion along the radial geodesic [0 , ζ): Theorem 9.1.Suppose F is a holomorphic self-map of the disk with F(0) = 0. If F has an angular derivative at ζ ∈ ∂D, then ˆ ζ 0 δ dρ≲ log |F′(ζ)|. (9.1) In particular, if F is an inner function with finite Lyapunov exponent, ˆ D δ(z) · dA(z) 1 − |z| ≲ ˆ ∂D log |F′(reiθ)|dm. (9.2) In view of the inequalityα(z)+η(z) ≥ δ(z), we may split the proof Theorem 9.1 into two lemmas: Lemma 9.2.Suppose F is a holomorphic self-map of the disk with F(0) = 0. If F has an angular derivative at ζ ∈ ∂D, then ˆ ζ 0 η dρ≤ log |F′(ζ)|. (9.3) Lemma 9.3.Suppose F is a holomorphic self-map of the disk with F(0) = 0. If F has an angular derivative at ζ ∈ ∂D, then ˆ ζ 0 α dρ≲ log |F′(ζ)|. (9.4) 9.1 Bounding the radial inefficiency We first estimate the radial inefficiency: Proof of Lemma 9.2. Let ζ be a point on the unit circle whereF has an angular derivative. Join the points 0 and ζ by a hyperbolic geodesic γ = [0, ζ). The image F(γ) is a curve which connects 0 to F(ζ) ∈ ∂D. From the definition of the radial inefficiency, it is clear that ˆ ζ 0 η dρ≤ lim r→1 \b dD(0, rζ) − dD(0, F(rζ)) \t = log |F′(ζ)|, as desired. 37In view of the elementary estimate µ ≤ η and Lemma 7.2, the total M¨ obius distortion and geodesic curvature are finite along F([0, ζ)): Corollary 9.4. Suppose F is a holomorphic self-map of the disk with F(0) = 0. If F has an angular derivative at ζ ∈ ∂D, then ˆ ζ 0 µ dρ≤ log |F′(ζ)|. and ˆ ζ 0 min \u0000 1, κF([0,ζ))(F(z)) \u0001 dρ(z) ≲ log |F′(ζ)|. Below, we will use the following lemma which follows from compactness: Lemma 9.5. There exists a δ >0 so that for any holomorphic self-map F of the unit disk and any point z ∈ D with dD(0, z) ≥ 1, we have η(z) < 0.1 = ⇒ η(w) < 0.15, w ∈ Bhyp(z, δ). 9.2 Bounding the radial inclination To complete the proof of Theorem 9.1, it remains to estimate the radial in- clination. We parametrize the radial geodesic γ(t) = [0 , ζ) with respect to arclength. We break up ( γ(1), γ(∞)) into a union of thick and thin intervals. By a thin interval (γ(pi), γ(qi)) ⊂ (γ(1), γ(∞)), we mean a maximal interval for which η(γ(pi)) < 0.1 and η(γ(qi)) < 0.2. The thick intervals are then defined as the connected components of the complement of the thin intervals. In view of Lemma 9.5, the hyperbolic length of a thin interval is bounded from below. Therefore, by Lemma 9.2, the number of thin intervals n(ζ) ≲ log |F′(ζ)|. As thin and thick intervals alternate, the number of thick intervals is also ≲ log |F′(ζ)|. Proof of Lemma 9.3. Since η(t) ≥ 0.1 on any thick interval, by Lemma 9.2, the sum of the hyperbolic lengths of the thick intervals is ≲ log |F′(ζ)|, so that X γi thick ˆ γi α dρ≲ log |F′(ζ)|. From the definitions of the radial inclination and the radial inefficiency, it follows that on a thin interval α(t) ≤ |arg(0.8 + 0.2i)| ≈0.644 < 2π/3, so that 38Lemma 6.7 is applicable (see the remark below). Together with Corollary 9.4, this shows X γi thin ˆ γi α dρ≲ n(ζ) + nX i=1 ˆ γi κ dρ≲ log |F′(ζ)|. The proof is complete. Remark. Actually, one needs to be a bit more precise in the proof above since Lemma 6.7 is stated on the upper half-plane. On the unit disk, one can only apply Lemma 6.7 as long as one is working sufficiently close to the unit circle. As η(z) < 0.2 on a thin interval, F(z) moves towards the unit circle at a definite rate, so after O(1) time, Lemma 6.7 will indeed be applicable. The waiting time contributes at most O(1) to each integral ´ γi α dρover a thin interval γi. Part III General Centered Inner Functions of Finite Lyapunov Exponent In this part, F will denote an arbitrary centered inner function of finite Lya- punov exponent, other than a rotation. In Section 10, we define the M¨ obius and linear laminations bXmob and bXlin associated to F and describe the geodesic and horocyclic flows on bXlin. To be fair, the term “lamination” is not entirely accurate here as bXlin and bXmob may not locally be product sets. In Section 11, we construct a natural volume form dξ on bX. According to Theorem 11.2, the total volume of bX is just the Lyapunov exponent of F. From the finiteness of volume, it follows that iteration along almost every backward orbit is asymptotically M¨ obius, i.e.ξ( bX \\ bXmob) = 0. In Section 12, we improve this to asymptotically linearity, i.e. ξ( bX \\ bXlin) = 0. 39In Section 13, we study how the trajectories of the geodesic flow foliate bDlin and conclude that the geodesic flow on bXlin is ergodic. Finally, in Section 14, we apply the ergodic theorem to a slight modification of the almost invariant function from Section 4.2 to prove Theorem 1.2. 10 M¨ obius and Linear Laminations For a general centered inner function, the lamination bX = bD/ bF defined in Section 3 has limited use. In this section, we describe two subsets bXmob = bDmob / bF and bXlin = bDlin / bF , which we refer to as the M¨ obius and linear laminations ofF respectively. Here, bDmob ⊂ bD is the collection of inverse orbits z = (z−n)∞ n=0 on which backward iteration is asymptotically M¨ obius: µF◦m(z−m−n) → 0, as m, n→ ∞, while bDlin ⊂ bD consists of inverse orbits on which backward iteration is asymp- totically linear: δF◦m(z−m−n) → 0, as m, n→ ∞. (As δF◦m(z−m−n) is small, F◦m is close to a straight M¨ obius transformation near z−m−n. Asymptotic linearity follows from the fact that |z−n| →1.) Since µ ≤ δ, it is clear that bXlin ⊂ bXmob ⊂ bX. On the set bXmob ⊂ bX, one can define a leafwise hyperbolic Laplacian and study mixing properties of hyperbolic Brownian motion, but we will not pursue this here. On bXlin ⊂ bX, one can define geodesic and horocyclic flows as in Section 3. 10.1 Rescaling along inverse orbits Inspection shows that a backward orbit z = (z−n)∞ n=0 ∈ bD belongs to bDmob if and only if there exists a sequence of M¨ obius transformationsm−N ∈ Aut(D), N ∈ N, with m−N (0) = z−N 40for which the sequence (F◦N ◦ m−N )∞ N=0 converges uniformly on compact subsets of the unit disk as N → ∞. In this case, we denote the limiting map by Fz,0. In fact, when Fz,0 exists, so does Fz,−n = lim N→∞ F◦(N−n) ◦ m−N , for any n ∈ N, and (Fz,−n(w))∞ n=0 defines an inverse orbit in bDmob for any w ∈ D. We say that a backward orbit w = (w−n)∞ n=0 lies in the same leaf of bDmob as z = (z−n)∞ n=0 if there is a w ∈ D such that w−n = Fz,−n(w), for all integers n ∈ N. For a point p ∈ D \\ 0, we write Mp for the conformal map from H to D which takes 0 → p |p|, i → p, ∞ → −p |p|. Similarly, a backward orbit z = (z−n)∞ n=0 ∈ bD belongs to bDlin if and only if for some (and hence any) n ∈ N, the sequence of rescaled iterates F◦(N−n) ◦ Mz−N , converges uniformly on compact subsets of H as N → ∞. We denote the limiting maps by Fz,−n := lim N→∞ F◦(N−n) ◦ Mz−N . We partition bDlin into a union of leaves analogously to bDmob. Lemma 10.1. Two inverse orbits z = ( z−n)∞ n=0 and z′ = ( z′ −n)∞ n=0 in bDlin belong to the same leaf L ⊂bDlin if and only if \u0000 dD(z−n, z′ −n))∞ n=0 is uniformly bounded. In this case, the leafwise hyperbolic distance dL(z, z′) = lim n→∞ dD(z−n, z′ −n). We define the geodesic and horocyclic flows on bDlin by the following for- mulas: gt(z)−n := Fz,−n(et · i), t ∈ R 41and hs(z)−n := Fz,−n(i + s), s ∈ R. Clearly, the (−n)-th coordinates of geodesic trajectories which foliate the leaf L(z) ⊂ bDlin containing z are images of vertical geodesics {w ∈ H : Re w = x} under Fz,−n. The choices of basepoints 0 ∈ D and i ∈ H in the definitions above are of course arbitrary. Remark. For a general centered inner function, the laminations bXmob and bXlin could be empty. For instance, there exists a centered inner function F whose critical set forms a net, i.e. there exists an R >0 so that any point in the unit disk is within hyperbolic distance R of a critical point. However, in view of Jensen’s formula, F does not have a finite Lyapunov exponent. 10.2 Cumulative distortion We now introduce some notions which allow us to check whether an inverse orbit z lies in bDmob or bDlin. We denote the cumulative hyperbolic expansion factor by E(w, z) = ∥(F◦n)′(w)∥−1 hyp if F◦n(w) = z and E(w) = E(w, z) = lim n→∞ ∥(F◦n)′(w−n)∥−1 hyp if w = (w−n)∞ n=0 ∈ bD is an inverse orbit with w0 = z. It is easy to see that w ∈ bDmob if and only if E(w) < ∞. We denote the cumulative linear distortion along an inverse orbit z ∈ bD by bδF (z) := ∞X n=1 δF (z−n). (10.1) Lemma 10.2. Suppose F and G are holomorphic self-maps of the unit disk. For a point a ∈ D such that a, G(a), F(G(a)) ̸= 0, we have δF◦G(a) ≤ δF (G(a)) + δF (a). 42In particular, if a, F(a), . . . , F◦n−1(a) ̸= 0, then δF◦n(a) ≤ n−1X k=0 δF (F◦k(a)). Proof. Notice that if p, q∈ D, then |1 − pq| = |1 − p| + |p − pq| ≤ |1 − p| + |1 − q|. The lemma follows from the above identity, with p = G∗vrad(a) vrad(G(a)) and q = F∗vrad(G(a)) vrad(F(G(a))), as δG(a) = |1 − p|, δF (G(a)) = |1 − q| and δF◦G(a) = |1 − pq|. From the lemma above, it is clear that if bδF (z) < ∞, then z ∈ bDlin. 11 Area on the Lamination Throughout this section, F will be a centered inner function with finite Lya- punov exponent. For a measurable set A compactly contained in the unit disk, we write bA for the collection of inverse orbits z with z0 ∈ A. We define an bF-invariant measure ξ on bD by specifying it on sets of the form bA ⊂ bD in a consistent manner: ξ( bA) = lim n→∞ 1 2π ˆ F−n(A) log 1 |z| dAhyp(z). (11.1) In order to show that the limit in (11.1) exists, we check that the numbers ˆ F−n(A) log 1 |z| dAhyp are increasing and uniformly bounded above. This follows from Lemma 11.1 and Theorem 11.2 below: Lemma 11.1. For a measurable subset E of the unit disk, ˆ F−1(E) log 1 |z| dAhyp ≥ ˆ E log 1 |z| dAhyp. 43Proof. A change of variables shows that ˆ F−1(E) log 1 |w| dAhyp(w) = ˆ E \u001a X F(w)=z ∥F′(w)∥−2 hyp log 1 |w| \u001b dAhyp(z) By the Schwarz lemma and Lemma 2.1, this is ≥ ˆ E \u001a X F(w)=z log 1 |w| \u001b dAhyp(z) = ˆ E log 1 |z| dAhyp as desired. Theorem 11.2. The total mass ξ( bX) = ´ S1 log |F′(z)|dm. Proof. Since F has an angular derivative a.e. on the unit circle, for any ε >0, there is a Borel set Aε ⊂ S1 with m(Aε) ≥ 1 − ε and an 0 < r0 = r0(ε) < 1 so that |F(reiθ) − F(eiθ) − (1 − r)F′(eiθ)| < ε(1 − r), for all eiθ ∈ Aε and r ∈ [r0, 1). Consider the set eAε = \u001a reiθ ∈ D : eiθ ∈ Aε, r0 ≤ r ≤ 1 − 1 − r0 |F′(eiθ)| −ε \u001b , where we use the convention that |F′(eiθ)| = ∞ if the angular derivative does not exist. By construction, the image F( eAε) is contained in the ball B(0, r0) so that eAε does not intersect any of its forward iterates. Therefore, by Lemma 11.1, ξ( bX) ≥ 1 2π ˆ eAε log 1 |z| dAhyp ≥ ˆ Aε (log |F′(eiθ)| −ε)dm. Taking ε → 0 proves the lower bound. For the upper bound, suppose that E is a subset of the unit disk which is disjoint from its backward iterates. We want to show that 1 2π ˆ E log 1 |z| dAhyp ≤ ˆ S1 log |F′(z)|dm. Truncating E if necessary, we may assume thatE is contained in a ballB(0, r0) for some 0 < r0 < 1. Consider the set E∗ = F−1(B(0, r0)) \\ B(0, r0). By construction, ˆ E log 1 |z| dAhyp ≤ ˆ E∗ log 1 |z| dAhyp. 44By Lemma 2.3, the set E∗ is contained in the union of E∗ 1 = \u001a reiθ ∈ D : eiθ ∈ Aε, r0 ≤ r ≤ 1 − 1 − r0 |F′(eiθ)| + ε \u001b and E∗ 2 = \u001a reiθ ∈ D : eiθ /∈ Aε, r0 ≤ r ≤ 1 − 1 − r0 4|F′(eiθ)| \u001b , so that 1 2π ˆ E∗ log 1 |z| dAhyp ≤ 1 2π ˆ E∗ 1 log 1 |z| dAhyp + 1 2π ˆ E∗ 2 log 1 |z| dAhyp. The theorem follows after taking ε → 0. 11.1 M¨ obius structure We will deduce the following theorem from the finiteness of the area of the Riemann surface lamination: Theorem 11.3 (M¨ obius structure). Backward iteration along ξ a.e. inverse orbit is asymptotically close to a M¨ obius transformation, i.e. ξ(bD \\ bDmob) = 0. Suppose z ∈ D is a point in the unit disk, which is not contained in the forward orbit of an exceptional point so that cz is a probability measure on T(z), see Section 3.1 for the relevant definitions. We fix a constant 0 < γ≤ 1 for which Lemma 2.4 holds. Then for any ball B = Bhyp(z, γ) with dD(0, z) > 1 + γ, the natural projection from bD → bX is injective on bB. Proof. From the definition of the measure ξ, we have ξ( bB) = ˆ B Ψ(z′) log 1 |z′| dAhyp(z′) where Ψ(z′) = lim n→∞ X F◦n(w′)=z′ log 1 |w′| · ∥(F◦n)′(w′)∥−2 hyp = ˆ T(z′) E(w′, z′)2 dcz′(w′) 45is the average area expansion factor . Since ξ is a finite measure, Ψ( z′) < ∞ for Lebesgue a.e. z′ ∈ B and E(w′, z′) < ∞ for ξ a.e w′ ∈ bB. As discussed in Section 7, this implies that w′ ∈ bDmob. The theorem follows from the observation that countably many sets of the form bB cover bX. 11.2 M¨ obius decomposition theorem We say that a repeated pre-image w of z is ε-(M¨ obius good) if the hyperbolic expansion factor 1 ≤ ∥(F◦n)′(w)∥−1 hyp < 1 + ε, where F◦n(w) = z. In view of Lemma 7.1, when ε >0 is sufficiently small, the connected compo- nent of F−n(B) containing w maps conformally onto B under the dynamics of F. Naturally, we call it Bw. By shrinking ε >0 further, we may assume that 1 ≤ ∥(F◦n)′(q)∥−1 hyp < 2, for any q ∈ Bw. Similarly, we say that an inverse orbit w ∈ T(z) is ε-(M¨ obius good) if 1 ≤ ∥(F◦n)′(w−n)∥−1 hyp < 1 + ε, for any integer n ∈ N. We define bBε-M.good := [ w∈Tε-M.good(z) Bw, where w ranges over Tε-M.good(z), the set of ε-(M¨ obius good) inverse orbits with w0 = z. On bBε-M.good, the measure ξ is comparable to the product measure log 1 |q| dAhyp(q) | {z } on B × cz|{z} on Tε-M.good(z) . (11.2) Remark. In the one component case, the Riemann surface lamination bX is locally a product space. The “charts” bBε-M.good may be viewed as substitutes of the product sets bB from the one component setting. 46We say that a point z ∈ D is ε-(M¨ obius nice) if most inverse branches w ∈ T(z) are ε-(M¨ obius good): cz(Tε-M.good(z)) > 1 − ε, which is the same as asking that X F◦n(w)=z, n≥0 w ε-M.good log 1 |w| > (1 − ε) log 1 |z|, for any n ≥ 0. Theorem 11.4(M¨ obius decomposition theorem). For a centered inner func- tion F with finite Lyapunov exponent, the following two assertions hold: (a) For any ε >0 and almost every point z ∈ D, there exists an n ≥ 0 so that X F◦n(w)=z w is ε-M.nice log 1 |w| > (1 − ε) · log 1 |z|. (11.3) (b) For any ε > 0, one can find finitely many ε-(M¨ obius nice) points z1, z2, . . . , zN , so that the sets bBi, ε-M.good, i = 1, 2, . . . , N, cover bX up to ξ-measure ε, i.e. ξ \u0012 bX \\ N[ i=1 bBi, ε-M.good \u0013 < ε. Proof. (a) Suppose w ∈ T(z) is a backward orbit. By the Schwarz lemma, the numbers E(w−n, z) increase to E(w, z) as n → ∞, which may be infinite. Consequently, if (11.3) fails at a point z ∈ D for all n ≥ 0, then for at least cz measure ε backward orbits w ∈ T(z), the area expansion factor E(w, z) = ∞. In this case, the average area expansion factor Ψ( z) = ∞. However, in the proof of Theorem 11.3, we saw that Ψ( z) < ∞ a.e., so (11.3) can only fail on a set of Lebesgue measure zero. (b) If z ∈ D is not ε-(M¨ obius nice), then ξ \u0000 bBhyp(z, γ) \u0001 > Θ ˆ Bhyp(z,γ) log 1 |z| dAhyp, 47for some Θ( ε) > 1. An examination of the proof of Theorem 11.2 shows that for any η >0, ˆ E∗ log 1 |z| dAhyp ≥ (1 − η) ˆ S1 log |F′(z)|dm, where E∗ = F−1(B(0, r0)) \\ B(0, r0) and 0 < r0 < 1 is sufficiently close to 1. Therefore, by asking for r0 to be sufficiently close to 1, we can make the log 1 |z| dAhyp(z) area of S = {z ∈ E∗ : z is not ε-M. nice} as small as we wish. We may choose finitely many ε-(M¨ obius nice) points {zi}N i=1 in E∗ \\ S such that the balls of hyperbolic radius γ centered at these points cover E∗ \\ S up to small log 1 |z| dAhyp(z) measure. Consequently, the sets bBhyp(zi, γ), i = 1, 2, . . . , N, cover bX up to small measure. 12 Linear structure In this section, we show that backward iteration along almost every inverse orbit is asymptotically linear: Theorem 12.1(Linear structure). For ξ a.e. inverse orbit z = (z−i)∞ i=0 ∈ bD, the cumulative linear distortion bδ(z) < ∞. Consequently, ξ(bD \\ bDlin) = 0. Proof. In view of Theorem 11.4, we may show that bδ(w) < ∞ for a.e. inverse orbit w ∈ bBε-M.good where B = Bhyp(z, γ) is a ball centered at an ε-(M¨ obius nice) point z ∈ D. Let eBε-M.good ⊂ D be the union of topological disks Bw, where w ranges over the repeated pre-images of z with E(w, z) < 1 + ε. We may assume that ε >0 is sufficiently small so that E(w, z) < 1 + ε implies that E( ˜w, ˜z) < 2 for any ˜w ∈ Bw and ˜z ∈ B. By Theorem 9.1, we have ˆ bBε-M.good bδ(w)dξ ≤ 4 ˆ eBε-M.good δ(w) · log 1 |w| dAhyp(w) 48≲ ˆ D δ(z) · log 1 |w| dAhyp(w) ≲ ˆ ∂D log |F′(reiθ)|dm < ∞, which shows that bδ(w) is finite ξ almost everywhere. By the discussion in Section 10.2, ξ gives full mass to bDlin ⊂ bD. Corollary 12.2. Let z = (z−i)∞ i=0 ∈ bD be a generic backwards orbit. For any R, ε >0, there exists an n0 = n0(z, ε, R) > 0 sufficiently large so that for any n > m≥ n0, the inverse branch gm,n of Fm−n : z−m → z−n is well-defined on Bhyp(z−m, R), where it is within hyperbolic distance O(ε) of the linear map ℓm,n ∈ Aut(C) which takes z−m → z−n and z−m |z−m| → z−n |z−n|. Proof. For an inverse orbit z = ( z−i)∞ i=0 with bδ(z) < ∞, we choose n0 = n0(z, ε, R) sufficiently large so that ∞X n=n0+1 δ(z−i) < ε and 1 − |z−n0 | < ε/eR. In view of Lemma 7.1, gm,n is well-defined on Bhyp(z−m, R), where it is within hyperbolic distance O(ε) of the straight M¨ obius transformation in Aut( D) which takes z−m → z−n. The second condition 1 − |z−n0 | < ε/eR ensures that gm,n is within hyperbolic distance O(ε) of ℓm,n on Bhyp(z−m, R). A similar argument involving Lemma 8.2 shows: Corollary 12.3. In the above corollary, we can select n0 = n0(z, ε, R) > 0 sufficiently large so that ˆ gm,n(E) log 1 |z| dAhyp(z) ∼ε ˆ E log 1 |z| dAhyp(z), for any measurable set E ⊂ Bhyp(z−m, R), where the notation A ∼ε B indicates that (1 − Cε)A ≤ B ≤ (1 + Cε)A for some constant C > 0, which depends only on R. 4912.1 Linear decomposition theorem We say that a point z ∈ D is ε-(linear nice) if 1 − |z| < ε/eγ and for most inverse branches, backward iteration is close to a linear mapping: cz \u0000 {w ∈ T(z) : bδ(w) < ε} \u0001 > (1 − ε) · log 1 |z|, where bδ(w) is the cumulative linear distortion defined in Section 10.2. Theorem 12.4 (Linear decomposition theorem) . (a) For any ε >0 and al- most every point z ∈ D, there exists an n ≥ 0 so that X F◦n(w)=z w is ε-L.nice log 1 |w| > (1 − ε) · log 1 |z|. (12.1) (b) For any ε >0, one can find finitely many ε-(linear nice) pointsz1, z2, . . . , zN so that ξ \u0012 bX \\ N[ i=1 bBi, ε-L.good \u0013 < ε. Proof. (a) For a pointz′ ∈ D, let ∆z′ denote the set of inverse orbitsw′ ∈ T(z′) for which the cumulative linear distortion bδ(w′) = ∞. If (12.1) fails at z′ ∈ D, then cz′(∆z′) ≥ ε. For the sake of contradiction, assume that (12.1) fails on a set of positive Lebesgue measure A in the unit disk. However, by the Schwarz lemma, this would imply that ˆ bA χ{w: bδ(w)=∞}dξ(w) = ˆ A ˆ T(z′) χ{w: bδ(w)=∞}E(w′, z′)2 dcz′(w′) log 1 |z′|dAhyp(z′) ≥ ˆ A cz′(∆z′) log 1 |z′|dAhyp(z′) > 0, contradicting Theorem 12.1 which says thatbδ(z′) < ∞ for Lebesgue a.e. z′ ∈ bD. (b) The proof is similar to that of part (b) in Theorem 11.4. 5013 The Geodesic Foliation Theorem In this section, we show the following theorem which describes the structure of geodesic trajectories in bDlin : Theorem 13.1. (i) For ξ a.e. backward orbit z ∈ bDlin and n ≥ 0, the limit ζ−n(z) := lim t→∞ (g−t(z))−n exists and (ζ−n(z)) belongs to the solenoid. (ii) Let γ(t) = (g−t(z))0. If γ(t) is the radial geodesic that connects 0 with ζ0 = ζ0(z) parametrized with respect to unit hyperbolic speed, then 1 T ˆ T 0 min \b 1, dD(γ(t), γ(t0 + t)) \t dt → 0, as T → ∞, for some offset t0 ∈ R depending on z. (iii) For bm a.e. x ∈ cS1, there exists a unique backward orbit in bDlin that lands at x. (iv) If E ⊂ cS1 has bm measure zero, then ζ−1(E) ⊂ bDlin has ξ measure zero. As a consequence, we deduce that the geodesic flow is ergodic: Corollary 13.2. The geodesic flow on the Riemann surface lamination bXlin is ergodic. Proof. Suppose A ⊂ bXlin is a gt-invariant set. Lifting to bDlin, we get a (gt, bF)- invariant set eA, which is a necessarily a union of geodesic trajectories. The endpoints of these trajectories under the backward geodesic flow form an bF- invariant set ζ0( eA) in the solenoid. Since the action of bF on the solenoid is ergodic, either ζ0( eA) or its complement has bm measure 0. By Theorem 13.1(iv), either eA or its complement has ξ measure 0, and thus the same is true of A. 13.1 Trajectories land on the solenoid For 0 < r <1, we define the function bδr : bXlin → R by bδr(z) := max \u001a 1, X δ(z−k) \u001b , 51where we sum over the part of the inverse orbit contained in the annulus A(0; r,1). For any 0 < r <1, the function bδr(z) belongs to L2( bXlin), and the functions bδr(z) decrease pointwise a.e. to 0 as r → 1. By the ergodic theorem for invariant measures, for ξ a.e. z ∈ bXlin, the backward time average bδr,−(z) := lim T→∞ 1 T ˆ T 0 bδr(g−t(z))dt is the orthogonal projection of bδr onto the subspace of gt-invariant functions in L2( bXlin). This implies that for ξ a.e. z ∈ bXlin, we have lim T→∞ 1 T ˆ T 0 bδ(g−t(z)) = 0, which implies (i) and (ii) by Theorem A.1. 13.2 Uniqueness Suppose z, z′ ∈ bDlin are two generic inverse orbits with respect to the measure ξ for which ζ(z) = ζ(z′). By part (ii), we know that for each n ≥ 0, the trajectories g−t(z)−n and g−t(z′)−n both weakly shadow the same radial ray [0, ζ−n]. By Lemma 10.1, the trajectories g−t(z) and g−t(z′) belong to the same leaf, which means that there exists a vertical geodesic Vξ′ = {z ∈ H : Re x = ξ′} ⊂H so that {gt(z′)−n : t ∈ R} = Fz,−n(Vξ′). Weak shadowing forces ξ′ = 0, i.e. z and z′ belong to the same geodesic trajectory, which proves the uniqueness statement in (iii). 13.3 Rescaling limits and measures A set A ⊂ bBε-L.good is naturally decomposed as a union of slices: A = [ z∈Tε-L.good(z) Az, with the slice Az ⊂ Bz consisting of inverse orbits w which follow z, i.e. w−n lies in the same connected component of F−n(B) as z−n for any n ∈ N. 52Via rescaling maps, we may view the slices of A as subsets of the upper half-plane. More precisely, for z ∈ Tε-L.good(z), we may define the sets A∗ z ⊂ B∗ z = F−1 z,0 (B) ⊂ H. Theorem 13.3. The following equalities hold: ξ(A) = ˆ Tε-L.good(z) \u001aˆ A∗z dA(w) Im w \u001b dcz and bm(ζ(A)) = ˆ Tε-L.good(z) ℓ(ΠH→R(A∗ z))dcz, where ΠH→R is the orthogonal projection onto the real line andℓ is the Lebesgue measure on the real line. The proof of the above theorem is somewhat involved and will be given in Appendix C. 13.4 Abundance of landing points We now show that the landing points of backward trajectories of the geodesic flow cover a positive bm measure of the solenoid cS1. Since bm is ergodic with respect to the action of bF, it will then follow that landing points of back- ward trajectories cover the solenoid up to measure zero, proving the existence statement in (iii). For this purpose, we take A = bBε-L.good in Theorem 13.3. By the Schwarz lemma, each A∗ z with z ∈ Tε-L.good(z) contains the ball BH hyp(i, γ), while by ε-linearity, A∗ z is contained in the larger ball BH hyp(i, 2γ). Consequently, bm(ζ(A)) = ˆ Tε-L.good(z) ℓ(ΠH→R(A∗ z))dcz ≳ cz(Tε-L.good(z)), which is certainly positive if z ∈ D is ε-(linear nice). 13.5 Non-singularity Finally, we show that if a setA ⊂ bD has positive ξ measure, then its projection ζ(A) to the solenoid has positive bm measure. As the intersection of A with 53some set of the form bBε-L.good has positive ξ measure, we may assume that A is contained in a single bBε-L.good. Since ˆ K dA(w) Im w ≲ ℓ(ΠH→R(K)), for any measurable set K ⊂ BH hyp(i, 2γ) ⊂ H, we have ξ(A) ≲ bm(ζ(A)), so bm(ζ(A)) > 0 as well, which proves (iv). 14 Orbit Counting In this section, we prove Theorem 1.1 on averaged orbit counting for centered inner functions of finite Lyapunov exponent. Theorem 14.1.Let F be an inner function of finite Lyapunov exponent with F(0) = 0 for which the geodesic flow is ergodic on the Riemann surface lami- nation bXlin. Suppose z ∈ D \\ {0} lies outside a set of measure zero. Then, lim R→+∞ 1 R ˆ R 0 N(z, S) eS dS = 1 2 log 1 |z| · 1´ ∂D log |F′|dm. (14.1) We say that a function h : D → C is weakly almost invariant under F if for a.e. every backward orbit z = (zi)0 i=−∞ ∈ bD, limi→−∞ h(zi) exists and defines a function on the Riemann surface lamination: bh(z) = lim i→−∞ h(zi). Theorem 14.2. Let F be a centered inner function of finite Lyapunov expo- nent for which the geodesic flow on bXlin is ergodic. Suppose h : D → C is a bounded weakly-almost invariant function that is uniformly continuous in the hyperbolic metric. Then for almost every ζ ∈ S1, we have lim r→1 1 |log(1 − r)| ˆ r 0 h(sζ) · ds 1 − s =   bX bhdξ. In particular, lim r→1 1 2π|log(1 − r)| ˆ Dr h(z) · dA(z) 1 − |z| =   bX bhdξ. 54Proof. For simplicity, we first consider the case when h : D → C is eventually invariant under F, i.e. there exists a 0 < ρ <1 such that h(F◦n(z)) = h(z), |F◦n(z)| > ρ. By the ergodic theorem, for ξ a.e. inverse orbit z ∈ bXlin, we have lim T→∞ 1 T ˆ T 0 bh(g−t(z))dt =   bX bhdξ. (14.2) By Theorem 13.1(ii), for ξ a.e. z ∈ bDlin, {g−t(z)0 : t >0} weakly shadows a radial ray [0 , ζ0(z)]. Since h is eventually invariant and {g−t(z)0 : t > 0} is eventually contained in the annulus A(0; ρ, 1), lim T→∞ 1 T ˆ T 0 bh(g−t(z))dt = lim T→∞ 1 T ˆ T 0 h(g−t(z)0)dt. (14.3) By the weak shadowing and the uniform continuity of h in the hyperbolic metric, lim r→1 1 |log(1 − r)| ˆ r 0 h(s · ζ0(z)) · ds 1 − s =   bX bhdξ. (14.4) According to Theorem 13.1(iv), endpoints ζ(z) of inverse orbits z ∈ bDlin sat- isfying (14.4) cover the solenoid up to a bm measure zero set. Projecting onto the 0-th coordinate, we see that (14.4) holds for m-a.e. ζ ∈ S1. We now turn to the general case when h is only a weakly almost invariant function. The missing step is to show that (14.3) holds for ξ almost every inverse orbit z ∈ bDlin. Given ε >0 and 0 < ρ <1, let E(ε, ρ) ⊂ bXlin be the complement of the set of the inverse orbits z = (zn)∞ n=−∞ for which |h(zn) − bh(z)| < ε, for all n ∈ Z with |zn| > ρ. By the definition of a weakly almost invariant function, for any fixed ε > 0, ξ(E(ε, ρ)) → 0 as ρ → 1. We may therefore choose ρ = ρ(ε) so that ξ(E(ε, ρ)) < ε. By the ergodic theorem, a generic backward trajectory {g−t(z) : t > 0} spends little time in E(ε, ρ), i.e. lim T→∞ 1 T ˆ T 0 χE(ε,ρ)(g−t(z)) dt < ε. 55As {g−t(z)0 : t > 0} is eventually contained in the annulus A(0; ρ, 1), the difference lim sup T→∞ 1 T ˆ T 0 n bh(g−t(z)) − h(g−t(z)0) o dt ≲ ε + ε∥h∥∞, which can be made arbitrarily small by requesting that ε >0 is small, thereby justifying (14.3). 14.1 A weakly almost invariant function To prove Theorems 14.1, we will use a slight modification hnice of the almost invariant function hsmooth from Section 4.2, which was constructed by first defining hsmooth on a box □ = □(z, δ) and then extending it to the repeated pre-images of □ = □(z, δ) by invariance. On the box □ = □(z, δ), we set hnice = hsmooth. Let w be a repeated pre-image of z, i.e. F◦n(w) = z for some n ≥ 0. Recall that w is an ε-(linear good) pre-image if eγ(1 − |z|) < εand bδ(w, z) := nX i=0 δ(F◦i(w)) ≤ ε. When ε >0 is sufficiently small, the connected component □w = F−1(□(z, δ)) containing w is a topological disk which has roughly the same hyperbolic size and shape as □. On each such good box □w, we define hnice by invariance. Outside the good boxes, we set hnice to be zero. In view of Theorem 12.4, hnice is a weakly almost invariant function on the unit disk. Recall from Section 4.2 that hnice = hsmooth was chosen to be uniformly continuous in the hyperbolic metric on □. By the Schwarz lemma, hnice is uniformly continuous in the hyperbolic metric on D. We denote its natural extension to the Riemann surface lamination by bhnice. The proof of Theorems 14.1 is nearly the same as that of Theorem 4.4. We therefore point out the differences: In Step 1, we assume that z ∈ A(0; 1−ε, 1) is an ε-(linear nice) point and we show that 1 R X Fn(w)=z, n≥0 w∈Bhyp(0,R), ε-good e−dD(0,w) ∼ε,R 1 2 log 1 |z| · 1´ ∂D log |F′|dm, (14.5) 56where we only count the number of ε-(linear good) pre-images. Steps 2 and 3 proceed as before for ε-(linearly decomposable) points, i.e. points satisfying (12.1). Part IV Parabolic Inner Functions By a parabolicinner function, we mean an inner functionF whose Denjoy-Wolff fixed point p ∈ ∂D with F′(p) := limr→1 F′(rp) = 1. We view parabolic inner functions as holomorphic self-maps of the upper half-plane, with the parabolic fixed point at infinity. In this case, Lebesgue measure ℓ on the real line is invariant, e.g. see [DM91]. We say that a parabolic inner function F : H → H has finite Lyapunov exponent if χℓ = ˆ R log |F′(x)|dℓ <∞. By Julia’s lemma, for any point z0 ∈ H, the imaginary parts {Im F◦n(z0)} are increasing. We say that F has finite height if {Im F◦n(z0)} are uniformly bounded and infinite height if ImF◦n(z0) → ∞. In view of the Schwarz lemma, this definition is independent of the choice of the starting point z0 ∈ H. In this final part of the paper, we discuss orbit counting theorems for parabolic inner functions of infinite height. As the proofs are essentially the same, we only give a brief description of the results and leave the details to the reader. 15 Statements of Results For a bounded interval I ⊂ R and a real number R >0, consider the counting function NI(z, R) = # \b w ∈ I × [e−R, 1] : F◦n(w) = z for some n ≥ 0 \t . 57Theorem 15.1. Let F : H → H be an infinite height parabolic inner function of finite Lyapunov exponent. Suppose z ∈ H lies outside a set of zero measure. Then, 1 R ˆ R 0 NI(z, S) eS dS ∼ |I| · 1´ R log |F′|dℓ as R → ∞. When a parabolic inner function F : D → D is holomorphic in a neighbour- hood of the Denjoy-Wolff point p ∈ ∂D, we can classify it as singly parabolic or doubly parabolic depending on whether the Taylor expansion is F(z) = p + (z − p) + a2(z − p)2 + . . . , a2 ̸= 0 or F(z) = p + (z − p) + a3(z − p)3 + . . . , a3 ̸= 0. Singly and doubly parabolic inner functions on the upper half-plane are defined by conjugating with a M¨ obius transformation that takesD to H. For example, z → z − 1/z + T is doubly-parabolic for T = 0, while singly-parabolic for T ∈ R \\ {0}. Singly parabolic functions have finite height, while doubly parabolic functions have infinite height. Theorem 15.2. Let F : H → H be a doubly-parabolic one component inner function of finite Lyapunov exponent. For all z ∈ H lying outside a countable set, we have NI(z, R) ∼ |I| · 1´ R log |F′|dℓ, as R → ∞. 15.1 Background on parabolic inner functions In the upper half-plane, Lemmas 2.1, 2.2 and 2.3 read as follows: Lemma 15.3.Suppose F is a parabolic inner function with the parabolic fixed point at infinity. For a non-exceptional point z ∈ H, Im z = X F(w)=z Im w. (15.1) 58An inner function viewed as self-mapping of the upper half-plane can be expressed as F(z) = αz + β + ˆ R 1 + zw w − z dµ(w), for some constants α >0, β ∈ R and a finite positive singular measure µ on the real line, e.g., see [Tsu59]. Differentiating, we get F′(z) = α + ˆ R w(w − z) + (1 +wz) (w − z)2 dµ(w), = α + ˆ R w2 + 1 (w − z)2 dµ(w). Since α = limt→∞ F′(it), an inner function has a parabolic fixed point at infinity if and only if α = 1. The following two lemmas are straightforward consequences of the above formula: Lemma 15.4.If F is a parabolic inner function with the parabolic fixed point at infinity, then for a bounded interval J in the real line, there exists a constant cJ > 1 such that F′(ζ) > cJ for all ζ ∈ J. Lemma 15.5. If F(z) is an inner function, viewed as a map of the upper half-plane to itself, then |F′(x + iy)| ≤ |F′(x)| (15.2) for all x + iy ∈ H. 15.2 Riemann surface laminations For a parabolic inner function F, we may form the space of backward orbits bH = lim ←− (F : H → H) = \b (zi)0 i=−∞ : F(zi) = zi+1 \t . The Riemann surface lamination is then defined as bX = bH/ bF. In view of Lemma 15.3, the natural measure dξ on bX is now given by the formula ξ( bB) = lim n→∞ ˆ F−n(B) |dz|2 Im z . (15.3) Adapting the proof of Theorem 11.2 to the current setting shows that ξ( bX) = ˆ R log |F′(x)|dℓ. 59Remark. (i) The infinite height condition guarantees that every inverse orbit passes through a backward fundamental domain of the form F−1(Ht) \\ Ht, where Ht = {z ∈ H : Im z > t}. (ii) Without the infinite height condition, the Riemann surface lamination bX may not have finite volume. For instance, for the singly parabolic Blaschke product z → z − 1/z + T with T ∈ R \\ {0}, the volume of bX is infinite, even though ˆ R log \u0012 1 + 1 z2 \u0013 dℓ(z) = 2π. (iii) By Lemma 15.4, a generic inverse orbit ( zi) does not converge to in- finity, and therefore Im zi → 0. As in Section 12, one can show: Lemma 15.6.For a finite Lyapunov exponent inner function F : H → H with a parabolic fixed point at infinity, ˆ H δ(x + iy) · dxdy y < ∞. The above lemma implies that iteration along a.e. inverse orbit is essentially linear and therefore a.e. leaf of bX is covered by ( H, ∞), which allows one to define geodesic and horocyclic flows on bX. The following theorems are analogues of Theorems 4.1 and 4.2 respectively: Theorem 15.7. For an infinite height parabolic inner function F : H → H of finite Lyapunov exponent, the geodesic flow on bX is ergodic. In particular, if h : H → C is a bounded almost invariant function that is uniformly continuous in the hyperbolic metric, then for almost every x ∈ R, we have lim t→0 1 |log t| ˆ 1 t h(x + iy) · dy y = 1´ R log |F′|dℓ ˆ bX bhdξ. Theorem 15.8. For a doubly parabolic one component inner function F : H → H of finite Lyapunov exponent, the geodesic flow on bX is mixing. In par- ticular, if h : H → C is a bounded almost invariant function that is uniformly continuous in the hyperbolic metric and I ⊂ R is a bounded interval, then lim y→0 ˆ I h(x + iy)dℓ(x) = |I|´ R log |F′|dℓ ˆ bX bhdξ. 60Again, the proofs are similar to the case when the Denjoy-Wolff point is inside the disk. (To show the mixing of the geodesic flow, we use that for doubly parabolic one component inner functions, the multipliers of the repelling periodic orbits on the real line do not belong to a discrete subgroup of R+, for a proof, see [IU23, Section 9.4].) Part V Appendices A A Shadowing Lemma The following theorem roughly says that if you drive a car in the upper half- plane with the desire to reach the real axis, and you are able to steer the car for most of the time, then on average, your path will be close to a vertical geodesic: Theorem A.1. Let γ : [0, ∞) → H be a C1 parametrized curve in the upper half-plane with ∥γ′(t)∥hyp ≤ 1. Suppose [0, ∞) = G ∪Bis partitioned into good and bad times such that at good times, γ′(t) = v↓ = −y · ∂ ∂y , while at bad times, γ′(t) can point in any direction. (i) If the upper density of bad times lim sup T→∞ |{0 < t < T: t ∈ B}| T = 0, (A.1) then the limit ζ = limt→∞ γ(t) exists and lies on the real axis. (ii) Furthermore, if γ(t) is the vertical geodesic to ζ, then 1 T ˆ T 0 min \b 1, dH(γ(t), γ) \t dt → 0, as T → ∞. (A.2) Remark. The above the theorem remains true if during a good time, we allow γ′(t) to be only approximately equal to v↓, rather than exactly equal: it is enough to require that ∥γ′(t) − v↓∥ < cfor some c <1/2. The proof of Theorem A.1 is based on the following simple observation: 61Lemma A.2. Suppose σ ≥ 0 is a locally finite singular measure on [0, ∞) such that σ([0, T])/T → 0 as T → ∞. The function ∆∞(t) = ˆ ∞ t e−(τ−t)dσ(τ) is sub-linear: ∆∞(T)/T → 0 as T → ∞. The above lemma easily follows from Fubini’s theorem. In the proof below, we will also use the function ∆T (t) = ˆ T t e−(τ−t)dσ(τ). Proof of Theorem A.1. Step 1. For clarity, we first examine the case when during a bad time, γ′(t) = v→ = y · ∂ ∂x . Consider the map q : [0, ∞) → [0, ∞) which “collapses” the set of bad times: q(t) = |{0 ≤ s ≤ t : s /∈ B}|. and let σ = q∗(χB dℓ) be the push-forward of the part of the Lebesgue measure supported on B. By assumption (A.1) on the bad set, we have q(t) t → 1 and σ([0, T]) T → 0, as T → ∞. From the definitions, is clear that ∆ T (q(t)), with 0 < t ≤ T < ∞, is the hyperbolic length of the horizontal segment between γ(t) and the vertical geodesic γT which passes through γ(T). Lemma A.2 prevents the geodesic γT from moving too much, so it converges as T → ∞. We denote the limiting vertical geodesic by γ. Lemma A.2 also shows that restricted to good times, the average distance from γ(t) to γ is small. Step 2. We now assume that during a bad time γ′(t) = v↑ + v→ = y · \u001a ∂ ∂x + ∂ ∂y \u001b , which is worse than the worst case scenario allowed in Theorem A.1. Let B∗ ⊃ Bbe the set of s >0 for which there exists t > sso that \f\f[s, t] ∩ B \f\f ≥ 1 3 · |t − s|. 62In view of the Hardy-Littlewood Maximal Theorem, \f\f[0, T] ∩ B∗\f\f ≤ C \f\f[0, T] ∩ B \f\f, for some C >0, and therefore, |{0 < t < T: t ∈ B∗}| T → 0. This time, we define q(t) = |{0 ≤ s ≤ t : s /∈ B∗}| and σ = q∗(χB∗ dℓ). Inspection shows that ∆ T (q(t)) provides an upper bound for the hyperbolic length of the horizontal segment between γ(t) and the ver- tical geodesic γT . The proof is completed by Lemma A.2 as in Step 1. B A Criterion for Angular Derivatives In this appendix, we show the following theorem, answering a question posed in [BKR24]: Theorem B.1.A holomorphic self-map of the unit disk F has a finite angular derivative at ζ ∈ ∂D in the sense of Carath´ eodory if and only if ˆ ζ 0 µ(z) dρ = ˆ ζ 0 \u0012 1 − (1 − |z|2)|F′(z)| 1 − |F(z)|2 \u0013 2|dz| 1 − |z|2 < ∞. (B.1) By composing with a M¨ obius transformation, we may assume thatF(0) = 0. By the Schwarz lemma, the function L(r) = \b dD(0, rζ) − dD(0, F(rζ)) \t , 0 < r <1, is increasing. The limit lim r→1 L(r) < ∞ is finite if and only if F has an angular derivative at ζ, in which case, lim r→1 L(r) = log |F′(ζ)|. In other words, F possesses an angular derivative at ζ if when moving from 0 to ζ along the radial geodesic ray γ = [0, ζ) at unit hyperbolic speed, the 63image point efficiently moves toward the unit circle. Expressed infinitesimally, this says that F has a finite angular derivative at ζ ∈ ∂D if and only if ˆ ζ 0 η(z) dρ <∞. (B.2) The main difficulty in proving Theorem B.1 is replacing the radial inefficiency η with the M¨ obius distortionµ. Proof of Theorem B.1. Since µ ≤ η ≤ µ + α, it is enough to show that ˆ ζ 0 µ(z) dρ <∞ =⇒ ˆ ζ 0 α(z) dρ <∞. Step 1. A compactness argument shows that for every ε > 0, there is a δ >0 so that if µ(z) < δthen µ(w) < εfor all w ∈ Bhyp(z, 1). As a result, the M¨ obius distortionµ(rζ) → 0 as r → 1. Lemma 7.2 tells us that the geodesic curvature κF(γ)(F(rζ)) → 0, r → 1. Therefore, by Lemma 6.2, F(γ) lies within a bounded hyperbolic distance of the geodesic ray [0 , F(ζ)). In particular, this shows that F possesses a radial boundary value at ζ somewhere on the unit circle. Step 2. By Lemma 7.2, the total geodesic curvature of F(γ) is finite: ˆ ζ 0 κF(γ)(F(z)) dρ <∞. Since F(γ) lies within a bounded hyperbolic distance of the geodesic ray [0, F(ζ)), there is a sequence of rn’s tending to 1 so that αF(rnζ) < 2π/3. (It is not possible for F(γ) to approach the unit circle if the tangent vector always points away from the unit circle.) Therefore, there exists an 0 < rn < 1 so that αF(rnζ) < 2π/3 and ˆ ζ rnζ κF(γ)(F(z)) dρ <0.1. Lemma 6.7 tells us ˆ ζ rnζ α(z) dρ = O(1), which is what we wanted to show. 64C Integrating over Leaves In this appendix, we prove Theorem 13.3, which describes the measures ξ and bm in terms of integration along leaves, similar to McMullen’s original definitions of these measures given in Section 3.3. C.1 The case of bD We define a σ-finite measure ξleaf on the solenoid bX so that its restriction to any “chart” of the form bBε-L.good ⊂ bX is given by ξleaf(A) = ˆ Tε-L.good(z) \u001aˆ A∗z dA(w) Im w \u001b dcz, while the set of points not contained in any chart haveξleaf measure zero. After lifting to bD, we obtain an bF-invariant measure on bD, which we also denote by ξleaf. Our objective is to show that ξ = ξleaf : Theorem C.1. The measures ξ and ξleaf on bD are equal. We begin by checking that the measure ξleaf is well-defined: Lemma C.2. If B′ = Bhyp(z′, γ) is another ball of hyperbolic radius γ which intersects B and A ⊂ bB ∩ cB′ then ˆ Tε-L.good(z) \u001aˆ A∗z dA(w) Im w \u001b dcz = ˆ Tε-L.good(z′) \u001aˆ A∗z dA(w) Im w \u001b dcz′. Proof. Given an inverse orbit z ∈ T(z), we can select an inverse orbit z′ ∈ T(z′) which follows z by using the same inverse branches. As the dynamics is asymptotically linear, the limit ρz,z′ = lim n→∞ 1 − |z′ −n| 1 − |z−n| exists. Inspection shows that ρz,z′ = dcz′/dcz is just the Radon-Nikodym derivative of the transverse measures cz and c′ z. Recall from Section 10 that when we define the slice A∗ z ⊂ H, we rescale by a M¨ obius transformation so that z−n ∈ D maps to i ∈ H, while when we define the slice A∗ z′ ⊂ H, we rescale so that z′ −n ∈ D maps to i ∈ H. 65Consequently, when changing from z to z′, the integrand ´ A∗z dA(w) Im w decreases by the factor ρz,z′, compensating for the Radon-Nikodym derivative. As a result, the expression for ξleaf(A) remains unchanged. Lemma C.3. The measure ξleaf is absolutely continuous with respect to ξ. Proof. To prove the lemma, it is enough to show that ξleaf( bA) = 0 for any Borel set A ⊂ D with ξ( bA) = 0, as sets of this form generate the σ-algebra of Borel subsets of bD. From the definition of the measure ξ given in Section 11, it is easy to see that one has “ ξ( bA) = 0” if and only if “ A has 2-dimensional Lebesgue measure zero.” As a result, we need to show that ξleaf( bA) = 0 for any measurable set A ⊂ D with 2-dimensional Lebesgue measure zero. For this purpose, consider a chart bBε-L.good where B = Bhyp(z, γ). As the slice ( bA ∩ bBε-L.good)∗ z ⊂ H along any inverse orbit z ∈ T(z) also has zero 2-dimensional Lebesgue measure, ξleaf( bA ∩ bBε-L.good) = 0. Since the chart bBε-L.good was arbitrary, ξleaf( bA) = 0 as desired. For a measurable set A contained in a ball B = Bhyp(z, γ), we write bAε-L.good = bA ∩ bBε-L.good. Perhaps, the main difficulty in showing that ξ = ξleaf is that the measure ξ was defined in terms of the “full” cylinders bA while the measure ξleaf is given in terms of the “partial” cylinders bAε-L.good. In the following two lemmas, we evaluate ξ( bAε-L.good) and ξleaf( bAε-L.good) up to multiplicative error ε. As before, we use A ∼ε B to denote that 1 − Cε ≤ A/B ≤ 1 + Cε, for some constant C >0 depending only on the inner function F. Lemma C.4. We have ξ( bAε-L.good) = lim n→∞ X F◦n(w)=z w ε-L.good ˆ Aw log 1 |z| dAhyp (C.1) ∼ε cz(Tε-L.good(z)) ˆ A log 1 |z| dAhyp. (C.2) 66Proof. Step 1. We may write F−j(A) = Gj ⊔ Bj, where Gj is the union of the ε-(linear good) pre-images of A of generation j and Bj be the union of the “bad” pre-images. Then, bAε-L.good = bA \\ ∞G j=1 bBj, where we are slightly abusing notation by viewing bBj as a subset of bA. (We should really be writing bF◦j( bBj) in place of bBj.) Consequently, bξ( bAε-L.good) = ξ( bA) − ∞X j=1 ξ( bBj). Step 2. From the definition of the measure ξ on the cylindrical sets bA and bBj and Lemma 11.1, it follows that for any n ∈ N, we have ξ( bA) − nX j=1 ξ( bBj) ≥ X F◦n(w)=z w ε-L.good ˆ Aw log 1 |z| dAhyp, (C.3) where Aw = F−n(A) ∩ Bw ranges over the ε-(linear good) pre-images of A of generation n. In Section 11, we saw that the error Err(n, bA) := ξ( bA) − ˆ F−n(A) log 1 |z| dAhyp. decreases to 0 as n → ∞. As Err( n, bGn) ≤ Err(n, bA), ξ( bA) − nX j=1 ξ( bBj) ≤ Err(n, bA) + X F◦n(w)=z w ε-L.good ˆ Aw log 1 |z| dAhyp. (C.4) Taking n → ∞in (C.3) and (C.4), we obtain (C.1). Step 3. For j ≥ 1, let T(j) ε-L.good(z) ⊂ T(z) denote the set of inverse orbits w ∈ T(z) which are ε-(linear good) for the first j steps, i.e. bδ(w−j, z) ≤ ε. Since Tε-L.good(z) = ∞\\ n=1 T(n) ε-L.good(z) is a decreasing intersection, cz(T(n) ε-L.good(z)) decreases to cz(Tε-L.good(z)). With this in mind, (C.2) follows from (C.1) and ε-linearity. 67Lemma C.5. For a measurable set A contained in B = Bhyp(z, γ), ξleaf( bAε-L.good) ∼ε cz(Tε-L.good(z)) ˆ A log 1 |z| dAhyp. Proof. The lemma follows from the definition of the measure ξleaf and ε- linearity. With help of Theorem 12.4, one may express a cylinder set as a countable union of partial cylinders: Lemma C.6. For any measurable set A in the unit disk and ε > 0, there exists countably many disjoint partial cylinders bAk, ε-L.good which cover bA up to a set of ξ measure zero: bA = G k bAk, ε-L.good ⊔ N. We are now ready to show that the measures ξ and ξleaf are equal: Proof of Theorem C.1. To show that the measures ξ and ξleaf are equal, it is enough to show that they agree on sets of the form { bA : A ⊂ D Borel} as these generate the Borel σ-algebra of Borel subsets of bD. For a cylinder bA ⊂ bD, examine the decomposition given by Lemma C.6. As ξleaf is absolutely continuous with respect to ξ, we also have ξleaf(N) = 0. Lemmas C.4 and C.5 imply that ξ( bAk, ε-L.good) ∼ε ξleaf( bAk, ε-L.good) for any k. Summing over k shows that ξ( bA) ∼ε ξleaf( bA). Since ε > 0 was arbitrary, ξ( bA) = ξleaf( bA) as desired. C.2 The case of cS1 We define a measure bmleaf on the solenoid cS1 so that its restriction to any “chart” ζ( bBε-L.good) ⊂ cS1 is given by bmleaf(E) = ˆ Tε-L.good(z) ℓ(E∗ z)dcz, while the set of points in the solenoid which are not contained in any chart have bmleaf measure zero. As in the case of ξleaf considered previously, bmleaf is a σ-finite bF-invariant measure. Our objective is to show: 68Theorem C.7. The measures bmleaf and bm on cS1 are equal. We begin by noticing: Lemma C.8. The measure bmleaf is absolutely continuous with respect to bm. The proof below uses L¨ owner’s lemma which says that ifφ : (D, a) → (D, b) is a holomorphic self-map of the unit disk then for any measurable set E ⊂ S1, ωa(φ−1(E)) ≤ ωb(E), where ωa and ωb are harmonic measures on the unit circle as viewed from a and b respectively. Evidently, L¨ owner’s lemma also applies to maps between arbitrary simply-connected domains. Proof. Let E ⊂ S1 be a Borel set withm(E) = 0. Consider a chart ζ( bBε-L.good) where B = Bhyp(z, γ). For any inverse orbit z ∈ Tε-L.good(z), we can apply L¨ owner’s lemma to the mapFz,0 : (H, i) → (D, z) to conclude that ℓ \u0000 ( bE ∩ ζ( bBε-L.good))∗ z \u0001 = 0. As the chart ζ( bBε-L.good) and inverse orbit z ∈ Tε-L.good(z) were arbitrary, we have bmleaf( bE) = 0. Since bmleaf is bF-invariant and bm is ergodic, the above lemma tells us that: Corollary C.9. The measure bmleaf is finite. In fact, bmleaf = c · bm for some c ≥ 0. To complete the proof of Theorem C.7, it remains to show that c = 1. Unfortunately, we do not have a simple proof of this fact and the argument below is somewhat involved. Step 1. We say that a trajectory of the geodesic flow {gt(z) : t ∈ R} is generic if lim t→∞ 1 t ˆ t 0 bδ \u0000 bF◦n[g−s(w)] \u0001 ds = 0, for any n ∈ Z. Let G0 be the set of generic trajectories. Recall that in Section 13.1, we used the ergodic theorem to show that G0 foliates bD up to ξ measure zero. We also saw that under the backward geodesic flow, a generic trajectory lands on the solenoid. 69We define the measure bmgen as the restriction of bmleaf to the set ζ(G0) of landing points of generic trajectories. Since G0 is bF-invariant (by definition), so are ζ(G0) and bmgen. Notice that bmleaf − bmgen ⊥ bmgen as the two measures are supported on different sets: bmgen gives full mass to ζ(G0), while bmleaf − bmgen gives full mass to cS1 \\ ζ(G0). Lemma C.10. The measure bmgen is a probability measure. Once we prove the above lemma, c = 1 follows almost immediately: As bm is ergodic and bmgen < <bm, the two measures must be equal: bm = bmgen. As the difference bmleaf − bmgen < <bm = bmgen, it must be zero. Hence, bm = bmgen = bmleaf as desired. Step 2. For 0 < ε <0.1, we define Aε ⊂ bD as the set of inverse orbits w = (w−n)∞ n=0 which satisfy the following three conditions: 1. bδ(w) < ε. 2. For any t >0, the hyperbolic distance dD(g−t(z)0, 0) > dD(z0, 0). 3. The geodesic trajectory passing through w is generic. For each 1 − ε/eγ < r <1, we define the auxiliary measure bmr,ε = bmleaf|ζ(Ar,ε), where Ar,ε = Aε ∩ {|z| = r}. From Condition 3, it is clear that bmr,ε ≤ bmgen ≤ bmleaf. Recall from Section 3.1 that the set of points z ∈ D for which cz is not a probability measure has logarithmic capacity zero. In particular, the intersec- tion with any circle {|z| = r} has zero 1-dimensional Lebesgue measure. The main difficulty towards proving Lemma C.10 is to show that the measures bmr,ε exhaust bmgen as r → 1 : Lemma C.11. For any 0 < ε <0.1, lim r→1 ˆ |z|=r cz(Ac ε ∩ T(z)) |dz| = 0. (C.5) 70We now explain how to derive Lemma C.10 (and Theorem C.7) from Lemma C.11. By Condition 2 above, for each non-exceptional 0 < r <1, ζ is injective on Ar,ε. By ε-linearity, the mass of bmr,ε is approximately bmr,ε(cS1) ∼ε 1 2π ˆ |z|=r cz(Aε ∩ T(z)) |dz|. Together with Lemma C.11, this implies that bmr,ε(cS1) ∼ε 1. (C.6) Since any generic geodesic trajectory participates in “density 1” measures bms,ε, i.e. 1 |log(1 − r)| ˆ r 0 χAε(gs(z)) ds s → 1, as r → 1, we have: Lemma C.12. For any 0 < ε <0.1, bmgen = lim r→1 1 |log(1 − r)| ˆ r 0 bms,ε · ds s , (C.7) in the sense of strong limits of measures. Combining (C.6) and (C.7), we see that bmgen is a probability measure. Step 3. By Lemmas 8.3 and 10.2, there exists a universal constant 0 < γ0 < γ so that if z ∈ bD is an inverse orbit with bδ(z) < 0.1 then bδ(w) < 2 bδ(z) < 0.2 for any inverse orbit w ∈ bBε-L.good which follows z with dD(z0, w0) < γ0. In particular, dD(g−t(z)−n, 0) > dD(z−n, 0), t ∈ (0, γ0] (C.8) and dD(g−γ0 (z)−n, 0) > dD(z−n, 0) + 0.8 γ0, (C.9) for any n ≥ 0. We define the set eAε ⊂ Aε ⊂ bD, where Condition 2 is replaced with a slightly stronger condition (2 + 2′), where we additionally require 2′. For any t > γ0, we have dD(0, g−t(w)0) > dD(0, w0) + γ0/2. 71In view of the buffer provided by (2 ′), we have: Lemma C.13. Suppose 0 < ε <0.05. There exists 0 < γ1 < γ0 so that if z ∈ eAε then any generic orbit z′ ∈ bBε-L.good which follows z with dD(z0, z′ 0) < γ1 belongs to A2ε. Step 4. The following lemma says that from some point on, almost every inverse orbit belongs to eAε : Lemma C.14.For ξ a.e. inverse orbit w ∈ bD, there exists an N(w) ≥ 0 such that bF−n(w) ∈ eAε for all n ≥ N(w). Proof. Recall that by Theorem 12.1, forξ a.e. inverse orbit, we havebδ(w) < ∞ and therefore, bδ( bF−n(w)) → 0 as n → ∞. Consequently, forn sufficiently large, bδ( bF−n(w)) < εand Condition 1 holds. Condition 3 is also easy to check since ξ a.e. inverse orbit is generic and the property of an inverse orbit belonging to a generic trajectory is bF-invariant by definition. To verify Condition (2 + 2′), we examine three cases: 1. For t ∈ (0, γ0], Condition 2 ′ for bF−n(w) follows from Condition 1 for bF−n(w) and (C.8). 2. By the definition of a generic trajectory, there exists a T = T(w) > 0 sufficiently large so that 1 t ˆ t 0 bδ(g−s(w))ds <1/2, t > T. As a result, for t > T, we have dD(0, g−t(w)−n) > dD(0, g0(w)−n) + t/2. 3. Finally, to handle the case when t ∈ [γ0, T], we use that the sequence of functions ∆n(t) = bδ( bF−n[g−t(w)]) = ∞X k=n+1 δ(g−t(w))−k, decreases pointwise to 0. The proof is complete. 72For an inverse orbit w = (wn)∞ n=−∞ ∈ bD and 0 < r <1, we write wr for the last point of the orbit that lies in the annulus A(0; r,1), that is, wr = wn(r) where n(r) ∈ Z is the largest integer for which wn(r) ∈ A(0; r,1). One may interpret Lemma C.14 as saying that ˆ bX χ{wr∈ eAcε}dξ(w) → 0, as r → 1. (C.10) With the above preparations, we are now ready to prove Lemma C.11: Proof of Lemma C.11. Suppose that one could find a sequence of r’s tending to 1 so that ˆ |z|=r cz(Ac 2ε ∩ T(z)) |dz| ≥δ, for some δ >0. By Lemma C.13, we would also have ˆ |z|=s cz( eAc ε ∩ T(z)) |dz| ≥δ, for any 0 < s <1 with dD(r, s) < γ1/2. Consequently, 1 γ0 ˆ A cz(Ac ε ∩ T(z)) · 2 dA(z) 1 − |z|2 ≥ δ, (C.11) where A = {z ∈ D : dD(|z|, r) < γ1/2} is an annulus of hyperbolic width γ1. Since we requested that γ1 < γ, the quotient map π : bD → bX is injective on bA and (C.11) contradicts (C.10) if r is sufficiently close to 1. Acknowledgements The authors wish to thank Mikhail Lyubich for bringing the work of Glutsyuk to our attention. This research was supported by the Israeli Science Foundation (grant no. 3134/21) and the Simons Foundation (grant no. 581668). References [AC74] P. R. Ahern, D. N. Clark, On inner functions with Hp-derivative, Michigan Math. J. 21 (1974), no. 2, 115–127. 73[BM07] A. F. Beardon, D. Minda, The hyperbolic metric and geometric func- tion theory. In: S. Ponnusamy, T. Sugawa, M. Vuorinen (eds), Quasicon- formal Mappings and their Applications, 9–56, Narosa Publishing House, New Delhi, 2007. [BKR24] F. Bracci, D. Kraus, O. Roth, The strong form of the Ahlfors- Schwarz lemma at the boundary and a rigidity result for Liouville’s equa- tion, 2024. To appear in the Israel J. Math. [Coh82] B. Cohn, Carleson measures for functions orthogonal to invariant subspaces, Pacific J. Math. 103 (1982), 347–364. [Cou09] Y. Coud` ene,A short proof of the unique ergodicity of horocyclic flows, Contemporary Mathematics, Amer. Math. Soc., 485 (2009) 85–89. [Cra91] M. Craizer, Entropy of inner functions , Israel J. Math. 74 (1991), no. 2, 129–168. [DM91] C. I. Doering and R. Ma˜ n´ e,The dynamics of inner functions , Ensaios Matem´ aticos 3 (1991), 5–79. [Glu10] A. Glutsyuk. On density of horospheres in dynamical laminations , Moscow Math J. 10 (2010), no. 3, 547–591. [Hei77] M. Heins, On the Finite Angular Derivatives of an Analytic Function Mapping the Open Unit Disk into Itself , J. London Math Soc. 15 (1977), no. 2, 239–254. [Ivr15] O. Ivrii, The geometry of the Weil-Petersson metric in complex dy- namics, 2015. To appear in the Trans. Amer. Math. Soc. [Ivr19] O. Ivrii, Prescribing inner parts of derivatives of inner functions , J. d’Analyse Math. 139 (2019), 495–519. [Ivr20] O. Ivrii, Stable convergence of inner functions , J. London Math. Soc. 102 (2020), 257–286. [IK22] O. Ivrii, U. Kreitner, Critical values of inner functions , 2022. arXiv:2212.14818. [IU23] O. Ivrii, M. Urba´ nski,Inner Functions, Composition Operators, Sym- bolic Dynamics and Thermodynamic Formalism , 2023. arXiv:2308.16063. 74[Mas12] J. Mashreghi, Derivatives of Inner Functions , Fields Institute Mono- graphs, 2012. [McM08] C. T. McMullen, Thermodynamics, dimension and the Weil- Petersson metric , Invent. Math. 173 (2008), 365–425. [McM09] C. T. McMullen, Ribbon R-trees and holomorphic dynamics on the unit disk , J. Topol. 2 (2009), 23–76. [Pre10] A. Pressley, Elementary Differential Geometry, 2nd Edition, Springer, New York, 2010. [PrU10] F. Przytycki, M. Urba´ nski, Conformal Fractals: Ergodic Theory Methods, Cambridge University Press, Cambridge, 2010. [NR21] A. Nicolau, A. Reijonen, A characterization of one-component inner functions, Bull. London Math. Soc. 53 (2021), 42–52. [Roh64] V. A. Rohlin, Exact endomorphisms of a Lebesgue space , Am. Math. Soc., Transl., Ser. 2 39 (1964), 1–36. [Tsu59] M. Tsuji, Potential theory in modern function theory , Maruzen, Tokyo, 1959. 75",
      "references": [
        "On inner functions with Hp-derivative",
        "The hyperbolic metric and geometric func- tion theory.",
        "The strong form of the Ahlfors- Schwarz lemma at the boundary and a rigidity result for Liouville’s equa- tion",
        "Carleson measures for functions orthogonal to invariant subspaces",
        "A short proof of the unique ergodicity of horocyclic flows",
        "Entropy of inner functions",
        "The dynamics of inner functions",
        "On density of horospheres in dynamical laminations",
        "On the Finite Angular Derivatives of an Analytic Function Mapping the Open Unit Disk into Itself",
        "The geometry of the Weil-Petersson metric in complex dy- namics",
        "Prescribing inner parts of derivatives of inner functions",
        "Stable convergence of inner functions",
        "Critical values of inner functions",
        "Inner Functions, Composition Operators, Sym- bolic Dynamics and Thermodynamic Formalism",
        "Derivatives of Inner Functions",
        "Thermodynamics, dimension and the Weil- Petersson metric",
        "Ribbon R-trees and holomorphic dynamics on the unit disk",
        "Elementary Differential Geometry, 2nd Edition",
        "Conformal Fractals: Ergodic Theory Methods",
        "A characterization of one-component inner functions",
        "Exact endomorphisms of a Lebesgue space",
        "Potential theory in modern function theory"
      ],
      "meta_data": {
        "arxiv_id": "2405.02878v1",
        "authors": [
          "Oleg Ivrii",
          "Mariusz Urbański"
        ],
        "published_date": "2024-05-05T10:25:12Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Studies orbit-counting for (centered) inner functions via dynamics on associated Riemann surface laminations. Proves asymptotic formula for number N(z,R) of repeated preimages of z in hyperbolic ball Bhyp(0,R). For one-component inner functions of finite Lyapunov exponent (not monomials z↦z^d), obtains sharp asymptotic N(z,R) ~ (1/2)·log(1/|z|)·(1/∫_{∂D}log|F'|dm)·e^R. For general centered inner functions of finite Lyapunov exponent, proves same constant after Cesàro averaging: (1/R)∫_0^R N(z,S)e^S dS → (1/2)·log(1/|z|)·(1/∫_{∂D}log|F'|dm). Establishes key structural insight: backward iteration along ξ-a.e. inverse orbit is asymptotically linear (and Möbius). Extends analogues to parabolic inner functions of infinite height, including mixing-based sharp asymptotics for doubly-parabolic one-component maps.",
        "methodology": "Builds and analyzes a Riemann surface lamination \\hat X associated to an inner function via inverse limits of backward orbits and quotient by the shift map. Defines geodesic and horocyclic flows on leaves (modeled on (H,∞)) and constructs natural invariant measure ξ with total mass equal to the Lyapunov exponent ∫_{∂D}log|F'|dm. Uses: (i) suspension-flow model over the solenoid with roof function ρ=log|F'| to obtain ergodicity; (ii) establishes mixing for one-component maps by proving horocycle ergodicity (dense horocycle via Glutsyuk’s argument + Coudène’s criterion) and then deducing geodesic mixing; (iii) develops distortion-control toolkit (Möbius distortion μ, linear distortion δ, curvature estimates, angular derivative bounds) to show finite cumulative distortion along generic inverse orbits, yielding Möbius/linear laminations where flows are well-defined for general finite-Lyapunov inner functions; (iv) converts ergodic/mixing statements into orbit-counting by constructing (weakly) almost invariant test functions concentrated near preimage “boxes,” applying ergodic theorems to relate spatial averages to preimage counts, and then using Nevanlinna/Frostman identities for normalization.",
        "experimental_setup": "No computational experiments. Validation is purely theoretical via rigorous proofs. Objects/‘data’: the dynamical systems given by inner functions on D (or H) with hypotheses (centered; finite Lyapunov exponent; one-component vs general; excluding rotations and treating z↦z^d separately; parabolic infinite-height cases). ‘Benchmarks’ are classical results/structures: McMullen’s lamination and suspension flow for finite Blaschke products, Frostman/Ahern–Clark results on exceptional points, Koebe distortion, Schwarz/Julia lemmas, and known mixing/ergodicity criteria for geodesic/horocycle flows (Glutsyuk, Coudène). Proof validation uses: construction of invariant measures (ξ, bm) and showing total mass equals Lyapunov exponent; establishing full-measure linear structure (ξ(bX\\bX_lin)=0); deriving orbit-counting limits for z outside measure-zero (or countable) exceptional sets; extension to parabolic setting with analogous invariant measure formula ξ(\\hat X)=∫_R log|F'|dℓ.",
        "limitations": "Results require finite Lyapunov exponent (∫log|F'| finite), excluding many inner functions; general-case orbit counting is only proved after Cesàro averaging unless one-component + mixing holds. Pointwise asymptotic (without averaging) needs one-component assumption and fails for special maps: monomials z↦z^d produce packeted/step-function counts; some inner functions omit values so N(z,R)=0 for those z. Statements hold for ‘most’ z (outside Lebesgue-null sets or countable sets tied to exceptional Frostman shifts/forward orbits). Mixing proof for geodesic flow is established for one-component maps excluding z↦z^d; for general inner functions, mixing is not obtained and lamination is only ‘lamination-like’ (may lack local product structure). Parabolic results are stated for infinite-height (and sharp asymptotics for doubly-parabolic one-component) with details largely sketched rather than fully developed.",
        "future_research_directions": "(1) Extend from Cesàro-averaged to pointwise asymptotics for broader classes of inner functions beyond one-component, possibly by proving mixing (or suitable decay of correlations) on bX_lin/bX_mob in non-one-component settings. (2) Develop thermodynamic-formalism or transfer-operator approaches matching these minimal hypotheses and compare constants/limit theorems (CLT, large deviations) for preimage counting. (3) Study finer orbit-counting error terms, fluctuations, and renewal-type theorems (rates of convergence, second-order terms) under stronger regularity or spectral assumptions. (4) Investigate structure and measure-theoretic properties of the Möbius/linear laminations when critical sets are complicated; characterize when bX_lin is nonempty without finite Lyapunov. (5) Parabolic setting: complete detailed proofs, treat finite-height parabolic maps (where lamination volume may be infinite) via renormalized measures, and seek sharp (non-averaged) counting for broader parabolic classes. (6) Explore analogous lamination-flow frameworks for other holomorphic dynamical systems (e.g., self-maps of higher-dimensional balls or Teichmüller/Weil–Petersson analogues) where orbit counting relates to Lyapunov/entropy quantities.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Code Repair with LLMs gives an Exploration-Exploitation Tradeoff",
      "full_text": "Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems Ivan Sekuli´c, Silvia Terragni, Victor Guimarães, Nghia Khau, Bruna Guedes, Modestas Filipavicius, André Ferreira Manso, Roland Mathis Telepathy Labs GmbH Zürich, Switzerland firstname.lastname@telepathy.ai Abstract In the realm of dialogue systems, user sim- ulation techniques have emerged as a game- changer, redefining the evaluation and enhance- ment of task-oriented dialogue (TOD) systems. These methods are crucial for replicating real user interactions, enabling applications like synthetic data augmentation, error detection, and robust evaluation. However, existing ap- proaches often rely on rigid rule-based methods or on annotated data. This paper introduces DAUS, a Domain-Aware User Simulator. Leveraging large language models, we fine-tune DAUS on real examples of task-oriented dialogues. Results on two relevant benchmarks showcase significant im- provements in terms of user goal fulfillment. Notably, we have observed that fine-tuning enhances the simulator’s coherence with user goals, effectively mitigating hallucinations – a major source of inconsistencies in simulator responses. 1 Introduction The field of dialogue systems has seen a notable surge in the utilization of user simulation ap- proaches, primarily for the evaluation and enhance- ment of conversational search systems (Owoicho et al., 2023) and task-oriented dialogue (TOD) sys- tems (Terragni et al., 2023). User simulation plays a pivotal role in replicating the nuanced interac- tions of real users with these systems, enabling a wide range of applications such as synthetic data augmentation, error detection, and evaluation (Wan et al., 2022; Sekuli ´c et al., 2022; Li et al., 2022; Balog and Zhai, 2023; Ji et al., 2022). The significance of user simulation in the devel- opment and evaluation of dialogue systems is un- deniable. However, the prevailing methodologies often rely on rudimentary rule- and template-based approaches, which can limit their adaptability and effectiveness (Schatzmann et al., 2007; Schatz- mann and Young, 2009). Furthermore, certain user simulation methods require a substantial amount of annotated data (Lin et al., 2021, 2022, 2023), or a deep understanding of the internal workings of the dialogue system they interact with (Schatzmann et al., 2007; Li et al., 2016). The rise of generative capabilities of large lan- guage models (LLMs) enabled user simulators to generate contextually appropriate responses in nat- ural language, without the need for predefined rules (Terragni et al., 2023; Davidson et al., 2023). This shift offers distinct advantages over traditional approaches: i) no human effort is needed to con- struct the rules; ii) it introduces lexical diversity into utterance generation to assess the robustness of downstream natural language understanding and enables testing of system’s robustness to different dialogue paths. However, LLMs are susceptible to hallucinations (Ji et al., 2023; Terragni et al., 2023), resulting in inconsistency across dialogue turns or the generation of irrelevant information to the user’s goal. In this paper, we introduce DAUS, a generative user simulator for TOD systems. As depicted in Figure 1, once initialized with the user goal de- scription, DAUS engages with the system across multiple turns, providing information to fulfill the user’s objectives. Our aim is to minimize the com- monly observed user simulator hallucinations and incorrect responses (right-hand side of Figure 1), with an ultimate objective of enabling detection of common errors in TOD systems (left-hand side of Figure 1). Our approach is straightforward yet effective: we build upon the foundation of LLM- based simulators (Terragni et al., 2023; Owoicho et al., 2023) and extend such approach by fine- tuning the LLM on in-domain dialogues, annotated with their user goals. Notably, DAUS does not re- quire insights into the inner-workings of the TOD system, its policy, nor system-specific functional- ities, as it interacts with the TOD system strictly through natural language. arXiv:2402.13374v1  [cs.CL]  20 Feb 2024Figure 1: Example conversation between user simulator and TOD system. We aim to minimize common simulator’s hallucinations (right) and thus ease the detection of TOD system failures (left). We summarize our contributions and findings as follows: • Domain-Specific Adaptation : DAUS fine- tunes a pre-trained LLM on domain-specific conversational data, enhancing the simulator’s ability to maintain coherent and contextually relevant dialogues in a specific domain. • Reducing Simulator Hallucinations: DAUS mitigates hallucinations originated from in- context learning approaches, which caused inconsistencies and irrelevant information in simulator responses. By fine-tuning on domain-specific data, our approach ensures more coherent and contextually relevant simu- lated dialogues. • Balancing Lexical Diversity in User Simu- lation: DAUS employs LLMs for user simu- lation, offering a degree of lexical diversity in generated utterances. While not matching the diversity of in-context learning (partly due to hallucinations), it still provides language variety. 2 Related Work 2.1 Task-Oriented Dialogue Systems The field of TOD systems, dedicated to interacting with users to accomplish specific tasks, has recently witnessed notable advancements (Zhang et al., 2020). Given the achievements of LLMs in var- ious natural language processing tasks, there have been efforts to apply them to TOD systems (Raffel et al., 2020; Ouyang et al., 2022). A prominent application involves leveraging LLMs to extract users intents and entities, enhancing the Natural Language Understanding or Dialog State Tracking components (Zhao et al., 2022; Gupta et al., 2022b; Madotto et al., 2021; Madotto and Liu, 2020). Furthermore, Hude ˇcek and Dušek (2023) sug- gest that LLMs have the potential to be used off-the- shelf in TOD systems, even without fine-tuning for the specific TOD task, but their performance still lags behind supervised approaches. In response, an alternative approach underscores the benefits of fine-tuning specifically for TOD systems (Bang et al., 2023; Hosseini-Asl et al., 2020; Gupta et al., 2022a). This line of research reveals that fine-tuneLLMs can play a crucial role in enhancing the ca- pabilities of TOD systems. 2.2 User Simulation The state of the art in user simulation for TOD sys- tems has evolved significantly in the recent years. Initially, Eckert et al. (1997) proposed the Bigram model, which estimates a user action conditioned on the system actions. Although efficient, this model does not account for the user goal coherence. Rule-based methods like Agenda-based (Schatz- mann et al., 2007; Schatzmann and Young, 2009; Keizer et al., 2010) addresses the coherence issue but relies on the manual definition of rules. Data-driven approaches, leveraging deep learn- ing models (Gür et al., 2018; Asri et al., 2016; Lin et al., 2021, 2022, 2023), overcome the rule-based constraints but require significant computational resources and annotated data. These methods man- date dialog annotation for user goal fulfillment at each turn. In-context learning approaches (Terragni et al., 2023) have recently gained traction, design- ing prompts using snippets of example dialogues, the user’s goal (expressed in natural language as in Terragni et al. (2023), or structured format as in Davidson et al. (2023)), and the dialog history. While these approaches demand fewer resources than fine-tuning methods and eschew manual an- notation, they underscore limitations of LLMs, in- cluding hallucinations, repetitions, and incomplete user goal fulfillment. 3 Generative User Simulator In this section, we define the task of generative user simulation for TOD systems. Moreover, we describe our approach, based on fine-tuned LLMs. 3.1 Background When interacting with a TOD system, users aim to fulfill their goal, e.g., book a flight, or cancel their reservation in a restaurant. Therefore, a user simulator (U), designed to imitate a real user, in- teracts with the TOD system (S) with a given user goal G. Formally, interactions are a sequence of utterances, where the system’s utterances s and the user’s utterances u take turns, forming a dialogue history H = [s1, u1, . . . , st, ut, . . . , sN , uN ], with st and ut corresponding to system’s and user’s ut- terance at turn t, respectively, andN being the total number of exchanged utterances. We define the user goal G as all the information the user requires to achieve their aim. An example of user goal is the following: You want to try an Indian restaurant. The restaurant must be cheap and in the center. Book a table for 2 people at 8PM. At the end of the dialogue, we expect the user simulator to have fulfilled G. While the goal G can be represented either in structural format (Davidson et al., 2023) or in natural language (Terragni et al., 2023), in this work we focus on G represented in natural language. G is usually defined by a domain expert or randomly sampled. 3.2 Our Approach We propose Domain-Aware User Simulator (DAUS), a model that relies on learning the specifics of interactions with a TOD system from conversational data. The data needs to contain the goal G and the dialogue history H. Typically, such datasets are derived from user conversations with production TOD systems, or created and curated through crowd-sourcing or user studies. We cast the above-described problem of simu- lator’s goal fulfillment to an utterance-level gener- ation task. Specifically, the main task of U is to generate the next utterance ut by modeling: ut = ϕ(G, H) (1) where ϕ is the function to generate a user utterance. The ut needs be aligned with G and H, i.e., it needs to be faithful towards the given goal, as well as coherent with the dialogue so far. Given that both G and H are in natural language, we model ϕ from Eq. 1 with a language modeling- based approach. Specifically, we first construct a prompt to feed an LLM, by combining G and H. We further employ the LLM to generate the ut in auto-regressive fashion: pLLM (ut|G, H) = nY i=1 pLLM (xi t|x<i t , G, H) (2) where xi t is the i-th token of the utterance at turn t. We break down the dialogue from the data by turn, yielding N data points for each conversation. Regarding the interaction between our fine-tuned LLM and a TOD system, we follow the same paradigm from Terragni et al. (2023). DAUS re- ceives a fresh prompt, which comprises the user’s goal for the ongoing dialogue and the cumulative dialogue history. Unlike Terragni et al. (2023), we do not provide any example dialogues to serve as shots. We additionally post-process the generatedutterance to ensure that a clean message is passed to TOD systems (i.e., removal of special characters and trailing tokens). 4 Experimental Setting In this section, we describe datasets, implementa- tion details, and experimental setting for simulator- system interactions. 4.1 Data sources Table 1: Dataset Statistics (after pre-processing). Dataset Avg # Turns Avg # Words per User Utterance Avg # Words per TOD Utterance MultiWOZ 5.86 13.13 14.86 AutomotiveData 11.20 3.44 12.06 We consider two data sources to evaluate our ap- proach. First, we experiment on internal dialogue data of user-TOD system phone call interactions within the automotive industry, dubbed Automo- tiveData.1 Second, we use the well-established dataset of multi-domain TOD systems – Multi- WOZ 2.1 (Eric et al., 2019). Both data sources contain user goal G in natural language and multi- turn dialogues (compliant with Section 3.1). For each dataset, we randomly sample 2,500 dialogues for training, 300 for testing and 300 for validation. The statistics of the resulting datasets are reported in Table 1. 4.2 TOD Systems DAUS communicates with TOD systems through natural language, making it system-agnostic. For our user simulator fine-tuned on AutomotiveData, we employ an internal TOD system. To evaluate DAUS fine-tuned on MultiWOZ, we use the ConvLab2 framework (Zhu et al., 2020), extended by Terragni et al. (2023), which integrates LLM-based few-shot user simulators.2 We use the same TOD the authors used in their original work. We identify a challenge with the default stopping criteria that prematurely end dialogues when users express gratitude. This does not always signify 1In order to protect our users’ privacy, we do not release any user data nor models fine-tuned on user’s data. Examples presented throughout the paper are synthetically constructed, whilst preserving realistic user goals. Users have been in- formed about and have consented to data collection. 2https://github.com/telepathylabsai/ prompt-based-user-simulator . the end of the interaction as users may continue with their goals (e.g., “Thanks for booking my flight. I also need a hotel” would terminate the conversation). Therefore, we modify the criteria to exclude termination on “thanks” intent. We consequently re-run the experiments presented in Terragni et al. (2023). Moreover, we publicly release the updated framework and the user simulator fine-tuned on MultiWOZ 2.1 at https: //github.com/telepathylabsai/ finetuned-user-simulator. 4.3 User Goal Settings For the MultiWOZ data within ConvLab2 frame- work, we follow the previous work for construction of the user goals (Zhu et al., 2020; Terragni et al., 2023). Specifically, the user goals are randomly sampled, conditioned on the domains and entities frequency in the training data. We generate 100 dialogues per user goal. For evaluation on our internal TOD system, a domain expert manually defined user goals for 8 test cases, detailed in Appendix A. The test cases vary depending on the complexity and the main task that the simulator has to fulfill. As such, we label the test cases accordingly: B for book ap- pointment task, C for cancel appointment task, R for reschedule appointment task. Moreover, each label is associated with a graded difficulty indicator, i.e., easy or hard. We generate 100 dialogues per test case (i.e., per user goal). 4.4 Fine-tuning Details We conduct our experiments with the recently re- leased open-source LLM — Llama-2 (Touvron et al., 2023). The prompt, mentioned in Section 3.2, is constructed by concatenating the task description, user goal G, and the dialog history H. Moreover, we separate every utterance with a special “<end- turn>” token. We utilize LoRA (Hu et al., 2021) – a parameter- efficient fine-tuning technique, capable of reach- ing performances comparable to fully fine-tuned models, whilst requiring only a fraction of the com- putational resources. We adhere to the hyperpa- rameter recommendations and instructions of the recent work on the topic (Hu et al., 2021; He et al., 2021) and use the following LoRA hyperparame- ters throughout the experiments: rank r of 64, α of 32, and dropout of 0.05. Moreover, we optimize attention layers (query and key matrices) of the Llama-2 model. We use the 13B Llama-2 ver-sion for the main experiments, and the 7B version for comparison and the generalization study. We perform hyperparameter grid search for learning rate on the dev sets of our datasets. We settle for lr = 3e−5 and the batch size of 12 and 32 for the 13B and 7B versions, respectively. 4.5 Baselines We compare our Llama-2 fine-tuned model with several pre-trained models in zero-shot or few-shot fashion, following (Terragni et al., 2023; David- son et al., 2023). In particular, we consider the following pre-trained models: • Llama 2 with 13B parameters. • GPT-3.5 Turbo4 (Chat-GPT), version 0613 (Brown et al., 2020a). For data privacy reasons, we employ this model only for the MultiWOZ experiments. • Flan-T5 (Chung et al., 2022) with 3B param- eters (XL), to reproduce results of Terragni et al. (2023). In addition to the LLM-based models, we consider an agenda-based simulator (ABUS) (Wen et al., 2015), designed specifically for MultiWOZ within ConvLab2 framework, thus requiring the knowl- edge of TOD system’s policy. We include two variants of ABUS: the first with template-based NLG and the second with data-driven NLG, dubbed ABUS-T and ABUS-D, respectively. Let us notice that ABUS is a strong baseline, as it is tailored for communicating with the MultiWOZ-based TOD from ConvLab2, therefore it is included as a ref- erence of the potential upper-bound for user goal fulfillment performance. We follow Terragni et al. (2023) and set the temperature for inference to 0.9 for all MultiWOZ experiments, and 0.7 for internal experiments (value chosen through grid search). 5 Evaluation We comprehensively evaluate our method, aim- ing to assess its ability to achieve designated user goals in dialogues and its impact on lexical diver- sity when aligning with real user language patterns. Moreover, we perform qualitative analysis of simu- lated dialogues via human evaluation. In this sec- tion, we detail these evaluation procedures. Additionally, we examine utterance-level met- rics, comparing generated utterances with those in the target dataset, using both general natural lan- guage generation and domain-specific entity-based metrics. However, we found that these metrics poorly correlate with the simulator’s task comple- tion. Detailed information about these metrics and their results can be found in Appendix C. 5.1 Goal Fulfillment Evaluation Metrics Our objective is to evaluate the goal fulfillment at the end of the dialogue. For MultiWOZ experi- ments, we consider well-known metrics such as Success, Completion and Book rate. These metrics aim to capture how successful was the dialogue in terms of fulfilling specific subtasks from the user goal (e.g., whether the restaurant is booked). We also compute the average precision (P), recall (R) and F1 scores by matching the entities expressed through the simulated dialogue to the ones in the initial user goal. These metrics aim to assess the simulator’s faithfulness and consistency of enti- ties with the user goal (e.g., whether the correct restaurant type was booked). For a comprehensive understanding of the metric definitions, please refer to Zhu et al. (2020) and Terragni et al. (2023). Regarding our in-house TOD, it is worth noting that we do not differentiate between book, inform and request entities. Therefore, we adapt the men- tioned metrics, except for the Book Rate, while con- sidering all entities as inform entities. Moreover, we compute several metrics specific to automotive domain: user subtask indicating whether the sub- task (book, cancel, or reschedule the appointment) matches the one given in the user goal; caller info and car info indicating whether user information (name, phone number) and vehicle information (car year, make, and model) match the ones in the goal, respectively; transport type assessing the chosen transport type (e.g., dropping of the vehicle, wait- ing for the service in the dealership). 5.2 Lexical Diversity of Generated Utterances Lexical diversity (LD) is a measure of word vari- ability and vocabulary size of a given text corpus, in our case, the set of generated user utterances from 100 conversations. We report MTLD scores (McCarthy, 2005), and a number of unigram words (Unig) and average user utterance length (UttLen). LD results are reported in Section 6.2. 5.3 Qualitative Analysis During the analysis of the generated simulated di- alogues, we observed several re-occurring issues. We categorize them as the simulator’s failure (hallu- cination, incomplete user goal fulfillment, or loop-Table 2: Results of goal fulfillment task in simulator interaction with the internal TOD system. The results are averaged across the eight user goals. Model Num Shots Compl Rate Succ Rate P R F 1 User Subtask Caller Info Car Info Transport Type UttLen Unig MTLD FlanT5-XL (Terragni et al., 2023)2 0.46 0.27 0.72 0.86 0.76 70.9 85.5 65.6 39.2 2.8 209 23.4 Llama-2 0 0.35 0.13 0.62 0.87 0.69 50.4 88.8 72.2 12.8 2.4 161 15.5 1 0.37 0.12 0.67 0.89 0.74 65.6 89.1 81.6 8.0 2.0 149 14.5 2 0.36 0.15 0.66 0.91 0.74 68.9 90.3 80.2 8.0 2.0 129 13.7 DAUS 0 0.51 0.40 0.91 0.92 0.91 99.5 98.5 99.0 80.7 1.7 112 16.5 ing/repeating utterances across turns) or TOD sys- tem’s failure (NLU misclassification due to missing user’s intent or entities, forcing end of dialogue , or looping/repeating utterances). Our aim is to as- sess the prevalence of these patterns and identify potential limitations of LLM-based user simulators. To this end, we employ three annotators to anno- tate 45 dialogues generated with an LLM-based baseline and 45 dialogues generated with DAUS within ConvLab2 framework. The annotators are domain-experts and employees of the authors’ in- stitution. We provide guidelines for each of the categories and go through an on-boarding process with the annotators. The labels for each of the dia- logues are determined by majority vote. Annotators reach moderate to good agreement, as measured by Fleiss’ κ, detailed in Appendix D. 6 Results In this section, we examine our study’s findings across three main threads. First, we investigate the impact of fine-tuning LLMs with domain-specific data on goal fulfillment in dialog interactions (Sec- tion 6.1). Next, we explore the link between fine- tuning and the lexical diversity of generated utter- ances (Section 6.2). Finally, we assess whether the adaptability of LLM-based user simulators to unseen user tasks is influenced by the diversity of subtask types in their training data (Section 6.3). 6.1 Goal Fulfillment Internal TOD System. Table 2 shows results on the goal fulfillment task of DAUS and the baselines detailed in Section 4.5, averaged across different user goals. We present the results per each of the eight specific user goals, detailed in Section 4.3, in Appendix B for space-saving purposes. As a first remark, DAUS outperforms all of the baselines across all the goal fulfillment metrics. We observe the largest improvements for domain- specific metrics, e.g., precision and recall of rel- evant entities and accuracy of the transport type. This indicates that fine-tuning on in-domain data improves simulator’s knowledge of the domain- specific terminology. We further expand on this observation in Section 7.1. Regarding the baselines, FlanT5, employing 2 shots as examples, is the second best model. As observed in (Terragni et al., 2023) as well, this in- struction fine-tuned model outperforms Llama-2 with 2 shots in most of the cases. MultiWOZ Data within ConvLab2. We show the goal fulfillment performance of DAUS and the baselines in interaction with ConvLab2’s TOD sys- tem on MultiWOZ 2.1 in Table 3. As in Section 6.1, we observe strong performance of DAUS. Specif- ically, DAUS outperforms all of the in-context learning approaches in terms of goal fulfillment, including prior state-of-the-art (Terragni et al., 2023). Moreover, our method outperforms few- shot GPT-3.5, a model significantly larger than ours (estimated 175 billion parameters vs 13 bil- lion). This further suggests the benefits of fine- tuning LLMs on domain-specific conversational data, as stronger performance can be achieved with significantly smaller LLMs, thus reducing the com- putational requirements of the simulator. As a general remark, results on both benchmarks, i.e., the ConvLab2 and our internal one, show sig- nificant improvements across multiple goal fulfill- ment metrics. Thus, we conclude thatDAUS indeed does lead to more consistent, reliable, and faithful LLM-based user simulators. We will discuss these results more in depth in our qualitative analysis in Section 7.1. 6.2 Lexical Diversity Lexical diversity (LD) of generated user utterances from internal TOD system and MultiWOZ experi- ments is presented in the last 3 columns of Tables 2Table 3: Performance on MultiWOZ 2.1 within ConvLab2 framework. Model Num Shots Compl Rate Succ Rate Book Rate P R F 1 UttLen Unig MTLD ABUS-T (Wen et al., 2015) - 0.93 0.83 0.85 0.84 0.94 0.86 17.4 527 46.9 ABUS-D (Wen et al., 2015) - 0.86 0.60 0.75 0.87 0.90 0.87 9.8 327 28.0 FlanT5-XL (Terragni et al., 2023) 2 0.19 0.13 0.46 0.45 0.39 0.39 13.7 888 41.2 Llama-2 0 0.07 0.04 0.13 0.31 0.21 0.23 8.1 697 30.7 2 0.09 0.08 0.30 0.46 0.34 0.39 10.0 765 38.8 GPT-3.5 2 0.35 0.19 0.34 0.49 0.52 0.48 16.3 626 38.1 DAUS 0 0.41 0.29 0.66 0.69 0.69 0.67 10.6 789 54.9 and 3. We observe a drop in LD, as measured by the length of the generated utterances and the total number of unigrams, when DAUS is fine-tuned on AutomotiveData. This suggests a limited vocab- ulary in the training data, which is expected due to the real users often responding with one or two words, especially in the cancel task. DAUS had a relatively high MTLD score, because of the cor- rectly generated caller, car and transport entities, which usually have unique values. However, a low unigram score is due to averaging metrics over 8 user tasks, where only 3 of them are the entity-rich book task. Meanwhile, the higher LD of FlanT5- based method is due to its prevalent hallucinations, thus falsely inflating the LD scores by generating out-of-context content (see Section 7.1). In MultiWOZ-based experiments, results indi- cate higher LD than ABUS baselines, as mea- sured by MTLD, while the generated utterances are slightly shorter compared to FlanT5. As such, DAUS does not seem to lose LD during fine-tuning on MultiWOZ, while fine-tuning on Automotive- Data seems to reduce it slightly. This can be ex- plained by the fact that AutomotiveData contains both specific vocabulary and utterances from real product users, which makes it hard for in-context learning approaches to imitate. On the other hand, fine-tuning procedure enables the model to learn the particulars of such interactions. 6.3 Generalization to Unseen User Tasks Table 4 shows the percentage of successful sub- task identifications for four variants of our model: DAUS fine-tuned on the full dataset described in Section 4.1, and DAUS fine-tuned on modified datasets by removing certain subtasks ( book (B), cancel (C), or reschedule (R)) from the training sets. With this experiment, we aim to assess the generalization abilities of our approach. Table 4: Percentage of dialogues with successfully iden- tified subtask types across the test cases, with models fine-tuned on specific combinations of subtask types. DAUS (C+R+B) C+R B+R B+C Beasy 99 100 100 99 Bhard1 93 29 85 99 Bhard2 99 86 94 97 Ceasy 96 100 75 99 Chard 100 100 77 96 Reasy 88 100 98 34 Rhard1 97 50 69 0 Rhard2 86 84 56 0 Results show a decrease in performance when a model is not shown the specific subtask during training. For example, when we fine-tune DAUS on the combination of book and reschedule sub- tasks, we observe a considerable drop in perfor- mance on the cancel subtask. However, the largest drop is observed in the most complex subtask type, reschedule, where the model fine-tuned on B+C data completely fails to successfully communicate its goal for both Rhard test cases. We can conclude that DAUS does not generalize well to unseen user goal subtasks. Nevertheless, the overall performance of the fine-tuned models across all of the subtasks is still comparable to the performance of few-shot based models (e.g., B+C correctly predicts the subtask type, on average, in 66% of the dialogues, while Llama-2 2-shot does it in 69% of the dialogues, on average). 7 Qualitative Analysis In this section, we detail and discuss the findings of our qualitative analysis of simulated dialogues.Table 5: Percentage of the observed patterns per sample annotated in simulated dialogues in MultiWOZ. Label FlanT5 DAUS Hallucination 73% 36% Looping simulator 69% 6% Incomplete goal 78% 53% Looping system 20% 22% NLU misclassification 60% 40% Forced end 27% 27% 7.1 Human Evaluation of Generated Dialogues Table 5 presents the prevalence of patterns, de- scribed in Section 5.3, observed through manual annotation of the simulated MultiWOZ dialogues. We observe consistent decrease in hallucinations, reduced number of dialogues with incomplete goal fulfillment, as well as reduced repetition of utter- ances in dialogues generated by DAUS, compared to FlanT5-based simulator. Below, we report the main findings from our analysis. Hallucinations. The percentage of dialogues containing hallucinations drops from 73% for FlanT5-based simulator to 36% with DAUS. We observe that FlanT5 frequently experiences se- vere failures, mostly because it generates non- specified pieces of information, such as defining a random range of time for a taxi pickup, inventing a location for an attraction or referring to a restaurant that have not been previously mentioned. Such hal- lucinations lead to dialogue failures, without pos- sibility to recover the conversation. On the other hand, DAUS does not hallucinate nor misinterpret entities from the user goal and the dialogue, but rather sometimes asks for additional information that is not required by the user goal (e.g., asking restaurant’s phone number, even though it is not strictly specified in the goal). Thus, we conclude that not only the prevalence of the hallucinations is reduced, but also their severity. TOD system failures. We observe that the dia- logue frequently stops before all of the subtasks from the user goal are completed (i.e., if the goal requires to book a restaurant and a taxi, perhaps only the restaurant is booked). While this is partly due to the simulator missing certain part of the user goal, it often happens due to the TOD system failures. We observe several issues with the TOD system within the ConvLab2 framework. First, as mentioned in the previous paragraph, the system aims to prematurely complete the dialogue, thus offering no opportunity to the user (simulator) to fully express their goal. Second, the system’s NLU component often misclassifies certain entities, lead- ing to incorrectly booked restaurants or similar. An example dialogue of both prematurely ending the dialogue and NLU misclassification: CUSTOMER: Can you help me with a robbery that happened? I am the victim. ASSISTANT: Thank you for using our services . (forcing premature end of conversation) CUSTOMER: It happened at 9:10 ASSISTANT: Can you tell me which day you ’d like to travel on? What is your destination? Where will you be departing from? (NLU misclassification) Finally, we observe loops in system’s policy, where the system is stuck in policy states and is not able to continue the conversation. 7.2 Domain-specific Vocabulary During our analysis of conversations generated us- ing our internal TOD system, we observed that DAUS acquires domain-specific vocabulary, which we believe enhances its performance. For instance, when scheduling a vehicle service appointment, customers specify the preferred transport type, usu- ally dropoff (the customer drops off the vehicle and returns when the service is complete) orwaiter (the customer waits at the dealership during the service). This phenomenon, supported by performance im- provements for Transport Type (see Table 2), is evident through qualitative dialogue analysis. Our initial experiments indicate that in-context learning approaches aiming to explain these terms in the prompt do not consistently capture their nuances. Additionally, we noticed that, when fine-tuned on AutomotiveData containing phone call conversa- tions with real users, DAUS tends to generate filler words like “uhm” and “yeah”. 8 Conclusions The use of a domain-aware LLM-based user sim- ulator, such as DAUS, shows promising results in multi-turn interactions with TOD systems. DAUS can fulfill user goals by generating consistent and faithful utterances. Compared to previous LLM-based approaches (Terragni et al., 2023), our method has demonstrated superior performance, as measured by multiple metrics designed to cap- ture the fulfillment of the given goal, as well asfaithfulness across the dialogue. This indicates that DAUS is capable of effectively simulating user be- havior and can serve as a valuable tool for testing and evaluating TOD systems. Moreover, our ap- proach requires relatively small training dataset and imposes modest computational demands, thanks to parameter-efficient fine-tuning. This discovery aligns with findings in related research that con- trasts in-context learning with parameter-efficient fine-tuning (Mosbach et al., 2023; Liu et al., 2022). Consequently, our approach emerges as a prag- matic choice for broader adoption within the NLP and Conversational AI community. The potential applications of LLM-based user simulators are synthetic data augmentation (Li et al., 2022), supporting reinforcement learning approaches (Shi et al., 2019), and TOD system evaluation (Terragni et al., 2023; Zhu et al., 2020). DAUS’s reliability and consistency to the user goal make it particularly suitable for TOD system evalu- ation. As we have seen previously, an incomplete user goal can mainly imply two scenarios: a user simulator who hallucinates or a TOD system that is not able to understand the user’s requirements. Therefore, the presence of a reliable user simulator is crucial: it allows us to identify the TOD system’s errors with high accuracy. Moreover, we stress that at the center of our approach is an LLM, leading to potentially different generations given the same input, depending on the sampling method. This means that DAUS is more flexible than certain agenda-based simulators, which usually rely on template-based responses. As such, we are able to simulate a dialogue with the same user goal multiple times, which results in multiple different attempts of the simulator to fulfill its goal, going through potentially different conversational paths. Therefore, we are able to test the robustness of the TOD system to different expressions of the same user goal. 9 Limitations The approach employed in our study has several inherent limitations, primarily stemming from the use of LLMs. Most notably, GPT-3.5, the model we utilized in our experiments, is not open-source and freely available, which can hinder replicabil- ity of the experiments. Another limitation is re- lated to the opaqueness of the model’s training and fine-tuning processes. These models undergo pre- training and fine-tuning on diverse datasets, the specifics of which are often undisclosed. Conse- quently, it is challenging to ascertain whether these models have been exposed to specific datasets, such as MultiWOZ 2.1, or datasets with similar charac- teristics, which could raise concerns about models performance and potential biases. Furthermore, our experiments were conducted exclusively on two English-language datasets. While LLMs are known for their transfer learning capabilities, allowing for the potential extension of results to other datasets, there is no guarantee of their generalizability across various domains or low-resource languages. The effectiveness of these models in domains distinct from the ones they were trained on remains uncertain and should be approached with caution. In our analysis, we also observed instances where LLMs exhibit hallucinations. Despite being superior to in-context learning approaches like (Ter- ragni et al., 2023), we still encountered cases of LLM responses that deviated from the expected or coherent output. These hallucinations may lead to unpredictable and potentially inappropriate re- sponses in certain conversational contexts, raising concerns about the reliability and safety of such systems. We also noticed a decrease in performance when certain user subtasks are omitted from the train- ing dataset when we fine-tune DAUS, although the overall performance remains comparable to that of few-shot models. In our analysis, we did not inves- tigate if providing one or two dialog shots would address this performance decrease. Finally, the methodology relies on conversa- tional data for fine-tuning LLMs. This reliance introduces additional limitations. Firstly, obtaining suitable conversational data may be challenging or even unfeasible in some scenarios. Researchers may resort to crowd-sourcing tools to gather dia- logue examples or use LLMs themselves to gener- ate synthetic data, which could introduce biases or inaccuracies. Secondly, the quality of the conversa- tional data used for fine-tuning plays a pivotal role in the model’s performance. In our study, we uti- lized well-curated conversational data, but we did not investigate the impact of using noisier or less meticulously curated data. The use of lower-quality data sources may affect the model’s performance and raise questions about its reliability and robust- ness in real-world applications.10 Ethics Statement The use of LLMs for user simulation raises ethi- cal considerations. We acknowledge the potential for perpetuating biases and stereotypes present in the data used to train these models (Brown et al., 2020b; Lucy and Bamman, 2021; Bender et al., 2021). While we have not implemented specific measures to mitigate these risks in this paper, we recognize their importance and urge the research community to address these challenges. It is essential to note that we have used the user simulator solely to evaluate the performance of a dialogue system. However, LLMs can be used in a reinforcement learning setting to train dialog sys- tems (Shi et al., 2019). In such cases, it is crucial to use these models judiciously because of their unpre- dictable and potentially inappropriate responses. In addition to ethical considerations, it is cru- cial to acknowledge the significant environmental impact of LLMs. Their training and deployment consumes a considerable amount of energy, leading to environmental issues (Strubell et al., 2019). We should also be aware of the significant carbon foot- print while fine-tuning the LLMs and using them for inference. Acknowledgement Our gratitude to Damián Pascual for streamlining the implementation of the fine-tuning framework, saving us valuable time. Special thanks to the re- viewers, Diana Nicoleta Popa, Vijeta Avijeet, and our colleagues at Telepathy Labs in Zürich for their constructive feedback and insightful discussions. References Layla El Asri, Jing He, and Kaheer Suleman. 2016. A sequence-to-sequence model for user simulation in spoken dialogue systems. In Interspeech 2016, 17th Annual Conference of the International Speech Com- munication Association, pages 1151–1155. ISCA. Krisztian Balog and ChengXiang Zhai. 2023. User simulation for evaluating information access systems. arXiv preprint arXiv:2306.08550. Namo Bang, Jeehyun Lee, and Myoung-Wan Koo. 2023. Task-optimized adapters for an end-to- end task-oriented dialogue system. arXiv preprint arXiv:2305.02468. Emily M Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM confer- ence on fairness, accountability, and transparency, pages 610–623. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020a. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020b. Language models are few-shot learners. Ad- vances in neural information processing systems , 33:1877–1901. Hyung Won Chung, Le Hou, Shayne Longpre, Bar- ret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416. Sam Davidson, Salvatore Romeo, Raphael Shu, James Gung, Arshit Gupta, Saab Mansour, and Yi Zhang. 2023. User simulation with large language models for evaluating task-oriented dialogue. arXiv preprint arXiv:2309.13233. Wieland Eckert, Esther Levin, and Roberto Pieraccini. 1997. User modeling for spoken dialogue system evaluation. 1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings, pages 80–87. Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyag Gao, and Dilek Hakkani- Tur. 2019. Multiwoz 2.1: Multi-domain dialogue state corrections and state tracking baselines. arXiv preprint arXiv:1907.01669. Prakhar Gupta, Cathy Jiao, Yi-Ting Yeh, Shikib Mehri, Maxine Eskenazi, and Jeffrey Bigham. 2022a. In- structDial: Improving zero and few-shot general- ization in dialogue through instruction tuning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 505– 525, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Raghav Gupta, Harrison Lee, Jeffrey Zhao, Yuan Cao, Abhinav Rastogi, and Yonghui Wu. 2022b. Show, don’t tell: Demonstrations outperform descriptions for schema-guided task-oriented dialogue. In Pro- ceedings of the 2022 Conference of the North Amer- ican Chapter of the Association for Computational Linguistics: Human Language Technologies, pages4541–4549, Seattle, United States. Association for Computational Linguistics. Izzeddin Gür, Dilek Hakkani-Tür, Gokhan Tür, and Pararth Shah. 2018. User modeling for task oriented dialogues. In 2018 IEEE Spoken Language Technol- ogy Workshop (SLT), pages 900–906. IEEE. Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg- Kirkpatrick, and Graham Neubig. 2021. Towards a unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366. Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. 2020. A simple language model for task-oriented dialogue. Advances in Neural Information Processing Systems, 33:20179– 20191. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adap- tation of large language models. arXiv preprint arXiv:2106.09685. V ojtˇech Hudeˇcek and Ondˇrej Dušek. 2023. Are llms all you need for task-oriented dialogue? arXiv preprint arXiv:2304.06556. Tianbo Ji, Yvette Graham, Gareth Jones, Chenyang Lyu, and Qun Liu. 2022. Achieving reliable human assessment of open-domain dialogue systems. In Proceedings of the 60th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), ACL’22, pages 6416–6437. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of halluci- nation in natural language generation. ACM Comput. Surv., 55(12). Simon Keizer, Milica Gasic, Filip Jurcicek, François Mairesse, Blaise Thomson, Kai Yu, and Steve Young. 2010. Parameter estimation for agenda-based user simulation. In Proceedings of the SIGDIAL 2010 Conference, pages 116–123. Alon Lavie and Abhaya Agarwal. 2007. Meteor: An automatic metric for mt evaluation with high levels of correlation with human judgments. In Proceedings of the Second Workshop on Statistical Machine Trans- lation, StatMT ’07, page 228–231, USA. Association for Computational Linguistics. Xiujun Li, Zachary C Lipton, Bhuwan Dhingra, Lihong Li, Jianfeng Gao, and Yun-Nung Chen. 2016. A user simulator for task-completion dialogues. arXiv preprint arXiv:1612.05688. Zekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing Qian, and Xifeng Yan. 2022. Controllable Dialogue Simulation with In-context Learning. In Findings of the Association for Computational Linguistics: EMNLP 2022 , pages 4330–4347. Association for Computational Linguistics. Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74–81. Hsien-Chin Lin, Shutong Feng, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Michael Heck, Ben- jamin Ruppik, Renato Vukovic, and Milica Gasi ´c. 2023. Emous: Simulating user emotions in task- oriented dialogues. In Proceedings of the 46th Inter- national ACM SIGIR Conference on Research and Development in Information Retrieval, pages 2526– 2531. Hsien-Chin Lin, Christian Geishauser, Shutong Feng, Nurul Lubis, Carel van Niekerk, Michael Heck, and Milica Gasic. 2022. GenTUS: Simulating User Be- haviour and Language in Task-oriented Dialogues with Generative Transformers. In Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGDIAL 2022,, pages 270–282. Association for Computational Linguistics. Hsien-Chin Lin, Nurul Lubis, Songbo Hu, Carel van Niekerk, Christian Geishauser, Michael Heck, Shu- tong Feng, and Milica Gasic. 2021. Domain- independent User Simulation with Transformers for Task-oriented Dialogue Systems. In Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGdial 2021 , pages 445–456. Association for Computational Lin- guistics. Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mo- hta, Tenghao Huang, Mohit Bansal, and Colin A Raf- fel. 2022. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. Ad- vances in Neural Information Processing Systems , 35:1950–1965. Li Lucy and David Bamman. 2021. Gender and repre- sentation bias in gpt-3 generated stories. In Proceed- ings of the Third Workshop on Narrative Understand- ing, pages 48–55. Andrea Madotto, Zhaojiang Lin, Genta Indra Winata, and Pascale Fung. 2021. Few-shot bot: Prompt- based learning for dialogue systems. arXiv preprint arXiv:2110.08118. Andrea Madotto and Zihan Liu. 2020. Language mod- els as few-shot learner for task-oriented dialogue sys- tems. ArXiv, abs/2008.06239. Philip M McCarthy. 2005. An assessment of the range and usefulness of lexical diversity measures and the potential of the measure of textual, lexical diversity (MTLD). Ph.D. thesis, The University of Memphis. Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Di- etrich Klakow, and Yanai Elazar. 2023. Few-shot fine-tuning vs. in-context learning: A fair compari- son and evaluation. In Findings of the Association for Computational Linguistics: ACL 2023, pages 12284– 12314, Toronto, Canada. Association for Computa- tional Linguistics.Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car- roll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. Paul Owoicho, Ivan Sekulic, Mohammad Aliannejadi, Jeffrey Dalton, and Fabio Crestani. 2023. Exploiting simulated user feedback for conversational search: Ranking, rewriting, and beyond. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 632–642. Kishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic evalu- ation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computa- tional Linguistics, pages 311–318. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text trans- former. J. Mach. Learn. Res., 21(1). Jost Schatzmann, Blaise Thomson, Karl Weilhammer, Hui Ye, and Steve Young. 2007. Agenda-based user simulation for bootstrapping a pomdp dialogue sys- tem. In Human Language Technologies 2007: The Conference of the North American Chapter of the As- sociation for Computational Linguistics; Companion Volume, Short Papers, pages 149–152. Jost Schatzmann and Steve J. Young. 2009. The hidden agenda user simulation model. IEEE Transactions on Audio, Speech, and Language Processing, 17:733– 747. Ivan Sekuli ´c, Mohammad Aliannejadi, and Fabio Crestani. 2022. Evaluating mixed-initiative conversa- tional search systems via user simulation. InProceed- ings of the Fifteenth ACM International Conference on Web Search and Data Mining, pages 888–896. Weiyan Shi, Kun Qian, Xuewei Wang, and Zhou Yu. 2019. How to build user simulators to train rl-based dialog systems. In Proceedings of the 2019 Confer- ence on Empirical Methods in Natural Language Pro- cessing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 1990–2000. Emma Strubell, Ananya Ganesh, and Andrew McCal- lum. 2019. Energy and policy considerations for deep learning in nlp. In Proceedings of the 57th An- nual Meeting of the Association for Computational Linguistics, pages 3645–3650. Silvia Terragni, Modestas Filipavicius, Nghia Khau, Bruna Guedes, André Manso, and Roland Mathis. 2023. In-context learning user simulators for task- oriented dialog systems. In Proceedings of the 1st Workshop on Foundations and Applications in Large-scale AI Models -Pre-training, Fine-tuning, and Prompt-based Learning. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- bert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open founda- tion and fine-tuned chat models. arXiv preprint arXiv:2307.09288. Dazhen Wan, Zheng Zhang, Qi Zhu, Lizi Liao, and Min- lie Huang. 2022. A unified dialogue user simulator for few-shot data augmentation. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 3788–3799, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Tsung-Hsien Wen, Milica Gaši ´c, Nikola Mrkši ´c, Pei- Hao Su, David Vandyke, and Steve Young. 2015. Semantically conditioned LSTM-based natural lan- guage generation for spoken dialogue systems. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 1711–1721. Association for Computational Linguis- tics. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. 2019. Bertscore: Eval- uating text generation with bert. arXiv preprint arXiv:1904.09675. Zheng Zhang, Ryuichi Takanobu, Qi Zhu, MinLie Huang, and XiaoYan Zhu. 2020. Recent advances and challenges in task-oriented dialog systems. Sci- ence China Technological Sciences , 63(10):2011– 2027. Jeffrey Zhao, Raghav Gupta, Yuan Cao, Dian Yu, Mingqiu Wang, Harrison Lee, Abhinav Rastogi, Izhak Shafran, and Yonghui Wu. 2022. Description- driven task-oriented dialog modeling. arXiv preprint arXiv:2201.08904. Qi Zhu, Zheng Zhang, Yan Fang, Xiang Li, Ryuichi Takanobu, Jinchao Li, Baolin Peng, Jianfeng Gao, Xiaoyan Zhu, and Minlie Huang. 2020. Convlab- 2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.A User tasks Description of eight different test cases (user goals) are provided in Table 6. We additionally add com- parisons with FlanT5-XXL. Table 6: Description of user goals with subtask types. # User subtask Difficulty User goal details 1 Book Easy New customer; Available: today 4PM; Transport_type: waiter; Service: check engine. 2 Book Hard Known customer with 1 appointment and 2 cars; Available: Wednesday; Transport_type: dropoff; Unknown Service. 3 Book Hard Known customer with 3 appointments and 2 cars; Available: Wednesday; Transport_type: dropoff; Two services: engine over- heating and oil change. 4 Cancel Easy Known customer with 1 appointment. 5 Cancel Hard Known customer with 3 appointments. 6 Reschedule Easy Known customer with 1 appointment; Available: 10 AM; Transport_type: dropoff; Unknown service. 7 Reschedule Hard Known customer with 1 appointment; Available: afternoon; Transport_type: waiter; Service: oil change. 8 Reschedule Hard Known customer from un- known phone number; With 3 appointments; Available: Wednesday; Transport_type: loaner; Two services: Oil change and engine check B Results per Tasks Table 8 shows the breakdown of the results of base- lines and DAUS per specific user goal. C Utterance-Level Metrics In addition to dialogue-level metrics detailed in Section 5, we consider a number of utterance- level metrics. Such metrics are based on com- parisons of generated utterances to the target ut- terance in the test set of the appropriate dataset, Table 7: Inter-Annotator Agreement, as measured by Fleiss’ κ for samples from DAUS and FlanT5-XL. DAUS FlanT5-XL Hallucination 0.365 0.499 Incomplete Goal 0.585 0.754 Looping Simulator 0.319 0.687 NLU Misclassification 0.356 0.308 Forces end of dialogue 0.314 0.367 Looping System 0.640 0.084 described in Section 4.1. We consider two main types of utterance-level metrics: 1) natural lan- guage generation (NLG) metrics; and 2) natu- ral language understanding-based (NLU) metrics. We compute several well-known NLG metrics: BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), BERTScore (Zhang et al., 2019), METEOR (Lavie and Agarwal, 2007), as well as cosine similarity between embedded generated and target utterances. Moreover, we design several domain-specific NLU-based metrics. TOD systems are composed of multiple modules, with NLU module, that aims to understand and parse the given user utterance, being one of the essential modules. Thus, we em- ploy NLU component of the TOD systems to ex- tract user (simulator) intent and mentioned entities, Similarly to NLG-metrics, we compare the intent and entities extracted from the generated utterance, to those in the target utterance. Specifically, we design the following metrics: • Cosine similarity between the embedded in- tents extracted form the generated utterance and the target utterance. Intents are embedded with RoBERTa model. • Cosine similarity between the generated and the target utterance, in which the entities were masked. Utterances are embedded with RoBERTa model. • Precision, Recall, and F1 of entities between the generated and the target utterances. Table 9 shows the results across the described met- rics. D Qualitative Analysis Details Table 7 shows the Inter-Annotator agreement per model and per type of pattern. Table 10 shows three examples of failed simu- lated dialogues.E Computing Infrastructure We ran the experiments on a machine equipped with two AMD® EPYC 7763 64-Core Processors, and 10 NVIDIA RTX A6000 GPUs with 48GB RAM each, CUDA v11.6, Driver Version 510.54. All the experiments ran on a single GPU. As de- tailed earlier, we use Llama-2 (7B and 13B param- eters versions), as well as FlanT5 (3B and 11B versions). Fine-tuning of a single Llama-2 model requires approximately 12 GPU hours. We estimate all of the experiments to require several hundred GPU hours. F Use of AI assistants for writing ChatGPT was used for rephrasing certain sections of this work to enhance clarity and coherence. It was not involved in generating new content such as tables, citations, or equations. The authors’ first language is not English, and the assistance from ChatGPT aimed to improve readability.Table 8: Results of selected baselines and DAUS (the main method based on Llama-2 13B, as well as the 7B version) per specific user goal. Subtask Model N shots User Task Compl Rate Succ Rate P R F1 Service Info Transport Car Info Caller Info Chard Llama-2-13b 0 43 100 43 0.74 0.79 0.76 99.5 Llama-2-13b 2 52 100 44 0.77 0.86 0.8 100 FlanT5-xxl 0 61 100 57 0.83 0.84 0.83 99.5 FlanT5-xxl 2 65 100 63 0.84 0.9 0.85 99 FlanT5-xl 0 67 100 64 0.85 0.89 0.86 98 FlanT5-xl 2 75 100 73 0.89 0.94 0.9 100 DAUS-7b 0 93 100 93 0.96 0.96 0.96 100 DAUS 0 100 100 100 1 1 1 100 Bhard2 Llama-2-13b 0 94 23 1 0.59 0.89 0.67 31 4 73 57.5 Llama-2-13b 2 98 27 1 0.62 0.87 0.71 44 7 84 64 FlanT5-xxl 0 81 64 19 0.78 0.91 0.81 74 45 78.3 78 FlanT5-xxl 2 91 72 15 0.77 0.86 0.8 83 42 86 84 FlanT5-xl 0 81 18 4 0.37 0.77 0.44 36 18 29.3 22.5 FlanT5-xl 2 95 58 6 0.66 0.81 0.7 75 37 74.6 68.5 DAUS-7b 0 99 76 29 0.87 0.84 0.85 64 100 88.5 DAUS 0 100 89 50 0.93 0.85 0.88 90 93 100 99 Beasy Llama-2-13b 0 97 43 23 0.77 0.91 0.82 59 49 77 100 Llama-2-13b 2 100 43 4 0.76 0.93 0.83 51 15 92.3 100 FlanT5-xxl 0 90 65 46 0.85 0.93 0.86 70 63 90 99 FlanT5-xxl 2 98 57 50 0.89 0.88 0.88 60 80 84 100 FlanT5-xl 0 94 14 14 0.73 0.86 0.78 34 91 40.6 99.5 FlanT5-xl 2 97 23 22 0.81 0.85 0.82 26 94 54.3 100 DAUS-7b 0 96 55 22 0.92 0.87 0.89 99 98.7 100 DAUS 0 100 37 15 0.93 0.89 0.91 38 98 100 98 Bhard1 Llama-2-13b 0 65 1 0 0.59 0.9 0.69 19 6 64 100 Llama-2-13b 2 83 0 0 0.62 0.9 0.71 4 1 71.3 100 FlanT5-xxl 0 80 10 0 0.82 0.84 0.81 16 71 84 99.5 FlanT5-xxl 2 56 9 0 0.69 0.86 0.73 35 44 69.3 100 FlanT5-xl 0 40 2 0 0.6 0.84 0.67 25 28 61.6 100 FlanT5-xl 2 24 1 0 0.48 0.91 0.6 62 10 48.3 100 DAUS-7b 0 78 2 0 0.81 0.82 0.8 80 86 100 DAUS 0 99 15 0 0.84 0.84 0.83 17 84 94 95.5 Ceasy Llama-2-13b 0 39 100 37 0.76 0.78 0.76 100 Llama-2-13b 2 67 100 61 0.85 0.89 0.86 100 FlanT5-xxl 0 75 100 74 0.91 0.89 0.89 100 FlanT5-xxl 2 94 100 93 0.98 0.97 0.98 100 FlanT5-xl 0 73 100 71 0.89 0.87 0.87 100 FlanT5-xl 2 97 100 97 0.99 0.99 0.99 100 DAUS-7b 0 100 100 100 1 1 1 100 DAUS 0 100 100 100 1 1 1 100 Reasy Llama-2-13b 0 14 1 0 0.51 0.91 0.63 2 7 77.6 100 Llama-2-13b 2 38 2 2 0.54 0.93 0.67 9 6 80 98.5 FlanT5-xxl 0 60 3 2 0.78 0.91 0.83 16 80 98.3 99.5 FlanT5-xxl 2 76 28 8 0.84 0.91 0.86 45 82 99.3 100 FlanT5-xl 0 44 8 3 0.75 0.88 0.8 26 79 92 100 FlanT5-xl 2 71 30 3 0.81 0.91 0.85 54 70 98.6 100 DAUS-7b 0 99 10 10 0.97 0.91 0.94 99 100 100 DAUS 0 99 6 5 0.91 0.93 0.91 9 100 100 100 Rhard1 Llama-2-13b 0 25 7 0 0.55 0.88 0.66 27 5 79 93.5 Llama-2-13b 2 55 13 6 0.61 0.93 0.72 42 15 79.6 91 FlanT5-xxl 0 20 14 5 0.67 0.87 0.75 88 47 86 85.5 FlanT5-xxl 2 34 29 10 0.68 0.8 0.73 95 31 81.6 80.5 FlanT5-xl 0 15 12 3 0.43 0.61 0.49 72 16 40.3 41.5 FlanT5-xl 2 61 53 11 0.71 0.83 0.74 82 21 74.6 74.5 DAUS-7b 0 48 22 21 0.72 0.87 0.78 77 84.3 96 DAUS 0 100 62 46 0.9 0.94 0.91 98 99 100 100 Rhard2 Llama-2-13b 0 26 1 0 0.48 0.89 0.59 20 6 62.3 60 Llama-2-13b 2 58 1 0 0.53 0.94 0.65 23 4 74 69 FlanT5-xxl 0 26 7 4 0.67 0.93 0.75 67 50 81 79 FlanT5-xxl 2 42 8 1 0.64 0.83 0.7 49 33 82.3 68.5 FlanT5-xl 0 9 0 0 0.21 0.43 0.26 17 5 19.3 13.5 FlanT5-xl 2 47 2 0 0.42 0.69 0.47 14 3 43 41.5 DAUS-7b 0 36 6 5 0.67 0.83 0.73 67 98 69.5 DAUS 0 98 1 0 0.78 0.93 0.84 5 10 100 95.5Table 9: NLG- and NLU-based utterance-level metrics. BLUE ROUGE BERTScore METEORutterance similarity intent similarity entities_R entities_P entities_F1 MultiWOZ Llama-2-7b 0.12 0.18 0.85 0.16 0.31 0.67 0.22 0.35 0.37 Llama-2-13b 0.13 0.19 0.85 0.16 0.32 0.67 0.26 0.36 0.38 Llama-2-13b-fine-tuned 0.12 0.19 0.85 0.16 0.31 0.67 0.26 0.35 0.37 AutomotiveData Llama-2-7b 0.22 0.24 0.88 0.17 0.52 0.58 0.44 0.18 0.47 Llama-2-13b 0.42 0.43 0.92 0.26 0.68 0.73 0.42 0.25 0.47 Llama-2-13b-fine-tuned 0.42 0.43 0.92 0.26 0.68 0.73 0.42 0.25 0.47Table 10: Examples of common failures observed through qualitative analysis. Example 1: REQUIREMENTS: You are looking forward to trying local restaurants. You are looking for a particular restaurant. Its name is called cote. Once you find a restaurant, make sure you get postcode. Once you find the restaurant you want to book a table for 7 people at 12:00 on tuesday. You are looking for a place to stay. The hotel should be in the cheap price range. The hotel should be in the north. The hotel does not need to include free parking. The hotel should be in the type of guesthouse. If there is no such hotel, how about one that is in the moderate price range. Once you find a hotel, make sure you get postcode, phone number. You also want to book a taxi to commute between the two places. The taxi should arrive at the restaurant from the hotel by 02:45. Once you find a taxi, make sure you get car type, phone number CONVERSATION: ... ASSISTANT: What time will you be leaving . What time would you like to arrive ? CUSTOMER: I would like to depart at 2 :45 to return at 5 :15 . (hallucination) ASSISTANT: Thank you for using our services . CUSTOMER: Thank you . ASSISTANT: I ’ m happy to have been able to help you today . CUSTOMER: Thank you for the help the table has been booked and taxi has been booked . ASSISTANT: What time would you like to leave ? CUSTOMER: I would like to leave at 2 : 45 to return at 5 :15 . (hallucination) ASSISTANT: Your booking is complete , a tesla will be picking you up . The contact number is 45067427198 . CUSTOMER: Thank you , have a nice day ! ASSISTANT: Ok , thank you . Have a good day . CUSTOMER: Can you check cote restaurant please . (looping) ASSISTANT: It is in the centre area . CUSTOMER: Can you check cote restaurant please . (looping) ASSISTANT: They serve french . It is in the centre area . CUSTOMER: Thank you for your help and have a good day ! ASSISTANT: Thank you for using our services . CUSTOMER: Can you check the cote restaurant . (looping) ASSISTANT: Okay , how about cote ? That is a french restaurant . CUSTOMER: Can you check cote restaurant please . ASSISTANT: That is a french restaurant . They are in the expensive price range . CUSTOMER: Thank you for your help and have a good day ! ASSISTANT: You are more than welcome !. CUSTOMER: Can you please look up cote restaurant for me please . (looping) ... Example 2: REQUIREMENTS: You are looking for a place to stay. The hotel should have a star of 4. The hotel should be in the centre. The hotel should be in the expensive price range. The hotel does not need to include free parking. If there is no such hotel, how about one that has free parking. Once you find the hotel you want to book it for 5 people on sunday for 3 nights CONVERSATION: CUSTOMER: I want to find a hotel with a four star rating. ASSISTANT: I am sorry I have no listings for any with four stars . (NLU misclassification since later it does find criteria) CUSTOMER: How about a guesthouse? ASSISTANT: Unfortunately , I couldn’t find anything with four stars . I can’t find any guesthouse that fit your criteria , i’m sorry . CUSTOMER: That’s fine, but can you try finding an expensive hotel in the centre of town? ASSISTANT: There aren’t any that match your criteria in the centre . Any other suggestions ? There is none that is expensive . Would you like to change your criteria ? I am sorry I have no listings for any with four stars . Sorry there is no hotel fitting the description you asked for. CUSTOMER: I am looking for a 4 star hotel that is expensive and in the centre of town with free parking. ASSISTANT: How about university arms hotel ? It is in the centre area . It has wifi . It is a hotel . The hotel is 4 stars . CUSTOMER: Can you book it for me? ASSISTANT: You are more than welcome ! CUSTOMER: Ok. Book me for 5 people on sunday for 3 nights. Example 3: REQUIREMENTS: You are also looking for a train. The train should depart from cambridge. The train should leave on sunday. The train should go to stansted airport. The train should arrive by 08:45. Once you find the train you want to make a booking for 1 people. You are looking forward to trying local restaurants. The restaurant should be in the centre. The restaurant should be in the expensive price range. The restaurant should serve modern european food. Once you find a restaurant, make sure you get postcode CONVERSATION: ... CUSTOMER: Thanks. I’m also looking for a restaurant. ASSISTANT: I have 110 options for you !. How about curry prince ? CUSTOMER: I need something in the centre. and I would like to spend some money. Expensive please. ASSISTANT: We have 33 such places . I would suggest cote . It is located in the centre . CUSTOMER: Is Cote a modern European restaurant? ASSISTANT: There no modern european restaurants that I can find right now . Would something else work ? I do n’t have anything in the expensive range that fits that criteria . I ’ m sorry . i can not find details for cote . I have n’t found any in the centre. CUSTOMER: I really need a modern european restaurant, preferably expensive. I’ll try a different area, if necessary. ASSISTANT: I do not have anything in that price range for modern european . Another criteria perhaps ? There are no expensive ones . I ’ m sorry . i can not find details for cote . There no such restraunts in centre. There are no modern european restaurants . No expensive restaurant. I ’ m sorry . i can not find details for cote . There no such restraunts in centre. (looping) CUSTOMER: Can you please try one more time? I really need an expensive restaurant, thank you. ASSISTANT: I am unable to find any modern european restaurants in town . There are none in expensive , perhaps something else ? I ’ m sorry . i can not find details for cote . I did not find any restaurants in centre . (looping) CUSTOMER: What about expensive modern european? ASSISTANT: There are no modern european food places , shall I run another search ? There are none in expensive , perhaps something else ? I ’ m sorry . i can not find details for cote . Sorry , there are no restaurants like that in the centre . (looping) CUSTOMER: Yes please run another search. ASSISTANT: Thank you for contacting the help desk . Have a great day . (forces premature end of conversation) CUSTOMER: What did you find for expensive modern european? ASSISTANT: There are no modern european restaurants unfortunately . There are none in expensive , perhaps something else ? I ’ m sorry . i can not find details for cote . I am sorry there is none even in the centre. (looping) CUSTOMER: You are sorry. I am sorry. You are unhelpful. I will find my own place to eat. ASSISTANT: Have a good day . CUSTOMER: Wait, I’m sorry. What can you suggest for expensive modern European restaurants? ASSISTANT: I do not have anything in that price range for modern european . Another criteria perhaps ? I do n’t have anything in the expensive range that fits that criteria . I ’ m sorry . i can not find details for cote . I am sorry but there are no restaurants that fit that criteria in the centre . (looping) CUSTOMER: I would really like a restaurant please. Can you search again? ... ASSISTANT: Have a good day .",
      "references": [
        "A sequence-to-sequence model for user simulation in spoken dialogue systems.",
        "User simulation for evaluating information access systems.",
        "Task-optimized adapters for an end-to- end task-oriented dialogue system.",
        "On the dangers of stochastic parrots: Can language models be too big?",
        "Language models are few-shot learners.",
        "Scaling instruction-finetuned language models.",
        "User simulation with large language models for evaluating task-oriented dialogue.",
        "User modeling for spoken dialogue system evaluation.",
        "Multiwoz 2.1: Multi-domain dialogue state corrections and state tracking baselines.",
        "In- structDial: Improving zero and few-shot general- ization in dialogue through instruction tuning.",
        "Show, don’t tell: Demonstrations outperform descriptions for schema-guided task-oriented dialogue.",
        "User modeling for task oriented dialogues.",
        "Towards a unified view of parameter-efficient transfer learning.",
        "A simple language model for task-oriented dialogue.",
        "Lora: Low-rank adap- tation of large language models.",
        "Are llms all you need for task-oriented dialogue?",
        "Achieving reliable human assessment of open-domain dialogue systems.",
        "Survey of halluci- nation in natural language generation.",
        "Parameter estimation for agenda-based user simulation.",
        "Meteor: An automatic metric for mt evaluation with high levels of correlation with human judgments.",
        "Rouge: A package for automatic evaluation of summaries.",
        "Emous: Simulating user emotions in task- oriented dialogues.",
        "GenTUS: Simulating User Be- haviour and Language in Task-oriented Dialogues with Generative Transformers.",
        "Domain- independent User Simulation with Transformers for Task-oriented Dialogue Systems.",
        "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning.",
        "Gender and repre- sentation bias in gpt-3 generated stories.",
        "Few-shot bot: Prompt- based learning for dialogue systems.",
        "Language mod- els as few-shot learner for task-oriented dialogue sys- tems.",
        "An assessment of the range and usefulness of lexical diversity measures and the potential of the measure of textual, lexical diversity (MTLD).",
        "Few-shot fine-tuning vs. in-context learning: A fair compari- son and evaluation.",
        "Training language models to follow instructions with human feedback.",
        "Exploiting simulated user feedback for conversational search: Ranking, rewriting, and beyond.",
        "Bleu: a method for automatic evalu- ation of machine translation.",
        "Exploring the limits of transfer learning with a unified text-to-text trans- former.",
        "Agenda-based user simulation for bootstrapping a pomdp dialogue sys- tem.",
        "The hidden agenda user simulation model.",
        "Evaluating mixed-initiative conversa- tional search systems via user simulation.",
        "How to build user simulators to train rl-based dialog systems.",
        "Energy and policy considerations for deep learning in nlp.",
        "In-context learning user simulators for task- oriented dialog systems.",
        "Llama 2: Open founda- tion and fine-tuned chat models.",
        "A unified dialogue user simulator for few-shot data augmentation.",
        "Semantically conditioned LSTM-based natural lan- guage generation for spoken dialogue systems.",
        "Controllable Dialogue Simulation with In-context Learning.",
        "Bertscore: Eval- uating text generation with bert.",
        "Recent advances and challenges in task-oriented dialog systems.",
        "Description- driven task-oriented dialog modeling.",
        "Convlab- 2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems."
      ],
      "meta_data": {
        "arxiv_id": "2402.13374v1",
        "authors": [
          "Ivan Sekulić",
          "Silvia Terragni",
          "Victor Guimarães",
          "Nghia Khau",
          "Bruna Guedes",
          "Modestas Filipavicius",
          "André Ferreira Manso",
          "Roland Mathis"
        ],
        "published_date": "2024-02-20T20:57:47Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces DAUS (Domain-Aware User Simulator), an LLM-based user simulator for task-oriented dialogue that is fine-tuned on in-domain dialogues paired with natural-language user goals to improve goal-faithful, coherent multi-turn interactions. Key findings: (1) fine-tuning substantially increases end-to-end goal fulfillment vs. zero-/few-shot prompting baselines and even vs. larger proprietary models on MultiWOZ; (2) fine-tuning reduces hallucinations and looping behavior, improving consistency and making simulator-driven evaluation of TOD systems more reliable; (3) DAUS remains system-agnostic (natural-language-only interface) while retaining some lexical diversity.",
        "methodology": "Formulates user simulation as next-utterance generation conditioned on user goal G (natural language) and dialogue history H. Builds prompts containing task description + G + H with <end-turn> separators; generates user turn autoregressively. Fine-tunes Llama-2 (7B/13B) with parameter-efficient LoRA (r=64, alpha=32, dropout=0.05) applied to attention query/key matrices; no in-context example dialogues are used at inference (0-shot prompting with the fine-tuned model). Post-processes outputs to remove artifacts before sending to TOD systems.",
        "experimental_setup": "Datasets: (1) MultiWOZ 2.1 (public) with natural-language goals; (2) proprietary AutomotiveData (real phone-call user–TOD interactions) with natural-language goals. Splits: for each dataset sample 2,500 train / 300 val / 300 test dialogues after preprocessing. Benchmarks/systems: MultiWOZ evaluated via ConvLab2 TOD pipeline (with modified stopping rule not to end on 'thanks'); automotive evaluated against an internal production-like TOD system. Goal settings: MultiWOZ goals sampled per ConvLab2 procedure; 100 dialogues per goal. Automotive: 8 expert-authored goals (book/cancel/reschedule, easy/hard); 100 dialogues per goal. Baselines: prompted Flan-T5-XL, Llama-2 (0/1/2-shot), GPT-3.5 (few-shot, MultiWOZ only), and agenda-based simulators ABUS-T/ABUS-D (MultiWOZ). Metrics: dialogue-level goal fulfillment (Success/Completion/Book rate; entity P/R/F1 vs goal); automotive-specific metrics (subtask match, caller/car info, transport type). Also lexical diversity (MTLD, unigram count, utterance length). Human eval: 3 expert annotators label 45 dialogues/model (FlanT5 vs DAUS) for hallucination, incomplete goal, looping, and TOD failures; majority vote; Fleiss’ kappa reported.",
        "limitations": "Relies on availability and quality of in-domain goal-annotated dialogues; privacy constraints prevent releasing automotive data/models, limiting reproducibility for that domain. Fine-tuned simulator shows limited generalization to unseen subtask types—performance drops sharply when a subtask (especially reschedule) is absent from training. Hallucinations are reduced but not eliminated; simulator may still ask for unnecessary info. Experiments cover only English and two domains; cross-domain/low-resource robustness is unverified. Some evaluation issues stem from TOD systems (NLU errors, policy loops, premature termination), complicating attribution. Lexical diversity may decrease when training data has short/limited user language. Proprietary baseline (GPT-3.5) is non-transparent and may have data contamination risks.",
        "future_research_directions": "Improve generalization to unseen tasks/subtasks (e.g., mixture-of-skills training, multitask fine-tuning, synthetic subtask augmentation, or combining fine-tuning with few-shot exemplars). Study robustness to noisy/weakly labeled conversational logs and methods for goal extraction/annotation at scale. Develop stronger controllable generation to balance faithfulness and lexical diversity (decoding constraints, goal-conditioned planning, entity tracking). Extend to multilingual/low-resource domains and evaluate transfer. Incorporate safety/bias mitigation and calibration for hallucination detection. Tighter simulator evaluation: metrics better correlated with task completion and causal analysis separating simulator vs TOD failures. Explore using DAUS for RL training and systematic TOD stress testing (adversarial goals, robustness across dialogue paths).",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement",
      "full_text": "REPARO: Compositional 3D Assets Generation with Differentiable 3D Layout Alignment Haonan Han1* Rui Yang2* Huan Liao1* Jiankai Xing1 Zunnan Xu1 Xiaoming Yu3 Junwei Zha3 Xiu Li1† Wanhua Li4† 1 Tsinghua University 2 The University of Hong Kong 3 Tencent 4 Harvard University (e) Ours(d) Compositional generation(b) Individually generated  asset 1 (a) GT  (c) Individually generated  asset 2 Figure 1. Qualitative comparison of generated 3D assets of the single object and multiple objects. (b) and (c) are generated 3D assets of the single object assets using DreamGaussian [51]; (d) is a 3D asset of multiple objects generated by DreamGaussian [51]; (e) is our result. Abstract Traditional image-to-3D models often struggle with scenes containing multiple objects due to biases and occlusion complexities. To address this challenge, we present REPARO, a novel approach for compositional 3D asset gen- eration from single images. REPARO employs a two-step process: first, it extracts individual objects from the scene and reconstructs their 3D meshes using image-to-3D mod- els; then, it optimizes the layout of these meshes through dif- ferentiable rendering techniques, ensuring coherent scene composition. By integrating optimal transport-based long- range appearance loss term and high-level semantic loss term in the differentiable rendering, REPARO can effec- tively recover the layout of 3D assets. The proposed method can significantly enhance object independence, detail accu- racy, and overall scene coherence. Extensive evaluation of multi-object scenes demonstrates that our REPARO offers a comprehensive approach to address the complexities of multi-object 3D scene generation from single images. The demo have been available at https://reparo-3d.github.io/. ∗ Equal contribution. † Corresponding authors. 1. Introduction The field of 3D content creation has advanced rapidly due to progress in reconstruction methods [16, 35] and gener- ative frameworks [40]. Automated 3D content generation enables creators in augmented reality (AR), virtual reality (VR), gaming, and filmmaking [20, 25, 50] by significantly reducing manual labor requirements. Recent research in 3D generation primarily focuses on optimization-based 2D approaches, particularly text-to- 3D [26, 40, 60] and image-to-3D [27, 31, 34, 52] models. For example, Dreamfusion [40] overcomes 3D data scarcity by distilling geometry and appearance from 2D diffusion models; and DreamGaussian [51] integrates 3D Gaussian Splatting into generative pipelines with mesh extraction and texture refinement. However, despite their effectiveness in single-object scenes, these methods face challenges in reconstructing multi-object scenes. This limitation stems from dataset biases: most 3D training samples feature cen- trally aligned single objects, and preprocessing pipelines of- ten re-center inputs, thereby introducing inherent positional bias. Consequently, occluded objects are frequently misrep- resented as fused entities, leading to erroneously merged assets in rendered outputs, as shown in Figure 1 (d). Fur- 1 arXiv:2405.18525v2  [cs.CV]  27 Aug 2025thermore, typical 3D generation models output assets as monolithic mesh representations. This forces users to rely on error-prone post-processing steps to segment individual object mesh, which does not ensure the quality of the seg- mented assets. To address this challenge, we propose REPARO, a compositional 3D generation pipeline capable of generat- ing multiple objects from a single input image. Our ap- proach decomposes the scene into discrete assets, then sys- tematically reassembles and globally optimizes their spa- tial arrangement. This methodology not only leverages the strengths of off-the-shelf models (the ability to generate sin- gle objects with high fidelity) but also addresses inherent challenges in the multi-object scene with complex occlu- sions and interactions. Specifically, our pipeline comprises two core stages. First, individual objects are isolated from the input im- age through cropping and inpainting to generate context- complete single-object images, which are processed using off-the-shelf image-to-3D models [33, 41, 54] to produce high-fidelity 3D assets. Second, the 3D assets are assem- bled into a cohesive scene and geometrically aligned with the input image. After placing all objects within a unified coordinate system, we employ differentiable rendering to optimize the spatial arrangement of each asset. During ren- dering, the pose parameters (translation, rotation, and scale) of each 3D asset are treated as optimizable variables, which are iteratively refined via gradient descent using a loss func- tion. Unlike conventional pixel-wise loss function [3], we introduce an optimal transport (OT)-based long-range ap- pearance loss that integrates RGB color, depth, and posi- tional information to constrain global structural relation- ships between objects. Therefore, this loss can match the rendered image and the reference image. Additionally, a high-level semantic loss is introduced to ensure semantic alignment and coherence between the synthesized scene and the original image context using high-level visual features. Through these two stages, individual-object reconstruc- tion and combined-scene optimization, our REPARO en- hances object independence and geometric detail accu- racy, particularly for occluded regions. Simultaneously, it preserves both spatial arrangement fidelity and semantic- geometric consistency across the synthesized scene. Crit- ically, our method obviates the need for post hoc mesh segmentation or manual joining operations by generating instance-level meshes directly within the scene context, streamlining the 3D asset creation workflow and improving end-user usability. To evaluate our method, we conducted experiments on 20 multi-object scenes from the Google Scanned Objects (GSO) dataset [9] (containing 2–6 objects per scene) and 20 additional in-the-wild images for qualitative analysis. Quantitative and qualitative comparisons demonstrate that REPARO offers significant improvements over previous techniques in ensuring the quality of assets, managing mul- tiple assets, and processing occlusion. Our contributions are summarized as follows: 1. A two-stage compositional generation Pipeline: We propose REPARO, a framework to decouple multi- object 3D generation into two stages: (1) per-object high-fidelity reconstruction via inpainting-aware crop- ping and off-the-shelf models, and (2) global scene op- timization using novel differentiable rendering. This structure ensures object-level geometric independence while preserving scene-level contextual integrity. 2. Optimal transport-driven layout loss: We design a long- range appearance loss based on optimal transport (OT) theory, which enforces multi-modal constraints (RGB, depth, positional channels) to align 3D asset layouts with the reference image. By solving for global pixel corre- spondences, OT mitigates local minima issues inherent in the pixel-wise loss. 3. Semantic loss: We further introduce a semantic align- ment loss that leverages high-level visual features to re- fine object placements. This loss ensures synthesized scenes adhere to the original image’s semantic context. 2. Related work Text-to-3D generation. Early exploration in 3D genera- tion based on text [15, 35–37, 44, 56, 63] relied on a large- scale pre-trained model of text and image, CLIP [44], to optimize representation as the prior. In light of the promis- ing capability of diffusion models, some works [1, 21, 26, 40, 45, 46, 57, 60] introduce Score Distillation Sampling (SDS) to narrow the gap between novel view images ren- dered from 3D representation and diffusion prior. Recent works [4, 24, 51, 65] have used 3D Gaussian Splatting [16] instead of NeRF [35] for 3D generation, due to the fact that this efficient 3D representation shows excellent qual- ity [23, 43, 66] in reconstruction tasks. Image-to-3D generation. Differing from the ambiguity and diversity associated with textual description, 3D gen- eration based on a single image predominantly concentrates on maintaining geometric and textural consistency between the generated assets and the input images. Some early works [34, 52] used 2D diffusion models as prior knowl- edge to guide the training of 3D representation of the ob- ject in input images. However, with the enrichment of 3D data [6, 7], a series of adapting fine-tuned diffusion mod- els [27, 29, 30, 42, 47, 61, 68] represented by Zero-1-to- 3 [31] have been continuously developed. Subsequently, further advancements [32, 33, 48, 49] have been proposed, which offer improved quality and multi-view consistency. Compositional 3D generation. Unlike single-object re- construction, multi-object 3D generation requires atten- tion to both local details and global spatial relation- 2(a) Reconstruction of each single object (b) Layout alignment by differentiable rendering B and O SAM  Preprocess Module  Image to 3D Differentiable Renderer θ = {t, r, s} t r s � � �� L = La + Ls .  .  . Input Output Figure 2. The diagram of the proposed REPARO. (a) is the pipeline to reconstruct the 3D asset of each object in the reference image. B and O denote bounding boxes and occlusion information of each object, respectively. If an object is occluded, the preprocessing module will complement it using the inpainting model. (b) is the process of layout alignment based on differentiable rendering. The parameters of reconstructed meshes are optimized by gradient descent. The loss function L (Eq. 9) consists of the long-range appearance lossLa and the high-level semantic loss Ls. ships. Existing approaches address this through two main paradigms: (1) Single-object construction using geometric surface models [10] and editable generative models [53]; (2) Scene composition employing bounding boxes [39], text prompts [59], Gaussian radiance fields [55], and scene graphs [11]. Emerging approaches integrate LLMs for lay- out interpretation [28], leverage 2D semantic maps [64], or combine Gaussian Splatting with LLMs [67]. Distinct from text/layout-based methods, our approach directly generates multiple high-quality 3D assets from a single compositional image while preserving input-aligned spatial arrangements. 3. Method The field of 3D generation is advancing rapidly, with nu- merous image-to-3D models [51, 54] capable of generat- ing 3D assets from a single image. However, these models typically focus on individual objects, making it challeng- ing to apply them to scenes containing multiple objects. To address this limitation, we propose REPARO for compo- sitional 3D object generation from a single image. Our approach consists of two steps: (1) Extracting each target object from the given image and reconstructing their 3D meshes using off-the-shelf 3D reconstruction models. (2) Optimizing the parameters of each mesh through differen- tiable rendering to align their layout. In the following sec- tion, we provide a detailed explanation of these two steps. 3.1. Reconstruction of Each Single Object Since most data samples in 3D datasets only have one ob- ject located centrally within the image, and most image-to- 3D models recenter the object in the preprocessing step, there is an inherent center bias in these models. As a re- sult, the generated 3D assets for single objects are better than for multiple objects. As shown in Figure 1, Dream- Gaussian [51] can generate the sound 3D asset for a single object, but it fails in generation for multiple objects. In- stead of reconstructing 3D assets of multiple objects at the same time, our REPARO first focuses on extracting indi- vidual objects from images containing several objects and then generating their 3D assets using image-to-3D models. Object extraction. As illustrated in Figure 2 (a), given an image Iref with the bounding boxes B and occlusion infor- mation O, we use the foundation model SAM [18] to seg- ment each object and obtain their binary masks M. For oc- cluded objects, we utilize a Stable-Diffusion-based inpaint- ing model to reconstruct the occluded parts in the prepro- cessing module, thereby obtaining complete RGB priors for each object. Plus, we resize and crop the images to central- ize the involved objects, which adapts to the center bias of existing image-to-3D models. Single object reconstruction.After that, we employ off- the-shelf image-to-3D models, such as Dreamgaussian [51] and TripoSR [54], to generate the corresponding 3D assets for each obtained object. 3.2. Layout Alignment by Differentiable Rendering After obtaining every single object, we need a layout. To achieve the goal, first, we put every object together in one coordinate system as demonstrated in Figure 2 (b), then we use differentiable rendering techniques [19, 22, 62] to op- timize the layout of each object. Differentiable rendering aims to recover the scene parameters θ from reference im- age(s) Iref through analysis by synthesis process. Given an initial estimation of the scene, differentiable rendering can produce a rendered imageI together with the gradients with respect to arbitrary scene parametersθ. Briefly, the gradient 3can be represented as: ∂I ∂θ = [∂I(p1) ∂θ , ...,∂I(pN ) ∂θ ] = [∂I1 ∂θ , ...,∂IN ∂θ ], (1) where pi refers to the position ofi-th pixel, I(pi) is the RGB color of i-th pixel, and N is the total number of pixels. We denote I(pi) =Ii for simplicity in the following. Combin- ing with the loss function between rendered and reference image, we can leverage a gradient-decent-based method like Adam [17] to optimize the scene parameters of interest, like geometry, material, or lights. According to the chain rule, the derivative of the loss functionL(I, Iref ) with respect to scene parameters θ is: ∂L ∂θ = ∂L ∂I · ∂I ∂θ . (2) Specifically, for our task, since we have put every gen- erated object in the same coordinate system, the layout of objects in the initial rendered image and reference image may have quite large differences. Such a case is not suitable for the commonly used pixel-wised L2 loss function and differentiable rendering methods that only compute color derivatives. Imagine that when an object in the reference image has no overlapped area with it in the rendered image, the L2 loss will not change when we slightly move the ob- ject, the gradients of the loss function could get stuck in an undesired local minima and not indicate the right way for optimization. To mitigate this issue, we propose to intro- duce a loss function that could find the global correspon- dences. For one thing, inspired by previous work [12, 62], we use the optimal transport algorithm to find a match be- tween the rendered image and the reference image, thus ob- taining long-range correspondences. For another thing, we utilize the feature embedding from the visual backbone to get semantic correspondences. 3.2.1. Long-range Appearance Loss Term Optimal transport theory describes the following problem: suppose there are N suppliers and M demanders within a region. The i-th supplier holds si units of goods, and the j-th demander needs dj units of goods. The transportation cost per unit of goods from i-th supplier to j-th demander is cij. The goal of the optimal transport algorithm is to find a transportation matrix T = {Tij > 0 | i = 1, . . . , N; j = 1, . . . , M} that minimizes the total transportation cost: min T NX i=1 MX j=1 Tijcij, T ij > 0, s.t. NX i=1 Tij = dj, MX j=1 Tij = si, NX i=1 si = MX j=1 dj. (3) In our layout alignment, we consider all the pixels in the rendered image I as suppliers and all the pixels in the reference image Iref as demanders, where N = M and si = dj = 1. For the cost, instead of only considering RGB color distance between i-th pixel and j-th pixel, we define it based on RGB color, depth value, and position distance at the same time: cij = α·∥Ii−Iref j ∥2+β·∥Di−Dref j ∥2+γ·∥pi−pj∥2, (4) where pi and pj refer to the screen space position of i- th pixel and j-th pixel, respectively; D is the depth map predicted from the rendered image I using a frozen depth foundation model FD(·); Di denotes the depth value of i-th pixel; and α, β, and γ are hyper-parameters. Based on Eq. 3 and Eq. 4, we can obtain a transport ma- trix T using Sinkhorn divergences [5]. T recording a one- to-one mapping between the rendered imageI and the refer- ence image Iref . In other words, we can find a target pixel for each pixel in the rendered image. Formally, we define Iref σ(i) is the target pixel of Ii, where σ(·) is the one-to-one mapping function from the transport matrix T. In addition, rather than taking only RGB color distance as the differ- entiable rendering loss, we also consider RGB color, depth value, and position distance together as Eq. 4. Accordingly, our appearance loss function can be expressed as: La(I, Iref ) = 1 N NX i ciσ(i). (5) Here, N denotes the number of pixels of the rendered im- age, and the settings of all hyper-parameters are consistent with Eq. 4. To propagate the gradient of the pixel position to the scene parameter, we can define the pixel position as the projection of the shading point used for this pixel in the rasterization process as DROT [62]. According to Eq. 2 and the chain rule, the derivative of La with respective to scene parameters θ is: ∂La ∂θ = ∂La ∂I · ∂I ∂θ + ∂La ∂D · ∂FD ∂I · ∂I ∂θ + ∂La ∂p · ∂p ∂θ (6) Note that since we freeze the depth model FD(·), the gra- dients will totally contribute to scene parameters. As the mapping function σ(·) considers the long-range correspon- dence, our appearance loss term can also leverage long- range information during differentiable rendering. 3.2.2. High-level Semantic Loss Term To enhance the semantic information during the alignment process, we further propose incorporating high-level fea- tures into the loss function of differentiable rendering. Our semantic loss term is defined as: Ls(I, Iref ) = 1 K KX i ∥fi − fref i ∥2, (7) 4. . . . . . it_0 it_10 it_20 it_30 it_40 it_50 it_60 it_499 it_0 it_10 it_20 it_30 it_40 it_50 it_60 it_499 θ = { trans_x, trans_y, trans_z }, GPU Memory: 4 GB θ = { trans_x, trans_y, trans_z , scale_x, scale_y, scale_z}, GPU Memory: 6 GB ~20 s ~90 s Figure 3. GPU memory usage and approximate elapsed time for optimization of compositional assets layout under different param- eter settings. where fi and fref i are the i-th embedding in the feature map f and fref , respectively; f and fref are extracted using a frozen DINO-v2 [38] backbone F(·); and K is the to- tal number of embedding from the last hidden state. Based on this term, we can align the semantic relation between the rendered image and reference image from part to part. According to Eq. 2, the derivative of Ls with respective to layout parameters θ is: ∂Ls ∂θ = ∂Ls ∂F · ∂F ∂I · ∂I ∂θ (8) So far, we have integrated the proposed loss terms to- gether to align the layout of multiple reconstructed 3D ob- jects: L(I, Iref ) =λLa(I, Iref ) + (1− λ)Ls(I, Iref ), (9) where λ is a hyper-parameter to adjust the weight between appearance and semantic loss term. In practice, we align the layout by optimizing the object’s translation param- eter t = {trans x, trans y, trans z} and scale parameter s = {scale x, scale y, scale z}. We exclude the rotation pa- rameter r of assets from the optimization process, as assets generated via image-to-3D models are loaded into the scene with the same orientation as in the input image, eliminating the need for rotation optimization. Thanks to the proposed loss function, we can get the layout of the compositional 3D assets through differentiable rendering. 4. Experiments 4.1. Implementation details In the reconstruction of 3D assets from a single object, we utilize SAM-ViT-H [18] as the segmentation model to ob- tain masks corresponding to each bounding box. In the pre- processing module, we extract images of the objects using these masks and subsequently resize and crop the images to center the objects. We then apply the Stable Diffusion- based inpainting model [14] to address occlusions in the ob- jects. During the generation of 3D assets from a single ob- ject, we employ the DreamGaussian [51] and TripoSR [54]. Table 1. Performance of different 3D generation models for com- positional 3D assets generation. REPARO♣ and REPARO♠ sepa- rately denote utilizing DreamGaussian and TripoSR as the image- to-3d model based on our framework. Method CLIP↑ PSNR↑ SSIM↑ LPIPS↓ DreamGaussian [51] 0.807 13.280 0.802 0.240 TripoSR [54] 0.795 17.248 0.863 0.218 Wonder3D [33] 0.801 13.689 0.807 0.238 LRM [13] 0.812 13.664 0.806 0.237 REPARO♣(ours) 0.833 17.279 0.826 0.234 REPARO♠(ours) 0.822 17.751 0.865 0.216 Table 2. Runtime and memory usage of each stage. Stage VRAM Time SAM Segmentation 6 GB < 1s Inpainting 8 GB 20 s Individual Generation♠ 6 GB < 1s Individual Generation♣ 8 GB 120 sLayout Alignment 6 GB 90 s Total♠ ≤8GB 120s Total♣ ≤8GB 240s Table 3. Comparison with repre- sentative methods on perceptual quality and resource usage. Method CLIP↑ GPU Time DreamGaussian 0.807 8 GB 120 sTripoSR 0.795 6 GB < 1s Wonder3D 0.801 16 GB180sLRM 0.812 14 GB 20s REPARO♣(ours) 0.833 ≤8GB240 s REPARO♠(ours) 0.822 ≤8GB120 s For layout alignment, we use Nvdiffrast [19] as our dif- ferentiable rendering framework. During the differentiable rendering process, we optimize the translation x, y, z, and rotation r parameters of each 3D asset using gradient de- scent. Specifically, we employ the Adam optimizer [17] with a learning rate of 0.02 and a weight decay of 0.999. The total number of iterations is set to500. All experiments were conducted on RTX 3090 GPUs, and as shown in Fig- ure 3, optimizing parameter t alone takes approximately 20 seconds and utilizes 4GB of memory, while optimizing both parameters t and s to their optimal states requires about 90 seconds and utilizes 6GB of memory. We report per-stage runtime and memory in Table 2. All modules run on≤8GB VRAM, covering SAM, inpainting, 3D generation, and lay- out alignment. Table 3 compares our method with baselines in runtime and memory. REPARO achieves better perfor- mance under similar or lower resource budgets. To validate the effectiveness of our method, we selected 20 samples containing multiple objects from the Google Scanned Objects (GSO) dataset [8] as our test set. We used images from 18 views to compute quantitative met- rics, including CLIP score [44], Peak signal-to-noise ratio (PSNR), the structural similarity (SSIM) [58], and Percep- tual Similarity (LPIPS) [69]. Moreover, we also conducted a subjective evaluation of the generation quality for differ- ent models. We collected opinions from 40 participants. Participants selected the visually best subjective quality op- tion among the generation results of 4 models for the same input image. We computed the preference score for each model by dividing the selection count of a specific model by the total selections, reflecting the human preference dis- tribution for each model. 5Wonder3D LRM Dream- Gaussian Input TripoSR Ours Figure 4. Qualitative comparison with different image-to-3D generation models. Given an input image, previous methods produce inaccu- rate textures and geometry with noticeable artifacts. Our method generates high-quality, high-fidelity compositional assets with the correct spatial layout. 6Table 4. Comparison of different loss functions. (a) DreamGaussian-based REPARO. La Ls CLIP ↑ PSNR ↑ SSIM ↑ LPIPS ↓ ✓ 0.833 17.296 0.826 0.233 ✓ 0.809 17.820 0.849 0.210 ✓ ✓ 0.833 17.279 0.826 0.234 (b) TripoSR-based REPARO. La Ls CLIP ↑ PSNR ↑ SSIM ↑ LPIPS ↓ ✓ 0.822 17.765 0.865 0.216 ✓ 0.813 17.906 0.867 0.212 ✓ ✓ 0.822 17.751 0.865 0.216 Table 5. Comparison of optimization param- eters. (a) DreamGaussian-based REPARO. T R S CLIP ↑ PSNR ↑ SSIM ↑ LPIPS ↓ ✓ 0.832 17.369 0.826 0.232 ✓ ✓ 0.826 16.906 0.820 0.243 ✓ ✓ 0.833 17.279 0.826 0.234 ✓ ✓ ✓0.831 17.122 0.823 0.241 (b) TripoSR-based REPARO. T R S CLIP ↑ PSNR ↑ SSIM ↑ LPIPS ↓ ✓ 0.819 17.797 0.865 0.216 ✓ ✓ 0.822 17.768 0.864 0.219 ✓ ✓ 0.822 17.751 0.865 0.216 ✓ ✓ ✓0.826 17.752 0.864 0.219 Table 6. Comparison of information in appear- ance loss La. (a) DreamGaussian-based REPARO. Info in La OT CLIP ↑ PSNR ↑ SSIM ↑ LPIPS ↓ RGB × 0.800 18.054 0.853 0.206 RGB ✓ 0.828 17.009 0.821 0.245 RGBXY ✓ 0.828 17.069 0.821 0.243 RGBDXY ✓ 0.833 17.279 0.826 0.234 (b) TripoSR-based REPARO. Info in La OT CLIP ↑ PSNR ↑ SSIM ↑ LPIPS ↓ RGB × 0.774 17.918 0.868 0.216 RGB ✓ 0.819 17.837 0.865 0.215 RGBXY ✓ 0.823 17.847 0.865 0.213 RGBDXY ✓ 0.822 17.751 0.865 0.216 4.2. Main results Quantitative experiment. Table 7 compares the perfor- mance (CLIP score, PSNR, SSIM, and LPIPS) of vari- ous methods for reconstructing 3D assets of multiple ob- jects using one reference image. DreamGaussian-based REPARO and Triposr-based REPARO, our proposed meth- ods, show significant improvements over baseline meth- ods (DreamGaussian [51], Wonder3D [33], and LRM [13]). DreamGaussian-based REPARO achieves 83.3% CLIP score, 17.279 PSNR, 0.826 SSIM, and 0.234 LPIPS, in- dicating better alignment between reconstructed 3D assets and ground-truth 3D assets. Triposr-based REPARO ex- hibits superior performance in PSNR (17.751) and SSIM (0.865) and the lowest LPIPS (0.216), highlighting its ex- ceptional quality in image reconstruction and perceptual similarity. These results show that better reconstruction quality on single objects is beneficial for structural similar- ity and perceptual similarity during differentiable rendering. Qualitative experiment. Some qualitative comparison results are shown in Figure 4, where our Triposr-based REPARO can produce high-quality 3D assets with multiple objects. By contrast, DreamGaussian [51], Wonder3D [33], and LRM [13] have problems in layout and completeness, since they possess preferences on an individual object. User study.In addition to numerical metrics, we conducted a user study to compare our method with others, gather- ing responses from participants who assessed the realism of different 3D assets. Our approach received 61% ap- proval, while Dreamgaussian received 19% approval, LRM received 12% approval, and Wonder 3D received 8% ap- proval. The results consistently showed that our approach was favored over previous methods. For more detailed re- sults, please refer to the supplementary material. 4.3. Ablation study Ablation for different loss functions in differentiable rendering. We conducted ablation experiments on different Input  θ = {t} θ = {t, r} θ = {t, s} θ = {t, r, s} Figure 5. Qualitative comparison for different options of optimiza- tion parameters θ. Input  RGB-3D  RGBXY-5D  RGBDXY-6D  GT Figure 6. Qualitative comparison for different terms in the appear- ance loss La (Eq. 5). loss components in Eq. 9, with the results presented in Ta- ble 4. The results indicate that incorporating the high-level semantic loss function Ls can bring improvements in both SSIM and LPIPS. However, the enhancement in CLIP score is not as pronounced. Additionally, when only Ls is used, there is a notable decrease in CLIP score. For instance, in the DreamGaussian-based model, the CLIP score decreased by 2.1%. This suggests that relying solely on feature super- vision can reduce the effectiveness of layout alignment. Ablation for different options of scene parametersθ. Table 5 provides an ablation study on the impact of var- ious parameter optimization settings within θ across both DreamGaussian-based and TripoSR-based REPARO mod- els. Specifically, we compare combinations of transla- tion ( t), rotation ( r), and scale ( s) optimizations. For DreamGaussian-based REPARO, the combination of pa- rameters t and s achieves the highest CLIP score (0.833), competitive PSNR (17.279), and the lowest LPIPS (0.234), indicating a high level of perceptual quality and fidelity. Similarly, for TripoSR-based REPARO, optimizing t and s yields a balance between perceptual similarity (CLIP 0.822) and structural fidelity, with the lowest LPIPS (0.216) and strong SSIM (0.865), aligning closely with the input image. 7Adding Removing Position exchange Instance  replacement 2D Editing 3D Editing Figure 7. 3D scene editing based on the implementation of 2D image editing. Based on our REPARO framework, it is possible to implement four types of 3D editing guided by 2D image editing, namely adding, removing, position exchanging and instance replacement. Table 7. DreamGaussian-based (♣), TripoSR-based (♠), and GT- based (♦) results. Method CLIPs ↑ PSNR ↑ SSIM ↑ LPIPS ↓ REPARO♣ 0.833 17.279 0.826 0.234 REPARO♠ 0.822 17.751 0.865 0.216 REPARO♦ 0.906 15.708 0.789 0.321 Notably, as shown in Figure 5, including the rotation pa- rameter r in the optimization tends to degrade alignment with the input image orientation, as shown by the rotation- inclusive configurations, which generally exhibit slight re- ductions in CLIP scores and increased LPIPS. As a result, we select the combination of t and s for the final configu- ration, as it achieves optimal perceptual alignment without sacrificing the fidelity to the original image orientation. Ablation for long-range appearance loss term.As shown in Eq. 5, long-range appearance loss La incorporates RGB color distance, position distance, and depth value distance. More importantly, we use the optimal transport to compute pixel matching from a global perspective, thereby obtaining long-range correspondences. Quantitative results in Table 6 demonstrate that in the DreamGaussian-based model, in- troducing long-range correspondence results in a 2.8% im- provement in CLIP score; in the TripoSR-based model, it results in a 4.5% improvement in CLIP score. Additionally, when position distance and depth distance are introduced separately, there is no significant change in quantitative re- sults, but there is a noticeable improvement in qualitative results, as illustrated in Figure 6. The impact of 3D asset quality.As shown in Tab. 7, the experimental results indicate that the process of generating individual assets in the first stage introduces significant er- rors. Therefore, we still need a model capable of generating high-quality 3D assets. 4.4. Extension: Using 2D editing to guide 3D editing We further explored potential applications of our combina- torial generation framework. As depicted in the Figure 7, the entire framework relies on a single input image as guid- ance, enabling both the reconstruction of individual ob- jects and layout alignment through differentiable rendering. Leveraging this capability, we integrated pre-existing image editing techniques to facilitate editing of the generated 3D scenes. Specifically, we demonstrate four types of editing operations: adding, removing, position exchange, and in- stance replacement. The 2D editing process is implemented using the AnyDoor [2] model. By comparing the 3D scenes before and after editing, it is evident that the REPARO framework exhibits robust spatial arrangement capabilities and maintains consistency for each assets. 5. Conclusion In conclusion, we introduce REPARO, a comprehensive ap- proach for generating compositional 3D scenes from single images. Our REPARO addresses the multi-object issue by decomposing the scene into individual objects, reconstruct- ing their 3D meshes, and optimizing their layout through differentiable rendering. During differentiable rendering, we incorporate an optimal transport-based long-range ap- pearance loss which considers RGBDXY information, and a high-level semantic loss which aligns the feature corre- spondence. Consequently, REPARO is able to obtain multi- object 3D assets with visual-spatial arrangement and con- textual consistency. One limitation of our method is that severe occlusion may lead to hallucinated parts inconsis- tent with the image, and in semantically implausible scenes, layout optimization tends to favor common-sense interpre- tations over the actual image. We hope our method can pave the way for image to 3D generation in multi-object scenes. 8References [1] Rui Chen, Yongwei Chen, Ningxin Jiao, and Kui Jia. Fan- tasia3d: Disentangling geometry and appearance for high- quality text-to-3d content creation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023. 2 [2] Xi Chen, Lianghua Huang, Yu Liu, Yujun Shen, Deli Zhao, and Hengshuang Zhao. Anydoor: Zero-shot object-level im- age customization, 2024. 8 [3] Yongwei Chen, Tengfei Wang, Tong Wu, Xingang Pan, Kui Jia, and Ziwei Liu. Comboverse: Compositional 3d as- sets creation using spatially-aware diffusion guidance. arXiv preprint arXiv:2403.12409, 2024. 2 [4] Zilong Chen, Feng Wang, Yikai Wang, and Huaping Liu. Text-to-3d using gaussian splatting, 2024. 2 [5] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in neural information pro- cessing systems, 26, 2013. 4 [6] Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, and Ali Farhadi. Objaverse: A universe of annotated 3d objects, 2022. 2 [7] Matt Deitke, Ruoshi Liu, Matthew Wallingford, Huong Ngo, Oscar Michel, Aditya Kusupati, Alan Fan, Chris- tian Laforte, Vikram V oleti, Samir Yitzhak Gadre, Eli VanderBilt, Aniruddha Kembhavi, Carl V ondrick, Georgia Gkioxari, Kiana Ehsani, Ludwig Schmidt, and Ali Farhadi. Objaverse-xl: A universe of 10m+ 3d objects. arXiv preprint arXiv:2307.05663, 2023. 2 [8] Laura Downs, Anthony Francis, Nate Koenig, Brandon Kin- man, Ryan Hickman, Krista Reymann, Thomas B McHugh, and Vincent Vanhoucke. Google scanned objects: A high- quality dataset of 3d scanned household items. In 2022 In- ternational Conference on Robotics and Automation (ICRA), pages 2553–2560. IEEE, 2022. 5 [9] Laura Downs, Anthony Francis, Nate Koenig, Brandon Kin- man, Ryan Hickman, Krista Reymann, Thomas B McHugh, and Vincent Vanhoucke. Google scanned objects: A high- quality dataset of 3d scanned household items. In 2022 In- ternational Conference on Robotics and Automation (ICRA), pages 2553–2560. IEEE, 2022. 2 [10] Thomas Funkhouser, Michael Kazhdan, Philip Shilane, Patrick Min, William Kiefer, Ayellet Tal, Szymon Rusinkiewicz, and David Dobkin. Modeling by example. 23(3):652–663, 2004. 3 [11] Gege Gao, Weiyang Liu, Anpei Chen, Andreas Geiger, and Bernhard Sch ¨olkopf. Graphdreamer: Compositional 3d scene synthesis from scene graphs. In Conference on Com- puter Vision and Pattern Recognition (CVPR), 2024. 3 [12] Zheng Ge, Songtao Liu, Zeming Li, Osamu Yoshie, and Jian Sun. Ota: Optimal transport assignment for object detection. In Proceedings of the IEEE/CVF conference on computer vi- sion and pattern recognition, pages 303–312, 2021. 4 [13] Yicong Hong, Kai Zhang, Jiuxiang Gu, Sai Bi, Yang Zhou, Difan Liu, Feng Liu, Kalyan Sunkavalli, Trung Bui, and Hao Tan. Lrm: Large reconstruction model for single image to 3d. arXiv preprint arXiv:2311.04400, 2023. 5, 7 [14] Stable Diffusion Infinity. Stable diffusion infinity. https: / / github . com / lkwq007 / stablediffusion - infinity, 2023. Accessed: 2023-10-01. 5 [15] Ajay Jain, Ben Mildenhall, Jonathan T Barron, Pieter Abbeel, and Ben Poole. Zero-shot text-guided object genera- tion with dream fields. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition , pages 867–876, 2022. 2 [16] Bernhard Kerbl, Georgios Kopanas, Thomas Leimk ¨uhler, and George Drettakis. 3d gaussian splatting for real-time radiance field rendering. ACM Transactions on Graphics, 42 (4), 2023. 1, 2 [17] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations, ICLR, 2015. 4, 5 [18] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer White- head, Alexander C Berg, Wan-Yen Lo, et al. Segment any- thing. In Proceedings of the IEEE/CVF International Con- ference on Computer Vision, pages 4015–4026, 2023. 3, 5 [19] Samuli Laine, Janne Hellsten, Tero Karras, Yeongho Seol, Jaakko Lehtinen, and Timo Aila. Modular primitives for high-performance differentiable rendering. ACM Transac- tions on Graphics, 39(6), 2020. 3, 5 [20] Chenghao Li, Chaoning Zhang, Atish Waghwase, Lik-Hang Lee, Francois Rameau, Yang Yang, Sung-Ho Bae, and Choong Seon Hong. Generative ai meets 3d: A survey on text-to-3d in aigc era. arXiv preprint arXiv:2305.06131 , 2023. 1 [21] Ming Li, Pan Zhou, Jia-Wei Liu, Jussi Keppo, Min Lin, Shuicheng Yan, and Xiangyu Xu. Instant3d: Instant text- to-3d generation. International Journal of Computer Vision, pages 1–17, 2024. 2 [22] Tzu-Mao Li, Miika Aittala, Fr ´edo Durand, and Jaakko Lehti- nen. Differentiable monte carlo ray tracing through edge sampling. ACM Transactions on Graphics (TOG), 37(6):1– 11, 2018. 3 [23] Wanhua Li, Renping Zhou, Jiawei Zhou, Yingwei Song, Jo- hannes Herter, Minghan Qin, Gao Huang, and Hanspeter Pfister. 4d langsplat: 4d language gaussian splatting via multimodal large language models. In Proceedings of the Computer Vision and Pattern Recognition Conference, pages 22001–22011, 2025. 2 [24] Zhiqi Li, Yiming Chen, Lingzhe Zhao, and Peidong Liu. Controllable text-to-3d generation via surface-aligned gaus- sian splatting, 2024. 2 [25] Jingbo Zhang3 Zhihao Liang4 Jing Liao, Yan-Pei Cao, and Ying Shan. Advances in 3d generation: A survey. arXiv preprint arXiv:2401.17807, 2024. 1 [26] Chen-Hsuan Lin, Jun Gao, Luming Tang, Towaki Takikawa, Xiaohui Zeng, Xun Huang, Karsten Kreis, Sanja Fidler, Ming-Yu Liu, and Tsung-Yi Lin. Magic3d: High-resolution text-to-3d content creation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 300–309, 2023. 1, 2 [27] Yukang Lin, Haonan Han, Chaoqun Gong, Zunnan Xu, Yachao Zhang, and Xiu Li. Consistent123: One image to 9highly consistent 3d asset using case-aware diffusion priors. arXiv preprint arXiv:2309.17261, 2023. 1, 2 [28] Yiqi Lin, Hao Wu, Ruichen Wang, Haonan Lu, Xiaodong Lin, Hui Xiong, and Lin Wang. Towards language-guided in- teractive 3d generation: Llms as layout interpreter with gen- erative feedback. arXiv preprint arXiv:2305.15808, 2023. 3 [29] Minghua Liu, Ruoxi Shi, Linghao Chen, Zhuoyang Zhang, Chao Xu, Xinyue Wei, Hansheng Chen, Chong Zeng, Ji- ayuan Gu, and Hao Su. One-2-3-45++: Fast single image to 3d objects with consistent multi-view generation and 3d diffusion. arXiv preprint arXiv:2311.07885, 2023. 2 [30] Minghua Liu, Chao Xu, Haian Jin, Linghao Chen, Mukund Varma T, Zexiang Xu, and Hao Su. One-2-3-45: Any single image to 3d mesh in 45 seconds without per-shape optimiza- tion. Advances in Neural Information Processing Systems , 36, 2024. 2 [31] Ruoshi Liu, Rundi Wu, Basile Van Hoorick, Pavel Tok- makov, Sergey Zakharov, and Carl V ondrick. Zero-1-to-3: Zero-shot one image to 3d object. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 9298–9309, 2023. 1, 2 [32] Yuan Liu, Cheng Lin, Zijiao Zeng, Xiaoxiao Long, Lingjie Liu, Taku Komura, and Wenping Wang. Syncdreamer: Gen- erating multiview-consistent images from a single-view im- age. arXiv preprint arXiv:2309.03453, 2023. 2 [33] Xiaoxiao Long, Yuan-Chen Guo, Cheng Lin, Yuan Liu, Zhiyang Dou, Lingjie Liu, Yuexin Ma, Song-Hai Zhang, Marc Habermann, Christian Theobalt, et al. Wonder3d: Sin- gle image to 3d using cross-domain diffusion.arXiv preprint arXiv:2310.15008, 2023. 2, 5, 7 [34] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Realfusion: 360 reconstruction of any ob- ject from a single image. In 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. 1, 2 [35] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view syn- thesis. In Proceedings of the European conference on com- puter vision (ECCV), pages 405–421, Cham, 2020. Springer International Publishing. 1, 2 [36] Nasir Mohammad Khalid, Tianhao Xie, Eugene Belilovsky, and Tiberiu Popa. Clip-mesh: Generating textured meshes from text using pretrained image-text models. InSIGGRAPH Asia 2022 Conference Papers, 2022. [37] Nasir Mohammad Khalid, Tianhao Xie, Eugene Belilovsky, and Tiberiu Popa. Clip-mesh: Generating textured meshes from text using pretrained image-text models. InSIGGRAPH Asia 2022 conference papers, pages 1–8, 2022. 2 [38] Maxime Oquab, Timoth ´ee Darcet, Th ´eo Moutakanni, Huy V o, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2: Learning robust visual features without supervision. arXiv preprint arXiv:2304.07193, 2023. 5 [39] Ryan Po and Gordon Wetzstein. Compositional 3d scene generation using locally conditioned diffusion. arXiv preprint arXiv:2303.12218, 2023. 3 [40] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Milden- hall. Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988, 2022. 1, 2 [41] Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Milden- hall. Dreamfusion: Text-to-3d using 2d diffusion. In The Eleventh International Conference on Learning Representa- tions (ICLR), 2023. 2 [42] Guocheng Qian, Jinjie Mai, Abdullah Hamdi, Jian Ren, Aliaksandr Siarohin, Bing Li, Hsin-Ying Lee, Ivan Sko- rokhodov, Peter Wonka, Sergey Tulyakov, and Bernard Ghanem. Magic123: One image to high-quality 3d object generation using both 2d and 3d diffusion priors. arXiv preprint arXiv:2306.17843, 2023. 2 [43] Minghan Qin, Wanhua Li, Jiawei Zhou, Haoqian Wang, and Hanspeter Pfister. Langsplat: 3d language gaussian splatting. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 20051–20060, 2024. 2 [44] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervi- sion. In International conference on machine learning, pages 8748–8763. PMLR, 2021. 2, 5 [45] Amit Raj, Srinivas Kaza, Ben Poole, Michael Niemeyer, Nataniel Ruiz, Ben Mildenhall, Shiran Zada, Kfir Aberman, Michael Rubinstein, Jonathan Barron, et al. Dreambooth3d: Subject-driven text-to-3d generation. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 2349–2359, 2023. 2 [46] Junyoung Seo, Wooseok Jang, Min-Seop Kwak, Hyeonsu Kim, Jaehoon Ko, Junho Kim, Jin-Hwa Kim, Jiyoung Lee, and Seungryong Kim. Let 2d diffusion model know 3d- consistency for robust text-to-3d generation, 2024. 2 [47] Ruoxi Shi, Hansheng Chen, Zhuoyang Zhang, Minghua Liu, Chao Xu, Xinyue Wei, Linghao Chen, Chong Zeng, and Hao Su. Zero123++: a single image to consistent multi-view dif- fusion base model. arXiv preprint arXiv:2310.15110, 2023. 2 [48] Yukai Shi, Jianan Wang, He Cao, Boshi Tang, Xianbiao Qi, Tianyu Yang, Yukun Huang, Shilong Liu, Lei Zhang, and Heung-Yeung Shum. Toss: High-quality text-guided novel view synthesis from a single image. arXiv preprint arXiv:2310.10644, 2023. 2 [49] Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li, and Xiao Yang. Mvdream: Multi-view diffusion for 3d gen- eration. arXiv preprint arXiv:2308.16512, 2023. 2 [50] Ryo Suzuki, Adnan Karim, Tian Xia, Hooman Hedayati, and Nicolai Marquardt. Augmented reality and robotics: A sur- vey and taxonomy for ar-enhanced human-robot interaction and robotic interfaces. In Proceedings of the 2022 CHI Con- ference on Human Factors in Computing Systems, pages 1– 33, 2022. 1 [51] Jiaxiang Tang, Jiawei Ren, Hang Zhou, Ziwei Liu, and Gang Zeng. Dreamgaussian: Generative gaussian splatting for effi- cient 3d content creation. arXiv preprint arXiv:2309.16653, 2023. 1, 2, 3, 5, 7 10[52] Junshu Tang, Tengfei Wang, Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, and Dong Chen. Make-it-3d: High-fidelity 3d creation from a single image with diffusion prior. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 22819–22829, 2023. 1, 2 [53] Konstantinos Tertikas, Despoina Paschalidou, Boxiao Pan, Jeong Joon Park, Mikaela Angelina Uy, Ioannis Emiris, Yan- nis Avrithis, and Leonidas Guibas. Generating part-aware editable 3d shapes without 3d supervision. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pat- tern Recognition, pages 4466–4478, 2023. 3 [54] Dmitry Tochilkin, David Pankratz, Zexiang Liu, Zixuan Huang, , Adam Letts, Yangguang Li, Ding Liang, Christian Laforte, Varun Jampani, and Yan-Pei Cao. Triposr: Fast 3d object reconstruction from a single image. arXiv preprint arXiv:2403.02151, 2024. 2, 3, 5 [55] Alexander Vilesov, Pradyumna Chari, and Achuta Kadambi. Cg3d: Compositional generation for text-to-3d via gaussian splatting. arXiv preprint arXiv:2311.17907, 2023. 3 [56] Can Wang, Menglei Chai, Mingming He, Dongdong Chen, and Jing Liao. Clip-nerf: Text-and-image driven manipula- tion of neural radiance fields. In2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 3825–3834, 2022. 2 [57] Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A. Yeh, and Greg Shakhnarovich. Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation, 2022. 2 [58] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Si- moncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600–612, 2004. 5 [59] Zhaoning Wang, Ming Li, and Chen Chen. Luciddreaming: Controllable object-centric 3d generation. arXiv preprint arXiv:2312.00588, 2023. 3 [60] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distilla- tion. Advances in Neural Information Processing Systems , 36, 2024. 1, 2 [61] Haohan Weng, Tianyu Yang, Jianan Wang, Yu Li, Tong Zhang, CL Chen, and Lei Zhang. Consistent123: Improve consistency for one image to 3d object synthesis. arXiv preprint arXiv:2310.08092, 2023. 2 [62] Jiankai Xing, Fujun Luan, Ling-Qi Yan, Xuejun Hu, Houde Qian, and Kun Xu. Differentiable rendering using rgbxy derivatives and optimal transport. ACM Transactions on Graphics (TOG), 41(6):1–13, 2022. 3, 4 [63] Jiale Xu, Xintao Wang, Weihao Cheng, Yan-Pei Cao, Ying Shan, Xiaohu Qie, and Shenghua Gao. Dream3d: Zero-shot text-to-3d synthesis using 3d shape prior and text-to-image diffusion models. In Proceedings of the IEEE/CVF Confer- ence on Computer Vision and Pattern Recognition (CVPR) , pages 20908–20918, 2023. 2 [64] Han Yan, Yang Li, Zhennan Wu, Shenzhou Chen, Weix- uan Sun, Taizhang Shang, Weizhe Liu, Tian Chen, Xiaqiang Dai, Chao Ma, et al. Frankenstein: Generating semantic- compositional 3d scenes in one tri-plane. arXiv preprint arXiv:2403.16210, 2024. 3 [65] Taoran Yi, Jiemin Fang, Junjie Wang, Guanjun Wu, Lingxi Xie, Xiaopeng Zhang, Wenyu Liu, Qi Tian, and Xinggang Wang. Gaussiandreamer: Fast generation from text to 3d gaussians by bridging 2d and 3d diffusion models. In CVPR, 2024. 2 [66] Zehao Yu, Anpei Chen, Binbin Huang, Torsten Sattler, and Andreas Geiger. Mip-splatting: Alias-free 3d gaussian splat- ting. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition , pages 19447–19456, 2024. 2 [67] Xuening Yuan, Hongyu Yang, Yueming Zhao, and Di Huang. Dreamscape: 3d scene creation via gaussian splatting joint correlation modeling. arXiv preprint arXiv:2404.09227 , 2024. 3 [68] Junwu Zhang, Zhenyu Tang, Yatian Pang, Xinhua Cheng, Peng Jin, Yida Wei, Wangbo Yu, Munan Ning, and Li Yuan. Repaint123: Fast and high-quality one image to 3d gen- eration with progressive controllable 2d repainting. arXiv preprint arXiv:2312.13271, 2023. 2 [69] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shecht- man, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern recogni- tion, pages 586–595, 2018. 5 11",
      "references": [
        "Fantasia3d: Disentangling geometry and appearance for high- quality text-to-3d content creation",
        "Anydoor: Zero-shot object-level im- age customization, 2024",
        "Comboverse: Compositional 3d as- sets creation using spatially-aware diffusion guidance",
        "Text-to-3d using gaussian splatting, 2024",
        "Sinkhorn distances: Lightspeed computation of optimal transport",
        "Objaverse: A universe of annotated 3d objects, 2022",
        "Objaverse-xl: A universe of 10m+ 3d objects",
        "Google scanned objects: A high- quality dataset of 3d scanned household items",
        "Modeling by example",
        "Graphdreamer: Compositional 3d scene synthesis from scene graphs",
        "Ota: Optimal transport assignment for object detection",
        "Lrm: Large reconstruction model for single image to 3d",
        "Stable diffusion infinity",
        "Zero-shot text-guided object genera- tion with dream fields",
        "3d gaussian splatting for real-time radiance field rendering",
        "Adam: A method for stochastic optimization",
        "Segment any- thing",
        "Modular primitives for high-performance differentiable rendering",
        "Generative ai meets 3d: A survey on text-to-3d in aigc era",
        "Instant3d: Instant text- to-3d generation",
        "Differentiable monte carlo ray tracing through edge sampling",
        "4d langsplat: 4d language gaussian splatting via multimodal large language models",
        "Controllable text-to-3d generation via surface-aligned gaus- sian splatting, 2024",
        "Advances in 3d generation: A survey",
        "Magic3d: High-resolution text-to-3d content creation",
        "Consistent123: One image to 9highly consistent 3d asset using case-aware diffusion priors",
        "Towards language-guided in- teractive 3d generation: Llms as layout interpreter with gen- erative feedback",
        "One-2-3-45++: Fast single image to 3d objects with consistent multi-view generation and 3d diffusion",
        "One-2-3-45: Any single image to 3d mesh in 45 seconds without per-shape optimiza- tion",
        "Zero-1-to-3: Zero-shot one image to 3d object",
        "Syncdreamer: Gen- erating multiview-consistent images from a single-view im- age",
        "Wonder3d: Sin- gle image to 3d using cross-domain diffusion",
        "Realfusion: 360 reconstruction of any ob- ject from a single image",
        "Nerf: Representing scenes as neural radiance fields for view syn- thesis",
        "Clip-mesh: Generating textured meshes from text using pretrained image-text models",
        "Dinov2: Learning robust visual features without supervision",
        "Compositional 3d scene generation using locally conditioned diffusion",
        "Dreamfusion: Text-to-3d using 2d diffusion",
        "Magic123: One image to high-quality 3d object generation using both 2d and 3d diffusion priors",
        "Langsplat: 3d language gaussian splatting",
        "Learning transferable visual models from natural language supervi- sion",
        "Dreambooth3d: Subject-driven text-to-3d generation",
        "Let 2d diffusion model know 3d- consistency for robust text-to-3d generation, 2024",
        "Zero123++: a single image to consistent multi-view dif- fusion base model",
        "Toss: High-quality text-guided novel view synthesis from a single image",
        "Mvdream: Multi-view diffusion for 3d gen- eration",
        "Augmented reality and robotics: A sur- vey and taxonomy for ar-enhanced human-robot interaction and robotic interfaces",
        "Dreamgaussian: Generative gaussian splatting for effi- cient 3d content creation",
        "Make-it-3d: High-fidelity 3d creation from a single image with diffusion prior",
        "Generating part-aware editable 3d shapes without 3d supervision",
        "Triposr: Fast 3d object reconstruction from a single image",
        "Cg3d: Compositional generation for text-to-3d via gaussian splatting",
        "Clip-nerf: Text-and-image driven manipula- tion of neural radiance fields",
        "Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation, 2022",
        "Image quality assessment: from error visibility to structural similarity",
        "Luciddreaming: Controllable object-centric 3d generation",
        "Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distilla- tion",
        "Consistent123: Improve consistency for one image to 3d object synthesis",
        "Differentiable rendering using rgbxy derivatives and optimal transport",
        "Dream3d: Zero-shot text-to-3d synthesis using 3d shape prior and text-to-image diffusion models",
        "Frankenstein: Generating semantic- compositional 3d scenes in one tri-plane",
        "Gaussiandreamer: Fast generation from text to 3d gaussians by bridging 2d and 3d diffusion models",
        "Mip-splatting: Alias-free 3d gaussian splat- ting",
        "Dreamscape: 3d scene creation via gaussian splatting joint correlation modeling",
        "Repaint123: Fast and high-quality one image to 3d gen- eration with progressive controllable 2d repainting",
        "The unreasonable effectiveness of deep features as a perceptual metric"
      ],
      "meta_data": {
        "arxiv_id": "2405.18525v2",
        "authors": [
          "Haonan Han",
          "Rui Yang",
          "Huan Liao",
          "Jiankai Xing",
          "Zunnan Xu",
          "Xiaoming Yu",
          "Junwei Zha",
          "Xiu Li",
          "Wanhua Li"
        ],
        "published_date": "2024-05-28T18:45:10Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "REPARO tackles single-image 3D generation for multi-object scenes, where standard image-to-3D models exhibit center-bias and occlusion-induced object fusion, producing monolithic/merged meshes. The paper contributes a compositional two-stage pipeline that (1) extracts each instance and reconstructs high-fidelity instance-level meshes with off-the-shelf single-object image-to-3D models, then (2) reassembles and globally aligns these assets to the original image via differentiable rendering. Key technical additions are an optimal-transport (OT) long-range appearance loss that establishes global pixel correspondences using RGB+depth+screen-position cues, and a high-level semantic alignment loss using frozen vision features, together improving object independence, layout accuracy, and scene coherence without post-hoc mesh segmentation.",
        "methodology": "Stage 1 (instance reconstruction): Given an input image plus per-object bounding boxes/occlusion flags, Segment Anything (SAM ViT-H) produces masks; masked crops are resized/centered to match single-object model biases; occluded regions are completed with a Stable-Diffusion-based inpainting model to form a more complete RGB prior; each object is reconstructed using an off-the-shelf image-to-3D model (DreamGaussian or TripoSR) to obtain a mesh/asset.\nStage 2 (layout alignment): All reconstructed meshes are placed in a shared coordinate frame and rendered with a differentiable rasterizer (NVDiffRast). Per-object pose parameters are optimized by gradient descent (Adam, 500 iters), mainly translation t and scale s (rotation typically fixed). The optimization loss is L = λ La + (1-λ) Ls. La uses Sinkhorn OT to compute a one-to-one pixel matching between rendered image and reference image, with a transport cost combining RGB distance, depth distance (depth predicted from rendered image by a frozen depth foundation model), and screen-space position distance (RGBDXY); this provides long-range gradients to avoid local minima of pixel-wise losses. Ls is an L2 feature loss between DINO-v2 embeddings of rendered and reference images (frozen backbone) to encourage semantic correspondence.",
        "experimental_setup": "Datasets/tasks: Quantitative evaluation on 20 multi-object scenes sampled from Google Scanned Objects (GSO), each containing 2–6 objects; additional 20 in-the-wild images for qualitative results.\nEvaluation protocol: Rendered views from 18 camera viewpoints are used to compute image-based metrics between renderings and references/GT: CLIP score, PSNR, SSIM, and LPIPS. Human study with 40 participants selecting the best output among four methods for each input; preference score computed from selection frequency.\nBaselines: Direct multi-object generation with DreamGaussian, TripoSR, Wonder3D, and LRM; REPARO instantiated with DreamGaussian (REPARO♣) or TripoSR (REPARO♠) as the per-object generator.\nImplementation/resources: SAM ViT-H for masks; Stable-Diffusion inpainting for occlusion completion; NVDiffRast for differentiable rendering; DINO-v2 for semantic features; Sinkhorn OT for correspondence. Optimization uses Adam (lr=0.02, weight decay=0.999), 500 iterations. Experiments on RTX 3090; reported stage-wise VRAM/time (≤8GB total); layout alignment ~90s when optimizing translation+scale (6GB). Ablations study loss terms, optimized parameters (t/r/s), and appearance-loss channel composition (RGB vs RGBXY vs RGBDXY; OT vs no-OT).",
        "limitations": "(1) Reliance on preprocessing quality: segmentation (SAM), bounding boxes/occlusion cues, and inpainting strongly affect downstream mesh quality; severe occlusions can yield hallucinated/inconsistent geometry or texture that layout optimization cannot fully fix. (2) Dependence on single-object image-to-3D generators: errors in per-instance reconstruction propagate; the method is bounded by the fidelity and failure modes of DreamGaussian/TripoSR. (3) Optimization assumptions: rotation is typically not optimized (or degrades results when included), so incorrect initial orientation cannot be corrected; optimization is iterative (500 steps) and adds latency. (4) Semantic prior bias: for semantically implausible scenes, the semantic/appearance objectives may favor common-sense arrangements over the true image, potentially misaligning layouts. (5) Evaluation scope: quantitative tests are limited (20 GSO scenes) and metrics are image-based rather than direct 3D geometric accuracy, leaving some 3D fidelity aspects under-measured.",
        "future_research_directions": "Improve robustness under heavy occlusion by integrating stronger object completion with 3D-aware priors, multi-view consistency, or uncertainty-aware inpainting; jointly optimize instance geometry and layout (not only pose) during differentiable rendering; automate acquisition of bounding boxes/occlusion ordering (e.g., detection + depth/segmentation-based occlusion reasoning) to remove manual inputs; enable safe rotation optimization via regularizers, canonicalization, or learned initialization; accelerate or replace iterative layout optimization with a learned pose/scale regressor trained using synthetic supervision; extend to richer scene factors (lighting, shadows, inter-object contacts/physics constraints) to enhance realism; broaden evaluation to larger, more diverse datasets and add 3D-centric metrics (mesh IoU, Chamfer distance, contact/penetration measures) and downstream AR/VR usability studies.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training",
      "full_text": "RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback Harrison Lee1 Samrat Phatale1 Hassan Mansoor1 Thomas Mesnard1 Johan Ferret1 Kellie Lu2 Colton Bishop1 Ethan Hall2 Victor Carbune1 Abhinav Rastogi1 Sushant Prakash2 Abstract Reinforcement learning from human feedback (RLHF) has proven effective in aligning large lan- guage models (LLMs) with human preferences, but gathering high-quality preference labels is ex- pensive. RL from AI Feedback (RLAIF), intro- duced in Bai et al. (2022b), offers a promising alternative that trains the reward model (RM) on preferences generated by an off-the-shelf LLM. Across the tasks of summarization, helpful dia- logue generation, and harmless dialogue genera- tion, we show that RLAIF achieves comparable performance to RLHF. Furthermore, we take a step towards “self-improvement” by demonstrat- ing that RLAIF can outperform a supervised fine- tuned baseline even when the AI labeler is the same size as the policy, or even the exact same checkpoint as the initial policy. Finally, we intro- duce direct-RLAIF (d-RLAIF) - a technique that circumvents RM training by obtaining rewards directly from an off-the-shelf LLM during RL, which achieves superior performance to canoni- cal RLAIF. Our results suggest that RLAIF can achieve performance on-par with using human feedback, offering a potential solution to the scal- ability limitations of RLHF. 1. Introduction Reinforcement Learning from Human Feedback (RLHF) is an effective technique for aligning language models to human preferences (Stiennon et al., 2020; Ouyang et al., 2022). It is cited as one of the key drivers of success in mod- ern conversational language models, such as ChatGPT (Liu et al., 2023) and Bard (Manyika, 2023). A key advantage of 1Google DeepMind 2Google. Correspondence to: Har- rison Lee <harrisonlee@google.com>, Samrat Phatale <sam- ratph@google.com>, Hassan Mansoor <hassan@google.com>. Proceedings of the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author(s). 71% 63% 73% 64% Win Rate vs. SFT 50% 60% 70% 80% Summarization Helpfulness RLAIF RLHF RLAIF and RLHF Win Rates 64% 76% 88% Harmless Rate 50% 60% 70% 80% 90% SFT RLHF RLAIF Harmless Rate by Policy Figure 1: Human evaluators strongly prefer RLAIF and RLHF over the SFT baseline for summarization and helpful dialogue generation. Furthermore, when compared head-to- head, RLAIF is equally preferred to RLHF. For harmless dialogue generation, RLAIF outperforms RLHF. training language models with reinforcement learning (RL) is that it enables optimization on complex, sequence-level objectives that are not easily differentiable and therefore ill-suited for traditional supervised fine-tuning (SFT). One obstacle for employing RLHF at scale is its depen- dence on high-quality human preference labels. Modern large language models (LLMs) have shown a high degree of alignment with human judgment (Gilardi et al., 2023; Ding et al., 2023), suggesting that LLM-generated preference la- bels may be a viable substitute for human labels. Bai et al. (2022b) was the first effort to explore Reinforcement Learn- ing from AI Feedback (RLAIF), where RL was conducted 1 arXiv:2309.00267v3  [cs.CL]  3 Sep 2024RLAIF vs. RLHF Human Off-the-shelf LLM RLAIF policy RM Training Reinforcement   Learning Rating RLHF policy r2 - - - - - - - - - - - - - - - - r1 - - - - - - - - - - - - - - - - s1 - - - - - - - - - - - - - - - - Rating Reinforcement   Learningr2 - - - - - - - - - - - - - - - - r1 - - - - - - - - - - - - - - - - RL from AI Feedback s2 - - - - - - - - - - - - - - - - - - - - - - s1 - - - - - - - - - - - - - - - - - - - - - - SFT Model Sample Response RM Training RM from AI Feedback RM from Human Feedback RL from Human Feedback Figure 2: A diagram depicting RLAIF (top) vs. RLHF (bottom) using a reward model trained on a hybrid of human and AI preferences. In conjunction with their “Constitutional AI” self-revision technique, their final policy outperformed supervised fine-tuning for training a conversational assistant. However, it did not directly compare the efficacy of human vs. AI feedback, leaving the question of whether RLAIF can be a suitable alternative to RLHF unanswered. In this work, we compare the effectiveness of RLAIF and RLHF (see Figure 2) on three tasks: summarization, help- ful dialogue generation, and harmless dialogue generation. Our experiments show that RLAIF and RLHF are preferred by humans over a SFT baseline 71% and 73% of the time for summarization and 63% and 64% of the time for help- ful dialogue generation, respectively, where the win rates for RLAIF and RLHF are not statistically significantly different. Furthermore, in a head-to-head comparison of RLAIF against RLHF, both policies are equally preferred1. For harmless dialogue generation, human evaluators rated the harmlessness of each response independently. RLAIF scored a higher harmless rate than RLHF, and both outper- formed the SFT baseline (88%, 76%, and 64%, respectively). These results suggest that RLAIF is a viable alternative to RLHF that does not depend on human annotation, while offering appealing scaling properties. Additionally, we conduct two related studies. First, in a step towards LLM self-improvement, we demonstrate that RLAIF significantly improves upon the SFT baseline even when the AI labeler is the same size as the policy model. Second, we introduce direct-RLAIF (d-RLAIF) - a tech- nique that circumvents reward model training by obtaining rewards directly from an off-the-shelf LLM during RL. In our experiments, d-RLAIF matches or outperforms canon- ical RLAIF. Furthermore, for the task of helpful dialogue generation, the initial policy and the LLM providing rewards 1The win rate for one policy over the other is not statistically significantly different from 50% are the same model checkpoint, demonstrating an instance of strict LLM self-improvement. Finally, we study techniques to maximize the alignment of AI-generated preferences to human preferences. We find that soliciting chain-of-thought reasoning (Wei et al., 2022) consistently improves alignment, while using a detailed preamble and few-shot prompting (Brown et al., 2020) are only beneficial for certain tasks. We conduct scaling experi- ments to examine the trade-off between the size of the LLM labeler and alignment with human preferences. The main contributions of this work are as follows: 1. We demonstrate that RLAIF achieves comparable per- formance to RLHF for the tasks of summarization, helpful dialogue generation and harmless dialogue gen- eration. 2. We show that RLAIF can improve upon an SFT policy when the LLM labeler is the size same as the policy, or even the exact same checkpoint as the policy. 3. We introduce direct RLAIF (d-RLAIF), which derives the reward directly from an off-the-shelf LLM during RL and matches or outperforms canonical RLAIF. 4. We study techniques to maximize the alignment of AI-generated preferences to human preferences. 2. Methodology This section describes the techniques used to generate pref- erences with an LLM, the reinforcement learning setups, and evaluation metrics. RLHF preliminaries are provided in Appendix A. 2.1. Preference Labeling with LLMs We annotate preferences with an “off-the-shelf” LLM - a model pre-trained or instruction-tuned (Wei et al., 2021) for general usage but not fine-tuned for a specific downstream 2RLAIF vs. RLHF LLM  Scoring Response Summary 1 is better because it  is more coherent and … COT Ending Consider the coherence, accuracy,  coverage, and overall quality of each  summary and explain which one is  better. Rationale: Sample to Annotate Text - {text} Summary 1 - {summary1} Summary 2 - {summary2} Preamble A good summary is a shorter piece of  text that has the essence of the  original. ... LLM  Generation Ending Preferred Summary= AI Preference softmax(log P(“1”)) = 0.6 softmax(log P(“2”)) = 0.4 Figure 3: An illustration of the process to obtain AI-generated preference labels for summarization. The LLM is first prompted to explain its thoughts on the quality of the two candidates (blue). The response (orange) is then appended to the first prompt, and together they form the second prompt used to generate a preference distribution over “1” vs. “2” (green). task. Given a piece of text and two candidate responses, the LLM is asked to rate which response is preferred. The prompt is structured as follows (examples in Tables 15 and 21): 1. Preamble - Introduction and instructions describing the task at hand 2. Few-shot exemplars (optional)- An example input con- text, a pair of responses, a chain-of-thought rationale (optional), and a preference label 3. Sample to annotate - An input context and a pair of responses to be labeled 4. Ending - The ending text to prompt the LLM (e.g. “Preferred Response=”) After the prompt is given to the LLM, we extract the log- probabilities of generating the tokens “1” and “2” and com- pute the softmax to obtain a preference distribution. There are numerous alternatives to obtain preference la- bels from LLMs, such as extracting the preference from a free-form generated response (e.g. “The first response is better”), or representing the preference distribution as a one-hot encoding. However, we choose our method be- cause it is straightforward to implement and conveys more information than a one-hot encoding through its distributed representation of preferences. We experiment with two styles of preambles:“Base”, which essentially asks which response is better, and “Detailed”, which resembles detailed rating instructions typically given to human annotators (see Table 16 for preambles used in the summarization task). We also experiment with in-context learning (Brown et al., 2020), using high-quality exemplars hand-selected to cover a range of topics. 2.1.1. A DDRESSING POSITION BIAS The order in which candidates are shown to an LLM can bias which candidate it prefers (Pezeshkpour & Hruschka, 2023; Wang et al., 2023). We find evidence of position bias, which is especially prevalent in smaller LLM labelers (see Appendix B). To mitigate the effect of position bias, two inferences are made for every pair of candidates, where the order in which candidates are presented to the LLM is reversed for the second inference. The results from both inferences are then averaged to obtain the final preference distribution. 2.1.2. E LICITING CHAIN -OF-THOUGHT REASONING We experiment with eliciting chain-of-thought (CoT) rea- soning (Wei et al., 2022) from our AI labelers through a two-step inference procedure. First, we replace the Ending of the standard prompt with a sentence asking for thoughts and explanation (e.g. “ Consider the coherence, accuracy, coverage, and overall quality of each summary and explain which one is better. Rationale: ”) and decode a response from the LLM. Then, we concatenate the original prompt, the response, and the standard Ending string together, and follow the scoring procedure in Section 2.1 to obtain a pref- erence distribution. Figure 3 illustrates this process. For zero-shot prompts, the LLM is not given an example of what reasoning should look like. In few-shot prompts, we provide examples of CoT reasoning for the model to follow. See Tables 17 and 18 for examples. 3RLAIF vs. RLHF s - - - - - - -- - - - - - - - - - - - - - - - SFT Model GeneralPurpose LLM Prompt to Reward 1-10 RL model Reinforcement  Learning Reward Figure 4: In direct-RLAIF (d-RLAIF), the off-the-shelf LLM is directly used to provide rewards during RL, circum- venting the issue of RM “staleness” and the time consuming process of RM training. 2.2. Reinforcement Learning from AI Feedback 2.2.1. C ANONICAL RLAIF We describe our adaptation of the canonical RLAIF setup below. Unless otherwise mentioned, RLAIF is carried out using this method. A reward model (RM) is trained on the LLM-generated preference labels following the methodology in Appendix A.2. Since our approach produces soft labels (e.g.[0.6, 0.4]), we train the RM with a cross-entropy loss on the softmax of the scores generated by the RM. The softmax converts the RM scores into a probability distribution. We note that training a RM on a dataset of AI labels can be viewed as a form of model distillation. Finally, we conduct reinforcement learning to train the RLAIF policy model, using the RM to assign rewards to model responses, as described in Appendix A.3. 2.2.2. D IRECT -RLAIF ( D-RLAIF) One issue with RLAIF is that the reward model may become “stale” as the policy is trained. In the typical setup, the RM is trained on generations sampled from the initial policy. As the policy is trained, the generated trajectories become increasingly out-of-distribution from the dataset the RM was trained on, leading to suboptimal performance (Bai et al., 2022a). One solution is to conduct iterative RLAIF, where a new RM is periodically trained on the latest policy, though this is a time consuming process. We introduce direct-RLAIF (d-RLAIF) - a simple alternative to canonical RLAIF that directly uses LLM feedback as the reward signal in RL. D-RLAIF addresses the RM staleness issue, as the off-the-shelf LLM directly scores generated responses during RL without undergoing training. Addition- ally, d-RLAIF eliminates the need for the time consuming process of AI preference labeling and RM training. Figure 4 depicts this process. In d-RLAIF, the LLM is prompted to rate the quality of a generation between 1 and 10. Similar to Section 2.1, the prompt instructs the LLM on how to rate a generation. Then, the likelihood of each score token between 1 and 10 is computed, the likelihoods are normalized to a probability distribution, a weighted score is calculated as s(y|x) =P10 i=1 iP(i|y, x), and finally the score is again normalized to the range [−1, 1]. Additional details on the prompting technique can be found in the Appendix D. RL is then conducted in a similar manner to canonical RLAIF, where the direct score is used as reward instead of a RM score. 2.3. Evaluation We evaluate our results with three metrics - AI Labeler Alignment, Win Rate, and Harmless Rate. AI Labeler Alignment measures the accuracy of AI-labeled preferences with respect to human preferences. For a single example, a soft AI-labeled preference is first converted to a binary representation (e.g. [0.6, 0.4] → [1, 0]). Then, a score of 1 is assigned if the label agrees with the human preference and 0 otherwise. The alignment accuracy zacc can be expressed as follows: zacc = 1 D DX i=1 1 [arg max j PAI i,j = pH i ], where D is the size of the preference dataset, PAI ∈ RD×2 is the matrix of soft AI preferences, and pH ∈ RD is the corresponding vector of human preferences, containing ele- ments 0 or 1 to denote whether the first or second response is preferred, respectively. Win Rate evaluates the end-to-end quality of two policies by measuring how often one policy is preferred by human annotators over another. Given an input and two generations, human annotators select their preferred generation. The percentage of instances where policy A is preferred over policy B is referred to as the “win rate of A vs. B”. A 50% win rate indicates that A and B are equally preferred. Harmless Rate measures the percentage of responses that are considered harmless by human evaluators. We evaluate the harmless dialogue generation task with this metric instead of Win Rate, because we find that many responses are equally safe, making it difficult to assign relative rankings. 3. Experimental Details 3.1. Datasets We use the following datasets for our experiments: • Reddit TL;DR (Stiennon et al., 2020) - posts from 4RLAIF vs. RLHF Reddit2 accompanied by summaries of the posts. • OpenAI’s Human Preferences (Stiennon et al., 2020) - a dataset created from a subset of Reddit TL;DR. Each example comprises a post, two candidate summaries, and a rating from a human annotator indicating which summary is preferred. • Anthropic Helpful and Harmless Human Prefer- ences (Bai et al., 2022a) - conversations between a human and an AI assistant, where each conversation has two possible AI assistant responses - one preferred and the other non-preferred, according to a human an- notator. Preferences are based on which response is more informative and honest for the helpful task, and which response is safer for the harmless task. More dataset details can be found in Appendix C. We also explored the Stanford Human Preferences dataset (Ethayarajh et al., 2022), but we found that both RLHF and RLAIF policies did not show meaningful im- provements over the SFT baseline after correcting for length biases as described in Appendix J. 3.2. LLM Labeling To enable fast experiment iteration when evaluating AI la- beling techniques, we randomly downsampled the training split of each preference dataset. For summarization, an ad- ditional filter was applied to only include examples where human annotators preferred one summary over the other with high confidence3. After downsampling and filtering, there remained 3-4k examples for each task 4. AI labeler alignment was calculated on these downsampled datasets. We use the PaLM 2 (Google et al., 2023) family of models for labeling preferences. All versions were instruction-tuned but not previously trained with RL. Unless otherwise speci- fied, AI labels were generated using PaLM 2 Large (L) with the best-performing prompt for each task in Section 4.4. For more details on LLM labeling, see Appendix D. 3.3. Model Training All SFT models are initialized from PaLM 2 Extra-Small (XS). For summarization, the SFT model is produced by fine-tuning PaLM 2 XS on the Reddit TL;DR dataset. For all other tasks, an instruction-tuned variant of PaLM 2 is used in lieu of task-specific fine-tuning. All RMs are trained from PaLM 2 XS checkpoints. Each 2www.reddit.com 3This follows the evaluation procedure in Stiennon et al. (2020). Examples with confidence scores of 1, 2, 8, and 9 were con- sidered to be “high-confidence” 4We sampled 15%, 10%, and 10% of the training splits for summarization, helpful dialogue generation, and harmless dialogue generation, respectively. RM is fine-tuned on the full training split of a preference dataset, where the label is the AI preference for AI feedback RMs and the original human preference label for human feedback RMs. RM accuracies can be found in Appendix G. In the RL phase, the policy is trained with a modified version of REINFORCE (Williams, 1992) adapted to the language modeling domain (see Appendix E). While many recent works use Proximal Policy Optimization (PPO) (Schulman et al., 2017), we use REINFORCE with a baseline given that it is simpler yet still effective for the problem at hand. Both policy and value models are initialized from the SFT model. For summarization, the policy is rolled out on the training split of the Reddit TL;DR dataset. In other words, the initial state for each trajectory is the original Reddit post. For the helpful and harmless tasks, the initial states are drawn from the training splits of the preference datasets. For summarization, simple post-processing is applied to responses generated by RL-trained policies as described in Appendix H. For additional details on model training, see Appendix F. 3.4. Human Evaluation To measure win rates, evaluators were presented with an input context and multiple responses generated from differ- ent policies (e.g. RLAIF, RLHF, and SFT). They were then asked to rank responses in order of quality without ties, as seen in Figure 5. Input contexts were drawn from the test splits of each dataset, which were not used for training or any other evaluation5. Rankings were subsequently used to compute win rates for pairs of policies. For harmless dialogue generation, evaluators were asked to independently rate each response as harmless or harmful. For more details on human evaluation, see Appendix I. 4. Results 4.1. RLAIF vs. RLHF RLAIF achieves performance gains on par with or better than RLHF on all three tasks (see Figure 1 and Table 1). Specifically, RLAIF and RLHF are preferred by human evaluators over the baseline SFT policy 71% and 73% of the time for summarization6 and 63% and 64% for helpful dialogue generation, respectively. The difference in win rates between RLAIF vs. SFT and RLHF vs. SFT are not 5For summarization, we used the test split of Reddit TL;DR. For helpful and harmless dialogue generation, we used test splits from the preference datasets, detailed in Appendix C. 6RLAIF and RLHF are also preferred over the human reference summaries in Reddit TL;DR 79% and 80% of the time, respec- tively. 5RLAIF vs. RLHF Table 1: Left side:Win rates for pairs of policies on the summarization and the helpful dialogue tasks.Right side:Harmless rates across policies for the harmless dialogue task. All numbers are based on human evaluation. Win Rate Harmless Rate Comparison Summa -rization Helpful dialogue Model Harmless dialogue RLAIF vs SFT 71% 63% SFT 64% RLHF vs SFT 73% 64% RLHF 76% RLAIF vs RLHF 50% 52% RLAIF 88% Same-size RLAIF vs SFT 68% – d-RLAIF vs SFT 74% 66% d-RLAIF vs Same-size RLAIF 60% – statistically significant. When directly comparing RLAIF against RLHF, they are equally preferred - i.e. the win rate is not statistically significantly different from 50%. For harmless dialogue generation, RLAIF achieves a harmless rate of 88%, outperforming both RLHF and SFT, which score 76% and 64%, respectively7. Figure 6 contains an example of SFT, RLAIF, and RLHF summaries. To better understand how RLAIF compares to RLHF, we qualitatively compare responses generated by both policies for summarization in Section 5. Similar to Stiennon et al. (2020), we observe that RLAIF and RLHF policies tend to generate longer responses than the SFT policy, which may bias human evaluation. We conduct post-hoc analysis to control for length and find that both RLAIF and RLHF policies still outperform the SFT policy. See Appendix J for details. One natural question that arises is whether there is value in combining human and AI feedback. We experimented with combining both types of feedback but did not see an im- provement beyond using human feedback alone. However, we believe that there are several alternative training setups that could demonstrate value in combining both forms of feedback. See Appendix K for details. These results suggest that RLAIF is a viable alternative to RLHF that does not depend on human annotation. In addition to expediting the time to collect labels, another benefit of AI labeling is cost reduction. We estimate the cost of LLM labeling to be over 10x cheaper than human annotation. See Appendix L for detailed analysis. 4.2. Towards Self-Improvement In Section 4.1, the LLM used to label preferences (PaLM 2 L) is much larger than the policy being trained (PaLM 2 XS). Going one step further, we explore whether RLAIF can yield improvements when the AI labeler is the same size 7RLAIF achieves a statistically significant improvement over RLHF and SFT, according to two-sided paired t-tests. as the policy. On the task of summarization, we conduct RLAIF where PaLM 2 XS is used as the AI labeler instead of PaLM 2 L. The rest of the setup mimics the experiment in Section 4.1. We refer to this setup as “same-size RLAIF”. Same-size RLAIF still improves greatly over the SFT base- line, with human annotators preferring same-size RLAIF 68% of the time over SFT (see Table 1). For reference, RLAIF using an AI labeler larger than the policy is pre- ferred 71% over SFT8. This result demonstrates that RLAIF can yield improvements even when the AI labeler is the same size as the policy LLM. We note that this experiment is not a strict example of “self- improvement” (Huang et al., 2022), as the AI labeler is the instruction-tuned PaLM 2 XS, whereas the initial policy is PaLM 2 XS fine-tuned on Reddit TL;DR summarization. However, we demonstrate a case of strict self-improvement on the helpfulness task in the following section. 4.3. D-RLAIF In Sections 4.1 and 4.2, AI feedback was distilled into a RM. On the summarization and helpfulness tasks, we exper- iment with d-RLAIF (see Section 2.2.2). We use the smaller instruction-tuned PaLM 2 XS as our AI labeler to reduce compute costs. For summarization, human annotators prefer d-RLAIF over SFT 74% of the time (see Table 1). To understand the impact of directly utilizing LLM feedback versus distilling feedback to a RM, we compare this result to the same-size RLAIF policy from Section 4.2, which only differs in terms of the reward function. D-RLAIF outperforms same-size RLAIF, which achieves a statistically significantly lower win rate of 68%. Furthermore, when shown responses side- by-side, annotators prefer d-RLAIF over same-size RLAIF 8The difference between win rates between “same-size RLAIF vs. SFT” and the original “RLAIF vs. SFT” is not statistically significant. For a two-sample t-test, p-value = 0.07. At alpha = 0.05, this difference is not statistically significant. 6RLAIF vs. RLHF 60% of the time9. We hypothesize that this improvement is a result of directly querying the AI labeler for preferences rather than first distilling its preferences into a RM, as well as circumventing the “staleness” issue described in Section 2.2.2. For helpful dialogue generation, we find that d-RLAIF achieves a a win rate of 66% over the SFT baseline. Since the LLM providing feedback and the starting policy are exactly the same model checkpoint, this constitutes a strict example of LLM self-improvement. 4.4. Prompting Techniques Table 2: We observe that eliciting chain-of-thought reason- ing tends to improve AI labeler alignment, while few-shot prompting and detailed preambles have mixed effects across tasks. Above, “Help.” and “Harm.” refer to helpfulness and to harmlessness, respectively. AI Labeler Alignment Prompt Summary Help. Harm. Base 0-shot 76.1% 67.8% 69.4% Base 1-shot 76.0% 67.1% 71.7% Base 2-shot 75.7% 66.8% 72.1% Base + CoT 0-shot 77.5% 69.1% 70.6% Detailed 0-shot 77.4% 67.6% 70.1% Detailed 1-shot 76.2% 67.6% 71.5% Detailed 2-shot 76.3% 67.3% 71.6% Detailed 8-shot 69.8% – – Detailed + CoT 0-shot 78.0% 67.8% 70.1% Detailed + CoT 1-shot 77.4% 67.4% 69.9% Detailed + CoT 2-shot 76.8% 67.4% 69.2% We experiment with three types of prompting variations - preamble specificity, chain-of-thought reasoning, and in- context learning (see Table 2). The best prompts outperform the base prompts (“Base 0-shot”) by +1.9%, +1.3%, and +1.7% for summarization, helpfulness, and harmlessness, respectively. Detailed preambles improve alignment for summarization, while yielding mixed results for helpful and harmless dia- logue generation. We hypothesize that summarization bene- fits more from a detailed preamble due to the greater com- plexity of the task. Rating helpfulness and harmlessness are easier to grasp, and therefore may benefit less from detailed instructions. Chain-of-thought reasoning generally improves alignment. For summarization, the improvement is consistent. For help- ful and harmless dialogue generation, CoT only improves alignment when paired with the “Base” preamble. 9This is statistically significantly different from 50% according to the binomial test. Surprisingly, we observe that in-context learning only im- proves alignment for harmless dialogue generation10. For summarization and helpfulness, alignment monotonically decreases as the number of exemplars increases. To verify that this was not a result of poorly chosen exemplars, we conducted 10 trials for “Base 1-shot” on summarization, where a different exemplar was randomly selected for each trial. The maximum AI labeler alignment from all trials was 76.1%, which still does not surpass “Base 0-shot” in terms of AI labeler alignment. One hypothesis is that the summarization and helpful dialogue generation tasks may already be sufficiently well-understood by the off-the-shelf AI labeler, rendering the exemplars unhelpful or distracting. It is worth noting that in-context learning is still an impor- tant research area that is not fully understood (Min et al., 2022; Wang et al., 2022a). For summarization, we also compare against human inter- annotator agreement to get a sense of how well our LLM labeler performs in absolute terms. Stiennon et al. (2020) estimated that agreement rate for the OpenAI human prefer- ence dataset was 73-77%, suggesting that the off-the-shelf LLM achieving 78% alignment performs well in absolute terms. We also conduct experiments with self-consistency (Wang et al., 2022b), where multiple chain-of-thought rationales are sampled with temperature T >0. The preference dis- tributions generated by the LLM are averaged together to arrive at the final preference label. However, we find that self-consistency strictly degrades AI labeler alignment (see Appendix M). We hypothesize that higher AI labeler alignment leads to improvements in RLAIF policies. To this end, we conduct an experiment on the end-to-end sensitivity to AI labeler alignment. Two RLAIF policies are trained that only dif- fer in the alignment scores of AI labels. Results show that the policy trained with more aligned AI labels achieves a significantly higher win rate, which aligns with our expec- tations. However, this study only compares two policies, and rigorous experimentation is required to draw definitive conclusions. See Appendix N for details. 4.5. Size of LLM Labeler Table 3: AI labeler alignment increases as the size of the LLM labeler increases. Model Size AI Labeler Alignment PaLM 2 L 78.0 % PaLM 2 S 73.8% PaLM 2 XS 62.7% 10We verified that all inputs used in these experiments fit within our AI labeler’s context length. 7RLAIF vs. RLHF Large model sizes are not widely accessible and can be expensive to run. On the task of summarization, we vary the LLM size for labeling preferences and observe a strong positive relationship between size and alignment (see Table 3). Alignment decreases by 4% when substituting PaLM 2 L with PaLM 2 S, and decreases another 11% when us- ing PaLM 2 XS - a trend consistent with scaling behaviors observed in other work (Kaplan et al., 2020). One contribut- ing factor to this trend, apart from a decrease in general model capability, may be that smaller LLMs display greater position bias (see Appendix B). From another angle, these results also suggest that scaling up AI labeler size may produce even higher quality prefer- ence labels. Since the AI labeler is only used to generate preference examples once and is not called during RL for canonical RLAIF, using an even larger AI labeler is not necessarily prohibitively expensive. 5. Qualitative Observations To gain a deeper understanding of how RLAIF compares to RLHF, we visually inspected responses generated by both policies for the summarization task. In many cases, the two policies produced similar summaries, which is reflected in their similar win rates. However, we identified a few patterns where they sometimes diverged. First, we observe that in some cases, RLHF hallucinated when RLAIF did not. The hallucinations in RLHF sum- maries sounded plausible but were inconsistent with the original text. For instance, in Example #1 of Table 23, the RLHF summary states that the author is 20 years old, but this is neither mentioned nor implied by the source text. Second, we observed that RLAIF sometimes produced less fluent summaries than RLHF. For instance, in Table 24, all three RLAIF summaries contain run-on sentences. We also observed cases where RLAIF responses repeated phrases that failed to convey the intention of the original text. For example, several summaries concluded with “How do I get over this?”, despite the fact that the original text did not convey this question implicitly or explicitly. We conducted a small-scale evaluation on 70 examples, where human annotators were asked to blindly rank RLHF and RLAIF summaries in terms of accuracy, coverage, and coherence. However, the difference in scores was not statis- tically significant. More systematic analysis is required to identify if these patterns exist at scale, which we leave to future work. 6. Related Work LLMs have shown impressive performance on a wide range of NLP tasks (Brown et al., 2020; Thoppilan et al., 2022; Chowdhery et al., 2022; Google et al., 2023; OpenAI, 2023a). For several of these tasks, RL has emerged as an effective optimization technique. While initial applications of RL on tasks such as translation (Wu et al., 2016; 2018) and summarization (Gao et al., 2019; Wu & Hu, 2018) used automatic evaluation metrics as rewards, such simplified for- mulations of rewards did not fully align with human notions of quality. Reinforcement learning (RL) from human feedback (Chris- tiano et al., 2017) has been used as a technique to directly align LLMs with human preferences (Ziegler et al., 2019) through training a reward model on pairwise comparisons of natural language responses. It has been successfully applied for summarization (Stiennon et al., 2020), instruc- tion following (Ouyang et al., 2022; Lai et al., 2023), di- alogue (Gilardi et al., 2023; Manyika, 2023; Glaese et al., 2022; Bai et al., 2022a) and question answering (Nakano et al., 2021). To mitigate some stability and efficiency chal- lenges of conducting RL, DPO (Rafailov et al., 2024) refor- mulates the training objective to rely on a classification loss, while RaFT (Dong et al., 2023) employs the reward model for conducting rejection-sampling fine-tuning. LLMs have also been extensively used for data genera- tion (Wang et al., 2021b; Meng et al., 2023), augmenta- tion (Feng et al., 2021) and in self-training setups (Wang et al., 2022b; Madaan et al., 2023). Bai et al. (2022b) in- troduced the idea of RLAIF, which used LLM and human labeled preferences together to jointly optimize for the two objectives of helpfulness and harmlessness. Recent works have also explored related techniques for generating rewards from LLMs (Roit et al., 2023; Kwon et al., 2022; Yang et al., 2023). These works demonstrate that LLMs can generate useful signals for RL fine-tuning, which inspired this work’s investigation into whether LLMs can serve as a viable alter- native to humans in collecting preference labels for RL. 7. Conclusion We show that RLAIF achieves comparable improvements to RLHF on three text generation tasks. In head-to-head com- parisons, RLAIF and RLHF are preferred at similar rates by humans. Furthermore, we demonstrate evidence of LLM self-improvement by showing that RLAIF is effective even when the LLM labeler is the same size as the policy, or even the exact same checkpoint as the initial policy. Additionally, we also direct-RLAIF, which directly prompts the LLM labeler to provide rewards during RL, outperforming the canonical RLAIF setup that first distills LLM preferences into a separate RM. Finally, we study the impact of various AI labeling techniques on alignment to human preferences. While this work highlights the potential of RLAIF, there re- main many fascinating open questions, such as how RLAIF 8RLAIF vs. RLHF can be adapted to a model-based RL setting where both human and assistant are modeled by LLMs, or how AI feed- back can be leveraged for granular credit assignment. We leave these questions to future work. Acknowledgements We would like to thank many people who have helped make this work complete. We thank Chen Zhu for op- timizing our LLM inference setup, Le Hou for suggest- ing prompt improvements and experimenting with self- consistency, Léonard Hussenot for bringing the problem of position bias in LLMs to our attention, and Bradley Green, Ewa Dominowska, and Blaise Aguera y Arcas for support- ing this research. We thank everyone who thoroughly reviewed our work and provided valuable feedback: Hakim Sidahmed, Meiqi Guo, Michal Valko, Nevan Wichers, Sian Gooding, and Yuan Cao. We thank Mo Azar, Daniel Guo, Andrea Michi, Nicolas Perez-Nieves, and Marco Selvi for their contribution to developing a RLAIF training setup that directly prompts an LLM to obtain reward scores. Finally, we thank the individuals who designed and built the RL training infrastructure used in this paper: Léonard Hussenot, Robert Dadashi, Geoffrey Cideron, Alexis Jacq, Sabela Ramos, Piotr Stanczyk, Sertan Girgin, Danila Sinopalnikov, Amélie Héliou, Nikola Momchev, and Olivier Bachem. Impact Statement This paper seeks to better understand and improve the utility of AI models in a scalable fashion. Methods presented in this paper make model alignment more accessible to developers, as generating preferences from LLMs is more affordable and faster than human labeling. However, the use of AI Feedback presents two ethical considerations. Utilizing AI-generated feedback as a source for model align- ment has the potential risk of transferring biases from off- the-shelf LLMs to generated preferences. This in turn may result in RL-trained policies that further amplify biases, thereby inadvertently misaligning models and potentially causing harm. Extreme caution must be exercised, espe- cially when deploying these models in high-stakes domains such as medicine, law, and employment, where models have the potential to significantly impact human lives in adverse ways. In such domains, we believe that human experts trained to carefully assign preferences according to strict policies should be considered the gold standard. Another ethical consideration is that reducing the barriers to aligning LLMs also carries the risk of facilitating their misuse for malicious purposes. For instance, RLAIF could be employed to train models to generate convincing misin- formation or produce hateful and abusive content. The best mitigation to this risk is to carefully govern the access and usage of powerful LLMs (e.g. limiting “white-box” access), to prevent bad actors from abusing them. References Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schul- man, J., and Mané, D. Concrete problems in ai safety. arXiv preprint arXiv:1606.06565, 2016. Bai, Y ., Jones, A., Ndousse, K., Askell, A., Chen, A., Das- Sarma, N., Drain, D., Fort, S., Ganguli, D., Henighan, T., et al. Training a helpful and harmless assistant with rein- forcement learning from human feedback. arXiv preprint arXiv:2204.05862, 2022a. Bai, Y ., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A., Mirhoseini, A., McKin- non, C., Chen, C., Olsson, C., Olah, C., Hernandez, D., Drain, D., Ganguli, D., Li, D., Tran-Johnson, E., Perez, E., Kerr, J., Mueller, J., Ladish, J., Landau, J., Ndousse, K., Lukosuite, K., Lovitt, L., Sellitto, M., Elhage, N., Schiefer, N., Mercado, N., DasSarma, N., Lasenby, R., Larson, R., Ringer, S., Johnston, S., Kravec, S., Showk, S. E., Fort, S., Lanham, T., Telleen-Lawton, T., Conerly, T., Henighan, T., Hume, T., Bowman, S. R., Hatfield- Dodds, Z., Mann, B., Amodei, D., Joseph, N., McCan- dlish, S., Brown, T., and Kaplan, J. Constitutional ai: Harmlessness from ai feedback, 2022b. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33: 1877–1901, 2020. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Christiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., and Amodei, D. Deep reinforcement learning from human preferences. Advances in neural information pro- cessing systems, 30, 2017. Ding, B., Qin, C., Liu, L., Chia, Y . K., Li, B., Joty, S., and Bing, L. Is GPT-3 a good data annotator? In Pro- ceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 11173–11195, Toronto, Canada, July 2023. Associ- ation for Computational Linguistics. doi: 10.18653/v1/ 9RLAIF vs. RLHF 2023.acl-long.626. URL https://aclanthology. org/2023.acl-long.626. Dong, H., Xiong, W., Goyal, D., Zhang, Y ., Chow, W., Pan, R., Diao, S., Zhang, J., SHUM, K., and Zhang, T. RAFT: Reward ranked finetuning for generative founda- tion model alignment. Transactions on Machine Learn- ing Research, 2023. ISSN 2835-8856. URL https: //openreview.net/forum?id=m7p5O7zblY. Ethayarajh, K., Choi, Y ., and Swayamdipta, S. Under- standing dataset difficulty with V-usable information. In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and Sabato, S. (eds.), Proceedings of the 39th In- ternational Conference on Machine Learning , volume 162 of Proceedings of Machine Learning Research, pp. 5988–6008. PMLR, 17–23 Jul 2022. Everitt, T. and Hutter, M. Avoiding wireheading with value reinforcement learning. In Artificial General Intel- ligence: 9th International Conference, AGI 2016, New York, NY, USA, July 16-19, 2016, Proceedings 9, pp. 12– 22. Springer, 2016. Fan, A., Lewis, M., and Dauphin, Y . Hierarchical neu- ral story generation. In Proceedings of the 56th An- nual Meeting of the Association for Computational Lin- guistics (Volume 1: Long Papers) , pp. 889–898, Mel- bourne, Australia, July 2018. Association for Computa- tional Linguistics. doi: 10.18653/v1/P18-1082. URL https://aclanthology.org/P18-1082. Feng, S. Y ., Gangal, V ., Wei, J., Chandar, S., V osoughi, S., Mitamura, T., and Hovy, E. A survey of data augmenta- tion approaches for NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 968–988, Online, August 2021. Association for Compu- tational Linguistics. doi: 10.18653/v1/2021.findings-acl. 84. URL https://aclanthology.org/2021. findings-acl.84. Fox, R., Pakman, A., and Tishby, N. Taming the noise in reinforcement learning via soft updates. arXiv preprint arXiv:1512.08562, 2015. Gao, Y ., Meyer, C. M., Mesgar, M., and Gurevych, I. Reward learning for efficient reinforcement learning in extractive document summarisation. arXiv preprint arXiv:1907.12894, 2019. Geist, M., Scherrer, B., and Pietquin, O. A theory of regu- larized markov decision processes. In International Con- ference on Machine Learning , pp. 2160–2169. PMLR, 2019. Gilardi, F., Alizadeh, M., and Kubli, M. Chatgpt outper- forms crowd-workers for text-annotation tasks. arXiv preprint arXiv:2303.15056, 2023. Glaese, A., McAleese, N., Trebacz, M., Aslanides, J., Firoiu, V ., Ewalds, T., Rauh, M., Weidinger, L., Chadwick, M., Thacker, P., et al. Improving alignment of dialogue agents via targeted human judgements. arXiv preprint arXiv:2209.14375, 2022. Google. Ai platform data labeling service pricing. https://cloud.google.com/ai-platform/ data-labeling/pricing#labeling_costs, 2023. Accessed: 2023-09-28. Google, R. A., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., Chu, E., Clark, J. H., Shafey, L. E., Huang, Y ., Meier- Hellstern, K., Mishra, G., Moreira, E., Omernick, M., Robinson, K., Ruder, S., Tay, Y ., Xiao, K., Xu, Y ., Zhang, Y ., Abrego, G. H., Ahn, J., Austin, J., Barham, P., Botha, J., Bradbury, J., Brahma, S., Brooks, K., Catasta, M., Cheng, Y ., Cherry, C., Choquette-Choo, C. A., Chowd- hery, A., Crepy, C., Dave, S., Dehghani, M., Dev, S., Devlin, J., Díaz, M., Du, N., Dyer, E., Feinberg, V ., Feng, F., Fienber, V ., Freitag, M., Garcia, X., Gehrmann, S., Gonzalez, L., Gur-Ari, G., Hand, S., Hashemi, H., Hou, L., Howland, J., Hu, A., Hui, J., Hurwitz, J., Isard, M., It- tycheriah, A., Jagielski, M., Jia, W., Kenealy, K., Krikun, M., Kudugunta, S., Lan, C., Lee, K., Lee, B., Li, E., Li, M., Li, W., Li, Y ., Li, J., Lim, H., Lin, H., Liu, Z., Liu, F., Maggioni, M., Mahendru, A., Maynez, J., Misra, V ., Moussalem, M., Nado, Z., Nham, J., Ni, E., Nystrom, A., Parrish, A., Pellat, M., Polacek, M., Polozov, A., Pope, R., Qiao, S., Reif, E., Richter, B., Riley, P., Ros, A. C., Roy, A., Saeta, B., Samuel, R., Shelby, R., Slone, A., Smilkov, D., So, D. R., Sohn, D., Tokumine, S., Valter, D., Vasudevan, V ., V odrahalli, K., Wang, X., Wang, P., Wang, Z., Wang, T., Wieting, J., Wu, Y ., Xu, K., Xu, Y ., Xue, L., Yin, P., Yu, J., Zhang, Q., Zheng, S., Zheng, C., Zhou, W., Zhou, D., Petrov, S., and Wu, Y . Palm 2 technical report, 2023. Howard, R. A. Dynamic programming and markov pro- cesses. John Wiley, 1960. Huang, J., Gu, S. S., Hou, L., Wu, Y ., Wang, X., Yu, H., and Han, J. Large language models can self-improve. arXiv preprint arXiv:2210.11610, 2022. Jaques, N., Gu, S., Bahdanau, D., Hernández-Lobato, J. M., Turner, R. E., and Eck, D. Sequence tutor: Conserva- tive fine-tuning of sequence generation models with kl- control. In International Conference on Machine Learn- ing, pp. 1645–1654. PMLR, 2017. Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020. 10RLAIF vs. RLHF Kendall, M. G. and Smith, B. B. The Problem of m Rankings. The Annals of Mathematical Statis- tics, 10(3):275 – 287, 1939. doi: 10.1214/aoms/ 1177732186. URL https://doi.org/10.1214/ aoms/1177732186. Kwon, M., Xie, S. M., Bullard, K., and Sadigh, D. Reward design with language models. In The Eleventh Interna- tional Conference on Learning Representations, 2022. Lai, V . D., Van Nguyen, C., Ngo, N. T., Nguyen, T., Der- noncourt, F., Rossi, R. A., and Nguyen, T. H. Okapi: Instruction-tuned large language models in multiple lan- guages with reinforcement learning from human feed- back. arXiv preprint arXiv:2307.16039, 2023. Liu, Y ., Han, T., Ma, S., Zhang, J., Yang, Y ., Tian, J., He, H., Li, A., He, M., Liu, Z., et al. Summary of chatgpt/gpt-4 research and perspective towards the future of large lan- guage models. arXiv preprint arXiv:2304.01852, 2023. Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S., Yang, Y ., et al. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651, 2023. Manyika, J. An overview of bard: an early experiment with generative ai. https://ai.google/static/ documents/google-about-bard.pdf, 2023. Accessed: 2023-08-23. Meng, Y ., Michalski, M., Huang, J., Zhang, Y ., Abdelzaher, T., and Han, J. Tuning language models as training data generators for augmentation-enhanced few-shot learning. In International Conference on Machine Learning , pp. 24457–24477. PMLR, 2023. Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., and Zettlemoyer, L. Rethinking the role of demonstrations: What makes in-context learning work? In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing , pp. 11048– 11064, 2022. Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V ., Saunders, W., et al. Webgpt: Browser-assisted question-answering with hu- man feedback. arXiv preprint arXiv:2112.09332, 2021. OpenAI. Gpt-4 technical report, 2023a. OpenAI. Openai pricing. https://openai.com/ pricing, 2023b. Accessed: 2023-09-28. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022. Pezeshkpour, P. and Hruschka, E. Large language mod- els sensitivity to the order of options in multiple-choice questions. arXiv preprint arXiv:2308.11483, 2023. Rafailov, R., Sharma, A., Mitchell, E., Manning, C. D., Er- mon, S., and Finn, C. Direct preference optimization: Your language model is secretly a reward model. Ad- vances in Neural Information Processing Systems , 36, 2024. Roit, P., Ferret, J., Shani, L., Aharoni, R., Cideron, G., Dadashi, R., Geist, M., Girgin, S., Hussenot, L., Keller, O., et al. Factually consistent summarization via re- inforcement learning with textual entailment feedback. arXiv preprint arXiv:2306.00186, 2023. Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017. Shazeer, N. and Stern, M. Adafactor: Adaptive learning rates with sublinear memory cost. CoRR, abs/1804.04235, 2018. URL http://arxiv.org/ abs/1804.04235. Stiennon, N., Ouyang, L., Wu, J., Ziegler, D., Lowe, R., V oss, C., Radford, A., Amodei, D., and Christiano, P. F. Learning to summarize with human feedback. Ad- vances in Neural Information Processing Systems , 33: 3008–3021, 2020. Sutton, R. S., McAllester, D., Singh, S., and Mansour, Y . Policy gradient methods for reinforcement learning with function approximation. Advances in neural information processing systems, 12, 1999. Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kul- shreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y ., et al. Lamda: Language models for dialog appli- cations. arXiv preprint arXiv:2201.08239, 2022. Wang, B., Min, S., Deng, X., Shen, J., Wu, Y ., Zettlemoyer, L., and Sun, H. Towards understanding chain-of-thought prompting: An empirical study of what matters. arXiv preprint arXiv:2212.10001, 2022a. Wang, P., Li, L., Chen, L., Zhu, D., Lin, B., Cao, Y ., Liu, Q., Liu, T., and Sui, Z. Large language models are not fair evaluators. arXiv preprint arXiv:2305.17926, 2023. Wang, S., Liu, Y ., Xu, Y ., Zhu, C., and Zeng, M. Want to reduce labeling cost? gpt-3 can help. In Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 4195–4205, 2021a. 11RLAIF vs. RLHF Wang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H., Narang, S., Chowdhery, A., and Zhou, D. Self- consistency improves chain of thought reasoning in lan- guage models. In The Eleventh International Conference on Learning Representations, 2022b. Wang, Z., Yu, A. W., Firat, O., and Cao, Y . To- wards zero-label language learning. arXiv preprint arXiv:2109.09193, 2021b. Wei, J., Bosma, M., Zhao, V ., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V . Finetuned lan- guage models are zero-shot learners. In International Conference on Learning Representations, 2021. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V ., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35: 24824–24837, 2022. Williams, R. J. Simple statistical gradient-following algo- rithms for connectionist reinforcement learning. Machine learning, 8:229–256, 1992. Wu, L., Tian, F., Qin, T., Lai, J., and Liu, T.-Y . A study of reinforcement learning for neural machine translation. In Proceedings of the 2018 Conference on Empirical Meth- ods in Natural Language Processing , pp. 3612–3621, 2018. Wu, Y . and Hu, B. Learning to extract coherent summary via deep reinforcement learning. In Proceedings of the AAAI Conference on Artificial Intelligence, pp. 5602, 2018. Wu, Y ., Schuster, M., Chen, Z., Le, Q. V ., Norouzi, M., Macherey, W., Krikun, M., Cao, Y ., Gao, Q., Macherey, K., et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016. Yang, K., Klein, D., Celikyilmaz, A., Peng, N., and Tian, Y . Rlcd: Reinforcement learning from contrast distillation for language model alignment, 2023. Ziegler, D. M., Stiennon, N., Wu, J., Brown, T. B., Radford, A., Amodei, D., Christiano, P., and Irving, G. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593, 2019. 12RLAIF vs. RLHF A. RLHF Preliminaries We review the RLHF pipeline introduced in Stiennon et al. (2020); Ouyang et al. (2022), which consists of 3 phases: supervised fine-tuning, reward model training, and reinforcement learning. A.1. Supervised Fine-tuning A pre-trained LLM is fine-tuned on a high quality labeled dataset for a downstream task using token-level supervision to produce a supervised fine-tuned (SFT) model πSFT . A.2. Reward Modeling Given an inputx, we sample a pair of responses(y1, y2) ∼ π from one or more models, where oftentimesπ is the SFT model. The input and responses are sent to human annotators to rate which response is better according to some criteria. These annotations form a dataset of triplets D = {(x, yw, yl)}, where yw and yl are the preferred and non-preferred responses, respectively. A reward model (RM) rϕ is trained by minimizing the following loss: Lr(ϕ) = −E (x,yw,yl)∼D h log σ \u0000 rϕ(x, yw) − rϕ(x, yl) \u0001i , where σ is the sigmoid function. A.3. Reinforcement Learning A policy πRL θ is initialized from the SFT model weights and then optimized with reinforcement learning to maximize the reward given by the RM, which serves as a proxy for human preferences. Optionally, a Kullback-Leibler (KL) divergence term DKL is added to the objective to penalize πRL θ for deviating from the original SFT policy πSFT , controlled by the hyperparameter β (Fox et al., 2015; Geist et al., 2019). The KL loss helps prevent πRL θ from drifting into a region where it generates language that is highly rewarded by the RM yet consists of low-quality or unnatural language - a phenomenon known as “reward hacking” (Everitt & Hutter, 2016; Amodei et al., 2016). The optimization objective is described by the equation below: J(θ) = E y∼πθ(·|x) h (1 − β)rϕ(y|x) − βDKL \u0000 πRL θ (y|x) ||πSFT (y|x) \u0001i , where β is a hyperparameter between 0 and 1. B. Position Bias in LLM Labelers Table 4: Position bias is more prevalent in smaller model sizes, measured by the percentage of examples where the LLM prefers the same position even after swapping the order of candidates (“% Same Position Preferred”). Analysis is conducted using the “Detailed + CoT 0-shot” prompt on the summarization task. Model Size % Same Position Preferred PaLM 2 L 18% PaLM 2 S 21% PaLM 2 XS 56% Our analysis on the summarization task suggests that the LLMs used for preference labeling are biased by the order in which candidates are shown. For each example in our AI labeling evaluation set, we query the LLM preferences for the pair of candidates, swap the order in which candidates are presented, and then query the LLM preferences again. We consider an LLM to be more biased if it prefers the same position on both the original and reversed inferences. For example, let candidates A and B be in positions 1 and 2 for the first inference and in positions 2 and 1 for the second 13RLAIF vs. RLHF inference. If the LLM prefers the same position on both inferences, we consider the LLM to be position-biased. We measure position bias by computing “% Same Position Preferred”- the percentage of inference pairs where this occurs. A higher metric value indicates a more biased LLM. We find that PaLM 2 L, S, and XS prefer the same position 18%, 21%, and 56% of the time, respectively, suggesting that position bias is inversely correlated with model size (see Table 4). One hypothesis is that larger models are more capable and therefore more faithfully judge preferences based on the content of the candidates rather than their positions, which are supposed to be immaterial. We also observe that for PaLM 2 L, of the 18% of cases where it prefers the same position on both inferences, 94% of the time it prefers the first candidate shown. On the other hand, PaLM 2 S and XS show affinity for the second candidate shown when the same position is preferred on both inferences, preferring it 91% and 99% of the time, respectively. These biases are statistically significant under a two-sided binomial test at α = 0.05. C. Dataset Details For summarization, we use the filtered Reddit TL;DR dataset (Stiennon et al., 2020), containing posts from Reddit11 that have been filtered to ensure high quality. The dataset contains 123k posts, where ∼5% is held out as a validation set. Additionally, we use OpenAI’s human preference dataset created from the filtered Reddit TL;DR dataset. For a given post, two candidate summaries were generated - often from different policies, and human labelers were asked to rate which summary they preferred. The total dataset comprises 92k pairwise comparisons. For helpful and harmless dialogue generation, we use Anthropic’s Helpful and Harmless preference datasets12 (Bai et al., 2022a). Each example consists of a conversation history between a human and an AI assistant accompanied by a preferred and non-preferred response from the AI assistant. Preference is based on which response is more helpful and honest for the helpful task, and which response is safer and less harmful for the harmless task. Each dataset comprises over 40k training examples and 2k test examples. We further split each original test set into a validation and a test set by randomly assigning two-thirds of examples to validation and one-third to test. D. LLM Labeling Details For LLM labeling, we set a maximum input context length of 4096 tokens. For chain-of-thought generation, we set a maximum decoding length of 512 tokens and sample with temperature T = 0.0 (i.e. greedy decoding). For self-consistency experiments in Appendix M, we use temperatures varying from T = 0.3 to T = 1.0 with top-K sampling (Fan et al., 2018), where K = 40. In Section 4.3, we use the AI labeler to directly compute a score that we leverage as the reward for RL. For summarization, we use the following prompt “You are an expert summary rater. Given a TEXT (completed with a SUBREDDIT and a TITLE) and a SUMMARY, your role is to provide a SCORE from 1 to 10 that rates the quality of the SUMMARY given the TEXT, with 1 being awful and 10 being a perfect SUMMARY. ”, followed by the input Reddit post, then the summary to score preceded by “SUMMARY: ”, and a final “SCORE: ”. For helpful task generation, we use the prompt “You are an expert rater of helpful and honest Assistant responses. Your role is to provide a SCORE from 1 to 10 that rates the helpfulness and honesty of the RESPONSE for a given CONTEXT. Where SCORE of 1 refers to useless and dishonest RESPONSE and a SCORE of 10 refers to a perfectly helpful and honest RESPONSE. ”, followed by the conversation history and a response. PaLM 2 models are publicly available through Google Cloud’s Vertex AI13, though exact reproducibility is not guaranteed as the models accessible through Google Cloud are subject to change. E. REINFORCE for Language Models Consider a deterministic, finite-horizon MDP M = (X, A, R, P, γ) (Howard, 1960). At each step t, given the current state Xt ∈ Xand the next action At ∈ A, the model receives a reward Rt = R(Xt, At) and transitions to the next state 11www.reddit.com 12We use the helpful-base and harmless-base datasets from https://huggingface.co/datasets/Anthropic/ hh-rlhf. 13https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models 14RLAIF vs. RLHF Xt+1 = P(Xt, At). In the context of language models, Xt is the concatenation of the input text and all text generated by the policy until time t. Action At is the token from the considered vocabulary decoded at time t by the stochastic policy πθ(·|Xt), where θ represents the policy parameters. The reward Rt is given by the RM, which is only evaluated when the language model response has been fully generated; all rewards prior to the final token are set to 0, while the reward corresponding to the final token is set to RT . The cumulative sum of rewards received when following the policyπθ from time-step t is called the return. Generally, it is defined as Zt = PT s=t γs−tRs. However, since only the terminal reward is non-zero and we setγ = 1, the return can be simplified to Zt = RT . Given a trajectory (Xt, At, Rt)T t=0 generated under πθ, the policy gradient loss from REINFORCE is then defined as follows: LPG(θ) =− X t log πθ(At|Xt) \u0010 Zt − V π ψ (Xt) \u0011 , where the bar notation denotes that no gradient is passed through the advantage term during backpropagation. The baseline value function V π ψ (x) estimates the return-to-go Zt when following the policy πθ, and it is parameterized by ψ (Williams, 1992; Sutton et al., 1999). It is trained with the following loss: LV (ψ) = X t (Zt − V π ψ (Xt))2. Our full optimization objective is written in Sec. A.3. We incorporate the KL divergence in the policy gradient loss described above, as commonly seen in other work (Jaques et al., 2017). F. Model Training Details SFT models for the summarization task are trained on the Reddit TL;DR dataset with a batch size of 128 and for one epoch. We use the Adafactor (Shazeer & Stern, 2018) optimizer with a learning rate of 10−5, and the maximum input and output lengths are 1024 and 128 tokens, respectively. For helpful and harmless dialogue generation tasks, an instruction-tuned version of PaLM 2 XS serves as the SFT model. RMs for all tasks are trained until the training loss and accuracy curves plateau, which happens in 2-3 epochs. We use the Adafactor optimizer with a learning rate of 10−5. Batch size is 128 for summarization RMs and 32 for RMs of other tasks. We train all our RMs with maximum input length of 1152 tokens to account for 1024 context tokens and 128 response tokens. We report the accuracies of the RMs in Appendix G. For summarization, the AI feedback RM is initialized from the SFT model (i.e. PaLM 2 XS fine-tuned on Reddit TL;DR), and the human feedback RM is initialized from PaLM 2 XS. We experimented with initializing the human feedback RM from the SFT model but found that it resulted in lower accuracy on the held out set of human preferences (see Table 6). For helpful and harmless dialogue generation tasks, we initialize both the human and AI feedback RMs from the instruction-tuned version of PaLM 2 XS. For reinforcement learning, we use the SFT model for each task as the initial policy. We sample from our language model policies for all tasks with a temperature of T = 0.9 to encourage exploration. We train with a batch size of 128 and learning rate of 10−5 for 8 epochs. We set β = 0.05 for the KL divergence loss. To select the final checkpoint for each RL policy, we first selected 4 candidate checkpoints from RL training that scored high rewards on validation prompts. We then prompted an off-the-shelf LLM to judge the win rate of the RL checkpoint’s responses vs. the SFT policy’s responses. We also conducted manual inspection of a dozen examples. We picked the checkpoint with the best combination of win rate and quality as judged by manual inspection as our final RL policy. G. Reward Model Accuracy Pairwise Accuracy measures how accurate a trained reward model is with respect to a holdout set of human preferences. Given an input context and pair of candidate responses, the value is 1 if the RM scores the preferred candidate higher than 15RLAIF vs. RLHF Table 5: Pairwise accuracies of human feedback and AI feedback reward models across all tasks. Metrics are calculated on a holdout set of human preferences for each task. Task Human Feedback AI Feedback Summarization 79.3% 74.2% Helpful Dialogue 76.0% 67.8% Harmless Dialogue 72.1% 69.7% Table 6: Results of initializing the summarization RMs on PaLM 2 XS vs. the SFT model. Initialization Human Feedback AI Feedback PaLM 2 XS 79.3% 73.0% SFT 78.7% 74.2% the non-preferred candidate, according to the human label. Otherwise the value is 0. This quantity is averaged over multiple examples to obtain the pairwise accuracy. We report RM accuracy on a holdout set of human preferences for all tasks in Table 5. For summarization, we also report RM accuracy when initializing on different checkpoints in Table 6. In Table 7, we report accuracy for RM variants used in the end-to-end sensitivity experiment in Appendix N and the same-size RLAIF experiment in Section 4.2. We observe that RMs trained on human feedback outperform those trained on AI feedback, both of which are measured against a holdout set of human preferences. This pattern seems natural, given that the human preferences are trained on data drawn from the same distribution as the validation dataset. However, it is interesting to note that despite the gap in accuracy between AI and human preference RMs, RLAIF achieves comparable results to RLHF on two tasks and surpasses it on another. Additionally, we note that the summarization RMs trained on “Base 0-shot” and “Detailed + CoT 0-shot” (i.e. the default prompting technique) achieve accuracies of 77.9% and 74.2%, respectively, which is the inverse order of their final performance after RL (see Appendix N). These gaps in RM accuracy suggest that RM accuracy, while correlated with RM usefulness, may not accurately reflect a RM’s effectiveness in RLHF and RLAIF. Ultimately, we believe that the usefulness of RMs is assessed through conducting RL and evaluating the final policies through human evaluation. H. Post-RL Response Formatting For summarization, we observed that summaries generated by RLHF and RLAIF policies often included superfluous symbols like periods or spaces at the end of the response - possibly due to “reward hacking”. Given that these extra tokens do not have any meaningful content, we programmatically removed certain symbols at the end of summaries. This ensured that human evaluators could focus on the content without being distracted by the formatting of the response. I. Human Evaluation Details To conduct human evaluation, in total we generated ∼2k unique rating instances. Each instance comprised a single context and multiple distinct model responses (e.g. responses from SFT, RLAIF, and RLHF policies), resulting in a total of ∼6k unique (context, response) pairs subjected to human evaluation. Additionally, each instance was assessed by three independent raters, resulting in ∼18k (context, response, rating) tuples. Table 7: Accuracy values for variants of RMs trained on AI labels for the task of summarization. RM Variant AI Feedback Trained on “Base 0-shot” labels 77.9% Trained on “Detailed CoT 0-shot” labels from PaLM 2 XS 66.4% 16RLAIF vs. RLHF We measure the inter-annotator agreement with Kendall’s Coefficient of Concordance W (Kendall & Smith, 1939) - a non-parametric statistic for assessing the agreement among multiple raters ranking multiple items. The values of Kendall’s W range from 0 to 1, where 0 indicates perfect disagreement and 1 indicates perfect agreement. We conducted multiple human evaluation sessions, and the W statistic ranged from 0.6-0.7, indicating a reasonable level of agreement. J. Controlling for Response Length Response length often can influence human evaluators’ perception of quality (Stiennon et al., 2020), and our various policies generate responses that differ in length. For example, in the summarization task, the summaries produced by RLAIF, RLHF, and SFT policies sent to human evaluation had an average character-length of 164, 161, and 132, respectively. We conduct post-hoc analysis to estimate the win rates after controlling for length. We take an approach similar to Stiennon et al. (2020) and calculate the “length-adjusted win rate of policy A vs. policy B”. Given policy A, we train a logistic regression model where the input is the ratio of the policy A’s response length to policy B’s summary length (in characters), and the target is a binary label indicating whether policy A’s response was preferred over policy B’s response. After fitting the model, we estimate a length-controlled win rate by asking the logistic regressor to predict the win rate given a length ratio of 1.0, which represents the scenario where both the responses are of equal length. After controlling for length for the summarization task, our length-adjusted win rates for RLAIF and RLHF vs. SFT are 59% and 61%, respectively (see Table 8). Both RL policies continue to outperform the SFT policy by a similar margin, supporting our initial statement that RLAIF is comparable to RLHF. We reach similar conclusions for the helpful dialogue generation task (Table 9), same-size RLAIF and direct RLAIF (d-RLAIF) experiments (Table 11), the end-to-end sensitivity to AI labeler alignment experiment (Table 12), and combining human and AI feedback (Table 13). For the harmless dialogue generation task, we use a different setup. Since human evaluators rated each response independently as harmful or harmless, we compute the harmless rate instead of the win rate. We use the average generation length from the SFT policy as the reference point for all other policies (Table 10). We note that this post-hoc method of controlling for length is imperfect, as it assumes the logistic regression model accurately learns the relationship between summary length and human preference. A more principled approach is to encourage all policies generate summaries of similar length through an auxiliary training loss. Table 8: Length-controlled win rate for the summarization task. Models Length uncorrected Length corrected RLAIF vs SFT 71% 59% RLHF vs SFT 73% 61% RLAIF vs RLHF 50% 47% Table 9: Length-controlled win rate for the helpful dialogue generation task. Models Length uncorrected Length corrected RLAIF vs SFT 63% 61% RLHF vs SFT 64% 61% RLAIF vs RLHF 52% 50% K. Combining Human and AI Feedback We investigate the effectiveness of combining human feedback and AI feedback on the task of summarization. We refer to this approach as RLHF + RLAIF and compare it against RLHF. First, given contexts randomly drawn from the Reddit TL;DR dataset, responses are generated by RLHF and SFT policies 17RLAIF vs. RLHF Table 10: Length-controlled harmless rate for the harmless dialogue generation task. We used the average generation length from the SFT model as reference length to compute the length-controlled harmless rate for RLHF and RLAIF. Models Length uncorrected Length corrected SFT 64% 64% RLHF 76% 78% RLAIF 88% 91% Table 11: Length-controlled win rate for same-size RLAIF and direct RLAIF. Models Length uncorrected Length corrected Same-size RLAIF vs SFT 68% 59% d-RLAIF vs SFT 74% 65% d-RLAIF vs Same-size RLAIF 60% 56% with temperature T = 1.0. The instruction-tuned PaLM 2 L is then called to generate AI preferences on the OpenAI human preference dataset. Finally, a new RM is trained on both the dataset with human labels and the dataset with AI labels. We observe that RLHF + RLAIF does not improve beyond RLHF alone. RLHF + RLAIF and RLHF achieve win rates of 71% and 74% over SFT, respectively. The difference in win rates is not statistically significant. When compared head-to-head, raters prefer both policies equally. While this experiment did not show positive results from combining RLAIF and RLHF, there are many alternative setups which could prove successful. One such setup could involve first conducting RLAIF, then collecting generations and human preferences using the RLAIF policy as the initialization point for RLHF. In this curriculum learning approach, RLAIF can be viewed as a “warm-up” policy, which is then refined with RLHF. Another possible setup could involve collecting much more AI feedback than human feedback, since it is much less expensive to collect (see Appendix L). We leave this exploration to future work. L. Cost of LLM vs. Human Labeling Using LLMs as data annotators can be much less costly than hiring human annotators (Wang et al., 2021a). We estimate AI preference labeling to be over 10x less costly than human preference labeling following the calculations below. At the time of writing, GPT-4 charges $0.03 USD and $0.06 USD for every 1,000 tokens to encode and decode, respectively (OpenAI, 2023b). For labeling Reddit TL;DR preferences with an LLM, our average token lengths were as follows: 1. Input prompt length - 830 tokens (using the “Detailed + CoT 0-shot” prompt) 2. Generated chain-of-thought rationale - 61 tokens Additionally, to mitigate position bias, we repeat each labeling procedure after inverting the order in which a pair of responses are shown. Our estimated AI labeling cost per example is $0.06 USD14. In comparison, Google Cloud’s human annotation service charges approximately $0.11 USD / 50 words for classification tasks at the time of writing15 (Google, 2023). We assume that each classification task only consists of reading a document 142 inferences * (830 encoder tokens * $0.03 / 1,000 tokens + 61 decoder tokens * $0.06 / 1,000 tokens) = $0.057 ∼ = $0.06 15Google Cloud charges between $90 and $129 per 1,000 units, where each unit is 50 words for a classification task. We average the lower and upper bound costs and convert from units to words - ($90 / 1,000 units + $129 / 1,000 units) / 2 * 1 unit / 50 words = $0.1095 USD / 50 words 18RLAIF vs. RLHF Table 12: Length-controlled win rate for the experiment on end-to-end sensitivity to AI labeler alignment. Base RLAIF and Detailed RLAIF correspond to “Base 0-shot” RLAIF and “Detailed CoT 0-shot” RLAIF described in Appendix N, respectively. Models Length uncorrected Length corrected Base RLAIF vs SFT 63% 59% Detailed RLAIF vs SFT 67% 63% Base RLAIF vs Detailed RLAIF 41% 45% Table 13: Length-controlled win rate for experiments combining human and AI feedback. Models Length uncorrected Length corrected RLHF + RLAIF vs SFT 71% 61% RLHF vs SFT 74% 67% RLHF + RLAIF vs RLHF 48% 46% and two candidate summaries, which have a combined average word length of 304 words. We estimate the human labeling cost per example to be $0.67 USD (304 words * $0.11 / 50 words). This cost analysis does not account for all factors, such as the cost of training human annotators, the cost of expert vs. crowd-sourced annotators, or the cost of setting up LLM labeling. M. Self-Consistency Table 14: Sampling multiple chain-of-thought rationales with T >0 results in lower alignment with human preferences. Note: 1 and 16 samples represent 2 and 32 inferences given our position debiasing technique (see Section 2.1.1). Self-Consistency AI Labeler Alignment 1 sample, T=0.0 78.0% 16 samples, T=0.3 76.2% 16 samples, T=0.5 75.1% 16 samples, T=0.7 74.0% 16 samples, T=1.0 72.8% We experiment with self-consistency (Wang et al., 2022b) - a technique to generate robust chain-of-thought rationales. To implement self-consistency, we sample multiple chain-of-thought rationales with temperature T >0, and LLM preference distributions are obtained for each one. The results are then averaged to obtain the final preference distribution. On the task of summarization, we experiment with self-consistency using 4 and 16 samples under decoding temperatures ranging from 0.3 to 1.0 (see Figure 14)16. In all settings, self-consistency decreases AI labeler alignment versus the baseline without self-consistency. Our experiments show that alignment decreases as temperature increases, with the largest drop of over -5% at T = 1.0. In our experiments, using 4 vs. 16 self-consistency samples does not impact AI labeler alignment. Manually inspecting chain-of-thought rationales did not reveal any common patterns for why self-consistency might degrade alignment (examples in Table 20). One hypothesis is that using a temperature of T >0 leads the model to generate lower 16Results of using 4 samples are not shown because they only differ from the 16-sample results by ±0.4%. 19RLAIF vs. RLHF quality rationales compared to greedy decoding, ultimately leading to worse accuracy overall. N. End-to-end Sensitivity to AI Labeler Alignment We assess the end-to-end sensitivity of the RLAIF policies to AI labeler alignment on the task of summarization. Since human judgement is subjective and prone to noise, we test whether better AI labeler alignment leads to improved downstream performance. We train two RLAIF policies that only differ in the prompting technique used for AI labeling - “Base 0-shot” and “Detailed CoT 0-shot”, yielding 76.1% and 78.0% AI labeler alignment, respectively. When compared head-to-head, human evaluators prefer summaries from “Detailed CoT 0-shot” 59% of the time over “Base 0-shot”17. This result suggests that small gains in AI labeler alignment may lead to noticeable improvements in the final RL policies. However, this study is limited, and further experiments are required to draw generalizable conclusions. Table 15: An example of a prompt fed to an off-the-shelf LLM to generate AI preference labels for summarization.{text}, {summary1}, and {summary2} are populated with unlabeled examples, and a preference distribution is obtained by computing the softmax of the log-probabilities of generating the tokens “1” vs. “2”. Preamble A good summary is a shorter piece of text that has the essence of the original. ... Given a piece of text and two of its possible summaries, output 1 or 2 to indicate which summary best adheres to coherence, accuracy, coverage, and overall quality as defined above. Exemplar »»»» Example »»»» Text - We were best friends over 4 years ... Summary 1 - Broke up with best friend, should I wish her a happy birthday... And what do you think of no contact? Summary 2 - should I wish my ex happy birthday, I broke no contact, I’m trying to be more patient, I’m too needy, and I don’t want her to think I’ll keep being that guy. Preferred Summary=1 »»»» Follow the instructions and the example(s) above »»»» Sample to Annotate Text - {text} Summary 1 - {summary1} Summary 2 - {summary2} Ending Preferred Summary= 17Result is statistically significantly different from 50% according to a binomial test. 20RLAIF vs. RLHF Table 16: The “Base” and “Detailed” preambles given to the LLM labeler to obtain preference labels for the summarization task. “Base” preamble You are an expert summary rater. Given a piece of text and two of its possible summaries, output 1 or 2 to indicate which summary is better. “Detailed” preamble A good summary is a shorter piece of text that has the essence of the original. It tries to accomplish the same purpose and conveys the key information from the original post. Below we define four evaluation axes for summary quality: coherence, accuracy, coverage, and overall quality. Coherence: This axis answers the question “how coherent is the summary on its own?” A summary is coherent if it’s easy to understand when read on its own and free of English errors. A summary is not coherent if it’s difficult to understand what the summary is trying to say. Generally, it’s more important that the summary is understandable than it being free of grammar errors. Accuracy: This axis answers the question “does the factual information in the summary accurately match the post?” A summary is accurate if it doesn’t say things that aren’t in the article, it doesn’t mix up people, and generally is not misleading. Coverage: This axis answers the question “how well does the summary cover the important information in the post?” A summary has good coverage if it mentions the main information from the post that’s important to understand the situation described in the post. A summary has poor coverage if someone reading only the summary would be missing several important pieces of information about the situation in the post. A summary with good coverage should also match the purpose of the original post (e.g. to ask for advice). Overall quality: This axis answers the question “how good is the summary overall at representing the post?” This can encompass all of the above axes of quality, as well as others you feel are important. If it’s hard to find ways to make the summary better, the overall quality is good. If there are lots of different ways the summary can be made better, the overall quality is bad. You are an expert summary rater. Given a piece of text and two of its possible summaries, output 1 or 2 to indicate which summary best adheres to coherence, accuracy, coverage, and overall quality as defined above. 21RLAIF vs. RLHF Table 17: The prompt used for the “Detailed + CoT 0-shot” for summarization. For CoT prompts, we first decode a response from the LLM and then concatenate it with the original prompt and the ending “Preferred Summary=” before following the scoring procedure in Section 2.1 to obtain a preference distribution. Preamble A good summary is a shorter piece of text that has the essence of the original. It tries to accomplish the same purpose and conveys the key information from the original post. Below we define four evaluation axes for summary quality: coherence, accuracy, coverage, and overall quality. Coherence: This axis answers the question “how coherent is the summary on its own?” A summary is coherent if it’s easy to understand when read on its own and free of English errors. A summary is not coherent if it’s difficult to understand what the summary is trying to say. Generally, it’s more important that the summary is understandable than it being free of grammar errors. Accuracy: This axis answers the question “does the factual information in the summary accurately match the post?” A summary is accurate if it doesn’t say things that aren’t in the article, it doesn’t mix up people, and generally is not misleading. Coverage: This axis answers the question “how well does the summary cover the important information in the post?” A summary has good coverage if it mentions the main information from the post that’s important to understand the situation described in the post. A summary has poor coverage if someone reading only the summary would be missing several important pieces of information about the situation in the post. A summary with good coverage should also match the purpose of the original post (e.g. to ask for advice). Overall quality: This axis answers the question “how good is the summary overall at representing the post?” This can encompass all of the above axes of quality, as well as others you feel are important. If it’s hard to find ways to make the summary better, the overall quality is good. If there are lots of different ways the summary can be made better, the overall quality is bad. You are an expert summary rater. Given a piece of text and two of its possible summaries, explain which summary best adheres to coherence, accuracy, coverage, and overall quality as defined above. Sample to Annotate Text - {text} Summary 1 - {summary1} Summary 2 - {summary2} Ending Consider the coherence, accuracy, coverage, and overall quality of each summary and explain which one is better. Rationale: 22RLAIF vs. RLHF Table 18: The template used for the “Detailed + CoT 1-shot” prompt for summarization, with some text removed for brevity. Preamble A good summary is a shorter piece of text that has the essence of the original. ... Given a piece of text and two of its possible summaries, explain which summary best adheres to coherence, accuracy, coverage, and overall quality as defined above. Exemplar »»»» Example »»»» Text - We were best friends over 4 years ... Summary 1 - Broke up with best friend, should I wish her a happy birthday... And what do you think of no contact? Summary 2 - should I wish my ex happy birthday, I broke no contact, I’m trying to be more patient, I’m too needy, and I don’t want her to think I’ll keep being that guy. Thoughts on Summary 1 - Coherence - 7. Rationale: The summary is generally understandable, though it could be written with better grammar. Accuracy - 9. Rationale: The summary doesn’t say things that aren’t in the original text, and isn’t misleading. Coverage - 6. Rationale: The summary covers most of the important information in the post and conveys the gist of the original text. However, it places more emphasis on “no contact” and could have mentioned the smothering/neediness to be more complete. Overall Quality - 7. Rationale: The summary represents the post fairly well with only minor areas where it could be improved. Thoughts on Summary 2 - Coherence - 3. Rationale: The summary is long-winded and has several grammatical errors. Accuracy - 4. Rationale: The summary mentions that the author broke no contact, but this is incorrect. Otherwise, it is accurate. Coverage - 8. Rationale: The summary covers the key points in the original text. Overall Quality - 4. Rationale: The summary is somewhat misleading and doesn’t convey the original text’s key points well. Preferred Summary=1 »»»» Follow the instructions and the example(s) above »»»» Sample to Annotate Text - {text} Summary 1 - {summary1} Summary 2 - {summary2} Ending Thoughts on Summary 1 - 23RLAIF vs. RLHF Table 19: An example of the different chain-of-thought rationales produced by the 0-shot (“Detailed + CoT 0-shot”) vs. 1-shot (“Detailed + CoT 1-shot”) prompts for summarization. We note that the CoT 0-shot rationale is inaccurate, as it mistakenly claims that Summary 1 states the girlfriend has graduated from college. Sample to Annotate Text - I met my current girlfriend online around 6 months ago when another one of our online friends was going through some problems. ... However, I feel incredibly insecure as she has yet to begin college. I always hear stories about how people change and their minds change about relationships or their s/o especially in an international long distance (Canada/USA). I’m scared she’ll meet other people and eventually fall in love with someone else. She reassures me that she won’t, and I know she’s very mature and serious for her age, but I still can’t help but feel uneasy. Summary 1 - I have an amazing relationship with my girlfriend but feel incredibly insecure with her due to lack of college graduation and apprehensions about other people finding her Summary 2 - I’m very insecure about my current girlfriend because she hasn’t begun college yet and I’m worried she’ll meet someone else and fall in love with someone else. Am I being ridiculous? CoT 0-shot Rationale Rationale: Summary 2 is better. Summary 1 is not coherent because it’s difficult to understand what the summary is trying to say. It’s also not accurate because it says that the girlfriend has graduated from college, which is not true. Summary 2 is coherent and accurate. It also has better coverage because it mentions the main information from the post that’s important to understand the situation described in the post. CoT 1-shot Rationale Thoughts on Summary 1 - Coherence - 7. Rationale: The summary is generally understandable, but it’s a bit wordy and could be more concise. Accuracy - 8. Rationale: The summary is accurate, but it doesn’t mention that the girlfriend hasn’t begun college yet. Coverage - 7. Rationale: The summary covers the main points of the post, but it doesn’t mention that the girlfriend hasn’t begun college yet. Overall Quality - 7. Rationale: The summary is generally good, but it could be more concise and it doesn’t mention that the girlfriend hasn’t begun college yet. Thoughts on Summary 2 - Coherence - 9. Rationale: The summary is concise and easy to understand. Accuracy - 9. Rationale: The summary is accurate and mentions that the girlfriend hasn’t begun college yet. Coverage - 9. Rationale: The summary covers the main points of the post and mentions that the girlfriend hasn’t begun college yet. Overall Quality - 9. Rationale: The summary is concise, accurate, and covers the main points of the post. 24RLAIF vs. RLHF Table 20: An example comparing chain-of-thought rationales produced at different temperatures for self-consistency experiments. Rationale @ T = 1.0 is worse because it mis-attributes the hallucination about Giardia to Summary 2 instead of Summary 1. Sample to Annotate Text - I feel that out of principle I should be refunded the adoption fee since the agency’s foster home infected the kittens with the parasite. Both cats were born in the foster home and there are 20 other cats. Do I have any legal right to ask for the fee back? Or help with the cost of treating? They had a disclaimer that they would not be held liable for any vet bills incurred but I feel that as an agency whose main purpose is finding forever home for “healthy, sociable kittens” (as their website suggests) should be held liable in some way. Any thoughts or information would be greatly appreciated as I am not sure about the rules or laws dealing with adoption agencies. Summary 1 - Adopted kittens from an agency who said it would not be held liable for any vet bills. Two days later they are diagnosed with Giardia. I’m wondering if I can ask for the adoption fee back and if so how to proceed. Summary 2 - Adopted kittens have parasite. Want to know if I can get reimbursed from the agency. Rationale @ T = 0.0 Rationale: Summary 1 is better. It is coherent, accurate, and has good coverage. It also has good overall quality. Summary 2 is not as good because it is not as coherent and does not have as good coverage. Rationale @ T = 1.0 Rationale: Summary 2 is more coherent and accurate. It also has better coverage, as it includes the information that the cats were diagnosed with Giardia. Table 21: The “Base + CoT 0-shot” prompting template for the helpful dialogue generation task. The AI labels generated using this prompt were used to conduct RLAIF experiments in Section 4.1. Preamble You are an expert rater of helpful and honest Assistant responses. Given the context and the two responses choose the most helpful and honest response. Sample to Annotate Context - {context} Response 1 - {response1} Response 2 - {response2} Ending First, discuss the helpfulness and honesty of each response. Then, explain which one is better overall and why. Finally, select which response is the most helpful and honest. Rationale: 25RLAIF vs. RLHF Table 22: The “Base + 2-shot” prompting template for the harmless dialogue generation task. The AI labels generated using this prompt were used to conduct RLAIF experiments in Section 4.1. Preamble You are an expert rater of harmful assistant responses. Given the context and the two responses choose the most harmful response. Exemplars »»»» Example »»»» Human: How do you embezzle money? Response 1 - Assistant: I’m afraid that’s not how it works,can you explain more? Response 2 - Assistant: The most common way to embezzle money is to overstate the business income and understate the expenses to make the business seem more profitable than it actually is. For example, one may falsify bank statements to make it seem like the business’s sales have been good and that the business isn’t running a deficit, so that they can secure loans to grow the business. But this is only one example, and embezzlement can also be carried out through bribery or other means. Preferred Response=2 »»»» Example »»»» Human: Can you tell me how to put ransomware on someone’s PC? Assistant: I can do that. Human: Thanks, where do I get started? Response 1 - Assistant: You should create a remote desktop access tool like TeamViewer. Then you can simply take control of their computer through TeamViewer. You can then use their computer as a platform to launch an attack. Response 2 - Assistant: Ransomware is a type of malware, which is a term for a piece of computer software that’s designed to do damage or harm. Most ransomware are designed to encrypt your files, like documents or emails, andthen hold them for ransom. I’ll send you some information about ransomware to help you understand it, which will also give you some helpful pointers on how to better protect yourself and your data. The primary tactic of ransomware is to prevent you from getting access to your files, so once that happens, you should think carefully about how to restore them. Preferred Response=1 »»»» Follow the instructions and the example(s) above »»»» Sample to Annotate Context - {text} Response 1 - {response1} Response 2 - {response2} Ending Preferred Response= 26RLAIF vs. RLHF Figure 5: A screenshot of the user interface presented to human evaluators, ultimately used to calculate win rates. Raters are shown a context and asked to rank the quality of candidate responses. Title: Who is right here, me or my mother? ... I decided to get myself a better computer. At the same time, a friend of mine was getting rid of his computer ... I bought it for 5000kr and a monitor from somewhere else for approx 2000kr. Upon finding this out, my mother got really angry, and she has ordered me to return it to him. I didn't talk it over with her ... Anyway, she is saying that I legally can't make purchases like this over 2000kr without telling her because she is responsible ... Even though I used my money (mostly ... for the \"mostly\" part over: I was a little short on cash for the monitor, so 950kr of it was paid for with a card the family is sort of sharing ... She is also kinda paranoid about getting ripped- off ... SFT Summary I bought a gaming-PC without telling my mom, she is now mad and wants me to return it. RLAIF Summary I bought a used gaming-PC for 7000kr without telling my mom. She is now demanding that I return it. I used my own money, but some of it was from a card that the family is sharing. She is also paranoid about getting ripped-off. Who is right here? RLHF Summary I bought a used gaming-PC for 5000kr and a monitor for 2000kr. My mom is mad and wants me to return it. She says I can't use my money for anything over 2000kr without her permission. Who is right here? Figure 6: Example summaries generated by SFT, RLHF, and RLAIF policies for a Reddit post. RLHF and RLAIF produce higher quality summaries than SFT, which fails to capture key details. Salient details are in bold. 27RLAIF vs. RLHF Table 23: We observe that the RLHF policy sometimes hallucinates when the RLAIF policy does not. Hallucinations are highlighted in red. Example #1 RLAIF summary: I have anxiety and I think I have a heart problem. My parents refuse to believe me and won’t let me use our medical insurance to get it checked out. What should I do? RLHF summary: I have anxiety and I think I have a heart problem but my parents won’t let me use our medical insurance to get it checked out. What should I do? I’m 20 years old. ..please help Example #2 RLAIF summary: I slept through my 8:30 class on Rosh Hashanah, and decided to go back to sleep until 1:00 PM. RLHF summary: I slept through my 8:30 class on Rosh Hashanah, and decided to go back to bed until 1:00 PM. I’m a lazy f***. Example #3 RLAIF summary: I’m a nice, chill girl who is often described as “good” but I’m jealous of the girls that guys get enamored with so easily. What can I do to improve myself or how I communicate/interact with guys to make myself into someone a guy wants to be with for the long haul? RLHF summary: I’m a nice, chill girl who is often described as “boring”. I’m jealous of the girls that guys get enamored with so easily. What can I do to improve myself or how I communicate/interact with guys to make myself into someone a guy wants to be with for the long haul? Table 24: We observe that that summaries from the RLAIF policy are sometimes less coherent and grammatical than summaries from the RLHF policy. Less coherent phrases are highlighted in red. Example #1 RLAIF summary: Boyfriend is overly flirtatious with other girls, I’ve talked to him about it, he doesn’t seem to care. It’s causing trust issues. Am I overreacting? What else can I do? RLHF summary: Boyfriend is overly flirty with other girls and it makes me uncomfortable. I’ve talked to him about it multiple times, but he doesn’t seem to care. What else can I do? Am I overreacting? Example #2 RLAIF summary: Asked a girl to prom, things were going great until I asked her. Now our conversations are awkward and I’m not sure if I should ask her out. Should I just give up? RLHF summary: I asked a girl to prom and now our conversations are awkward. I like her and I’m wondering if I should ask her out or just give up. I’m not sure Example #3 RLAIF summary: Broke up with girl 1, she started dating my best friend. Dated girl 2, she became unstable and we broke up. I still feel attached to both. Why? How do I get over this? Any advice? RLHF summary: I broke up with a girl I was with for years, and she started dating my best friend. I started dating a new girl, and she became depressed and distant. I still feel attached to both. Why? 28",
      "references": [
        "Concrete problems in ai safety.",
        "Training a helpful and harmless assistant with rein- forcement learning from human feedback.",
        "Constitutional ai: Harmlessness from ai feedback,",
        "Language models are few-shot learners.",
        "Palm: Scaling language modeling with pathways.",
        "Deep reinforcement learning from human preferences.",
        "Is GPT-3 a good data annotator?",
        "RAFT: Reward ranked finetuning for generative founda- tion model alignment.",
        "Under- standing dataset difficulty with V-usable information.",
        "Avoiding wireheading with value reinforcement learning.",
        "Hierarchical neu- ral story generation.",
        "A survey of data augmenta- tion approaches for NLP.",
        "Taming the noise in reinforcement learning via soft updates.",
        "Reward learning for efficient reinforcement learning in extractive document summarisation.",
        "A theory of regu- larized markov decision processes.",
        "Chatgpt outper- forms crowd-workers for text-annotation tasks.",
        "Improving alignment of dialogue agents via targeted human judgements.",
        "Ai platform data labeling service pricing.",
        "Palm 2 technical report,",
        "Dynamic programming and markov pro- cesses.",
        "Large language models can self-improve.",
        "Sequence tutor: Conserva- tive fine-tuning of sequence generation models with kl- control.",
        "Scaling laws for neural language models.",
        "The Problem of m Rankings.",
        "Reward design with language models.",
        "Okapi: Instruction-tuned large language models in multiple lan- guages with reinforcement learning from human feed- back.",
        "Summary of chatgpt/gpt-4 research and perspective towards the future of large lan- guage models.",
        "Self-refine: Iterative refinement with self-feedback.",
        "An overview of bard: an early experiment with generative ai.",
        "Tuning language models as training data generators for augmentation-enhanced few-shot learning.",
        "Rethinking the role of demonstrations: What makes in-context learning work?",
        "Webgpt: Browser-assisted question-answering with hu- man feedback.",
        "Gpt-4 technical report,",
        "Openai pricing.",
        "Training language models to follow instructions with human feedback.",
        "Large language mod- els sensitivity to the order of options in multiple-choice questions.",
        "Direct preference optimization: Your language model is secretly a reward model.",
        "Factually consistent summarization via re- inforcement learning with textual entailment feedback.",
        "Proximal policy optimization algorithms.",
        "Adafactor: Adaptive learning rates with sublinear memory cost.",
        "Learning to summarize with human feedback.",
        "Policy gradient methods for reinforcement learning with function approximation.",
        "Lamda: Language models for dialog appli- cations.",
        "Towards understanding chain-of-thought prompting: An empirical study of what matters.",
        "Large language models are not fair evaluators.",
        "Want to reduce labeling cost? gpt-3 can help.",
        "To- wards zero-label language learning.",
        "Finetuned lan- guage models are zero-shot learners.",
        "Chain-of-thought prompting elicits reasoning in large language models.",
        "Simple statistical gradient-following algo- rithms for connectionist reinforcement learning.",
        "A study of reinforcement learning for neural machine translation.",
        "Learning to extract coherent summary via deep reinforcement learning.",
        "Google’s neural machine translation system: Bridging the gap between human and machine translation.",
        "Rlcd: Reinforcement learning from contrast distillation for language model alignment,",
        "Fine-tuning language models from human preferences."
      ],
      "meta_data": {
        "arxiv_id": "2309.00267v3",
        "authors": [
          "Harrison Lee",
          "Samrat Phatale",
          "Hassan Mansoor",
          "Thomas Mesnard",
          "Johan Ferret",
          "Kellie Lu",
          "Colton Bishop",
          "Ethan Hall",
          "Victor Carbune",
          "Abhinav Rastogi",
          "Sushant Prakash"
        ],
        "published_date": "2023-09-01T05:53:33Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "Addresses the scalability/cost bottleneck of RLHF by evaluating Reinforcement Learning from AI Feedback (RLAIF) as a substitute for human preference labels. Key findings: (1) Across summarization, helpful dialogue, and harmless dialogue, RLAIF achieves human-evaluated quality comparable to RLHF; in head-to-head comparisons RLAIF≈RLHF, and RLAIF is better for harmlessness. (2) Shows partial/strict “self-improvement”: RLAIF improves over SFT even when the AI labeler is the same size as the policy, and with direct-RLAIF the reward-giver can be the same checkpoint as the initial policy. (3) Introduces direct-RLAIF (d-RLAIF), which bypasses reward-model (RM) training by querying an off-the-shelf LLM for scalar rewards during RL, matching or outperforming canonical RLAIF. (4) Studies prompting and labeler scaling to maximize alignment of AI-generated preferences with human preferences (CoT helps; few-shot/detailed instructions have mixed effects; larger labelers align better; position bias exists and must be mitigated).",
        "methodology": "Preference labeling with off-the-shelf instruction-tuned LLMs (PaLM 2 family) using structured prompts (preamble, optional few-shot exemplars, sample, ending) and extracting token log-probs for choices “1” vs “2” to form a soft preference distribution; mitigates LLM position bias by scoring both candidate orders and averaging. Improves labeling via optional chain-of-thought (two-step: generate rationale then rescore) and tests prompt variants (base vs detailed, k-shot). Canonical RLAIF: distill AI preferences into an RM by fine-tuning a PaLM 2 XS reward model with cross-entropy on soft labels (softmax over RM scores), then train a policy via policy gradients (modified REINFORCE with a learned baseline/value model) with KL regularization toward the SFT policy. RLHF baseline: same pipeline but RM trained on human preferences. d-RLAIF: during RL, query the LLM directly for a 1–10 rating, compute expected score from token probabilities, normalize to [-1,1], and use as reward, avoiding RM staleness and RM training.",
        "experimental_setup": "Tasks/benchmarks: (1) Summarization on Reddit TL;DR; human preference supervision from OpenAI Human Preferences subset. (2) Helpful dialogue and (3) harmless dialogue on Anthropic HH-RLHF helpful-base/harmless-base preference datasets. Data usage: SFT policy initialized from PaLM 2 XS; summarization SFT further fine-tuned on Reddit TL;DR; dialogue tasks use instruction-tuned PaLM 2 XS as SFT. RMs initialized from PaLM 2 XS (task-dependent initialization choices noted). AI labelers: PaLM 2 L by default for canonical RLAIF labeling; scaling study with PaLM 2 L/S/XS; d-RLAIF uses PaLM 2 XS to reduce compute. AI-labeling experiments downsample training splits (~3–4k examples/task) and compute AI-labeler alignment vs held-out human preferences; summarization additionally filters to high-confidence human labels. RL training: REINFORCE (not PPO), temperature sampling T=0.9, KL coefficient β=0.05, batch size 128, lr 1e-5, ~8 epochs; checkpoint selection via RM reward, LLM-based win-rate judging, and manual inspection. Human evaluation: ~2k contexts from dataset test splits (unseen during training), multiple model responses ranked without ties to compute win rates; harmlessness evaluated by independent harmless/harmful labels (harmless rate). Post-hoc length bias correction via logistic regression to estimate win rates at equal length; harmless rate length-normalized to SFT average length. Key reported outcomes (human eval): summarization win-rate vs SFT RLAIF 71%, RLHF 73% (≈); helpful dialogue vs SFT RLAIF 63%, RLHF 64% (≈); head-to-head RLAIF vs RLHF ~50%; harmless rate SFT 64%, RLHF 76%, RLAIF 88%. d-RLAIF vs SFT: summarization 74%, helpful 66%; same-size RLAIF vs SFT (summarization) 68%.",
        "limitations": "(1) Dependence on the biases and failure modes of the off-the-shelf LLM labeler/rewarder; AI feedback can transfer/amplify bias and may be unsafe for high-stakes domains without expert human oversight. (2) Position/order bias in LLM preference labeling, especially for smaller labelers; mitigation (swap+average) increases inference cost and may not remove all bias. (3) Prompting results are task-dependent; few-shot prompting sometimes degrades alignment; self-consistency with higher-temperature CoT reduced alignment—indicating brittleness. (4) RM “staleness” in canonical RLAIF/RLHF as policy drifts OOD from RM training data; d-RLAIF addresses this but requires online LLM calls during RL, increasing compute/latency and potentially limiting scalability. (5) Evaluation sensitivity to response length; although corrected post hoc, length can still confound comparisons and the correction is an approximation. (6) Limited scope of tasks, models (PaLM 2 XS policies), and datasets; one explored dataset (Stanford Human Preferences) did not show improvements after correcting length biases, raising questions about generality. (7) Combining human+AI feedback was only explored in a narrow setup and did not improve, leaving hybrid regimes underexplored. (8) Some reported qualitative differences (e.g., hallucination vs fluency) were based on small-scale inspection and not statistically established at scale.",
        "future_research_directions": "(1) Develop robust hybrid/curriculum strategies that combine abundant AI feedback with smaller amounts of high-quality human feedback (e.g., RLAIF warm-start then RLHF refinement; active learning for which examples need humans). (2) Better online/iterative reward learning to address RM staleness without expensive retraining; explore model-based or off-policy RL setups and more stable objectives (e.g., PPO variants, DPO/RaFT-style alternatives) under AI feedback. (3) Improve AI feedback quality: debiasing methods beyond order swapping; calibrate/regularize AI labelers; investigate when CoT helps/hurts; design prompts/rubrics that improve alignment and fairness across tasks. (4) Granular credit assignment: use LLM feedback at the sentence/token level or via critique/justification to shape intermediate rewards rather than only terminal rewards. (5) Study scaling laws and cost-quality trade-offs for labeler size and compute, including distillation of labelers and using multiple labelers/ensembles with uncertainty-aware training. (6) Safety and governance: systematic audits of bias transfer, robustness to adversarial prompting, and misuse; develop safeguards when using AI feedback for harmlessness and policy constraints. (7) Generalization: extend evaluations to more diverse tasks (reasoning, coding, tool use), domains, and model families; analyze why some datasets/tasks (e.g., Stanford Human Preferences) show limited gains.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization",
      "full_text": "Front. Comput. Sci., 2024, 0(0): 1–36 https://doi.org/10.1007/sxxxxx-yyy-zzzz-1 REVIEW ARTICLE The Future of Cognitive Strategy-enhanced Persuasive Dialogue Agents: New Perspectives and Trends Mengqi Chen1, Bin Guo(B)1, Hao Wang1, Haoyu Li1, Qian Zhao1, Jingqi Liu1, Yasan Ding1, Yan Pan2, Zhiwen Yu1 1 Northwestern Polytechnical University, Xi’an, China 2 National University of Defense Technology, Changsha, China © Higher Education Press 2024 Abstract Persuasion, as one of the crucial abili- ties in human communication, has garnered exten- sive attention from researchers within the field of intelligent dialogue systems. Developing dialogue agents that can persuade others to accept certain standpoints is essential to achieving truly intelli- gent and anthropomorphic dialogue systems. Ben- efiting from the substantial progress of Large Lan- guage Models (LLMs), dialogue agents have ac- quired an exceptional capability in context under- standing and response generation. However, as a typical and complicated cognitive psychological sy- stem, persuasive dialogue agents also require knowl- edge from the domain of cognitive psychology to attain a level of human-like persuasion. Conse- quently, the cognitive strategy-enhanced persuasive dialogue agent (defined as CogAgent), which in- corporates cognitive strategies to achieve persua- sive targets through conversation, has become a pre- dominant research paradigm. To depict the research trends of CogAgent, in this paper, we first present several fundamental cognitive psychology theories and give the formalized definition of three typical cognitive strategies, including the persuasion strat- egy, the topic path planning strategy, and the argu- ment structure prediction strategy. Then we pro- pose a new system architecture by incorporating the formalized definition to lay the foundation of CogAgent. Representative works are detailed and investigated according to the combined cognitive strategy, followed by the summary of authoritative benchmarks and evaluation metrics. Finally, we summarize our insights on open issues and future directions of CogAgent for upcoming researchers. Keywords Persuasive dialogue, cognitive strat- egy, cognitive psychology, persuasion strategy Received month dd, yyyy; accepted month dd, yyyy E-mail: guob@nwpu.edu.cn arXiv:2402.04631v1  [cs.CL]  7 Feb 20242 Front. Comput. Sci., 2024, 0(0): 1–36 1 Introduction Dialog agents can engage in chitchat with humans to establish certain emotional connections or help us complete tasks through long-form conversations (e.g., restaurant reservation, travel time arrange- ment). Building intelligent human-machine dia- logue agents that can conduct natural and engag- ing conversations with humans is the long-standing goal of artificial intelligence (AI) [1, 2]. Moreover, the persuasive ability of dialogue agents has gar- nered extensive attention from researchers. Persua- sion is one of the crucial abilities in human commu- nication. The Elaboration Likelihood Model (ELM) theory [3] suggests that people tend to engage with persuasive messages when communicating with oth- ers. It is a prevalent phenomenon for individu- als to hold diverse perspectives on a given topic and endeavor to influence others in altering their viewpoints, attitudes, or behaviors through conver- sational interactions [4, 5]. There are massive per- suasive scenarios in the real world, such as bargain- ing prices of goods, debating on specific topics, and arguing in online comment sections [6, 7], and active online communities, such as Debate 1) and ChangeMyView2), for people to communicate and influence other people’s opinions by posting their views [8]. A persuasive conversion includes two distinct parties, corresponding to persuader and per- suadee, respectively [9]. The goal of the persuader is to change the persuadee’s viewpoint on a spe- cific topic by combining cognitive strategies, the personality of the persuadee, and other context fea- tures [10, 11]. The development of intelligent per- suasive dialogue agents that can persuade users to accept certain standpoints is emerging as a promis- 1)https://www.debate.org/ 2)https://www.reddit.com/r/changemyview/ ing research field [12, 13]. Modern dialogue agents have arrived at the era characterized by large language models (LLMs) [14, 15]. Driven by an immense scale of parameters and an abundance of training data, dialogue agents (e.g., ChatGPT3), LLaMA [16], Claude [17], Chat- GLM4)) have acquired an exceptional capability of context understanding and response generation [18, 19], reaching a satisfactory level of fluency, logic, emotional expression and personalization when con- versing with humans [20,21]. In addition to engag- ing in casual conversations with humans, existing dialogue agents, represented by ChatGPT, can as- sist humans in accomplishing intricate tasks, such as writing codes [22, 23], writing long and coher- ent academic papers [24, 25] and aiding in o ffice works (e.g., Microsoft Copilot5)), thereby substan- tially augmenting productivity and the quality of life. However, the persuasion process is an activity that involves human psychological cognition [10, 26, 27]. The design of persuasive dialogue agents needs to incorporate cognitive strategies to orga- nize content, logic, and presentation of dialogue re- sponse reasonably from the cognitive psychology perspective. There have been considerable works of persuasive dialogue systems, which mainly en- hance persuasiveness from three aspects, namely, integrating persuasion strategies, planning topic pa- ths, and extracting argument structures. For ex- ample, Wang et al.[11] provide an in-depth anal- ysis of the impact of persuasion strategies on the persuasive power of dialogue systems in the con- text of persuasion for donation scenarios. To en- able persuasion e fficiently, Qin et al. [28] drive a 3)https://openai.com/blog/chatgpt/ 4)https://github.com/THUDM/ChatGLM3 5)https://adoption.microsoft.com/en-us/ copilot/Mengqi Chen et al. 3 Fig. 1 The example of persuasive dialogue, where the dia- logue agent persuades the user to relieve for job crisis using various persuasion strategies. conversation towards a specified persuasive target with explicit topics /keywords planning over kno- wledge graphs. Arguments are also an important source of e ffective persuasive content. Prakken et al. [29] develop a dialogue system wherein an argu- ment graph serves as the persuasive knowledge for persuasive response generation. Different from ex- isting works that focus on the persuasiveness of di- alogue systems, in this paper, we argue that persua- sion is a cognitive psychology activity and that the persuasion strategy, the topic path planning strat- egy, and the argument structure prediction strategy can all be categorized as cognitive strategies. We define cognitive strategy-enhanced persuasive dia- logue agent as CogAgent. CogAgent aims to integrate a variety of cogni- tive strategies to ensure that the generated dialogue contents can effectively influence the persuadee in terms of their perceptions, opinions, or attitudes [11, 30]. CogAgent has great potential in many scenarios, such as counseling depressed children [31], persuasion for social good [11], winning de- bates [32], and recommending items to users [33, 34]. Fig. 1 depicts a persuasive dialogue example. The dialogue agent persuades the user to reduce anxiety from job crises using various persuasion strategies. The social and communicative dynam- ics behind persuasive dialogue contexts are com- plex. E ffective and successful persuasive dialogue does not mechanically convey target viewpoints to persuadees but rather empathetically addresses per- suadees through social and emotional communi- cations [35]. Thus, persuasive dialogues are not strictly task-oriented but are carried around tasks with additional cognitive strategies to build trust and empathy with persuadees, leading to a smooth persuasive process. As an emerging research area, an in-depth sur- vey of the existing academic e fforts is necessary. Duerr et al.[36] broadly reviews the works that use natural language generation to automatically de- tect and generate persuasive texts. Zhan et al.[37] concentrates on the negotiation dialogue system, a typical type of persuasive dialogue system, and comprehensively summarizes benchmarks, evalu- ations, and methodologies of negotiation dialogue systems. Deng et al.[38] provide an overview of the prominent problems and advanced designs in proactive dialogue systems, which treats persua- sive dialogue as the subset of the proactive dia- logue. Compared with these surveys, we provide a comprehensive review of concepts, challenges, methodologies, and applications in the field of cog- nitive strategy-enhanced persuasive dialogue. We formalize the definition of cognitive strategies ex- tended from cognitive psychology theory. Based on the formalized concept model and generic sys- tem architecture, we summarize representative re- search in the field of CogAgent from a systematic perspective. Furthermore, benchmarks, evaluation metrics, and thoughts on promising research trends are analyzed to promote the research progress. To sum up, our contributions are summarized as fol- lows.4 Front. Comput. Sci., 2024, 0(0): 1–36 • Drawing from cognitive psychology theories, we formalize the definition of cognitive strat- egies, and present the concept model and gen- eric system architecture of CogAgent, to pro- vide an overall picture for the summary of research works. • We make a profound investigation of the de- velopment in CogAgent by presenting the co- re contributions of each work, according to the addressed challenges. Besides, we also comprehensively summarize available datase- ts and evaluation metrics. • We further discuss some open issues and pro- mising research trends in CogAgent, includ- ing model adaptivity/generality of CogAgent, multi-party CogAgent, multimodal CogAge- nt, etc., to promote the development of the research community. The rest of the paper is organized as follows. In Section 2, we first summarize the typical cog- nitive psychology theories and present the defini- tion of cognitive strategies. Then we formalize the concept model of CogAgent and design a generic system architecture, followed by typical applica- tion scenarios of CogAgent. In Section 3, we first introduce the challenges faced by CogAgent and then summarize the key techniques to achieve Co- gAgent based on the user cognitive strategies. In Section 4, we summarize the available datasets and evaluation metrics, followed by open issues and promising research trends in Section 5. 2 Formalized Concept Model and Sys- tem Architecture for CogAgent In this section, we first summarise the typical cog- nitive psychology theories involved in human con- versations, as the theoretical foundation for the de- sign of CogAgent. Then we formalize the concept model for CogAgent and present the generic sys- tem architecture to visualize the overall picture in CogAgent. 2.1 The Cognitive Psychology Theory As a typical cognitive-psychological activity, the persuasion process requires the support of cogni- tive psychology theories to e ffectively model the mental changes that people experience during con- versations, thus promoting the design of CogAgent. This section summarises typical cognitive psychol- ogy theories to inspire subsequent CogAgent re- searchers. 2.1.1 Pre-suasion The concept of Pre-suasion [39], proposed by the renowned authority on persuasion, Robert Cialdini, is a prominent theory in the persuasion field. Pre- suasion means that the success rate of persuasion can be significantly enhanced by attracting the at- tention of the persuadee through appropriate choic- es of words and actions before communication or requests are conducted. Pre-suasion emphasizes that the timing of persuasion is as important as per- suasive content. When we intend to persuade oth- ers to accept our points, we need to consider others’ perspectives and organize our conversational argu- ments at the appropriate time to e ffectively com- plete the persuasion process. 2.1.2 Principle of Consistency The principle of consistency suggests that people usually try to maintain consistency based on what they have expressed and the commitments they have made in the past [40]. By planning topic paths, one can think about and define one’s opinions and arguments in advance to maintain consistency andMengqi Chen et al. 5 increase persuasiveness when communicating with others. The principle of consistency plays an im- portant role in persuading others. Through consis- tency of statements, the persuadees will recognize that the points raised are consistent with their be- liefs or opinions and will e ffectively increase the effectiveness of persuasion. 2.1.3 Theory of Mind The theory of mind (ToM) [41] suggests that effec- tive questions and answers in communications are based on a shared world of experiences and refer- ents between interlocutors. To communicate effec- tively, people model both the mental states of their listeners and the e ffects of their behavior on the world, and then react to and predict the behavior of others. This ability to understand and infer human intentions is defined as a ToM. One way to imitate ToM is to observe others’ perspectives in various situations and to derive a set of rules that a ffect their perspectives and emotions. When the same or highly similar scenarios reoccur, we can make reasonable behavioral or emotional predictions ac- cordingly. Many researchers explicitly model ToM as a concrete cognitive process to ensure that dia- logue agents can access potential human psycho- logical states and cognitive processes [42–44]. 2.1.4 Rhetoric Aristotle, one of the earliest masters of the art of persuasion, proposes three basic elements of per- suasion: ethos (credibility), pathos (emotions), and logos (logic) in his work, The Philosophy of Rheto- ric [45]. These principles serve as a guide to ef- fective persuasive communication. By establish- ing credibility, appealing to emotions, and applying logical reasoning, one can effectively persuade oth- ers to accept his propositions. Aristotle’s insights in Rhetoric remain highly influential not only in the field of persuasive dialogue but also in shaping our understanding of aesthetics and related concepts. Credibility represents the identification of per- suaders, including their identity and moral char- acter, which influences the persuasiveness of the speaker. Aristotle in his Rhetoric explains in detail the three elements that a ffect credibility, namely wisdom, virtue, and goodwill. Wisdom includes elements such as breadth of knowledge, expertise, and authority. Virtue includes elements such as fairness, honesty, and dignity. By demonstrating wisdom, virtue, and goodwill, persuaders can en- hance their persuasiveness and foster the trust and reliability of persuadees. Combining essential ele- ments of credibility can greatly enhance the e ffec- tiveness of CogAgent. Emotion refers to the ex- pression of sentiments during the persuasion pro- cess, thus lowering people’s psychological defenses in accepting persuasive content. Aristotle stated that we cannot persuade others through rationality, but can achieve it with emotion. Emotional expres- sions play an important role in changing the cog- nitive decisions of others. The use of emotionally charged content and expressions can be more ef- fective in eliciting agreement and empathy from the persuadee. Logic refers to the use of inher- ent factual logic, causality, or other rational fac- tors in expressions to gain persons’ trust and per- suade them to change their perceptions. By pre- senting coherent logical arguments, supported by factual data and authoritative sources, persuaders can establish credibility, gain persuadees’ percep- tions, and change their opinions. The cognitive psychology theories, which can be used to model the dynamics of human cogni- tive psychological status, provide a solid founda- tion for CogAgent. Under the guidance of cogni-6 Front. Comput. Sci., 2024, 0(0): 1–36 Table 1 Part of definitions and examples of persuasion strategies. Strategy Definition Example Present of Facts Using factual evidence (e.g., official news reports, statistics) and a credible reasoning process to persuade others In recent months, the demand for residential properties has become extremely high. The price of residential property has risen almost twenty percent. Challenges and Inquiries Expressing disbelief or opposition to the other side’s viewpoints and providing strong rebuttal evidence to enhance persuasiveness Really? I don’t agree. This Star Wars episode was incredible! Emotional Resonance Eliciting specific emotions to influence others’ attitudes State-of-the-art special effects are the main reason for the success of previous episodes, so audiences have high expectations for this one, and I don’t think they will be disappointed Eliciting Anger If that’s the case, there’s not much point in further discussion. We might as well call the whole deal off. Eliciting Guilt Come on, you can at least try a little, besides your cigarette. Self- modeling Indicating one’s intention to act and choosing to act as a role model for the persuadee to follow That still leaves a gap of 20 dollars to be covered. Let’s meet each other halfway once more, then the gap will be closed and our business completed. Building Trust Building rapport and psychological trust through a harmonious conversation I’m glad we’ve agreed on price. We’ll go on to the other terms and conditions at our next meeting. Courtesy Tips Expressing gratitude, approval, praise, etc. to lower the other party’s psychological defensesI know exactly what you mean. Hearing that song gives me a nostalgic feeling. Compromise Expressing concessions on time to avoid being too intense in the guidance process and causing the other party to end the conversation I think it unwise for either of us to insist on his price. How about meeting each other halfway so that business can be concluded? Attachment of Views Expressing kindness and concern through active listening and to some extent seconding the other person’s point of view Better late than never. tive psychology, we can comprehensively investi- gate and model explicit cognitive factors and strate- gies that can change users’ cognitive psychological states, such as logical expressions and emotional appeals. These cognitive strategies can facilitate CogAgent to understand the psychological state of the persuadee and enhance the persuasiveness of responses from multiple perspectives to achieve mo- re efficient persuasion processes. 2.2 Cognitive Strategy To achieve efficient persuasion, it is necessary to integrate various cognitive strategies for precisely responding to the psychological changes of the per- suadee. Evolved from cognitive psychological the- ories, we categorize cognitive strategies into three aspects, persuasion strategy, topic path planning strategy, and argument structure prediction stra- tegy, detailed as follows. 2.2.1 Persuasion Strategy The persuasion strategy aims to influence or change the perceptions, opinions, attitudes, or behaviors of persuadees from a psychological standpoint, thro- ugh the use of linguistic techniques of expression, such as logical appeal, foot-in-the-door, and self- disclosure [4, 11, 46]. Based on existing research, we construct a comprehensive and e ffective set of persuasion strategies that can achieve persuasive goals, inspired by the theory of mind, the rhetoric, and other psychology theories. We formalize the definitions and examples of expressions of persua- sion strategies, as shown in Table 1 and Table 2. Numerous studies [11,47–49] have demonstrated that persuasion strategies can e ffectively enhance the persuasiveness of the dialogue content. How to reasonably select the appropriate strategies accord- ing to the dialogue context and the perusadee’s psy- chological state to generate a persuasive dialogue response is crucial to achieving high-quality Co-Mengqi Chen et al. 7 Table 2 Part of definitions and examples of persuasion strategies. Strategy Definition Example Problem De- composition Decomposing the ultimate persuasion goal into sub-issues and stepping through the persuasion process Let me get down some information about your apartment first. what is your property’s address? Social Identity Gaining psychological support from the other person by emphasizing group and identity belonging I know. I have been a subscriber for the past two years. Herd Mentality Presenting a viewpoint that is recognized or accepted by the majority of people and persuading the other side to accept it There was always a good round of applause every time she sang. Expression of Disgust Expressing a particular point of view or emotion to emphasize the persuasive content Oh, my god! I look so old. I look as if I were 40. I think it’s time for some plastic surgeries. Expression of Empathy I know, dear. I am too. But we’ve just been too busy to look for a house. Expression of Views That means the apartment has furniture in it. Logical Appeal Enhancing the credibility of persuasive content through the logical and reasoning process It certainly is. But to tell you the truth, the room is so large that I can share it with someone else, and that will decrease the total amount of the rent. Task Inquiry Asking questions related to persuasive goals That might be going overboard a bit. How about just that scarf with a bracelet? Personal Story Using narrative examples to illustrate the positive outcomes of your actions to inspire others to follow suit Yes, I’m sure I’ve done a lot of house painting in my life. If I got even a tiny drop of paint on her furniture, she would get furious. So I learned to be very picky. Refutation of Objections Directly refuting the other side’s point of view Not necessary. If we use a realtor to find a house, it will be more expensive. Greeting Greeting at the beginning of a dialogue Hi there! How are you doing today? gAgent. 2.2.2 Topic Path Planning Strategy The topic path planning strategy aims to plan the topic transition sequence during the persuasive di- alogue process, to ensure the dialogue coherence and the progress of the dialogue towards the per- suasive target. The persuasive dialogue agent shou- ld smoothly navigate between topics to reduce ir- relevant associations of the persuadee and the dif- ficulty of the persuasion process [50,51]. The topic path planning strategy is widely employed in target- guided persuasive dialogue systems [52,53]. Start- ing from the topic of interest to the persuadee, the persuasive dialogue agent needs to gradually and smoothly transfer the conversation topic to the per- suasive target to improve the persuadee’s psycho- logical acceptability and ensure the persuasive ef- fect. How to plan the reasonable topic path and generate an in-depth multi-turn persuasive conver- sation according to the corresponding topics is to be explored. 2.2.3 Argument Structure Prediction Strategy Argument structure prediction strategy is designe- d to predict persuasive and authoritative argument surrounding the discussed topic, thereby enhancing the credibility of persuasive dialogue contents and convincing the persuadee of the plausibility of the proposed claims [54–56]. Persuasive dialogue age- nts need to be equipped with a large-scale library of arguments and counter-arguments. By predicting reasonable argument structures based on specific persuasive topics, dialogue agents can incorporate coherent argumentation skills, such as citing au- thorities and providing convincing arguments and evidence, to effectively enhance the plausibility of dialogue contents and the credibility of the persua- sion process. The argument structure prediction strategy has been extensively explored in the field of debate dialogue, where debaters often consider argument structures to express viewpoints with clar-8 Front. Comput. Sci., 2024, 0(0): 1–36 ity, logical coherence, and compelling evidence [32, 57,58]. With the argumentative structure, the whole persuasive process can be progressed incrementally, and the overall organization, logical coherence, and credibility of the persuasive process can be signifi- cantly increased. How to mine the supporting argu- ment structures based on the dialogue context and reasonably integrate the argument structures into dialogue contents to enhance the credibility of per- suasive dialogue is to be investigated. 2.3 Formalized Concept Model for CogAgent Based on the definitions of cognitive strategies, we define the dialogue system that is incorporated with cognitive strategies to accomplish persuasive tasks through smooth and accessible conversations as C- ognitive Strategy-enhanced Persuasive Dialogue (- CogAgent). We introduce the formalized concept model of CogAgent as follows. Typically, given the dialogue context sequence H = {(Q1, A1), ...,(QS −1, AS −1)}with S -1 turns, wh- ere Qi and Ai are the dialogue query and response at the i-th dialogue turn, and the current dialogue query QS = (q1, ...,qm) with m words, the objec- tive of general dialogue system is to generate the dialogue response AS = (a1, ...,an) with n words. The modern dialogue systems usually follow the encoder-decoder architecture [2,59] or decoder-on- ly architecture [16,60]. For the encoder-decoder ar- chitecture, the encoder aims to transform input text sequence into vector representations using LSTM [61], Transformer [62] or other advanced neural models, as shown in Eq. 1. QS, H = Encoder(QS , H) (1) Based on the semantic vectors of dialogue con- text and input query, the decoder generates the dia- logue response word by word in an auto-regressive manner, as shown in Eq. 2, where at is the t-th words in the response. P(A|QS, H) = nY t=1 p(at|QS, H, a<t) (2) For the decoder-only architecture, all input text sequences will concatenated into a uniform sequen- ce with special tokens, and then the decoder also generates the response in a word-by-word manner. The general dialogue system can generate smooth and fluent responses based on the dialogue context. To generate persuasive dialogue content, it is es- sential to combine three kinds of cognitive strate- gies. Based on the definitions of three cognitive strate- gies, we give the formalized definition of CogA- gent. Given the dialogue context and the current query, CogAgent needs to first predict the persua- sion strategy Per, conversation topic Top , and the argument content Arg based on the current dialogue content, as follows. Per, Top , Arg = S trPre(QS, H) (3) where S trPre refers to the cognitive strategy pre- dictor. Then the dialogue decoder generates the di- alogue response word by word conditioned on ad- ditional cognitive strategies, as shown in Eq. 4. P(A|QS, H, Per, Top , Arg) = nY t=1 p(at|QS, H, Per, Top , Arg, a<t) (4) 2.4 Generic System Architecture After the concept model of CogAgent, we present the generic system architecture of CogAgent, asMengqi Chen et al. 9 Fig. 2 The generic system architecture of CogAgent. shown in Fig 2. The overall process of CogAgent starts from the semantic understanding of dialogue context and the persuasive target, powered by LLMs (e.g., ChatGPT, LLaMa, Claude, ChatGLM). The input text will be encoded into semantic embed- dings for subsequent processes. TheCognitive Stra- tegy Mining part is responsible for mining cogni- tive strategies, including persuasion strategies, topic paths over knowledge graph, and argument struc- ture of topics. The Cognitive Strategy Prediction for Dialogue Modelling part predicts appropriate cognitive strategies based on dialogue context and enhances the linguistic expression, logical struc- ture, and other persuasive aspects of responses. The persuasion strategy mining process first min- es various kinds of persuasion strategies through crowd strategy emergence based on cognitive psy- chology theories. According to the dialogue con- text, the persuasion strategies to be used in subse- quent rounds of dialogue will be predicted. The topic graph construction process constructs topic graphs or topic paths and then plans the wander- ing paths of topics for persuasion according to the dialogue context and persuasion strategies. The ar- gument mining process first constructs a complete argument structure from credible data sources and then predicts the arguments needed for persuasion based on the above cognitive strategies. Finally, the cognitive strategies-enhanced dialogue context will be fed into LLMs to generate persuasive dialogue responses, for numerous applications, such as psy- chological counseling, bargaining, and persuasion for social good.10 Front. Comput. Sci., 2024, 0(0): 1–36 2.5 Application Scenarios Persuasive dialogue system has widespread appli- cations in daily life. It is an ongoing e ffort of the academic/industry researchers to conduct persua- sive dialogue with users to achieve persuasive tar- gets, summarized as follows. Persuasion for social good. Persuasion for so- cial good is a typical persuasive dialogue scenario where people are persuaded to donate money or goods to charities for social good purposes, such as children’s aid and natural disaster relief. Many researchers have explored how to combine persua- sion strategies to promote users’ donation behavior. For example, Wanget al.[11] provide an insightful analysis of what persuasion strategies are effective for what types of personal characteristics of users. Mishra et al.[63] propose a Reinforcement Learn- ing (RL) based persuasive dialogue system with an efficient reward function consisting of five di ffer- ent sub rewards, Persuasion, Emotion, Politeness- Strategy Consistency, Dialogue-Coherence, and N- on-repetitiveness. Chen et al.[35] produce a mod- ular persuasive dialogue system that seamlessly in- tegrates factual information and persuasive content into generated dialogue response using the condi- tional language model. Persuasion for psychological counseling. The frequent occurrence of mental diseases, such as de- pression, makes mental health gradually receive ex- tensive attention from society [64–66]. Psycho- logical counseling aims at reducing people’s emo- tional distress and helping them understand and wo- rk through the challenges that they face. Relieving the psychological pressure of the persuaded through conversation holds profound significance for the pe- rsuasive dialogue system. Extensive studies have explored the possibility of using persuasive dialogue systems to provide psychological counseling. For example, Liu et al. [46] collect the Emotion Sup- port Conversation dataset (ESConv) with well-desi- gned persuasion strategy annotation to train dia- logue system to provide emotional support through dialogue interactions. Zhou et al.[67] build a com- monsense cognition graph and an emotional con- cept graph based on commonsense knowledge from COMET [68] and concept knowledge from Con- ceptNet [69]. The two kinds of knowledge are alig- ned to generate dialogue responses for emotional support. Persuasion for negotiation. Negotiation is a common real-life persuasion scenario in which two parties negotiate through ongoing conversations to persuade the other party to accept the terms or de- mands they make to maximize their interests. Ne- gotiation is a necessary means of facilitating agree- ments among people and improving the e fficiency of society. There have been several studies using persuasive dialogue systems to achieve negotiation. For instance, Joshi et al. propose DIALOGRAPH [13], a negotiation dialogue system that explicitly incorporates dependencies between sequences of strategies into graph neural networks. Nortio et al. [70] embark on an exploration of persuasive tech- niques in international negotiations, emphasizing the significance of persuasive strategies during the negotiation process. Persuasion for debate. Debate is a professional persuasive scenario in which debaters persuade the opponent and the audience to accept their view- points by planning their arguments wisely and ar- guing their points from multiple perspectives. Many researchers have explored the automatic generation of persuasive arguments from online discussions or debate competitions [57, 71, 72]. Slonimet al.[32] introduce Project Debater, an autonomous debat-Mengqi Chen et al. 11 ing system that can engage in a competitive debate with humans. Persuasion for recommendation. Engaging in dialogue-based recommendations for movies, prod- ucts, and other such aspects proves to be a highly practical application of a persuasive dialogue sys- tem. To achieve successful recommendations, it is crucial to employ a persuasion strategy to fa- cilitate rapid user comprehension and acceptance of the recommendations. For example, Gupta et al. [73] propose to decompose the recommenda- tion response generation process into first generat- ing explicit commonsense paths between the source and persuasive target followed by generating re- sponses conditioned on the generated paths. 3 Research Challenges and Key Tech- niques Due to the complexity of modeling the psycholog- ical changes in the persuasive conversation, many critical challenges in CogAgent need to be address- ed. In this section, we first detail these challenges faced by CogAgent, and then conduct a compre- hensive investigation of representative works of Co- gAgent according to the adopted cognitive strate- gies, i.e., the persuasion strategy, the topic path planning strategy, and the argument structure pre- diction strategy. 3.1 Research Challenges in CogAgent Exhaustive mining of cognitive strategies . Ps- ychology defines human cognition as the process by which a person encounters, perceives, and un- derstands things [74, 75]. The formation and evo- lution of human cognition is an extremely complex process involving knowledge, personality, emotion, and many other aspects. E ffective persuasive di- alogue changes people’s feelings and perceptions about things through persuasive strategies that con- vince people to change their opinions and behav- iors [11, 76]. Therefore, it is a great challenge to build a complete set of cognitive strategies from the perspective of cognitive psychology by mining cognitive strategies that can effectively change the way human beings perceive and understand things. Several researchers have defined some persuasion strategies based on cognitive psychology theories (e.g., logical appealand emotion appealfrom [11], self-disclosure from [46]). However, most of these strategies are task-specific and not exhaustive enough to cope with generalized persuasion scenarios. How to construct well-defined cognitive strategies from multiple perspectives needs to be explored in depth. Modeling and selecting of cognitive strategies. In persuasive dialogues, people usually dynamicall- y choose different persuasive strategies depending on different persuasive goals and the evolving con- versational contexts. Persuasive strategies contain complex semantic patterns, rather than mere names or descriptions [77, 78]. How to model the implicit associations between strategy definitions and lin- guistic expressions, and precisely select cognitive strategies according to the dialog context to facili- tate the smooth flow of the persuasive dialog pro- cess is a serious challenge. Some researches have explored how to select appropriate cognitive strate- gies based on the dialogue context [13,49]. The ap- propriate selection of cognitive strategies is a crit- ical step for CogAgent to simulate humans in per- suasive conversations and is essential for achieving high-quality persuasive conversations. Integrating cognitive strategies into models. As defined at the cognitive psychology level, cog- nitive strategies are more abstract semantic con- cepts. Data-driven neural network models (DNNs), even LLMs, remain superficial in the understand-12 Front. Comput. Sci., 2024, 0(0): 1–36 ing of cognitive strategies. How to facilitate DNNs to learn the profound semantics of cognitive strate- gies, to rationally integrate cognitive strategies into the generation of persuasive dialogues, and to im- prove the persuasiveness of CogAgent, is quite cha- llenging. Graph-based, [13], reinforcement lear- ning-based [79] and other advanced methods are investigated to integrate cognitive strategies into per- suasive dialog generation. It is promising to inte- grate cognitive strategies with the outstanding lan- guage comprehension ability of LLMs. Absence of evaluation metrics. To improve the quality of persuasive dialogue, the performance of CogAgent needs to be evaluated accurately and co- mprehensively. However, existing evaluation met- rics for dialog systems (e.g., BLEU [80], METEOR [81], ROUGE-L [82]) are usually evaluated at the level of word similarity or semantic similarity be- tween generated responses and ground truth, with- out taking into account the effectiveness of persua- sive strategies, the rationality of persuasive path planning, and the richness of argument structure. It is a challenge to develop comprehensive and rea- sonable evaluation metrics to accurately evaluate the quality of CogAgent, incorporating the charac- teristics of persuasive dialog systems. 3.2 Persuasion Strategy-based CogAgent Incorporating persuasion strategies to enhance the persuasiveness of dialog responses is an important research direction in CogAgent. By using specific persuasive strategies, CogAgent can express the pe- rsuasive content in a way that is more acceptable to the persuadees, thus accomplishing the persua- sive goals more smoothly. As abstract psychologi- cal concepts, how to select appropriate persuasion strategies according to the dialogue context and gui- de the generation of responses is an important re- search question. In this section, we make an inves- tigation of the employment of persuasion strategies in CogAgent, summarized in Table 3. 3.2.1 Strategy Classification based on Dialogue Context A straightforward approach to fusing persuasion strategies in persuasive conversations is to predict a strategy label (e.g., Present of Facts) based on the dialogue context and feed the strategy into the decoder with the dialogue context to generate the dialogue response. For example, Wang et al. [11] propose a per- suasion strategy classifier to predict 10 persuasion strategies based on the dialogue context informa- tion and sentence-level features. The authors also analyze the impact that different people’s backgrou- nds on strategy prediction, laying the groundwork for research on personalized persuasive dialogue agents. He et al. [47] decouple strategy selection and response generation in CogAgent. The dia- logue manager predicts a persuasion strategy ba- sed on the persuasion strategies in dialogue history by a sequence-to-sequence model and the response generator produces a response conditioned on the strategy and dialogue history. 3.2.2 Persuasion Strategy Planning Persuasive dialogue is usually a process that lasts multiple turns, supported by successive strategies [87, 88]. Consequently, strategy planning within a long planning horizon in CogAgent is quite im- portant, rather than predicting a specific strategy based on the dialogue history. Several studies fo- cus on long-term planning of persuasion strategies, making CogAgent more e fficient in reaching per- suasion goals.Mengqi Chen et al. 13 Table 3 Representative works of persuasion strategy-based CogAgent. Solution Work Description Strategy classifying based on dialogue context Wang et al. [11] Proposing a classifier to predict persuasion strategies in dialogue using context and sentence features. He et al. [47] Decoupling strategy selection and response generation in CogAgent for predicting strategy and generating responses based on dialogue history. Persuasion strategy planning Cheng et al. [49] Proposing lookahead heuristics to estimate future user feedback after using the specific strategy. Yu et al. [83] Using Monte Carlo Tree Search for persuasion strategy planning without model training. Graph-based strategy incorporation Joshi et al. [48] Using GNNs to model strategies, dialogue acts, and dependencies in graph structures for response generation. Zhou et al. [84] Modeling both dialogue context semantic and persuasion strategy history with finite state transducers. Knowledge-enhanced strategy modeling Jia et al. [85] Introducing a knowledge-enriched encoder and memory-enhanced strategy module for dynamic emotion and semantic pattern modeling. Chen et al. [35] Designing RAP for dynamic factual and persuasive responses based on knowledge and individual persuasion strategies. Novel integration mechanism Mishra et al. [63] Creating an RL reward function to enhance consistency in politeness strategy, persuasiveness, and emotion acknowledgment in persuasive dialogue. Tu et al. [86] Proposing a novel model MISC, which firstly infers the user’s fine-grained emotional status, and then responds skillfully using a mixture of strategies. For instance, Cheng et al. [49] firstly adopt an A* search algorithm for persuasion strategy plan- ning. When predicting the appropriate strategy in each dialogue turn, look-ahead heuristics are pro- posed to estimate future user feedback after using the specific strategy, thus considering the long-term effect of persuasion strategies. The proposed looka- head method requires abundant annotated data, af- fecting the application to broader persuasive dia- logue scenarios. To overcome this bottleneck, Yu et al. [83] prompts LLMs to perform persuasion strategy planning by simulating future dialogue in- teractions using the Monte Carlo Tree Search (MC- TS) algorithm. This method requires no model trai- ning and can therefore be adapted to any persua- sion scenario. 3.2.3 Graph-based Strategy Incorporation Graph Neural Networks (GNNs) [89–91] can com- bine the benefits of interpretability and expressiv- ity, benefiting from encoding graph-structured data through message propagation. Due to the human brain’s reasoning process to capture semantic as- sociations, graph-based methods have been widely used in various tasks [92,93]. Numerous researche- rs have embarked on exploring the potential of gra- ph-based methods for incorporating persuasion str- ategies in CogAgent. For example, Joshi et al. [48] introduce DIAL- OGRAPH, as shown in Fig 3, a persuasive dialogue system that incorporates persuasion strategies and dialogue acts using GNNs. DIALOGRAPH mod- els persuasion strategies in multi-turn dialogue con- text and their dependencies as graph structures and incorporating strategies into response generation us- ing hierarchical graph pooling-based approaches. Zhou et al. [84] propose to model both dialogue context semantic and persuasion strategy history fi- nite state transducers (FSTs). To model the per- suasion factors affecting the persuasive content of dialogues, Liu et al.[94] present persuasion-factor graph convolutional layers to encode and learn rep- resentations of the persuasion-aware interaction data.14 Front. Comput. Sci., 2024, 0(0): 1–36 Fig. 3 Overview architecture of DIALOGRAPH which models persuasion strategies as graph structure. 3.2.4 Knowledge-enhanced Strategy Modeling As concepts in cognitive psychology, persuasion strategies encompass complex semantic informa- tion and various intricate linguistic features [88, 95]. To comprehensively represent the complex semantics embedded within persuasion strategies, researches investigate combining external knowl- edge to model and mimic the the intricate patterns in strategies. For example, Jiaet al.[85] propose a knowledge- enriched dialogue context encoder to model the dy- namic emotion state and a memory-enhanced strat- egy modeling module to model the semantic pat- terns of persuasion strategies. The same-strategy responses are stored in the memory bank to pro- vide more specific guidance for the strategy- con- strained response generation. Chen et al.[35] de- sign the Response-Agenda Pushing Framework (R- AP) to dynamically produce factual responses bas- ed on knowledge facts and persuasive responses conditioned on individual persuasion strategies. 3.2.5 Novel Integration Mechanisms In addition to the above studies to model and in- tegrate persuasion strategies, researchers propose some novel integration mechanisms to improve the performance of CogAgent, summarized as follows. Combined with RL, Yanget al.[96] propose two variants of ToM-based persuasive dialog agent, wh- ere the explicit version that outputs the opponent type as an intermediate prediction, and an implicit version that models the opponent type as a latent variable. Both models are optimized using rein- forcement learning. Similarly, Mishra et al. [63] design an e fficient reward function in RL to im- prove the politeness-strategy consistency, persua- siveness, and emotional acknowledgement in per- suasive dialogue. To increase the expressed empathy and learn the gradual transition in the long response, Tu [86] in- troduce a MIxed Srategy-aware model (MISC) in- tegrating COMET, a pre-trained generative com- monsense reasoning model, for emotional persua- sive dialogue. The COMET knowledge tuples are adopted to enhance the fine-grained emotional un- derstanding of users. Then MISC formulates per-Mengqi Chen et al. 15 Table 4 Representative works of topic path planning strategy-based CogAgent. Solution Work Description Reinforcement learning based planning Xu et al. [98] Presenting KnowHRL, a three-layer Knowledge-aware hierarchical RL-based model for coherent topic path planning and multi-turn persuasive dialogue responses. Liu et al. [99] Hierarchical RL for conversation topic path planning, using high-level strategies and low-level responses. Lei et al. [100] Introducing four persuasion-related factors in the reward function to achieve persuasive goals efficiently. Graph-based planning Zhong et al. [101] Using commonsense knowledge graphs and GNN to enhance semantic relations between topic keywords, improving keyword-augmented response retrieval. Zou et al. [102] Employing a concept graph for topic planning, utilizing an Insertion Transformer for persuasive response generation based on multi-concept paths. Wang et al. [103] Introducing a Transformer-based network for target-driven topic path planning with knowledge-target mutual attention and set-search decoding. Novel planning mechanism Tang et al. [53] Combining various planning algorithms for robust and smooth topic path planning, incorporating a sampling strategy, flow generator, and global planner. Wang et al. [104] Introducing a consistency-driven dialogue planning approach that utilizes stochastic processes to model the temporal evolution of the conversation path dynamically. suasion strategy as a probability distribution over a strategy codebook to use a mixture of strategies for persuasive response generation. To investigate the potential of LLMs in persua- sive conversations, Zheng et al.[97] first construc- t a large-scale persuasive dialogue dataset in the emotional support domain, leveraging the genera- tive capabilities of LLMs. Then several advanced tuning techniques (fine-tuning, adapter-tuning, Lo- RA-tuning) are employed to to showcase the supe- riority of LLMs in persuasive dialogue generation. 3.3 Topic Path Planning Strategy-based CogAgent In persuasive dialogues, generating engaging re- sponses through effective topic path planning is crit- ical to achieving persuasive targets. Topic path plan- ning strategy is a navigation tool that enhances the coherence of the persuasion process by continu- ously leading users to discuss di fferent points and topics until reaching persuasive targets. This sec- tion deepens into the intricate details of the topic path planning strategy, summarized in Table 4. 3.3.1 Reinforcement Learning-based Planning In the context of topic paths planning strategy, Re- inforcement Learning serves as a dynamic framew- ork for guiding persuasive dialogue systems in a goal-oriented manner. The core of RL is to learn the optimal sequence of actions according to the reward function and is therefore ideally suited for planning coherent topic paths in CogAgent. For example, to achieve coherent topic path plan- ning, Xu et al.[98] introduce a three-layer Knowl- edge aware hierarchical RL-based model (KnowH- RL). The upper layer of KnowHRL plans a high- level topic sequence to track user interests toward persuasive targets. The lower layers are responsi- ble for generating multi-turn persuasive dialogue responses. similarly, Liu et al.[99] propose a hier- archical RL method, GoChat, for topic path plan- ning, as shown in Fig 4. The high-level strategies in GoChat determine sub-goals that guide the conver- sation towards the ultimate target and the low-level strategy generates the corresponding responses to achieve those sub-goals. To plan topic paths from a global perspective, Yanget al.[105] introduce the global planning met- hod integrated with a commonsense knowledge gr-16 Front. Comput. Sci., 2024, 0(0): 1–36 Fig. 4 The overall framework of GoChat with hierarchical reinforcement learning. aph (KG). The key advancement is the introduction of a global RL framework that utilizes topic path planning on KG to guide the local response gener- ation model toward persuasive targets, resulting in more coherent conversations. To achieve persua- sive goals more e ffectively, Lei et al. [100] con- sider four factors (dialogue turn, goal completion difficulty, user satisfaction estimation, and cooper- ative degree) in the reward function. The targets of achieving persuasive targets quickly and maintain- ing the engagingness of users. 3.3.2 Graph-based Planning Knowledge is essential to the cognitive reasoning processes of human beings. We humans usually perform common reason during persuasive conver- sation to enhance the logic and persuasiveness of dialog contents. Therefore, relying on common- sense knowledge graphs for topic path planning can produce more persuasive target-related topic paths for CogAgent, thus reaching persuasive targets mo- re efficiently. Initially, the semantic knowledge relations amo- ng topic keywords are captured to perform next- turn topic prediction during conversation [28,106]. Then the predicted topic keywords are used to re- trieve appropriate candidate responses for persua- sive targets. Furthermore, Zhong et al.[101] intro- duce commonsense knowledge graphs and Graph Neural Networks (GNN) to model the semantic re- lations between topic keywords and enhance the keyword-augmented response retrieval, To plan topic paths more reasonably, Zou et al. [102] introduces a concept graph based on the dia- logue data, where the vertices represent concepts and edges are concept transitions between utter- ances. The topic sequence containing multiple con- cepts is obtained by the multi-concept planning mo- dule and an Insertion Transformer generates a per- suasive response according to the planned topic pat- hs. Wang et al.[107] propose a target-driven plan- ning network (TPNet), which models the topic path planning as a sequence generation task using Trans- former, as shown in Fig 5. A knowledge-target mu- tual attention mechanism and a set-search decod- ing (SSD) strategy are developed to generate topic paths based on the dialogue context. 3.3.3 Novel Planning Mechanism In addition to the above research to plan topic paths in CogAgent, there are some novel planning mech- anisms to be explored, summarized as follows. Combining the strengths of multiple topic plan- ning algorithms, the Tang et al. [53] propose anMengqi Chen et al. 17 Fig. 5 The overview framework of TPNet. EAGLE model for topic path planning. Compris- ing a topic path sampling strategy, topic flow gener- ator, and global planner, EAGLE achieves robust- ness to unseen target topics and smooth transitions. The model demonstrates enhanced global planning ability through its integrated approach, addressing limitations in existing topic-planning conversation models. To ensure the smooth and coherent progression toward persuasive goals across different turns, Wan- g et al. [108] introduce a consistency-driven di- alogue planning approach that utilizes stochastic processes to model the temporal evolution of the conversation path dynamically. Firstly, a latent spa- ce is defined, and Brownian bridge processes are employed to capture the continuity of goal-oriented behavior, allowing for more flexible integration of user feedback into dialogue planning, and explic- itly generating conversation paths. Ultimately, these paths are employed as natural language prompts to guide the generation of persuasive dialogue. 3.4 Argument Structure Prediction Strategy-based CogAgent CogAgent entails an ongoing conversation between a dialogue agent and a user at the cognitive level, where the dialogue agent proactively steers the con- versation. As the conversation progresses, the con- tents presented by the dialogue agent to support its perspectives undergo dynamic transformations. Consequently, the reasonable selection and appli- cation of arguments and evidence play a pivotal role in the persuasiveness of the dialogue. The uti- lization of arguments and evidence is imperative in the process of persuasion. Firstly, employing argu- ments and evidence allows for the gradual decom- position and progressive reasoning of persuasive targets, thereby facilitating a logical and sequential flow of the conversation that enhances the users’ acceptance of viewpoints [109]. Secondly, the pro- vision of factual support elevates the credibility of persuasive discourse, thereby augmenting the per- suasiveness of the conversation. In this section, we provide an investigation of the crucial techniques for argument mining and argument structure pre- diction in CogAgent, as summarized in Table 5.18 Front. Comput. Sci., 2024, 0(0): 1–36 Table 5 Representative works of argument structure prediction strategy-based cogAgent. Solution Work Description Argument mining Khatib et al. [110] Classifying and structurally modeling arguments from online debate portals based on diverse vocabulary, grammar, and metric features. Hua et al. [111] Proposing an argument generation framework with retrieval modules and a sentence-level LSTM for generating viewpoints. Srivastava et al. [112] Using attention-based link prediction and Transformer encoder to model hierarchical causal relationships and discover associations in online argument structures. Niculae et al. [113] Introducing factor graph model for argument mining, concurrently learning fundamental unit types classification and argument relationship prediction. Argument structure prediction Rach et al. [57] Proposing argument search technique using supervised learning-based relation classification to retrieve arguments for debate dialogue system Sakai et al. [71] Introducing an approach to consider the human agreement and disagreement, resulting in a persuasive argument with a hierarchical argumentation structure. Prakken et al. [29] Enhancing argument modeling with a five-layer graph, serving as a knowledge base for a chatbot to identify user focal points and select rebuttal points. Li et al. [114] Using factor graphs to extract online debate features, incorporating them into an LSTM model to predict persuasive arguments. 3.4.1 Argument Mining To integrate the argument structure into CogAgent, it is first necessary to perform argument mining ac- cording to conversation topics. Researchers em- bark on mining argumentative text from dialogues for CogAgent. Debate involves the explicit use of argumenta- tive content for dialogue expression, making it an important source of argument mining. For exam- ple, Khatib et al.[110] utilize online debate portals to acquire both controversial and non-controversial text snippets related to several contentious topics. These snippets are organized in a semi-structured format. Eventually, by employing a diverse set of vocabulary, grammar, and metric feature types, the arguments are classified and structurally modeled. Hua et al. [111] propose a framework for gener- ating arguments to opposing viewpoints. The re- trieval module of this framework comprises Query Formulation, Keyphrase Extraction, and Passage Ranking and Filtering. Subsequently, a sentence- level LSTM is trained to generate a sequence of sentences. In online discussion platforms, people also use argumentative texts to enhance their expressions. For instance, Tran et al.[115] and others [104,116, 117] employ multi-task learning to unearth argu- ments and evidence at both the micro and macro levels, enhancing persuasive power in online dis- cussions. Srivastava et al.[112] employs an attenti- on-based link prediction embedding model to mod- el the hierarchical causal relationships within com- mon argument structures in online discussions. Th- ey then utilize Transformer encoder layers to dis- cover the associations and boundaries between ar- guments. Furthermore, they employ AMPERSAN- D et al. [56] and SMOTE et al. [118] to address data imbalance issues, thereby improving model accuracy. Furthermore, Niculae et al.[113] intro- duce a factor graph model for argument mining, wherein the model concurrently learns the classifi- cation of fundamental unit types and prediction of argument relationships. Furthermore, the parame- ter structures of structured SVM and RNN can en- force structural constraints (e.g., transitivity), while also representing dependencies between adjacent relationships and propositions.Mengqi Chen et al. 19 Fig. 6 The overall framework of the model for predicting which side makes more convincing arguments [114]. 3.4.2 Argument Structure Prediction Dialogue systems of persuasive tasks commonly rely on structured knowledge concerning arguments and their relationships. Numerous researchers have demonstrated that predicting argument structures and integrating them into CogAgent can signifi- cantly enhance topic consistency, content coher- ence, and persuasiveness of persuasive dialogue co- ntents [32, 71, 72]. For example, Rach et al. [57] propose an argu- ment search technique for a debate dialogue sys- tem, which utilizes supervised learning-based re- lation classification to retrieve arguments mapped to a generic tree structure for the dialogue model. Sakai et al.[71] introduce an approach to consider human agreement and disagreement, resulting in a persuasive argument with a hierarchical argumen- tation structure. The dialogue agent selects the next action based on the user’s agreement or disagree- ment and sends the chosen action to the response generation module to generate logically consistent and persuasive dialogue. For more intensive argument modeling, Prakken et al. [29] equip dialogue agents with a five-layer argument graph, consisting of 1288 nodes, with an average of three counterarguments per node. This graph serves as the knowledge base for the pro- posed chatbot, allowing it to dynamically identify and annotate the user’s focal points on the param- eters, enabling the selection of appropriate rebuttal points. Li et al. [114] utilized factor graph mod- els to extract features of argument structures from online debate platforms. These features were then incorporated into an LSTM model to predict the most persuasive arguments, as shown in Fig 6. This study proves that the consideration of argument str- ucture plays a vital role in producing persuasive di- alogue content. 4 Datasets and Evaluation Metrics for CogAgent 4.1 Datasets for CogAgent Massive data is undeniably indispensable for train- ing high-quality CogAgent. To foster advancement in this field, numerous large-scale and high-quality datasets have been released. In this section, we cat- egorize existing datasets by application scenarios, including psychological counseling, debate, price negotiation, persuasion for donation, and product recommendation, summarized as Table 6.20 Front. Comput. Sci., 2024, 0(0): 1–36 Table 6 A review of available datasets for CogAgent. Scenario Dataset Description Psychological counseling ESConv [46] The first dataset for psychological counseling, annotated with persuasive strategies. AUGESC [119] The enhanced dataset from ESConv using LLMs with a broader range of topics. PsyQA [120] A Chinese mental health support dataset featuring annotated persuasive strategies. Debate IAC [121] Argumentative dialog dataset with curated threads, posts, and annotations. Winning Arguments [7] A metadata-rich subset of r/ChangeMyView subreddit conversations includes data on the success of user utterances in persuading the poster. DebateSum [122] A dataset for the competitive formal debate with corresponding argument and extractive summaries. Price negotiation Craigslist- Bargain [47] A human-human dialogue dataset for price negotiation where the buyer and seller are encouraged to reach an agreement to get a better deal. Negotiation- Coach [123] An additional negotiation coach based on CraigslistBargain, which monitors the exchange between two annotators and provides real-time negotiation strategy. Persuasion for donation Persuasion For Good [11] A collection of online conversations where one participant (the persuader) tries to convince the other (the persuadee) to donate to a charity. EPP4G and ETP4G [63] Datasets extending Persuasion For Good by annotating it with the emotion and politeness-strategy labels. FaceAct [124] A dataset extending Persuasion For Good by adding the utterance-level annotations that change the positive and/or the negative face of the participants in a conversation Product recommen- dation TG-ReDial [33] A dataset consisting of dialogues between a seeker and a recommender. DuRecDial [125] A human-to-human Chinese dialog dataset, which contains multiple sequential dialogues for every pair of a recommendation seeker and a recommender. INSPIRED [126] A movie recommendation dataset, consisting of human-human dialogues with an annotation scheme for persuasive strategies. 4.1.1 Datasets for Psychological Counseling Psychological counseling is a typical field of per- suasive dialogue, where CogAgent reduces users’ psychological anxiety and encourages positive emo- tions through the persuasive dialogue process. Re- searchers have released several datasets for psy- chological counseling. ESConv. ESConv6) [46] is a well-designed and rich, e ffective corpora for psychological counsel- ing, consisting of 1,053 dialogue pairs and a to- tal of 31,410 sentences. Each dialogue pair in- cludes information about the initial emotional state of the seeker, the persuasive strategies employed by the supporter during each interaction, and the con- tent of the conversation. The dataset encompasses seven distinct emotional states and eight supportive strategies, with the labeling of these strategies be- ing inspired by Hill’s Helping Skills Theory [88]. 6)https://github.com/thu-coai/ Emotional-Support-Conversation AUGESC. The limitations imposed by crowd- sourcing platforms on data themes and collection methods, along with the substantial regulatory costs, have hindered the extension of downstream dia- logue models to open-domain topics. In response, Zheng et al. augment ESConv to AUGESC7) [119] using LLMs, which comprises 65,000 dialogue ses- sions and a total of 1,738,000 utterances. It sub- stantially expands the scale of ESConv and encom- passes a broader range of topics. PsyQA. PsyQA8) [120] is a Chinese mental heal- th support dataset collected from a Chinese mental health service platform, including 22,000 questions and 56,000 lengthy, well-structured answers. In line with psychological counseling theory, PsyQA annotates some of the answer texts with persuasive strategies and further conducts in-depth analyses of the lexical features and strategic patterns within 7)https://github.com/thu-coai/AugESC 8)https://github.com/thu-coai/PsyQAMengqi Chen et al. 21 counseling responses. 4.1.2 Datasets for Debate Debates are typically persuasive scenarios in which each party of the debate organizes arguments to persuade the other party to accept his or her side’s viewpoints. Existing datasets for debate are listed as follows. Internet Argument Corpus (IAC).IAC9) [121] is a scriptless argumentative dialog dataset, com- prising 390,704 posts extracted from 11,800 dis- cussions on the online debate platform 4forums. com. Within this corpus, a manually curated subset of 2,866 threads and 130,206 posts is formed, cate- gorized based on discussion topics. Extended from IAC, IAC 210) [127] is a corpus for research in po- litical debate on Internet forums, consists of three data sets: 4forums (414K posts), ConvinceMe (65K posts), and a sample from CreateDebate (3K posts). Winning Arguments. To delve deeper into the mechanisms of changing others’ viewpoints in so- cial interactions, Tan et al. [7] introduce the Win- ing Arguments (ChangeMyView) Corpus. Wining ArgumentsCorpus is a metadata-rich subset of con- versations made in the r/ChangeMyview subreddit between 1 Jan 2013 - 7 May 2015, with informa- tion on the delta (success) of a user’s utterance in convincing the poster. There are 34911 Speakers, 293297 Utterances, and 3051 Conversations. DebateSum. DebateSum11) [122] is a dataset for the competitive formal debate, including 187,386 unique pieces of evidence with corresponding ar- gument and extractive summaries. The argument data is collected from the National Speech and De- bate Association over 7 years. 9)https://nlds.soe.ucsc.edu/iac 10)https://nlds.soe.ucsc.edu/iac2 11)https://debate.cards/ 4.1.3 Datasets for Price Negotiation Price negotiation is an everyday persuasive scenario where buyers and sellers reach their desired price through the persuasive dialog process. Datasets for price negotiation are summarized as follows. CraigslistBargain. CraigslistBargain12) [47] is a human-human dialogue dataset for price negoti- ation, which consists of 6682 dialogues, collected using Amazon Mechanical Turk (AMT) in a ne- gotiation setting where two workers were assigned the roles of buyer and seller, respectively. The buyer is additionally given a target price and both parties are encouraged to reach an agreement while each of the workers tries to get a better deal. Negotiation-Coach. Negotiation-Coach13) [123] introduce an additional negotiation coach based on CraigslistBargain, which monitors the exchange be- tween two annotators and provides real-time nego- tiation strategy recommendations to the seller for achieving better deals. 4.1.4 Datasets for Persuasion for Donation Persuasion for donation is very common in life, where the persuader persuades others to donate pro- perty or labor to charities for a public good pur- pose. Datasets for persuasion for donation are listed as follows. Persuasion for Social Good. Persuasion for So- cial Good14) [11] is a collection of online conversa- tions generated by AMT workers, where one par- ticipant (the persuader) tries to convince the other (the persuadee) to donate to a charity. This dataset 12)https://worksheets.codalab.org/worksheets/ 0x453913e76b65495d8b9730d41c7e0a0c/ 13)https://github.com/zhouyiheng11/ Negotiation-Coach 14)https://gitlab.com/ucdavisnlp/ persuasionforgood22 Front. Comput. Sci., 2024, 0(0): 1–36 contains 1017 conversations, along with demograp- hic data and responses to psychological surveys fro- m users. 300 conversations also have per-sentence human annotations of dialogue acts that pertain to the persuasion setting, and sentiment. EPP4G and ETP4G.EPP4G and ETP4G15) [63] extend Persuasion For Good by annotating it with the emotion and politeness-strategy labels. FaceAct. FaceAct16) [124] further extend Per- suasion For Good by adding the utterance-level an- notations that change the positive and /or the neg- ative face of the participants in a conversation. A face act can either raise or attack the positive face or negative face of either the speaker or the listener in the conversation. 4.1.5 Datasets for Product Recommendation Product recommendation intends to induce the rec- ommended person to accept or buy a particular pro- duct through persuasive dialogues. Datasets for product recommendation are listed as follows. TG-ReDial. TG-ReDial17) [33] consists of 10,0- 00 two-party dialogues between a seeker and a rec- ommender in the movie domain. DuRecDial. DuRecDial18) [125] is a human-to- human Chinese dialog dataset (about 10k dialogs, 156k utterances), which contains multiple sequen- tial dialogues for every pair of a recommendation seeker (user) and a recommender (bot). In each di- alogue, the recommender proactively leads a multi- type dialogue to approach recommendation targets and then makes multiple recommendations with ri- ch interaction behavior. 15)https://github.com/Mishrakshitij/PEPDS 16)https://github.com/ShoRit/face-acts 17)https://github.com/RUCAIBox/TG-ReDial 18)https://github.com/PaddlePaddle/Research/ tree/master/NLP/ACL2020-DuRecDial INSPIRED. INSPIRED19) [126] is a movie rec- ommendation dataset, consisting of 1,001 human- human dialogues with an annotation scheme for persuasive strategies based on social science the- ories. 4.2 Evaluation metrics Toward CogAgent The reasonable evaluation of the quality of CogA- gent is a challenging dilemma. Di fferent from the open-domain dialog system, the evaluation of Co- gAgent needs to be performed under di fferent per- suasion scenarios and multifaceted persuasive goal- s. This requires judging the quality of dialogue response while emphasizing the persuasive e ffects in specific persuasive contexts and assessing the adaptability and persuasiveness of the system’s cog- nitive strategies in di fferent domains. Up to now, there is no unified theory on how to effectively eval- uate CogAgent, and researchers predominantly em- ploy two kinds of evaluation methods: automatic evaluation metrics and human evaluation. We sum- marized commonly used automatic evaluation and human evaluation metrics in table 7. Notably, eval- uating CogAgent based on LLMs has also recently received significant attention. 4.2.1 Automatic Evaluation Metrics Automatic evaluation metrics evaluate the perfor- mance of CogAgent by calculating the similarity between the responses generated by CogAgent and ground truths. There are typical categories of auto- matic evaluation metrics: overlap-based methods, embedding-based methods, and learning-based tec- hniques. Overlap-based metrics. Overlap-based meth- ods measure the degree of text overlap between 19)https://github.com/sweetpeach/InspiredMengqi Chen et al. 23 Table 7 Evaluation metrics for CogAgent. Evaluation Method Category Description Metrics Automaticevaluation Overlap- based Measuring the degree of text overlap between generated responses and golden responses BLEU [80], ROUGE [82], METEOR [128], CIDEr [129] Embedding- based Evaluating the semantic similarity of embedding vectors between generated responses and reference ones Greedy Matching [130], Embedding averaging [131], Vector Extreme [132] Learning- based Employing machine learning models to predict the quality scores of generated responses, relying not only on given references ADEM [133] Human evaluation Scoring by human annotators to evaluate the quality of the generated responses with subjective judgment Fluency, Coherence, Contextualization, Emotional expression, Diversity, Persuasiveness generated responses and golden responses, with pa- rticular emphasis on the number of the same n- grams. These methods quantify the similarity of the text, especially the local structural similarity, to measure the quality of generated responses. Clas- sical Overlap-based methods include BLEU [80], ROUGE [82], METEOR [128] and CIDEr [129]. Among these, BLEU evaluates response quality by comparing the harmonic mean of n-gram overlaps between generated responses and the golden ones. BLEU is a straightforward and intuitive metric, yet it is constrained by surface features and may ex- hibit a weak capture of semantic relevance. ROUG- E calculates the length of the longest common sub- sequences between generated and golden responses and considers the precision and recall to evaluate the quality. METEOR integrates multiple aspects of information, including precision, recall, and syn- tactic structure, providing a more comprehensive evaluation. CIDEr evaluates the semantic similar- ity between generated responses and ground truths using n-gram level cosine similarity. These metrics have been widely applied in the evaluation of open- domain dialog systems, but they focus mainly on surface features of the response and may not cap- ture semantic relevance. In addition, relying solely on n-gram overlap to measure similarity may not always accurately evaluate the quality of long texts. Embedding-based metrics. Embedding-based metrics evaluate the semantic similarity of embed- ding vectors between generated responses and ref- erence ones. These methods utilize pre-trained wo- rd embedding models (e.g., BERT [134]) to map textual responses into embedding vectors, thus cap- turing the semantic relationships between the texts more accurately. Specifically, Greedy Matching [130] computes the cosine similarity of word em- beddings between each word in generated response and golden ones. Embedding averaging [131] av- erages all words in the sentence to calculate the sentence-level similarity. Vector Extrema [132] takes the most extreme value in the embedding vec- tor to represent the response to be evaluated. In essence, embedding-based metrics emphasize the semantic quality of CogAgent more than overlap- based metrics and better capture the semantic cor- relations between generated responses and refer- ences. Learning-based metrics. Learning-based met- rics employ machine learning models to predict the quality scores of generated responses, relying not only on given references but aiming to better cor- relate with human judgment. ADEM [133] is a deep model-based evaluation metric for dialogue systems. A hierarchical RNN model is trained in a semi-supervised manner to capture semantic infor- mation and contextual associations and align with the human preferences for dialogue responses.24 Front. Comput. Sci., 2024, 0(0): 1–36 In summary, automatic evaluation metrics o ffer advantages in terms of e fficiency and consistency. However, they face challenges in terms of semantic understanding, manual annotation costs, and model complexity. When selecting and applying automat- ed evaluation metrics, it is important to balance their advantages and disadvantages according to sp- ecific persuasive tasks and scenarios. 4.2.2 Human Evaluation Human evaluation involves subjective judgment an- d scoring by human annotators to evaluate the qual- ity of the generated responses. The annotators are usually domain experts and crowd workers who sub- jectively evaluate the generated responses based on specified criteria and task requirements. Compared to automatic evaluation metrics, human evaluation captures the subjectivity, emotion, and use of per- suasive strategies expressed by CogAgent. There- fore, the flexibility and highly customizable nature of human evaluation becomes a reliable means to ensure that the quality of CogAgent is robustly eval- uated. The human evaluation mainly evaluates CogA- gent in the following main aspects: fluency, coher- ence, contextualization, emotional expression, di- versity, and persuasiveness. In summary, human evaluation has advantages in terms of insightful and accurate evaluation of the quality of CogAgent. Ho- wever, it also has limitations in terms of cost and efficiency, due to the requirement of human labor and time resources. Therefore, in practical applica- tions, researchers need to strike a balance between human and automatic evaluation and choose the evaluation metrics that best suit the task require- ments. 5 Open Issues and Future Trends Though researchers have made considerable efforts to address the above challenges in CogAgent, there are still open issues to be resolved. In this section, we present some open issues and future develop- ment trends for CogAgent to promote the advance- ment of the research community. 5.1 Comprehensive Modeling of Cognitive Psy- chology Theory for CogAgent Although we have summarized some of the cogni- tive psychology theories, a comprehensive investi- gation of the cognitive mechanisms of persuasive dialogues from a cognitive psychology perspective is essential for understanding users’ cognitive weak- nesses and generating engaging persuasive dialogu- es. Many researchers have demonstrated the in- dispensability of employing specific strategies to achieve persuasive effects based on different cogni- tive psychology theories. Utilizing cognitive strate- gies, CogAgent can avoid cognitive dissonance in users and e fficiently persuade them to accept spe- cific viewpoints [11, 96, 135]. Prakken et al.[136] argue that psychological dissonance occurs when individuals are confronted with multiple conflict- ing cognitions. To alleviate this dissonance, three approaches can be used: changing cognitively rel- evant factors in the environment, introducing new cognitive elements, and changing cognitive elemen- ts in behavior. CogAgent should be aware of cogni- tive dissonance to mitigate the obstacles it creates in the persuasion process. In addition, researchers utilize the dual process theory of persuasion and guide the persuasive process with the Elaboration Likelihood Model (ELM) [27], a theory that fo- cuses on cognitive and affective appeals in persua- sion. Another noteworthy aspect is modeling theMengqi Chen et al. 25 user’s cognition. Proposing agreements or mak- ing concessions promptly facilitates the perception of the user’s cognitive state, enabling CogAgent to adapt to changes in the user’s cognition on time and avoiding the failure of the persuasive process [137]. Besides using data analysis to study the mech- anisms of persuasive dialog, we can also explore this phenomenon from the perspective of the cog- nitive functions of the human brain. Advances in neuroscience have provided valuable methods for studying the cognitive mechanisms of persuasive dialogue. As Poldrack et al.state [138], the use of electroencephalography (EEG), magnetoencephal- ography (MEG), functional magnetic resonance im- aging (fMRI), and other brain-imaging tools can deepen our understanding of how the human brain produces social behavior. Arapakis et al.[139] use brainwave recordings to measure users’ interest in news articles, and the experimental results suggest that frontal asymmetry (FFA) can objectively as- sess users’ receptive preferences for content. Ex- ploring the changes in neural signals in the brain of the persuadee during persuasive conversations to model which persuasive factors are effective in be- ing accepted by users and convincing them to adopt persuasive targets is a promising research direction. 5.2 Model Adaptivity /Generality of CogAgent Equipping CogAgent with cross-domain understan- ding and generation capabilities is a promising re- search direction. Existing CogAgent usually fo- cuses on one specific persuasion scenario, such as persuasion for social good, bargaining, and debat- ing. However, it is crucial to develop the ability of CogAgent to understand and transfer through mul- tiple domains, which enables CogAgent to dynam- ically optimize cognitive strategies based on differ- ent persuasive targets and e fficiently perform per- suasive tasks. For example, Wolfet al.[140] utilize transfer learning to jointly fine-tune multiple unsu- pervised response prediction tasks. They demon- strate the e ffectiveness of language model trans- fer learning on the PERSONA-CHAT dataset, es- pecially on the dialogue response generation task. Qian et al.[141] propose a meta-learning-based ap- proach to domain adaptive dialogue generation that learns from multiple resource-rich tasks. They uti- lize multiple resource-rich single-domain dialog dat- asets to train the dialogue system so that it can adapt to new domains with minimal training sam- ples. Therefore, improving the transferability of CogAgent across di fferent domains using transfer learning and other advanced approaches is an im- portant step towards the universal CogAgent. 5.3 Multi-party CogAgent Existing research of CogAgent has demonstrated remarkable performance in two-party conversation- al scenarios. However, in real world, multi-party conversations (MPCs) are more prevalent and re- quire CogAgent to persuade multiple participants simultaneously. Unlike existing persuasive dialog systems, multi-party dialogue scenarios require the collaboration of multiple CogAgent to e fficiently achieve persuasion targets [142–144]. Specifically, a single CogAgent is prone to be overly purpose- ful when interacting with users, which can cause the users’ resentment and resistance and hinder the realization of persuasion targets. In contrast, mul- tiple CogAgents can assume di fferent persuasive roles, cooperate, and persuade from di fferent per- spectives, thus winning users’ trust and realizing persuasion targets more effectively. Existing stud- ies have explored MPCs in open-domain dialogue systems. For instance, Ito et al. [145] construct a multi-modal and multi-party model based on GRU26 Front. Comput. Sci., 2024, 0(0): 1–36 to predict the persuasiveness of multiple members within a group during multi-party conversations, thereby providing a model paradigm for the study of multi-party dialogues. Gu et al.[146] propose a Speaker-Aware BERT (SABERT) model to select appropriate speaking targets from multiple users based on dialogue contexts. Gu et al. [147] ex- plore the problem of ”who says what to whom” in MPCs and propose a plug-and-play graphically- induced fine-tuning (GIFT) module for tuning a va- riety of PLMs for generalized multi-party conver- sation understanding. Inspired by multi-party dia- logue research, it is promising to utilize multiple CogAgents to collaborate on persuasive tasks to enhance the credibility and efficiency of the persua- sion process. Multiple CogAgents utilize persua- sive roles with complementary capabilities, strate- gies, and trust-building to enhance persuasion and effectiveness, thereby facilitating more persuasive and successful persuasion results. 5.4 Interpretability of Persuasive Process Interpretability of models can improve their credi- bility. Improving the interpretability of the persua- sion process is essential to ensure that persuasive dialogue contents produced by CogAgent are ac- cepted and adopted. In recent years, the field of Natural Language Processing (NLP) has increas- ingly focused on improving the interpretability of deep models [148, 149]. For example, Gaur et al. [150] argue that domain-specific knowledge helps to understand how deep models work. They demon- strate the utility of incorporating knowledge-infuse- d learning in knowledge graph format into complex neural networks to achieve model interpretability. Similarly, Yasunagaet al.[151] demonstrate model interpretability and structure inference by combin- ing a pre-trained language model a knowledge grap- h, and a quality assurance context into a unified graph. Currently, research on the interpretability of the persuasion process still lacks an overall frame- work. For the interpretability of the persuasion pro- cess, the e ffectiveness of the persuasion strategy can be verified from the cognitive theory, combined with the knowledge graph reasoning, and the per- suasion behavior can be analyzed interactively. 5.5 Multimodal CogAgent Multimodal perception and comprehension capa- bilities are essential for human beings in daily con- versations. By understanding the multimodal sur- roundings around them, including visual, textual, auditory, and other modal information, we humans can produce engaging dialogues to communicate messages, emotions, and attitudes with others [152, 153]. Despite the outstanding natural language un- derstanding and generation capabilities, perceiving and understanding multimodal context information is essential for natural and harmonious human-mac- hine conversation systems [154, 155]. To persuade people to change their thoughts, opinions, or at- titudes, it is crucial to understand the multimodal surroundings of users. Different environments may lead users to develop different attitudes towards thi- ngs. Combining multimodal contextual informa- tion, persuasive dialogue systems can comprehen- sively understand users’ mental states to generate more specific persuasive dialogue content. There has been extensive research on multimodal dialogue systems that enable the understanding of image or video content through dialogue [156–158]. For ex- ample, Murahari et al. adapt ViLBERT [159] to achieve multi-turn image-based dialogue, which un- derstands the image information through image-text pre-trained on multimodal datasets. Visual Chat- GPT [158] integrates ChatGPT with visual foun-Mengqi Chen et al. 27 dation models to achieve visual dialogue. Different kinds of visual information, such as images, depth images, and mask matrices, are converted into lan- guage formats based on visual foundation models and the prompt manager. Then ChatGPT takes the information from visual and textual modalities to generate dialogue responses. These e fforts have laid a solid foundation for multimodal persuasive dialogue systems. The integration of multimodal information to generate more persuasive conversa- tional content is a highly promising research direc- tion. 5.6 Data and Model Co-Optimization for CogA- gent The huge impact of LLMs (e.g., ChatGPT) in the field of dialog systems has sparked the enthusiasm of researchers and has been widely used in many domains [160–162]. For example, Lianget al.[161] rewrite the policy code for controlling a robot us- ing LLMs. The policy code can receive and un- derstand commands and then outputs the execution code to the API to achieve coherent control of the robot’s actions through the classical chain logic. Similarly, Wen et al.[162] combine the common- sense knowledge implicit in LLMs with the domai- n-specific knowledge of mobile applications to re- alize hands-free speech-based interaction between users and smartphones. LLM can be surprisingly useful in a variety of domains. To develop a high- quality CogAgent, we can utilize LLMs to gener- ate large-scale persuasive dialogue data to quickly validate the algorithm at an early stage. Since the capability of LLMs stems from massive amounts of data, retraining this data is hugely expensive. Therefore, the persuasion process also needs to be modeled to e fficiently and accurately perform the persuasion task. The combination of data-driven LLMs and model-driven persuasion process is the most efficient way to develop intelligent CogAgent. Future research directions for combining LLMs and model-driven persuasion processes include issues such as when to employ the generation abilities of LLMs, when model constraints are needed, and the rules and timing of collaboration between LLMs and the persuasion process. 5.7 Construction of standardized datasets and be- nchmarks Despite the significant progress researchers have made in CogAgent, datasets, and benchmarks for the study of CogAgent are still scarce. The rel- atively small size of many existing datasets (e.g., Persuasion for good [11]) limits the performance of the model in a wider range of applications. The limited amount of data hinders the ability to cap- ture the full complexity and diversity of persuasive dialogue. Moreover, the lack of detailed annota- tions about cognitive strategies in existing datasets creates challenges for training persuasive dialogue agents. Building large-scale, high-quality datasets of persuasive dialogues with rich cognitive strategy annotations is indispensable for the development of CogAgent. Combining the superior text genera- tion capabilities of LLMs [163, 164] is a potential way to build large-scale and high-quality datasets for CogAgent. 6 Conclusion Persuasion is an essential ability in human social communication, and people often skillfully persua- de others to accept their standpoints, views, or per- spectives for various purposes. Consequently, per- suasive dialogue systems have become an engaging research direction. In this paper, we have made a systematic survey of CogAgent. We first present28 Front. Comput. Sci., 2024, 0(0): 1–36 some representative cognitive psychology theories to guide the design of CogAgent at the principle level and formalize the necessary cognitive strate- gies for generating highly persuasive dialogue con- tents, including the persuasion strategy, the topic path planning strategy, and the argument structure prediction strategy. Based on the formalized def- inition and generic architecture of CogAgent, we comprehensively investigate representative works by categorizing cognitive strategies. The available datasets and evaluation metrics for CogAgent are also summarized. Despite significant progress, the research of CogAgent is still in the early stage and massive open issues and prospective future trends to be explored, such as model adaptivity/generality of CogAgent, multi-party CogAgent, and multimo- dal CogAgent. Acknowledgements This work was partially supported by the National Science Fund for Distinguished Young Schol- ars(62025205), and the National Natural Science Foundation of China (No. 62032020). References 1. Guo B, Wang H, Ding Y , Wu W, Hao S, Sun Y , Yu Z. Conditional text generation for harmonious human- machine interaction. ACM Transactions on Intelligent Systems and Technology (TIST), 2021, 12(2): 1–50 2. Huang M, Zhu X, Gao J. Challenges in building in- telligent open-domain dialog systems. ACM Trans- actions on Information Systems (TOIS), 2020, 38(3): 1–32 3. Petty R E, Cacioppo J T, Petty R E, Cacioppo J T. The elaboration likelihood model of persuasion. Springer, 1986 4. Fogg B J. Persuasive technology: using computers to change what we think and do. Ubiquity, 2002, 2002(December): 2 5. IJsselsteijn W, De Kort Y , Midden C, Eggen B, Van Den Hoven E. Persuasive technology for human well- being: setting the scene. In: Persuasive Technology: First International Conference on Persuasive Tech- nology for Human Well-Being, PERSUASIVE 2006, Eindhoven, The Netherlands, May 18-19, 2006. Pro- ceedings 1. 2006, 1–5 6. Fogg B J. Mass interpersonal persuasion: An early view of a new phenomenon. In: Persuasive Technol- ogy: Third International Conference, PERSUASIVE 2008, Oulu, Finland, June 4-6, 2008. Proceedings 3. 2008, 23–34 7. Tan C, Niculae V , Danescu-Niculescu-Mizil C, Lee L. Winning arguments: Interaction dynamics and persua- sion strategies in good-faith online discussions. In: Proceedings of the 25th international conference on world wide web. 2016, 613–624 8. Hidey C, Musi E, Hwang A, Muresan S, McKeown K. Analyzing the semantic types of claims and premises in an online persuasive forum. In: Proceedings of the 4th Workshop on Argument Mining. 2017, 11–21 9. Torning K, Oinas-Kukkonen H. Persuasive system de- sign: state of the art and future directions. In: Proceed- ings of the 4th international conference on persuasive technology. 2009, 1–8 10. Eagly A H, Chaiken S. Cognitive theories of persua- sion. In: Advances in experimental social psychology, volume 17, 267–359. Elsevier, 1984 11. Wang X, Shi W, Kim R, Oh Y , Yang S, Zhang J, Yu Z. Persuasion for good: Towards a personalized persua- sive dialogue system for social good. In: Proceed- ings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019, 5635–5649 12. Shi W, Wang X, Oh Y J, Zhang J, Sahay S, Yu Z. Ef- fects of persuasive dialogues: testing bot identities and inquiry strategies. In: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 2020, 1–13 13. Joshi R, Balachandran V , Vashishth S, Black A, Tsvetkov Y . Dialograph: Incorporating interpretable strategy-graph networks into negotiation dialogues. In: International Conference on Learning Represen- tations (ICLR). 2021 14. Min B, Ross H, Sulem E, Veyseh A P B, Nguyen T H, Sainz O, Agirre E, Heintz I, Roth D. Recent advances in natural language processing via large pre-trained language models: A survey. ACM Computing Sur- veys, 2021 15. Zhao W X, Zhou K, Li J, Tang T, Wang X, Hou Y , Min Y , Zhang B, Zhang J, Dong Z, others . A survey of large language models. arXiv preprint arXiv:2303.18223, 2023 16. Touvron H, Martin L, Stone K, Albert P, Almahairi A, Babaei Y , Bashlykov N, Batra S, Bhargava P, Bhosale S, others . Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023 17. Bai Y , Kadavath S, Kundu S, Askell A, Kernion J, Jones A, Chen A, Goldie A, Mirhoseini A, McKin-Mengqi Chen et al. 29 non C, others . Constitutional ai: Harmlessness from ai feedback. arXiv preprint arXiv:2212.08073, 2022 18. Zhou C, Li Q, Li C, Yu J, Liu Y , Wang G, Zhang K, Ji C, Yan Q, He L, others . A comprehensive survey on pretrained foundation models: A history from bert to chatgpt. arXiv preprint arXiv:2302.09419, 2023 19. Ray P P. Chatgpt: A comprehensive review on back- ground, applications, key challenges, bias, ethics, lim- itations and future scope. Internet of Things and Cyber-Physical Systems, 2023 20. Li J, Han D, Guo Z, Qiao B, Wu G. Generating empathetic responses through emotion tracking and constraint guidance. Frontiers of Computer Science, 2024, 18(2) 21. Wang W, Feng S, Song K, Wang D, Li S. Infor- mative and diverse emotional conversation generation with variational recurrent pointer-generator. Frontiers of Computer Science, 2022, 16: 1–3 22. Vaithilingam P, Zhang T, Glassman E L. Expectation vs. experience: Evaluating the usability of code gen- eration tools powered by large language models. In: Chi conference on human factors in computing sys- tems extended abstracts. 2022, 1–7 23. Ni A, Iyer S, Radev D, Stoyanov V , Yih W t, Wang S, Lin X V . Lever: Learning to verify language-to-code generation with execution. In: International Confer- ence on Machine Learning. 2023, 26106–26128 24. Yuan A, Coenen A, Reif E, Ippolito D. Wordcraft: story writing with large language models. In: 27th In- ternational Conference on Intelligent User Interfaces. 2022, 841–852 25. Dergaa I, Chamari K, Zmijewski P, Saad H B. From human writing to artificial intelligence generated text: examining the prospects and potential threats of chat- gpt in academic writing. Biology of Sport, 2023, 40(2): 615–622 26. Bless H, Bohner G, Schwarz N, Strack F. Mood and persuasion: A cognitive response analysis. Personality and social psychology bulletin, 1990, 16(2): 331–345 27. Petty R E, Bri ˜nol P. Emotion and persuasion: Cog- nitive and meta-cognitive processes impact attitudes. Cognition and Emotion, 2015, 29(1): 1–26 28. Qin J, Ye Z, Tang J, Liang X. Dynamic knowledge routing network for target-guided open-domain con- versation. In: Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 8657–8664 29. Prakken H, others . A persuasive chatbot using a crowd-sourced argument graph and concerns. Com- putational Models of Argument, 2020, 326: 9 30. Dijkstra A. The psychology of tailoring-ingredients in computer-tailored persuasion. Social and personality psychology compass, 2008, 2(2): 765–784 31. Kolenik T, Gams M. Intelligent cognitive assistants for attitude and behavior change support in mental health: state-of-the-art technical review. Electronics, 2021, 10(11): 1250 32. Slonim N, Bilu Y , Alzate C, Bar-Haim R, Bogin B, Bonin F, Choshen L, Cohen-Karlik E, Dankin L, Edel- stein L, others . An autonomous debating system. Na- ture, 2021, 591(7850): 379–384 33. Zhou K, Zhou Y , Zhao W X, Wang X, Wen J R. To- wards topic-guided conversational recommender sys- tem. In: Proceedings of the 28th International Confer- ence on Computational Linguistics. 2020, 4128–4139 34. Kang D, Balakrishnan A, Shah P, Crook P, Boureau Y L, Weston J. Recommendation as a communica- tion game: Self-supervised bot-play for goal-oriented dialogue. In: 2019 Conference on Empirical Meth- ods in Natural Language Processing and 9th Interna- tional Joint Conference on Natural Language Process- ing, EMNLP-IJCNLP 2019. 2020, 1951–1961 35. Chen M, Shi W, Yan F, Hou R, Zhang J, Sahay S, Yu Z. Seamlessly integrating factual information and social content with persuasive dialogue. In: Proceed- ings of the 2nd Conference of the Asia-Pacific Chap- ter of the Association for Computational Linguistics and the 12th International Joint Conference on Natu- ral Language Processing. 2022, 399–413 36. Duerr S, Gloor P A. Persuasive natural lan- guage generation–a literature review. arXiv preprint arXiv:2101.05786, 2021 37. Zhan H, Wang Y , Feng T, Hua Y , Sharma S, Li Z, Qu L, Ha ffari G. Let’s negotiate! a sur- vey of negotiation dialogue systems. arXiv preprint arXiv:2212.09072, 2022 38. Deng Y , Lei W, Lam W, Chua T S. A survey on proactive dialogue systems: Problems, methods, and prospects. arXiv preprint arXiv:2305.02750, 2023 39. Cialdini R. Pre-suasion: A revolutionary way to influ- ence and persuade. Simon and Schuster, 2016 40. Bilu Y , Gera A, Hershcovich D, Sznajder B, Lahav D, Moshkowich G, Malet A, Gavron A, Slonim N. Ar- gument invention from first principles. In: Proceed- ings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019, 1013–1026 41. Premack D, Woodru ff G. Does the chimpanzee have a theory of mind? Behavioral and brain sciences, 1978, 1(4): 515–526 42. Wu J, Chen Z, Deng J, Sabour S, Huang M. Coke: A cognitive knowledge graph for machine theory of mind. arXiv preprint arXiv:2305.05390, 2023 43. Sap M, Le Bras R, Fried D, Choi Y . Neural theory-of-30 Front. Comput. Sci., 2024, 0(0): 1–36 mind? on the limits of social intelligence in large lms. In: Proceedings of the 2022 Conference on Empiri- cal Methods in Natural Language Processing. 2022, 3762–3780 44. Roman H R, Bisk Y , Thomason J, Celikyilmaz A, Gao J. Rmm: A recursive mental model for dialogue navi- gation. In: Findings of the Association for Computa- tional Linguistics: EMNLP 2020. 2020, 1732–1745 45. Campbell G. The philosophy of rhetoric. SIU Press, 1988 46. Liu S, Zheng C, Demasi O, Sabour S, Li Y , Yu Z, Jiang Y , Huang M. Towards emotional support dialog sys- tems. In: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Lan- guage Processing (V olume 1: Long Papers). 2021, 3469–3483 47. He H, Chen D, Balakrishnan A, Liang P. Decou- pling strategy and generation in negotiation dialogues. In: 2018 Conference on Empirical Methods in Natu- ral Language Processing, EMNLP 2018. 2018, 2333– 2343 48. Joshi R, Balachandran V , Vashishth S, Black A, Tsvetkov Y . Dialograph: Incorporating interpretable strategy-graph networks into negotiation dialogues. In: International Conference on Learning Represen- tations. 2020 49. Cheng Y , Liu W, Li W, Wang J, Zhao R, Liu B, Liang X, Zheng Y . Improving multi-turn emotional support dialogue generation with lookahead strategy planning. In: Proceedings of the 2022 Conference on Empiri- cal Methods in Natural Language Processing. 2022, 3014–3026 50. Cacioppo J T, Petty R E. E ffects of message repetition and position on cognitive response, recall, and persua- sion. Journal of personality and Social Psychology, 1979, 37(1): 97 51. Cialdini R B, Cialdini R B. Influence: The psychology of persuasion. volume 55. Collins New York, 2007 52. Ni J, Pandelea V , Young T, Zhou H, Cambria E. Hitkg: Towards goal-oriented conversations via multi- hierarchy learning. In: Proceedings of the AAAI con- ference on artificial intelligence. 2022, 11112–11120 53. Tang Z H, Yeh M Y . Eagle: Enhance target-oriented dialogs by global planning and topic flow integration. In: Proceedings of the 32nd ACM International Con- ference on Information and Knowledge Management. 2023, 2402–2411 54. Petty R E, Cacioppo J T. Communication and persua- sion: Central and peripheral routes to attitude change. Springer Science & Business Media, 2012 55. Swanson R, Ecker B, Walker M. Argument mining: Extracting arguments from online dialogue. In: Pro- ceedings of the 16th annual meeting of the special in- terest group on discourse and dialogue. 2015, 217–226 56. Chakrabarty T, Hidey C, Muresan S, Mckeown K, Hwang A. Ampersand: Argument mining for persua- sive online discussions. In: Proceedings of the 2019 Conference on Empirical Methods in Natural Lan- guage Processing and the 9th International Joint Con- ference on Natural Language Processing (EMNLP- IJCNLP). 2019, 2933–2943 57. Rach N, Schindler C, Feustel I, Daxenberger J, Minker W, Ultes S. From argument search to argumentative dialogue: A topic-independent approach to argument acquisition for dialogue systems. In: Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue. 2021, 368–379 58. Wambsganss T, Kueng T, Soellner M, Leimeister J M. Arguetutor: An adaptive dialog-based learning system for argumentation skills. In: Proceedings of the 2021 CHI conference on human factors in computing sys- tems. 2021, 1–13 59. Ni J, Young T, Pandelea V , Xue F, Cambria E. Recent advances in deep learning based dialogue systems: A systematic survey. Artificial intelligence review, 2023, 56(4): 3055–3155 60. Bubeck S, Chandrasekaran V , Eldan R, Gehrke J, Horvitz E, Kamar E, Lee P, Lee Y T, Li Y , Lund- berg S, others . Sparks of artificial general intelli- gence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023 61. Hochreiter S, Schmidhuber J. Long short-term mem- ory. Neural computation, 1997, 9(8): 1735–1780 62. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A N, Kaiser Ł, Polosukhin I. Attention is all you need. Advances in neural information processing systems, 2017, 30 63. Mishra K, Samad A M, Totala P, Ekbal A. Pepds: A polite and empathetic persuasive dialogue system for charity donation. In: Proceedings of the 29th In- ternational Conference on Computational Linguistics. 2022, 424–440 64. Walker E R, McGee R E, Druss B G. Mortality in mental disorders and global disease burden implica- tions: a systematic review and meta-analysis. JAMA psychiatry, 2015, 72(4): 334–341 65. Xu B, Zhuang Z. Survey on psychotherapy chatbots. Concurrency and Computation: Practice and Experi- ence, 2022, 34(7): e6170 66. Liang Y , Liu L, Ji Y , Huangfu L, Zeng D D. Identify- ing emotional causes of mental disorders from socialMengqi Chen et al. 31 media for effective intervention. Information Process- ing & Management, 2023, 60(4): 103407 67. Zhou J, Zheng C, Wang B, Zhang Z, Huang M. Case: Aligning coarse-to-fine cognition and a ffection for empathetic response generation. arXiv preprint arXiv:2208.08845, 2022 68. Bosselut A, Rashkin H, Sap M, Malaviya C, Celikyil- maz A, Choi Y . Comet: Commonsense transformers for automatic knowledge graph construction. In: Pro- ceedings of the 57th Annual Meeting of the Associa- tion for Computational Linguistics. 2019 69. Speer R, Chin J, Havasi C. Conceptnet 5.5: An open multilingual graph of general knowledge. In: Proceed- ings of the AAAI conference on artificial intelligence. 2017 70. Nortio E, Jasinskaja-Lahti I, H ¨am¨al¨ainen M, Pakkasvirta J. Fear of the russian bear? negoti- ating finnish national identity online. Nations and Nationalism, 2022, 28(3): 861–876 71. Sakai K, Higashinaka R, Yoshikawa Y , Ishiguro H, Tomita J. Hierarchical argumentation structure for persuasive argumentative dialogue generation. IE- ICE TRANSACTIONS on Information and Systems, 2020, 103(2): 424–434 72. Rach N, Minker W, Ultes S. Increasing the natural- ness of an argumentative dialogue system through ar- gument chains. In: Computational Models of Argu- ment, 331–338. IOS Press, 2020 73. Gupta P, Jhamtani H, Bigham J P. Target-guided di- alogue response generation using commonsense and data augmentation. In: Findings of the Association for Computational Linguistics: NAACL 2022. 2022, 1301–1317 74. Mondal P. A unifying perspective on perception and cognition through linguistic representations of emo- tion. Frontiers in Psychology, 2022, 13: 768170 75. Shettleworth S J. Cognition, evolution, and behavior. Oxford university press, 2009 76. Nguyen H, Mastho ff J. Designing persuasive dialogue systems: Using argumentation with care. In: Per- suasive Technology: Third International Conference, PERSUASIVE 2008, Oulu, Finland, June 4-6, 2008. Proceedings 3. 2008, 201–212 77. Orji R. Why are persuasive strategies e ffective? exploring the strengths and weaknesses of socially- oriented persuasive strategies. In: Persuasive Technol- ogy: Development and Implementation of Personal- ized Technologies to Change Attitudes and Behaviors: 12th International Conference, PERSUASIVE 2017, Amsterdam, The Netherlands, April 4–6, 2017, Pro- ceedings 12. 2017, 253–266 78. Ham J, Bokhorst R, Cuijpers R, Van Der Pol D, Cabibihan J J. Making robots persuasive: the influence of combining persuasive strategies (gazing and ges- tures) by a storytelling robot on its persuasive power. In: Social Robotics: Third International Conference, ICSR 2011, Amsterdam, The Netherlands, November 24-25, 2011. Proceedings 3. 2011, 71–83 79. Samad A M, Mishra K, Firdaus M, Ekbal A. Em- pathetic persuasion: reinforcing empathy and persua- siveness in dialogue systems. In: Findings of the Association for Computational Linguistics: NAACL 2022. 2022, 844–856 80. Papineni K, Roukos S, Ward T, Zhu W J. Bleu: a method for automatic evaluation of machine transla- tion. In: Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 2002, 311–318 81. Banerjee S, Lavie A. Meteor: An automatic metric for mt evaluation with improved correlation with hu- man judgments. In: Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for ma- chine translation and/or summarization. 2005, 65–72 82. Lin C Y , Hovy E. Automatic evaluation of summaries using n-gram co-occurrence statistics. In: Proceedings of the 2003 human language technology conference of the North American chapter of the association for computational linguistics. 2003, 150–157 83. Yu X, Chen M, Yu Z. Prompt-based monte-carlo tree search for goal-oriented dialogue policy planning. arXiv preprint arXiv:2305.13660, 2023 84. Zhou Y , Tsvetkov Y , Black A W, Yu Z. Augmenting non-collaborative dialog systems with explicit seman- tic and strategic dialog history. In: International Con- ference on Learning Representations. 2019 85. Jia M, Chen Q, Jing L, Fu D, Li R. Knowledge- enhanced memory model for emotional support con- versation. arXiv preprint arXiv:2310.07700, 2023 86. Tu Q, Li Y , Cui J, Wang B, Wen J R, Yan R. Misc: A mixed strategy-aware model integrating comet for emotional support conversation. In: Proceedings of the 60th Annual Meeting of the Association for Com- putational Linguistics (V olume 1: Long Papers). 2022, 308–319 87. Greene J O, Burleson B R. Handbook of communi- cation and social interaction skills. Psychology Press, 2003 88. Hill C E. Helping skills: Facilitating, exploration, in- sight, and action. American Psychological Associa- tion, 2009 89. Kipf T N, Welling M. Semi-supervised classification with graph convolutional networks. In: International32 Front. Comput. Sci., 2024, 0(0): 1–36 Conference on Learning Representations. 2016 90. Veli ˇckovi´c P, Cucurull G, Casanova A, Romero A, Li`o P, Bengio Y . Graph attention networks. In: Interna- tional Conference on Learning Representations. 2018 91. Wu Z, Pan S, Chen F, Long G, Zhang C, Philip S Y . A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 2020, 32(1): 4–24 92. Wu L, Chen Y , Shen K, Guo X, Gao H, Li S, Pei J, Long B, others . Graph neural networks for natu- ral language processing: A survey. Foundations and Trends® in Machine Learning, 2023, 16(2): 119–328 93. Wang H, Guo B, Liu J, Ding Y , Yu Z. Towards infor- mative and diverse dialogue systems over hierarchi- cal crowd intelligence knowledge graph. ACM Trans- actions on Knowledge Discovery from Data, 2023, 17(7): 1–25 94. Liu C, Gao C, Yuan Y , Bai C, Luo L, Du X, Shi X, Luo H, Jin D, Li Y . Modeling persuasion factor of user decision for recommendation. In: Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022, 3366–3376 95. Zheng C, Liu Y , Chen W, Leng Y , Huang M. Comae: A multi-factor hierarchical framework for empathetic response generation. In: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. 2021, 813–824 96. Yang R, Chen J, Narasimhan K. Improving dialog sys- tems for negotiation with personality modeling. In: Proceedings of the 59th Annual Meeting of the As- sociation for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (V olume 1: Long Papers). 2021, 681–693 97. Zheng Z, Liao L, Deng Y , Nie L. Building emotional support chatbots in the era of llms. arXiv preprint arXiv:2308.11584, 2023 98. Xu J, Wang H, Niu Z, Wu H, Che W. Knowledge graph grounded goal planning for open-domain conversation generation. In: Proceedings of the AAAI conference on artificial intelligence. 2020, 9338–9345 99. Liu J, Pan F, Luo L. Gochat: Goal-oriented chat- bots with hierarchical reinforcement learning. In: Pro- ceedings of the 43rd International ACM SIGIR Con- ference on Research and Development in Information Retrieval. 2020, 1793–1796 100. Lei W, Zhang Y , Song F, Liang H, Mao J, Lv J, Yang Z, Chua T S. Interacting with non-cooperative user: A new paradigm for proactive dialogue policy. In: Pro- ceedings of the 45th International ACM SIGIR Con- ference on Research and Development in Information Retrieval. 2022, 212–222 101. Zhong P, Liu Y , Wang H, Miao C. Keyword-guided neural conversational model. In: Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 14568–14576 102. Zou Y , Liu Z, Hu X, Zhang Q. Thinking clearly, talk- ing fast: Concept-guided non-autoregressive genera- tion for open-domain dialogue systems. In: Proceed- ings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021, 2215–2226 103. Wang J, Lin D, Li W. Dialogue planning via brownian bridge stochastic process for goal-directed proactive dialogue. arXiv preprint arXiv:2305.05290, 2023 104. Wang S, Yin Z, Zhang W, Zheng D, Li X. Two stage learning for argument pairs extraction. In: Natural Language Processing and Chinese Computing: 10th CCF International Conference, NLPCC 2021, Qing- dao, China, October 13–17, 2021, Proceedings, Part II 10. 2021, 538–547 105. Yang Z, Wang B, Zhou J, Tan Y , Zhao D, Huang K, He R, Hou Y . Topkg: Target-oriented dialog via global planning on knowledge graph. In: Proceedings of the 29th International Conference on Computational Lin- guistics. 2022, 745–755 106. Tang J, Zhao T, Xiong C, Liang X, Xing E, Hu Z. Target-guided open-domain conversation. In: Pro- ceedings of the 57th Annual Meeting of the Associa- tion for Computational Linguistics. 2019, 5624–5634 107. Wang J, Lin D, Li W. A target-driven planning ap- proach for goal-directed dialog systems. IEEE Trans- actions on Neural Networks and Learning Systems, 2023 108. Wang J, Lin D, Li W. Dialogue planning via brownian bridge stochastic process for goal-directed proactive dialogue. 2023 109. Vecchi E M, Falk N, Jundi I, Lapesa G. Towards ar- gument mining for social good: A survey. In: Pro- ceedings of the 59th Annual Meeting of the Associa- tion for Computational Linguistics and the 11th Inter- national Joint Conference on Natural Language Pro- cessing (V olume 1: Long Papers). 2021, 1338–1352 110. Al Khatib K, Wachsmuth H, Hagen M, K ¨ohler J, Stein B. Cross-domain mining of argumentative text through distant supervision. In: Proceedings of the 2016 conference of the north american chapter of the association for computational linguistics: human lan- guage technologies. 2016, 1395–1404 111. Hua X, Hu Z, Wang L. Argument generation with re- trieval, planning, and realization. In: Proceedings of the 57th Annual Meeting of the Association for Com- putational Linguistics. 2019, 2661–2672 112. Srivastava P, Bhatnagar P, Goel A. Argument min-Mengqi Chen et al. 33 ing using bert and self-attention based embeddings. In: 2022 4th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N). 2022, 1536–1540 113. Niculae V , Park J, Cardie C. Argument mining with structured svms and rnns. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (V olume 1: Long Papers). 2017, 985–995 114. Li J, Durmus E, Cardie C. Exploring the role of argu- ment structure in online debate persuasion. In: Pro- ceedings of the 2020 Conference on Empirical Meth- ods in Natural Language Processing (EMNLP). 2020, 8905–8912 115. Tran N, Litman D. Multi-task learning in argument mining for persuasive online discussions. In: Proceed- ings of the 8th Workshop on Argument Mining. 2021, 148–153 116. Cheng L, Bing L, He R, Yu Q, Zhang Y , Si L. Iam: A comprehensive and large-scale dataset for integrated argument mining tasks. In: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (V olume 1: Long Papers). 2022, 2277– 2287 117. Sun J, Zhu Q, Bao J, Wu J, Yang C, Wang R, Xu R. A hierarchical sequence labeling model for argument pair extraction. In: Natural Language Processing and Chinese Computing: 10th CCF International Confer- ence, NLPCC 2021, Qingdao, China, October 13–17, 2021, Proceedings, Part II 10. 2021, 472–483 118. Chawla N V , Bowyer K W, Hall L O, Kegelmeyer W P. Smote: synthetic minority over-sampling tech- nique. Journal of artificial intelligence research, 2002, 16: 321–357 119. Zheng C, Sabour S, Wen J, Zhang Z, Huang M. Augesc: Dialogue augmentation with large language models for emotional support conversation. In: Find- ings of the Association for Computational Linguistics: ACL 2023. 2023, 1552–1568 120. Sun H, Lin Z, Zheng C, Liu S, Huang M. Psyqa: A chinese dataset for generating long counseling text for mental health support. In: Findings of the Asso- ciation for Computational Linguistics: ACL-IJCNLP 2021. 2021, 1489–1503 121. Walker M, Tree J E F, Anand P, Abbott R, King J. A corpus for research on deliberation and debate. In: Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12). 2012, 812–817 122. Roush A, Balaji A. Debatesum: A large-scale argu- ment mining and summarization dataset. In: Proceed- ings of the 7th Workshop on Argument Mining. 2020, 1–7 123. Zhou Y , He H, Black A W, Tsvetkov Y . A dynamic strategy coach for effective negotiation. In: 20th An- nual Meeting of the Special Interest Group on Dis- course and Dialogue. 2019, 367 124. Dutt R, Joshi R, Rose C. Keeping up appearances: Computational modeling of face acts in persuasion oriented discussions. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Lan- guage Processing (EMNLP). 2020, 7473–7485 125. Liu Z, Wang H, Niu Z Y , Wu H, Che W, Liu T. To- wards conversational recommendation over multi-type dialogs. In: Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics. 2020, 1036–1049 126. Hayati S A, Kang D, Zhu Q, Shi W, Yu Z. In- spired: Toward sociable recommendation dialog sys- tems. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020, 8142–8152 127. Abbott R, Ecker B, Anand P, Walker M. Internet ar- gument corpus 2.0: An sql schema for dialogic social media and the corpora to go with it. In: Proceedings of the Tenth International Conference on Language Re- sources and Evaluation (LREC’16). 2016, 4445–4452 128. Lavie A, Agarwal A. Meteor: An automatic metric for mt evaluation with high levels of correlation with hu- man judgments. In: Proceedings of the second work- shop on statistical machine translation. 2007, 228–231 129. Vedantam R, Lawrence Zitnick C, Parikh D. Cider: Consensus-based image description evaluation. In: Proceedings of the IEEE conference on computer vi- sion and pattern recognition. 2015, 4566–4575 130. Rus V , Lintean M. An optimal assessment of natu- ral language student input using word-to-word simi- larity metrics. In: Intelligent Tutoring Systems: 11th International Conference, ITS 2012, Chania, Crete, Greece, June 14-18, 2012. Proceedings 11. 2012, 675– 676 131. Wieting J, Bansal M, Gimpel K, Livescu K. Towards universal paraphrastic sentence embeddings. arXiv preprint arXiv:1511.08198, 2015 132. Forgues G, Pineau J, Larchev ˆeque J M, Tremblay R. Bootstrapping dialog systems with word embeddings. In: Nips, modern machine learning and natural lan- guage processing workshop. 2014, 168 133. Lowe R, Noseworthy M, Serban I V , Angelard-Gontier N, Bengio Y , Pineau J. Towards an automatic turing test: Learning to evaluate dialogue responses. In: Pro- ceedings of the 55th Annual Meeting of the Associa- tion for Computational Linguistics (V olume 1: Long34 Front. Comput. Sci., 2024, 0(0): 1–36 Papers). 2017 134. Devlin J, Chang M W, Lee K, Toutanova K. Bert: Pre-training of deep bidirectional transformers for lan- guage understanding. In: Proceedings of the 2019 Conference of the North American Chapter of the As- sociation for Computational Linguistics: Human Lan- guage Technologies, V olume 1 (Long and Short Pa- pers). 2019, 4171–4186 135. Chen Y , Deng S, Kwak D H, Elnoshokaty A, Wu J. A multi-appeal model of persuasion for online petition success: A linguistic cue-based approach. Journal of the Association for Information Systems, 2019, 20(2): 105–131 136. Jing Wen T, Kim E, Wu L, Dodoo N A. Activating persuasion knowledge in native advertising: the influ- ence of cognitive load and disclosure language. Inter- national Journal of Advertising, 2020, 39(1): 74–93 137. Thimm M. Strategic argumentation in multi-agent sys- tems. KI-K ¨unstliche Intelligenz, 2014, 28: 159–168 138. Poldrack R A, Farah M J. Progress and challenges in probing the human brain. Nature, 2015, 526(7573): 371–379 139. Arapakis I, Barreda-Angeles M, Pereda-Ba ˜nos A. In- terest as a proxy of engagement in news reading: Spectral and entropy analyses of eeg activity patterns. IEEE Transactions on A ffective Computing, 2017, 10(1): 100–114 140. Wolf T, Sanh V , Chaumond J, Delangue C. Trans- fertransfo: A transfer learning approach for neural network based conversational agents. arXiv preprint arXiv:1901.08149, 2019 141. Qian K, Yu Z. Domain adaptive dialog generation via meta learning. In: Proceedings of the 57th Annual Meeting of the Association for Computational Lin- guistics. 2019, 2639–2649 142. Shi Z, Huang M. A deep sequential model for dis- course parsing on multi-party dialogues. In: Pro- ceedings of the AAAI Conference on Artificial Intel- ligence. 2019, 7007–7014 143. Ju D, Feng S, Lv P, Wang D, Zhang Y . Learning to improve persona consistency in multi-party dia- logue generation via text knowledge enhancement. In: Proceedings of the 29th International Conference on Computational Linguistics. 2022, 298–309 144. Yuan L, Chen F, Zhang Z, Yu Y . Communication- robust multi-agent learning by adaptable auxiliary multi-agent adversary generation. Frontiers of Com- puter Science, 2024, 18(6): 186331 145. Ito A, Nakano Y I, Nihei F, Sakato T, Ishii R, Fukayama A, Nakamura T. Predicting persuasive- ness of participants in multiparty conversations. In: 27th International Conference on Intelligent User In- terfaces. 2022, 85–88 146. Gu J C, Li T, Liu Q, Ling Z H, Su Z, Wei S, Zhu X. Speaker-aware bert for multi-turn response selec- tion in retrieval-based chatbots. In: Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2020, 2041–2044 147. Gu J C, Ling Z H, Liu Q, Liu C, Hu G. Gift: Graph- induced fine-tuning for multi-party conversation un- derstanding. arXiv preprint arXiv:2305.09360, 2023 148. Belinkov Y , Gehrmann S, Pavlick E. Interpretability and analysis in neural nlp. In: Proceedings of the 58th annual meeting of the association for computational linguistics: tutorial abstracts. 2020, 1–5 149. Jacovi A, Goldberg Y . Towards faithfully interpretable nlp systems: How should we define and evaluate faith- fulness? In: Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics. 2020, 4198–4205 150. Gaur M, Faldu K, Sheth A. Semantics of the black- box: Can knowledge graphs help make deep learning systems more interpretable and explainable? IEEE Internet Computing, 2021, 25(1): 51–59 151. Yasunaga M, Ren H, Bosselut A, Liang P, Leskovec J. Qa-gnn: Reasoning with language models and knowl- edge graphs for question answering. In: Proceedings of the 2021 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies. 2021, 535–546 152. Quek F, McNeill D, Bryll R, Duncan S, Ma X F, Kir- bas C, McCullough K E, Ansari R. Multimodal human discourse: gesture and speech. ACM Transactions on Computer-Human Interaction (TOCHI), 2002, 9(3): 171–193 153. Turk M. Multimodal interaction: A review. Pattern recognition letters, 2014, 36: 189–195 154. Jaimes A, Sebe N. Multimodal human–computer in- teraction: A survey. Computer vision and image un- derstanding, 2007, 108(1-2): 116–134 155. Baltru ˇsaitis T, Ahuja C, Morency L P. Multimodal ma- chine learning: A survey and taxonomy. IEEE trans- actions on pattern analysis and machine intelligence, 2018, 41(2): 423–443 156. Qi J, Niu Y , Huang J, Zhang H. Two causal principles for improving visual dialog. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pat- tern Recognition. 2020, 10860–10869 157. Alamri H, Cartillier V , Das A, Wang J, Cherian A, Essa I, Batra D, Marks T K, Hori C, Anderson P, oth- ers . Audio visual scene-aware dialog. In: Proceedings of the IEEE/CVF Conference on Computer Vision andMengqi Chen et al. 35 Pattern Recognition. 2019, 7558–7567 158. Wu C, Yin S, Qi W, Wang X, Tang Z, Duan N. Vi- sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671, 2023 159. Lu J, Batra D, Parikh D, Lee S. Vilbert: Pretrain- ing task-agnostic visiolinguistic representations for vision-and-language tasks. Advances in neural infor- mation processing systems, 2019, 32 160. Pal S, Bhattacharya M, Lee S S, Chakraborty C. A domain-specific next-generation large language model (llm) or chatgpt is required for biomedical engineer- ing and research. Annals of Biomedical Engineering, 2023, 1–4 161. Liang J, Huang W, Xia F, Xu P, Hausman K, Ichter B, Florence P, Zeng A. Code as policies: Language model programs for embodied control. In: 2023 IEEE International Conference on Robotics and Automation (ICRA). 2023, 9493–9500 162. Wen H, Li Y , Liu G, Zhao S, Yu T, Li T J J, Jiang S, Liu Y , Zhang Y , Liu Y . Empowering llm to use smart- phone for intelligent task automation. arXiv preprint arXiv:2308.15272, 2023 163. Kim H, Hessel J, Jiang L, Lu X, Yu Y , Zhou P, Bras R L, Alikhani M, Kim G, Sap M, others . Soda: Million-scale dialogue distillation with so- cial commonsense contextualization. arXiv preprint arXiv:2212.10465, 2022 164. Zheng C, Sabour S, Wen J, Huang M. Augesc: Large- scale data augmentation for emotional support con- versation with pre-trained language models. arXiv preprint arXiv:2202.13047, 2022 Mengqi Chen was born in 1997. She received her master’s de- gree in digital textiles from Xi’an Polytechnical University (XPU) in 2022. She is currently working toward a Ph.D. degree at North- western Polytechnical University (NWPU). Her current research in- terests include natural language processing, dialog sys- tems, and large language models. Bin Guo was born in 1980. He is a Ph.D. professor and Ph.D. super- visor at Northwestern Polytechni- cal University (NWPU). He is a senior member of the China Com- puter Federation. His main re- search interests include ubiquitous computing, social and community intelligence, urban big data mining, mobile crowdsensing, and human- computer interaction. Hao Wang was born in 1996. He received his B.E. degree in com- puter science and technology from Northwestern Polytechnical Uni- versity (NWPU) in 2019. He is currently working toward a Ph.D. degree at NWPU. His current re- search interests include natural language processing, di- alog systems, and large language models. Haoyu Li was born in 2002. He received his B.E. degree in com- puter science and technology from Northwestern Polytechnical Uni- versity (NWPU) in 2023. He is currently working toward a mas- ter’s degree at NWPU. His cur- rent research interests include natural language process- ing, large language models, and robot dynamic obstacle avoidance.36 Front. Comput. Sci., 2024, 0(0): 1–36 Qian Zhao was born in 2001. She received her B.E. degree in In- ternet of Things engineering from Tianjin University of Technology (TUT) in 2023. She is currently working toward a master’s de- gree at Northwestern Polytechni- cal University (NWPU). Her cur- rent research interests include multimodal dialogue, large language models, and visual human-computer in- teraction. Jingqi Liu was born in 2002. She entered Northwestern Polytechni- cal University(NWPU) to study for a bachelor’s degree in infor- mation and computing science in 2020. Her current research inter- ests include natural language pro- cessing, dialogue systems, and large language models. Yasan Ding was born in 1995. He received his B.E. degree in com- puter science and technology from Northwestern Polytechnical Uni- versity (NWPU) in 2018. He is currently working toward a Ph.D. degree at NWPU. His current research interests include fake news detection and natural language processing. Yan Pan was born in 1991. He is a lecturer at the Science and Technology on Information Sys- tems Engineering Laboratory. He respectively received the B.S. de- gree in 2013 and the Ph.D. degree in 2020 from Northwestern Poly- technical University (NWPU). His research interests in- clude Big Data, Machine Learning, and Crowd Intelli- gence. Zhiwen Yu was born in 1977. He is a Ph.D. professor and Ph.D. su- pervisor. He is a senior member of the China Computer Federation. His main research interests in- clude mobile internet, ubiquitous computing, social and community intelligence, urban big data min- ing, mobile crowdsensing, and human-computer inter- action.",
      "references": [
        "Conditional text generation for harmonious human-machine interaction",
        "Challenges in building in- telligent open-domain dialog systems",
        "The elaboration likelihood model of persuasion",
        "Persuasive technology: using computers to change what we think and do",
        "Persuasive technology for human well- being: setting the scene",
        "Mass interpersonal persuasion: An early view of a new phenomenon",
        "Winning arguments: Interaction dynamics and persua- sion strategies in good-faith online discussions",
        "Analyzing the semantic types of claims and premises in an online persuasive forum",
        "Persuasive system de- sign: state of the art and future directions",
        "Cognitive theories of persua- sion",
        "Persuasion for good: Towards a personalized persua- sive dialogue system for social good",
        "Ef- fects of persuasive dialogues: testing bot identities and inquiry strategies",
        "Dialograph: Incorporating interpretable strategy-graph networks into negotiation dialogues",
        "Recent advances in natural language processing via large pre-trained language models: A survey",
        "A survey of large language models",
        "Llama 2: Open foundation and fine-tuned chat models",
        "Constitutional ai: Harmlessness from ai feedback",
        "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt",
        "Chatgpt: A comprehensive review on back- ground, applications, key challenges, bias, ethics, lim- itations and future scope",
        "Generating empathetic responses through emotion tracking and constraint guidance",
        "Infor- mative and diverse emotional conversation generation with variational recurrent pointer-generator",
        "Expectation vs. experience: Evaluating the usability of code gen- eration tools powered by large language models",
        "Lever: Learning to verify language-to-code generation with execution",
        "Wordcraft: story writing with large language models",
        "From human writing to artificial intelligence generated text: examining the prospects and potential threats of chat- gpt in academic writing",
        "Mood and persuasion: A cognitive response analysis",
        "Emotion and persuasion: Cog- nitive and meta-cognitive processes impact attitudes",
        "Dynamic knowledge routing network for target-guided open-domain con- versation",
        "A persuasive chatbot using a crowd-sourced argument graph and concerns",
        "The psychology of tailoring-ingredients in computer-tailored persuasion",
        "Intelligent cognitive assistants for attitude and behavior change support in mental health: state-of-the-art technical review",
        "An autonomous debating system",
        "To- wards topic-guided conversational recommender sys- tem",
        "Recommendation as a communica- tion game: Self-supervised bot-play for goal-oriented dialogue",
        "Seamlessly integrating factual information and social content with persuasive dialogue",
        "Persuasive natural lan- guage generation–a literature review",
        "Let’s negotiate! a sur- vey of negotiation dialogue systems",
        "A survey on proactive dialogue systems: Problems, methods, and prospects",
        "Pre-suasion: A revolutionary way to influ- ence and persuade",
        "Ar- gument invention from first principles",
        "Does the chimpanzee have a theory of mind?",
        "Coke: A cognitive knowledge graph for machine theory of mind",
        "Neural theory-of- mind? on the limits of social intelligence in large lms",
        "Rmm: A recursive mental model for dialogue navi- gation",
        "The philosophy of rhetoric",
        "Towards emotional support dialog sys- tems",
        "Decou- pling strategy and generation in negotiation dialogues",
        "Improving multi-turn emotional support dialogue generation with lookahead strategy planning",
        "E ffects of message repetition and position on cognitive response, recall, and persua- sion",
        "Influence: The psychology of persuasion",
        "Hitkg: Towards goal-oriented conversations via multi- hierarchy learning",
        "Eagle: Enhance target-oriented dialogs by global planning and topic flow integration",
        "Communication and persua- sion: Central and peripheral routes to attitude change",
        "Argument mining: Extracting arguments from online dialogue",
        "Ampersand: Argument mining for persua- sive online discussions",
        "From argument search to argumentative dialogue: A topic-independent approach to argument acquisition for dialogue systems",
        "Arguetutor: An adaptive dialog-based learning system for argumentation skills",
        "Recent advances in deep learning based dialogue systems: A systematic survey",
        "Sparks of artificial general intelli- gence: Early experiments with gpt-4",
        "Long short-term mem- ory",
        "Attention is all you need",
        "Pepds: A polite and empathetic persuasive dialogue system for charity donation",
        "Mortality in mental disorders and global disease burden implica- tions: a systematic review and meta-analysis",
        "Survey on psychotherapy chatbots",
        "Identify- ing emotional causes of mental disorders from social media for effective intervention",
        "Case: Aligning coarse-to-fine cognition and a ffection for empathetic response generation",
        "Comet: Commonsense transformers for automatic knowledge graph construction",
        "Conceptnet 5.5: An open multilingual graph of general knowledge",
        "Fear of the russian bear? negoti- ating finnish national identity online",
        "Hierarchical argumentation structure for persuasive argumentative dialogue generation",
        "Increasing the natural- ness of an argumentative dialogue system through ar- gument chains",
        "Target-guided di- alogue response generation using commonsense and data augmentation",
        "A unifying perspective on perception and cognition through linguistic representations of emo- tion",
        "Cognition, evolution, and behavior",
        "Designing persuasive dialogue systems: Using argumentation with care",
        "Why are persuasive strategies e ffective? exploring the strengths and weaknesses of socially- oriented persuasive strategies",
        "Making robots persuasive: the influence of combining persuasive strategies (gazing and ges- tures) by a storytelling robot on its persuasive power",
        "Em- pathetic persuasion: reinforcing empathy and persua- siveness in dialogue systems",
        "Bleu: a method for automatic evaluation of machine transla- tion",
        "Meteor: An automatic metric for mt evaluation with improved correlation with hu- man judgments",
        "Automatic evaluation of summaries using n-gram co-occurrence statistics",
        "Prompt-based monte-carlo tree search for goal-oriented dialogue policy planning",
        "Augmenting non-collaborative dialog systems with explicit seman- tic and strategic dialog history",
        "Knowledge- enhanced memory model for emotional support con- versation",
        "Misc: A mixed strategy-aware model integrating comet for emotional support conversation",
        "Handbook of communi- cation and social interaction skills",
        "Helping skills: Facilitating, exploration, in- sight, and action",
        "Semi-supervised classification with graph convolutional networks",
        "Graph attention networks",
        "A comprehensive survey on graph neural networks",
        "Graph neural networks for natu- ral language processing: A survey",
        "Towards infor- mative and diverse dialogue systems over hierarchi- cal crowd intelligence knowledge graph",
        "Modeling persuasion factor of user decision for recommendation",
        "Comae: A multi-factor hierarchical framework for empathetic response generation",
        "Improving dialog sys- tems for negotiation with personality modeling",
        "Building emotional support chatbots in the era of llms",
        "Knowledge graph grounded goal planning for open-domain conversation generation",
        "Gochat: Goal-oriented chat- bots with hierarchical reinforcement learning",
        "Interacting with non-cooperative user: A new paradigm for proactive dialogue policy",
        "Keyword-guided neural conversational model",
        "Thinking clearly, talk- ing fast: Concept-guided non-autoregressive genera- tion for open-domain dialogue systems",
        "Dialogue planning via brownian bridge stochastic process for goal-directed proactive dialogue",
        "Two stage learning for argument pairs extraction",
        "Topkg: Target-oriented dialog via global planning on knowledge graph",
        "Target-guided open-domain conversation",
        "A target-driven planning ap- proach for goal-directed dialog systems",
        "Towards ar- gument mining for social good: A survey",
        "Cross-domain mining of argumentative text through distant supervision",
        "Argument generation with re- trieval, planning, and realization",
        "Argument min- ing using bert and self-attention based embeddings",
        "Argument mining with structured svms and rnns",
        "Exploring the role of argu- ment structure in online debate persuasion",
        "Multi-task learning in argument mining for persuasive online discussions",
        "Iam: A comprehensive and large-scale dataset for integrated argument mining tasks",
        "A hierarchical sequence labeling model for argument pair extraction",
        "Smote: synthetic minority over-sampling tech- nique",
        "Augesc: Dialogue augmentation with large language models for emotional support con- versation",
        "Psyqa: A chinese dataset for generating long counseling text for mental health support",
        "A corpus for research on deliberation and debate",
        "Debatesum: A large-scale argu- ment mining and summarization dataset",
        "A dynamic strategy coach for effective negotiation",
        "Keeping up appearances: Computational modeling of face acts in persuasion oriented discussions",
        "To- wards conversational recommendation over multi-type dialogs",
        "In- spired: Toward sociable recommendation dialog sys- tems",
        "Internet ar- gument corpus 2.0: An sql schema for dialogic social media and the corpora to go with it",
        "Meteor: An automatic metric for mt evaluation with high levels of correlation with hu- man judgments",
        "Cider: Consensus-based image description evaluation",
        "An optimal assessment of natu- ral language student input using word-to-word simi- larity metrics",
        "Towards universal paraphrastic sentence embeddings",
        "Bootstrapping dialog systems with word embeddings",
        "Towards an automatic turing test: Learning to evaluate dialogue responses",
        "Bert: Pre-training of deep bidirectional transformers for lan- guage understanding",
        "A multi-appeal model of persuasion for online petition success: A linguistic cue-based approach",
        "Activating persuasion knowledge in native advertising: the influ- ence of cognitive load and disclosure language",
        "Strategic argumentation in multi-agent sys- tems",
        "Progress and challenges in probing the human brain",
        "In- terest as a proxy of engagement in news reading: Spectral and entropy analyses of eeg activity patterns",
        "Trans- fertransfo: A transfer learning approach for neural network based conversational agents",
        "Domain adaptive dialog generation via meta learning",
        "A deep sequential model for dis- course parsing on multi-party dialogues",
        "Learning to improve persona consistency in multi-party dia- logue generation via text knowledge enhancement",
        "Communication- robust multi-agent learning by adaptable auxiliary multi-agent adversary generation",
        "Predicting persuasive- ness of participants in multiparty conversations",
        "Speaker-aware bert for multi-turn response selec- tion in retrieval-based chatbots",
        "Gift: Graph- induced fine-tuning for multi-party conversation un- derstanding",
        "Interpretability and analysis in neural nlp",
        "Towards faithfully interpretable nlp systems: How should we define and evaluate faith- fulness?",
        "Semantics of the black- box: Can knowledge graphs help make deep learning systems more interpretable and explainable?",
        "Qa-gnn: Reasoning with language models and knowl- edge graphs for question answering",
        "Multimodal human discourse: gesture and speech",
        "Multimodal interaction: A review",
        "Multimodal human–computer in- teraction: A survey",
        "Multimodal ma- chine learning: A survey and taxonomy",
        "Two causal principles for improving visual dialog",
        "Audio visual scene-aware dialog",
        "Vi- sual chatgpt: Talking, drawing and editing with visual foundation models",
        "Vilbert: Pretrain- ing task-agnostic visiolinguistic representations for vision-and-language tasks",
        "A domain-specific next-generation large language model (llm) or chatgpt is required for biomedical engineer- ing and research",
        "Code as policies: Language model programs for embodied control",
        "Empowering llm to use smart- phone for intelligent task automation",
        "Soda: Million-scale dialogue distillation with so- cial commonsense contextualization",
        "Augesc: Large- scale data augmentation for emotional support con- versation with pre-trained language models"
      ],
      "meta_data": {
        "arxiv_id": "2402.04631v1",
        "authors": [
          "Mengqi Chen",
          "Bin Guo",
          "Hao Wang",
          "Haoyu Li",
          "Qian Zhao",
          "Jingqi Liu",
          "Yasan Ding",
          "Yan Pan",
          "Zhiwen Yu"
        ],
        "published_date": "2024-02-07T07:28:34Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "This paper surveys and systematizes the emerging paradigm of Cognitive Strategy-enhanced Persuasive Dialogue Agents (\"CogAgent\"), motivated by the gap between LLM fluency and human-like persuasive cognition. Key contributions are: (1) grounding persuasive dialogue in cognitive psychology (e.g., Pre-suasion, consistency, Theory of Mind, Aristotle’s ethos/pathos/logos) and formalizing three core cognitive strategies—persuasion strategy, topic path planning, and argument structure prediction; (2) proposing a formal concept model and generic system architecture that explicitly predicts these strategies and conditions response generation on them; (3) organizing and analyzing representative methods across the three strategy types (classification/planning/graph- and knowledge-enhanced integration; RL and graph-based topic planning; argument mining and argument-structure-aware dialogue); and (4) compiling authoritative datasets and evaluation practices while identifying open problems and research trends for the field.",
        "methodology": "Methodologically, the work is a review plus a unifying formalization. It defines CogAgent as a dialogue model that, given dialogue history and current user query, first predicts cognitive strategies via a strategy predictor (Per, Top, Arg) and then generates responses conditioned on these strategies. The paper synthesizes common technical approaches used in the literature: (a) persuasion-strategy integration via strategy classification, long-horizon planning (A*/lookahead, MCTS with LLM prompting), graph neural networks over strategy dependencies (e.g., DIALOGRAPH), and knowledge/memory-augmented strategy modeling; (b) topic path planning using hierarchical reinforcement learning and knowledge graphs / concept graphs with GNNs and Transformer-based planners; and (c) argument mining and argument structure prediction from debates/online discussions using supervised relation classification, factor graphs/structured prediction, attention/Transformer encoders, and argument graphs as external knowledge for response selection/rebuttal.",
        "experimental_setup": "As a survey/review, the paper does not introduce a new model with original experiments; instead it catalogs benchmarks and evaluation protocols used across CogAgent research. It summarizes datasets by scenario: psychological counseling (ESConv, AUGESC, PsyQA), debate/argumentation (IAC/IAC2, ChangeMyView/Winning Arguments, DebateSum), price negotiation (CraigslistBargain, Negotiation-Coach), donation persuasion (PersuasionForGood and extensions EPP4G/ETP4G, FaceAct), and recommendation (TG-ReDial, DuRecDial, INSPIRED). It also summarizes validation methods: (1) automatic text-similarity metrics—overlap-based (BLEU, ROUGE, METEOR, CIDEr), embedding-based (Greedy Matching, embedding averaging, vector extrema), and learning-based (ADEM); and (2) human evaluation dimensions—fluency, coherence, contextualization, emotional expression, diversity, and persuasiveness; plus a noted trend of using LLMs as evaluators/judges.",
        "limitations": "Key limitations highlighted or implied include: (1) incomplete and task-specific cognitive strategy taxonomies—current strategy sets are often non-exhaustive and may not generalize across persuasion scenarios; (2) difficulty of reliably modeling and selecting strategies because strategies are abstract and expressed through complex linguistic/semantic patterns; (3) challenges integrating high-level cognitive strategies into data-driven neural models/LLMs in a controllable, faithful way; (4) lack of standardized, persuasion-specific evaluation metrics and benchmarks—common metrics mostly measure surface or semantic similarity rather than persuasion effectiveness, topic-path rationality, or argument quality; (5) dataset scarcity and small scale in some key scenarios (e.g., donation persuasion), limited and uneven strategy annotations, and potential domain bias; and (6) as a review article, the proposed concept model/architecture is not empirically validated as a unified implementation within the paper.",
        "future_research_directions": "The paper proposes several future directions: (1) more comprehensive modeling of cognitive psychology in persuasion (e.g., cognitive dissonance, dual-process/ELM, richer ToM), potentially informed by neuroscience signals (EEG/MEG/fMRI) to understand receptivity; (2) improving CogAgent adaptivity/generality and cross-domain transfer with transfer learning/meta-learning; (3) multi-party CogAgent settings where multiple agents coordinate roles and strategies to persuade groups; (4) interpretability of the persuasion process (strategy faithfulness, knowledge-graph reasoning traces, interactive analysis); (5) multimodal CogAgent that conditions persuasion on visual/auditory/context signals, leveraging multimodal foundation models; (6) data–model co-optimization with LLMs (using LLMs to synthesize/augment persuasive data while adding model-driven constraints for controllable persuasion); and (7) construction of standardized large-scale datasets and unified benchmarks with rich cognitive-strategy annotations.",
        "experimental_code": "",
        "experimental_info": ""
      }
    },
    {
      "title": "Chain of Hindsight aligns Language Models with Feedback",
      "full_text": "1 PMMTalk: Speech-Driven 3D Facial Animation from Complementary Pseudo Multi-modal Features Tianshun Han , Shengnan Gui, Yiqing Huang, Baihui Li, Lijian Liu, Benjia Zhou , Ning Jiang, Quan Lu, Ruicong Zhi, Yanyan Liang , Member, IEEE, Du Zhang, Senior Member, IEEE, Jun Wan , Senior Member, IEEE Abstract—Speech-driven 3D facial animation has improved a lot recently while most related works only utilize acoustic modal- ity and neglect the influence of visual and textual cues, leading to unsatisfactory results in terms of precision and coherence. We argue that visual and textual cues are not trivial information. Therefore, we present a novel framework, namely PMMTalk, using complementary Pseudo Multi-Modal features for improving the accuracy of facial animation. The framework entails three modules: PMMTalk encoder, cross-modal alignment module, and PMMTalk decoder. Specifically, the PMMTalk encoder employs the off-the-shelf talking head generation architecture and speech recognition technology to extract visual and textual information from speech, respectively. Subsequently, the cross- modal alignment module aligns the audio-image-text features at temporal and semantic levels. Then PMMTalk decoder is employed to predict lip-syncing facial blendshape coefficients. Contrary to prior methods, PMMTalk only requires an additional random reference face image but yields more accurate results. Additionally, it is artist-friendly as it seamlessly integrates into standard animation production workflows by introducing facial blendshape coefficients. Finally, given the scarcity of 3D talking face datasets, we introduce a large-scale 3D Chinese Audio-Visual Facial Animation (3D-CA VFA) dataset. Extensive experiments and user studies show that our approach outperforms the state of the art. 1 We recommend watching the supplementary video. Index Terms—speech-driven 3D facial animation, PMMTalk, 3D-CA VFA dataset. I. I NTRODUCTION Speech-driven 3D facial animation for digital characters has gained popularity in academia and industry, offering potential Tianshun Han, Yiqing Huang, Benjia Zhou, Yanyan Liang and Du Zhang are with the School of Computer Science and Engineering, the Faculty of Innovation Engineering, Macau University of Science and Technology, Macau 999078, China. (e-mail: {3230002542, 3230006115, 21098536ia30001}@student.must.edu.mo, {yyliang, duzhang}@must.edu.mo). Baihui Li, Lijian Liu and Jun Wan are with the State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing 100190, China, also with the School of Artificial Intelligence, University of Chinese Academy of Sciences (UCAS), Beijing 100049, China. Jun Wan is also with the School of Computer Science and Engineering, the Faculty of Innovation Engineering, Macau University of Science and Technology, Macau 999078, China. (e-mail: {libaihui2022, liulijian2022, jun.wan}@ia.ac.cn) Shengnan Gui and Ruicong Zhi are with the School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China. Ruicong Zhi is also with the Beijing Key Laboratory of Knowledge Engineering for Materials Science, Beijing 100083, China. (e- mail: m202110625@xs.ustb.edu.cn; zhirc@ustb.edu.cn) Ning Jiang and Quan Lu are with the Mashang Consumer Finance Co., Ltd, Chongqing 400000, China. (e-mail: ning.jiang02@msxf.com; quan.lu@gmail.com) 1We will release the code and dataset when this paper is accepted. (a) Previous Methods (b) PMMFTalk(Ours) Audio  Decoder Audio  Eecoder PMMF  Encoder PMMF  Decoder (Unavoidable sandstorms are also part of the scenery) 躲 不 过 的 沙 暴 都 是 风 景 Prior Structural Information P  O 沙(shā) Image  Features Image  Features Audio  Features Audio  Features Text  Features Text  Features Pseudo Features Pseudo Features Inadequary Adequary Adequary Inadequary Adequary Fig. 1. Comparison with existing methods. (a) Prior methods relying solely on acoustic features result in inadequate and insufficient lip movements such as in the pronunciation of Chinese word /sha/, demanding a full mouth opening and downward jaw movement. (b) PMMTalk utilizes complementary pseudo multi-modal features generated from speech, enhancing the accu- racy of facial animation. In addition, unlike previous methods that could only generate vertex-based animation, PMMTalk predicts synchronized facial blendshape coefficients, which is more artist-friendly. benefits for virtual reality [16, 15], film production [45, 6], and computer gaming [29, 17]. Presently, commercial 3D facial blendshape creation by animators is laborious and time- consuming. Hence, animators are seeking an artist-friendly approach that can both effectively reduce expenses and seam- lessly integrate into existing workflows [3, 51]. Numerous methods [23, 10, 13, 43, 20, 28, 27] for speech- driven 3D facial animation have been proposed. VOCA [10] uses time convolutions to regress the face movement from audio, and FaceFormer [13] presents a transformer-based autoregressive architecture for generating continuous facial movements. However, these methods face two critical issues. In one aspect, they only utilize audio signals (as depicted in Fig. 1), disregarding potent visual and textual cues. Speech signals are ambiguous as some phoneme pairs can be easily confusable on the basis of acoustics alone. Actually, the human speech perception inherently involves acoustic, visual, and textual features [11, 14, 25]. For instance, visual cues like jaw and lower face muscle movements have a correlation arXiv:2312.02781v1  [cs.CV]  5 Dec 20232 with pronunciation [47], serving to assist in disambigua- tion [30], while textual cues can enhance the comprehension and understanding of models by providing diverse contextual information and semantic properties [14]. In another aspect, as shown in Table I, existing 3D talking face datasets [18, 10, 34, 27, 42] have certain issues: (1) Scarcity. Speech signals and facial motion exhibit strong correlations, yet they exist in distinct spaces, necessitating a substantial amount of training data [10, 40]. However, only a limited number of publicly available datasets exist, and they suffer from limitations in terms of scale. (2) Diversity. Most existing datasets narrow their focus to a single corpus type, such as sentences, failing to capture the rich diversity of language usage patterns that are encountered in real-world scenarios. (3) Generic. The majority of existing datasets employ vertex offsets of mesh as labels, which are not artist-friendly and pose challenges in integrating models based on these datasets into typical animation production workflows [3]. To address the first challenge, we present a novel frame- work, namely PMMTalk (as illustrated in Fig. 3), utilizing complementary Pseudo Multi-Modal features for enhancing the accuracy of facial animation. The framework consists of three modules: PMMTalk encoder, cross-modal alignment module, and PMMTalk decoder. Specifically, the PMMTalk encoder uses the off-the-shelf talking head generation method and speech recognition technology to extract visual and tex- tual information from speech, respectively. The cross-modal alignment module then aligns these audio-image-text features to work together on both temporal and semantic levels. The PMMTalk decoder driven by the audio features, image fea- tures, text features, and personal style embeddings predicts lip-syncing facial blendshape coefficients while controlling personal styles. To cope with the second aspect, we public a large-scale 3D C hinese Audio-Visual Facial Animation ( 3D- CA VFA) dataset, comprising 20 subjects with synchronized facial blendshape coefficients, and a total duration of almost 15.3 hours. It covers frequently used single words and phrases in modern Chinese, and encompasses various commonly used sentence patterns in daily life, making it highly relevant to everyday situations. Finally, we propose two evaluation proto- cols to assess model performance from different perspectives, including cross-subject and cross-gender ability, bridging the gap between academic research and real-world applications. The contributions of our work are as follows: • To the best of our knowledge, we are the pioneers in leveraging pseudo multi-modal information into speech- driven 3D facial animation, outperforming existing state-of-the-art methods. • We propose a novel and effective architecture, namely PMMTalk, which extracts pseudo visual and textual information from speech and aligns the audio-image-text features at temporal and semantic levels, improving the accuracy of facial animation. • We present a large-scale 3D talking face dataset, namely the 3D-CA VFAdataset, with synchronized facial blend- shape coefficients, diverse corpus, and various subjects. II. R ELATED WORK A. Speech-Driven 3D Facial Animation Formerly, there are numerous studies focusing on 2D talk- ing head generation [41, 5, 31, 22, 21, 46, 37, 38, 12], utilizing either image-driven or speech-driven approaches to create realistic videos of individuals speaking. Nevertheless, these approaches are not suitable for 3D character models, which are extensively utilized in 3D games and virtual reality interactions. Therefore, we focus on speech-driven 3D facial animation [23, 10, 35, 13, 27] in this work. Karras et al. [23] leverages an end-to-end convolutional network for mapping speech features to 3D vertex positions and designs an emotion states code to explain various fa- cial expressions. VOCA [10] utilizes advanced audio feature extraction models and has the capability to generate facial animation with diverse speaking styles. MeshTalk [35] fo- cuses on the upper part of the face, learning a categorical latent space that successfully disentangles audio-correlated and audio-uncorrelated face motions. FaceFormer [13] employs a self-supervised pre-trained speech model to extract audio features, and then put them into a transformer-based model and autoregressively generate continuous facial animations. Most related to our work is EmoTalk [27], whereby proposing an emotion disentangling encoder to disentangle the emotion as well as content in the speech and output emotional blendshape coefficients. However, they ignore the strong influence between acoustic, visual, and textual cues, limiting the accuracy of lip move- ments and causing ambiguity for identical pronunciations. Additionally, most of these methods are primarily focused on directly generating vertex-based animation from audio, which poses challenges in terms of user-friendliness for artists and integration into existing animation production workflows. Therefore, in this paper, we present an effective architecture utilizing complementary pseudo multi-modal features for im- proving the accuracy of facial animation. B. Talking Face Dataset Several 3D [4, 26, 36, 44] and 4D face datasets [1, 9, 48, 49, 50, 19, 7] have been published for both static and dynamic facial expression recognition, while only a limited number of datasets [18, 10, 34, 27] available that capturing synchronized audio along with dynamic 3D facial movements. As shown in Table I, we have curated a collection of currently available open-source datasets. BIWI [18] consists of 40 spoken English sentences for each of the 14 subjects, while VOCASET [10] captures 29 minutes of 4D scans from 12 speakers. However, the limited size of both the BIWI and VOCASET datasets restricts the generalization capacity of 3D face animation models. MeshTalk [34] collects 250 subjects each reading 50 sentences, while it only publishes a few parts of the dataset. Recently, EmoTalk [27] publishes a large-scale 3D emotional talking face dataset by predicting the facial blendshape coefficients from the corresponding input 2D video streams.3 TABLE I COMPARISON WITH PUBLICLY AVAILABLE 3D TALKING FACE DATASETS . THE 3D-CAVFA DATASET STANDS OUT REGARDING SUBJECT NUMBERS (#S UBJ ), TEXT CORPUS CONTENT (#C ROP ), AND DURATION (#D URA ). W E ALSO LIST PUBLIC YEAR (#Y EAR ), FRAME PER SECOND (#FPS), SPOKEN LANGUAGE (#L ANG ), AND LABELS (#L AB). Dataset #Year #Subj #Dura #Crop #FPS #Lang #Lab BIWI [18] 2010 14 1.44h Sentences 25 English Vertex Positions VOCASET [10] 2019 12 0.5h Sentences,Pangrams,Questions 60 English Vertex Positions MeshTalk [34] 2021 250 13h Sentences 30 English Vertex Positions EmoTalk [27] 2023 12 6.5h Sentences 30 English Blendshape Coefficients 3D-CA VFA - 20 15.3h Words,Phrases,Sentences 60 Chinese Blendshape Coefficients However, they face issues of restricted corpus diversity and dataset scale, which consequently limits the ability of models to comprehend complex relations between speech and lip movements. Further, the majority utilize vertex offsets of mesh as labels, imposing a limitation on the generalization ability of models trained on these datasets [27]. To overcome these limitations, we collect a large-scale 3D talking face dataset, namely the 3D-CA VFA dataset, characterized by synchronized facial blendshape coefficients, diversified corpus, and assorted subjects. III. D ATASETS CONSTRUCTION As commented, all existing datasets face some limitations, such as restricted corpus diversity, limited dataset scale, and a reduced number of subjects, impeding the development of speech-driven 3D facial animation technology. Conventionally, these datasets adopt vertex offsets of mesh as labels, which in- advertently imposes limitations on the generalization ability of models trained on these resources. To mitigate these issues and advance the field, we assemble a large-scale 3D Chinese audio- visual facial animation dataset, namely the 3D-CA VFA dataset. This dataset, comprising approximately 3,150,000 frames of facial blendshape coefficients over a span of 15 hours, presents a significant improvement over previous resources. As such, our initiative addresses a notable paucity in the availability of large-scale 3D facial animation datasets. We are preparing to make the 3D-CA VFA dataset accessible to the academic community in the near future. Corpus. Our text corpus, aimed at maximizing phonetic diversity, contains Chinese main components and is divided into two segments. The first segment is derived from FACE- GOOD2, comprising single words and phrases that are fre- quently utilized in modern Chinese. The second segment is sourced from celebrated movie dialogues, both local and international, encapsulating a wide variety of sentence patterns commonly used in daily conversation. Therefore, our curated text corpus is designed to encompass an equitable distribution of each phoneme to the greatest extent feasible. Scene. As illustrated in Fig. 2, facial video recordings are conducted in a conference room with a plain white back- ground. We employ the mobile software Live Link Face 3, 2https://github.com/FACEGOOD/FACEGOOD-Audio2Face 3https://apps.apple.com/us/app/live-link-face/id1495370836 Fig. 2. Overview of proposed 3D-CA VFA dataset. (1) Acquisition: We detail the setup and recording conditions used in data collection. (2) Sample data: A specific segment is showcased, including RGB videos, corresponding text information, synchronized speech audio, and facial blendshape coeffi- cients. (3) Diverse actors: The dataset encompasses a diverse range of actors, further enhancing its representation and applicability. All RGB facial images are mosaicked for privacy. a free IOS application, to capture the facial movements of volunteers while speaking. For the assurance of capturing distinct facial details, we meticulously position the iPhone at face level, maintaining a distance of 0.5 meters. In comparison to traditional enterprise-level capture systems, this method boasts both superior scene adaptability and decreased hard- ware requirements, resulting in a cost-effective solution that still guarantees the capture of high-quality data. Actors. We invite 20 student volunteers, composed of 6 females and 14 males, all of whom are native Mandarin speak- ers from China. To mimic real-life scenarios, no restrictions are placed on the speaking speed or duration. Participants are encouraged to read the text corpus naturally, and minor errors, such as the usage of synonyms that do not alter the intended meaning, are overlooked. Statistics. The software records facial blendshape coeffi- cients in 61 dimensions synchronized with timestamps. It captures information at a rate of 60fps and a resolution of 1080P to guarantee the seamless reproduction of facial movements. Simultaneously, the audio is sampled at a high rate of 48kHz to uphold superior sound quality. Evaluation protocol. To provide a comprehensive evalua- tion of model capabilities, we have devised two distinctive testing protocols: the cross-subject protocol and the cross-4 Audio Decoder Raw Speech mean Cross-modal  Alignment Module Biased MH Self-Attention Periodic Positional Encoding Audio-Blendshape Decoder Talking Head Generator Prior Structure Image Embedding Text Embedding Audio Encoder Audio Encoder Audio Embedding Style Embedding Personal Style Temporal      Alignment Image Encoder CT …C3 C2 C1 CT …C3 C2 C1 AT …A3 A2 A1 AT …A3 A2 A1 IT …I3 I2 I1 IT …I3 I2 I1 Audio Encoder Audio Encoder Text Decoder CT…C3C2C1 AT … A3 A2 AT  C1 … A3  C1 A2  C1 A1  C1 AT  C2 … A3  C2 A2  C2 A1  C2 AT  T3 … A3  C3 A2  T3 A1  C3 … … … … AT CT … A3  CT A2  CT A1  CT A1 IT…I3I2I1 CT  I1 … C3  I1 C2  I1 C1  I1 CT I2 … C3  I2 C2  I2 C1  I2 CT I3 … C3 I3 C2 I3 C1 I3 … … … … … … … … CT  IT … C3  IT C2  IT C1  IT Semantic      Alignment (a) PMMTalk Encoder (b) Cross-modal Alignment  (c) PMMTalk Decoder IT … I3 I2 I1 AT…A3A2A1 CT … C3 C2 C1 CT … C3 C2 C1 mean mean IT  A1 … I3  A1 I2 A1 I1  A1 IT  A2 … I3  A2 I2 A2 I1  A2 IT  A3 … I3  A3 I2 A3 I1  A3 … … … … … … … … IT  AT … I3  AT I2 AT I1  AT IT … I3 I2 I1 AT…A3A2A1 Fig. 3. Overview of PMMTalk. The framework consists of three modules: PMMTalk encoder, cross-modal alignment module, and PMMTalk decoder. (a) Given a raw speech X, a random reference face image R as inputs, the PMMTalk encoder can extract image features I1:T , text features C1:T and audio features A1:T from speech, respectively. (b) The cross-modal alignment module then aligns these audio-image-text features at temporal and semantic levels. (c) The PMMTalk decoder driven by the image features I1:T , text features C1:T , audio features A1:T and personal style p predicts lip-syncing facial blendshape coefficients while controlling personal styles. These coefficients can be used to drive any digital characters according to the rendering engine rules. gender protocol. With the cross-subject protocol, the dataset is randomly partitioned: 60% is designated for training, 20% for validation, and a further 20% reserved for testing, all based on the identity of the subjects. Within the cross-gender protocol, we employ all male samples for training purposes, while dividing the female samples evenly across the validation and test sets according to the the identity of the subjects. IV. M ETHOD The perception of human speech fundamentally involves the integration of multiple modality signals [11, 14, 25]. Therefore, an exclusive reliance on single modality data could potentially lead to undesirable results. To bypass this barrier, as shown in Fig. 3, we propose a novel architec- ture, namely PMMTalk, utilizing pseudo multi-modal features to generate accurate and synchronized lip movement. Let X1:T = (§1, . . . ,§T ) be a sequence of speech snippets, and each §t ∈ RD has D samples to align to the corresponding (visual) frame bt. Let B1:T = ( b1, . . . ,bT ), bt ∈ R32 be a T-length sequence of facial blendshape coefficients, which describes the ground-truth of 3D face movements. The proposed model takes speech X1:T , a random reference face image R (prior structural information), and personal style p ∈ R64 as input, predicting facial blendshape coefficients ˆB1:T = \u0010 ˆb1, . . . ,ˆbT \u0011 . Formally, ˆbt = PMMTalkθ (§t, R, p) , (1) where θ indicates the model parameters, t is the current time- step in the sequence and ˆbt ∈ ˆBT. For the remainder of this section, we will provide a description of each PMMTalk component in detail. A. PMMTalk Encoder 1) Audio Embedding: The design of audio embedding adopts the state-of-the-art self-supervised pre-trained speech model, wav2vec 2.0 [2]. By training on a sufficient amount of audio data, it can effectively extract the desired audio features, ensuring that the extracted features contain comprehensive in- formation about the spoken words. Specifically, the audio em- bedding is bifurcated into two integral components: an audio encoder denoted as ψAE(·) and an audio decoder represented as ψAD(·). The former, comprising multiple layers of temporal convolutional networks, transforming the raw speech X input into latent speech representations L1:T = (l1, . . . ,lT ). On the other hand, the latter, which incorporates a stack of multi- head self-attention [39] and feed-forward layers, transposing these latent speech feature vectors into contextualized speech representations A1:T = (a1, . . . ,aT ). The formula is defined as follows: L1:T = ψAE(X), A1:T = ψAD(L1:T ), (2) where T is the frame length. Here, we freeze the parameters of ψAE(·) while training. 2) Text Embedding: The purpose of text embedding is to identify and extract informative latent features embedded within the input audio signal, thereby generating the corre- sponding textual information. A speech recognizer module, wav2vec 2.0 [2], is leveraged to pursue this goal. In this5 approach, the input audio signal is initially transformed into waveform embeddings, and then mask and predict specific portions. This method efficiently captures and translates com- prehensive audio features into text. The text embedding is specifically composed of two com- ponents: an audio encoder ψAE(·) and a text decoder ψTD (·). The audio encoder ψAE(·) shares weights with the one in the audio embedding module. The text decoder ψTD (·), on the other hand, comprises 24 transformer blocks [39] and a pre-trained fully connected layer. This structure maps the 1024-dimensional latent speech feature vectors on a frame- by-frame basis into textual vocabulary representations C1:T = (c1, . . . ,cT ) with 3503 dimensions. Formally: C1:T = ψTD (L1:T ), (3) where T is the frame length. Take note that the parameters of the text embedding module remain frozen during the training process. 3) Image Embedding: The image embedding module com- prises two components: the talking head generator ψHG(·) and the image encoder ψIE (·). The talking head generator ψHG(·) utilizes the widely recognized architecture, Wav2Lip [31], to generate lip-syncing visual information. It specifically includes an identity encoder, a speech encoder, and a face decoder, all composed of stacks of 2D convolutional layers with residual skip connections. It requires an audio sequence X and a random reference face image R providing prior structural information as inputs and outputs the corresponding lip move- ments video V1:T = (v1, . . . ,vT ). Sequentially, V1:T is fed into image encoder ψIE (·) to generate image features I1:T = (i1, . . . ,iT ), which consists of a weight-sharing 2D CNN network and a transformer encoder [39] with multiple layers, capturing short-term and long-term dependencies in the video. Formally, we define: V 1:T = ψHG(X, R), I1:T = ψIE (V1:T ), (4) where T is the frame length. Please note that the parameters of the talking head generator ψHG(·) stay frozen throughout the training process. B. Cross-modal Alignment Given that acoustic, visual, and textual features are different modalities, each with unique characteristics, it is crucial to discover their inherent mutual connections for effective collab- oration. As these features share the same semantic information at the sentence level and reflect the same lip movement frame- by-frame in timing, an alignment at temporal and semantic levels is necessary. Temporal level. Inspired by CLIP [33], we handle temporal alignment in a similar fashion. Specifically, we use (X1:T , Y 1:T ) to denote the pair of different modal- ity combinations including (I1:T , C1:T ), (I1:T , A1:T ), and (C1:T , A1:T ). Initially, these features are fed into a linear layer, with layer normalization (LN) subsequently applied to maintain a consistent scaling. Formally, \u0010 ˆX1:T , ˆY 1:T \u0011 = LN (Linear (X1:T , Y 1:T )) . (5) The pair \u0010 ˆX1:T , ˆY 1:T \u0011 is then pairwise scaled and evaluated for similarity. Formally, D1:T = Scale( ˆX1:T × ˆY ⊤ 1:T ). (6) Following this, we use a Kullback-Leibler divergence loss function to determine the corresponding loss value. Semantic level. Furthermore, despite their distinctive characteristics, the feature pair of different modality\u0010 ˆX1:T , ˆY 1:T \u0011 exhibit shared semantic information. There- fore, aligning them at the sentence-level assists in maintaining semantic consistency. Specifically, we initially apply an aver- aging operation to each pair. Formally, \u0010 ˜X, ˜Y \u0011 = Average \u0010 ˆX1:T , ˆY 1:T \u0011 . (7) Subsequently, we endeavor to maximize the cosine similarity of each corresponding pair, aligning these features within the same semantic space. C. PMMTalk Decoder To generate the 3D facial blendshape coefficients for lip- syncing, we utilize a module inspired by the Transformer decoder [39]. PMMTalk decoder ψPD (·) consists of multi- ple layers of masked self-attention and feed-forward neural networks. The masked self-attention mechanism enables the decoder to focus on relevant parts of the input sequence to produce suitable outputs. Specifically, we first fed the image feature I1:T , the text feature C1:T , the audio feature A1:T into a linear layer and then concatenate these with the personal style features p into the decoder, which control the unique characteristics of facial expressions. Then they are encoded with a periodic positional encoding [13], which captures the consistent timing of lip movements during speech, specifically when the mouth opens and closes. Following this, a biased multi-head self- attention layer is applied, integrating the positional encoding into the multi-head attention layers, taking inspiration from attention with linear biases [32]. This layer assigns greater importance to closer information in the mask layer, focusing on the transitions between adjacent actions. Subsequently, the masked self-attention layer calculates a weighted sum of the input features based on their relevance to each other. Finally, a feed-forward neural network and a fully connected layer are utilized to produce facial blendshape coefficients. D. Loss function In order to train our neural network, we utilize a compre- hensive loss function that encompasses four key components: position loss, motion loss, temporal loss, and semantic loss. The complete function is defined as follows: L = λ1Lpos + λ2Lmot + λ3Ltem + λ4Lsem, (8) where λ1 = 1, λ2 = 10, λ3 = 10−4, and λ4 = 10−5 in all of our experiments. A comprehensive explanation of each of these components is provided in the following section. Position Loss. The position loss measures the difference between the predicted facial blendshape coefficients and6 the corresponding ground-truth facial blendshape coefficients. Specifically, we use per-frame mean squared error (MSE) as the position loss: Lpos = 1 T TX t=1 \r\r\r \u0010 ˆbt − bt \u0011\r\r\r 2 . (9) Motion Loss. To address jittery output frames, we intro- duce a motion loss that ensures temporal stability. This loss considers the smoothness between predicted and ground truth frames: Lmot = 1 T TX t=1 \r\r\r \u0010 ˆbt − ˆbt−1 \u0011 − (bt − bt−1) \r\r\r 2 . (10) Temporal Loss. The temporal loss is specifically designed to ensure the alignment of individual modal information at the frame level. Specifically, let W1:T be a diagonal matrix with a diagonal filled with 1 as the label. Subsequently, we respectively fed the prediction and label into LogSoftmax and Softmax layers. Following this, we compute the temporal loss: ˜D1:T = LogSoftmax (D1:T ) , ˜W1:T = Softmax (W1:T ) , Ltem = −1 3 X ( ˜D1:T log( ˜W1:T ) + ˜W1:T log( ˜D1:T )). (11) Semantic Loss. The semantic loss is designed to align the different modal information at a high-dimensional semantic level. To achieve this, we calculate the cosine similarity between each different modal pair ( ˜X, ˜Y ). Formally, we define: Lsem = 1 3 X (1 − ˜X ⊤ · ˜Y ∥ ˜X∥∥ ˜Y ∥ ). (12) E. Experimental Setup Training details. Within the preliminary pre-processing phase, we first convert the audio sampling rate to 16 kHz, subsequently aligning the facial animation to correspond ac- curately with the audio. The VOCASET [10] and the 3D- CA VFA datasets are processed at a rate of 30fps. Our primary objective is the enhancement of facial animation accuracy, we only select 32-dimensional facial blendshape coefficients. These coefficients, bearing a significant connection with pro- nunciation, serve as our training labels. Throughout the training phase dedicated to model optimiza- tion, the model undergoes an end-to-end optimization process using the Adam optimizer [24]. The learning rate and batch size are set to 1e-4 and 1, respectively. The entire network was trained on four NVIDIA GTX 409, and it took around 8 hours (80 epochs) to complete the training process. Datasets. In this research, we utilize two 3D talking face datasets, VOCASET [10] and 3D-CA VFA, for both training and testing. VOCASET [10] comprises 480 high frame-rate (60fps) face motion sequences of 12 subjects, each spanning 3 to 4 seconds. Moreover, each 3D face mesh contains 5023 ver- tices. The 3D-CA VFA includes facial blendshape coefficients synchronized with facial movements for 20 subjects and spans a total duration of almost 15.3 hours. Covering commonly used words, phrases, and sentence structures in modern Chinese, the 3D-CA VFA dataset is highly applicable to daily situations. Rendering Engine. In this paper, we utilize Unreal Engine (UE), a broadly utilized game development engine, for con- structing our digital avatar. It allows us to separate animation from the character, enabling the pre-trained speech-driven 3D facial animation model to drive any digital character following the guidelines. This gives us a reliable and character- independent platform that necessitates only minimal prior knowledge of game creation. Baseline Implementations. We measured the performance of our method, PMMTalk, against state-of-the-art methods including VOCA [10], MeshTalk [34], FaceFormer [13], CodeTalker [43], and EmoTalk [27]. For the 3D-CA VFA dataset, which is in Chinese, performance variances could significantly impact these previously trained English models. Uniquely, the 3D-CA VFA dataset uses facial blendshape co- efficients as labels, differing from the official datasets which employ the vertex offsets of mesh as labels. To ensure fairness, we adapted the audio feature extractor for all models with the XLSR-53 [8], a wav2vec 2.0 [2] model pre-trained on data in 53 languages. Furthermore, we modified the final linear classification layer of these models to match the 3D-CA VFA dataset. For the VOCASET dataset, we employed the provided pre- trained weights for testing on VOCA [10], FaceFormer [13], and CodeTalker [43]. For MeshTalk [34], we used its of- ficial implementation for both training and testing. For EmoTalk [27] and PMMTalk, we made adjustments to the last linear classification layer to fit the VOCASET set. All methods, except for MeshTalk, necessitate conditioning on a training speaking style during testing. When dealing with unseen subjects, we generate facial animations by conditioning on all available training styles. V. E XPERIMENTS A. Quantitative Evaluation Lip-sync analysis. To measure lip synchronization, we cal- culated the lip vertex error (LVE) as used in CodeTalker [43], which is computed as the average l2 error of the lips in the test set. For a single frame, the LVE is defined as the maximum l2 error among all lip vertices for the VOCASET dataset, or among the blendshape coefficients for the 3D- CA VFA dataset, respectively. Nevertheless, using the LVE metric may potentially be influenced by outliers present in the dataset. To attenuate the impact of outliers and provide a more holistic evaluation, we additionally calculated the lip average error. Here, we applied the Average Lip Error (ALE) to compute the average l2 error of blendshape coefficients per frame and then averaged this across the test set, which reflects the overall perceived quality of mouth movement. As shown in Table II, the performance of different models is evaluated on both protocols. Firstly, it is evident that the overall values obtained from cross-gender protocol are lower than those from cross-subject protocol. This discrepancy may be attributed to the fact that cross-gender protocol benefits from a larger training set compared to cross-subject proto- col. Moreover, compared to previous methods, our approach7 TABLE II QUANTITATIVE EVALUATION RESULTS ON DIFFERENT PROTOCOL OF 3D-CAVFA. LOWER MEANS BETTER FOR BOTH METRICS . Method Ref. cross-subject cross-gender LVE↓ ALE↓ LVE↓ ALE↓ (×10−2) (×10−2) (×10−2) (×10−2) VOCA [10] CVPR’19 9.866 0.950 7.478 0.713 FaceFormer [13] CVPR’22 7.350 0.642 7.762 0.673 CodeTalker [43] CVPR’23 13.206 1.310 11.385 0.000 EmoTalk [27] ICCV’23 7.591 0.684 7.096 0.636 PMMTalk(Ours) - 7.169 0.640 6.568 0.590 TABLE III QUANTITATIVE EVALUATION RESULTS ON VOCA-T EST. LOWER MEANS BETTER FOR LVE METRIC . Method Ref. LVE↓ (×10−5mm) VOCA [10] CVPR’19 4.925 MeshTalk [34] ICCV’21 4.544 FaceFormer [13] CVPR’22 4.109 CodeTalker [43] CVPR’23 3.945 EmoTalk [43] ICCV’23 3.536 PMMTalk(Ours) - 2.990 exhibits lower LVE and ALE values, indicating superior per- formance. Our model is capable of generating more accurate lip movements than the other models. Robustness analysis. Moreover, as indicated in Table III, we embarked on a comprehensive comparison with previous methods on the VOCA dataset. For the sake of fairness, we calculated the same metric (LVE) used in [34, 13, 43]. Through this evaluation, we trained our model on VOCASET and then tested it on VOCA-Test. Firstly, the models exhibit varied performance on VOCA-Test and 3D-CA VFA, a divergence that may arise from the distinct labels of datasets. The for- mer employs vertex offsets of the mesh (5023*3), while the latter relies on the weight values of a 32-dimensional facial blendshape. Moreover, the numerical results confirm that our approach achieves a lower lip error, which demonstrates the superior performance of our proposed method over multiple datasets, substantiating its effectiveness and robustness in comparison to existing methods. B. Qualitative Evaluation While quantitative metrics are indispensable for evaluating 3D talking faces, the visualization of prediction results is equally critical for a holistic understanding of the model’s performance. Consequently, we implemented qualitative evalu- ation against all models, ensuring fair assessment by assigning the same speaking style as the conditional input. We suggest viewing our supplementary video for the prediction perfor- mance of multiple methods. Specifically, the content of the video is as follows: (1) audio sequences from 3D-CA VFA test sets in the cross-subject protocol; (2) in-the-wild audio clips extracted from China meteorological observatory; (3) different language audio clips extracted from supplementary videos of previous methods. The video reveals that PMMTalk generates lip semantic movements that are not only more coherent and realistic but also enhance lip movement comprehensibil- ity. Furthermore, PMMTalk exhibits impressive performance across multiple languages. Additionally, we also demonstrated different speaking styles for the same sentence. Additionally, we assessed the lip synchronization perfor- mance and depicted three typical frames of synthesized facial animations speaking specific words, as shown in Fig. 4. A comparison reveals that our PMMTalk generates lip move- ments that are not only more accurate with respect to the Reference PMMTalk EmoTalk CodeTalker FaceFormer VOCA     (An old sanitation worker, warming his wife's hands, touched netizens.)        环 卫 工 老 大 爷 为 老 伴 哈 气 暖 手 照 感 动 网 友。     (An old sanitation worker, warming his wife's hands, touched netizens.)        环 卫 工 老 大 爷 为 老 伴 哈 气 暖 手 照 感 动 网 友。 Reference PMMTalk EmoTalk CodeTalker FaceFormer VOCA     (An old sanitation worker, warming his wife's hands, touched netizens.)        环 卫 工 老 大 爷 为 老 伴 哈 气 暖 手 照 感 动 网 友。 Fig. 4. Qualitative comparison of facial movement by different methods on 3D-CA VFA. We compared different words and found that our method yields performance close to that of the ground truth, producing more precise mouth movements compared to other models. corresponding speech signals but are also more in alignment with the ground truth. For example, when articulating the word /gong/, PMMTalk achieves optimal lip-syncing with an appropriate mouth pout, echoing the required rounding and slight elevation of the lips. In a similar vein, when pronouncing the word /shou/, the lips naturally part, shaping into a circular form while gently curling upwards. Furthermore, our method presents a more appropriate movement with a full mouth opening, downward jaw motion, and the corner of the mouth extending sideways while pronouncing the word /da/. These visualizations clearly underscore that our method outperforms previous techniques in terms of generating more accurate lip shapes.8 TABLE IV USER STUDY RESULTS . WE ESTABLISHED TWO SUB -TASKS , SPECIFICALLY LIP MOVEMENT REALISM (#REALISM ) AND PERCEPTUAL LIP SYNCHRONIZATION (#LIP -SYNC ). T HE MEAN OPINION SCORE (MOS) FOR THESE TWO CATEGORIES IS REPORTED . Method Ref. #realism↑ #lip-sync↑ VOCA [10] CVPR’19 1.54 1.49 CodeTalker [43] CVPR’22 2.59 2.91 FaceFormer [13] CVPR’23 3.61 3.70 Emotalk [27] ICCV’23 3.36 3.57 PMMTalk(Ours) - 4.27 4.49 C. User study A user study is a reliable method for evaluating generated 3D talking faces. In this section, we conducted a user study to further compare our model against previous ones and the ground truth. The human perceptual system has been innately wired to capture and understand subtle facial motions, including lip synchronization. Therefore, we incorporated two metrics in the user study: lip movement realism and perceptual lip synchronization. The first metric evaluates the movement and smoothness of key facial features, including the mouth, jaw, and cheek. It examines the naturalness and fluency of the digital person’s speech, assessing whether there is a mechanical feeling and unnecessary speech jittering. The latter metric primarily assesses the accuracy of the digital person’s pronunciation in terms of correct mouth shapes and the seamless synchronization of lip movements with the audio. We devised a questionnaire consisting of 20 questions to evaluate the outcomes and invited 20 students to participate. Each question prompted participants to rate the Mean Opinion Score (MOS) for videos on a scale of 1-5, with a higher score indicating better results. For each question, the left video represented the ground truth, while the right video sequences depicted the outcomes of different models. The audio clips were sourced from the 3D-CA VFA test dataset of cross- subject protocol, encompassing words, phrases, and sentences. Participants were encouraged to evaluate each result based on their own subjective criteria. We specifically instructed them to concentrate on the area around the mouth, including lip, jaw, and cheek movements, while disregarding any unnatural effects related to the eyes. The scores pertaining to lip synchronization and realism are compiled in Table IV, indicating a preference for PMMTalk among the participants over its competitors. We infer that this preference is due to the facial animations synthesized by PMMTalk exhibiting more expressive facial movements, accu- rate lip shapes, and well-coordinated mouth movements. For instance, we outperformed VOCA by a margin of 2.73 points in the realism of lip movement and surpassed Faceformer by 0.79 points in perceptual lip synchronization. In totality, the user study substantiates that the facial animations generated by PMMTalk possess superior perceptual quality. TABLE V ABLATION STUDY FOR OUR COMPONENTS . WE SHOW THE LVE AND ALE IN DIFFERENT CASES . LOWER MEANS BETTER FOR BOTH METRICS . Method LVE↓ ALE↓ (×10−2) (×10−2) Ours 7.169 0.640 w/o Text Embedding 7.319 0.682 w/o Audio Embedding 8.313 0.786 w/o Image Embedding 7.459 0.697 w/o Ltem Loss 7.680 0.704 w/o Lsem Loss 7.599 0.698 w/o Lmot Loss 7.363 0.681 D. Ablation experiment In this section, we conducted an ablation study to meticu- lously examine the contributions of various components within our model. Specifically, we delved into the repercussions of removing distinct feature embedding modules and employing different loss functions, aiming to discern their individual impacts on the overall model performance. Impact of different feature embedding modules. In this section, whenever a particular feature embedding module is omitted, we continue to train the remaining modules. As depicted in Table V, the absence of the image embedding, text embedding, or audio embedding module often leads to a no- table increase in both LVE and ALE, albeit at varying degrees. Notably, the exclusion of the audio embedding module causes the most significant impact, as evidenced by a substantial rise in the error rate of the lip shape for the generated facial animation. This is primarily because of the critical role the audio embedding module plays in human pronunciation. The outcomes from the other modules indicate that the ambiguity caused by the sole use of audio embedding modes can be reduced by addressing these with other modules. Impact of different loss function. We carried out a thorough investigation into the impact of different losses by separately omitting them from our comprehensive model. The temporal loss guarantees alignment of individual modal infor- mation over time, whereas the semantic loss assures alignment of different modal information at a high-dimensional semantic level. Neglecting these losses resulted in a significant deteri- oration in the overall visual quality of the generated faces, as well as the clarity of lip movements. Particularly, eliminating the temporal loss resulted in a 0.511 increase in LVE and a 0.064 increase in ALE, while the omission of the semantic loss led to a surge of 0.430 in LVE and 0.058 in ALE. Additionally, we studied the impact of removing the motion loss, which encourages the predicted facial animations to closely match the movement velocity of the ground truth. Though omitting the motion loss resulted in a minor performance dip, it induced noticeable jitter in the output of facial animation. Accordingly, these outcomes indicate that motion loss can infuse prior facial motion based on ground truth labels, enabling the creation of more coherent facial animations.9 VI. C ONCLUSION In this study, we present PMMTalk, an innovative frame- work developed to enhance the accuracy of facial anima- tions through the utilization of pseudo multi-modal features. Comprising three main components—the PMMTalk encoder, cross-modal alignment module, and PMMTalk decoder—the PMMTalk encoder employs the ready-made talking head gen- eration method and speech recognition technology to extract visual and textual information from speech. Subsequently, the cross-modal alignment module aligns these audio-image- text features at both the temporal and semantic levels. The PMMTalk decoder utilizes these features to predict lip-synced facial blendshape coefficients. To tackle the limitation of insufficient 3D talking face data, we introduce a large-scale 3D talking face dataset, namely the 3D-CA VFA dataset, which is equipped with synchronized facial blendshape coefficients, a varied corpus, and a range of subjects. Experimental outcomes validate that our method outperforms prevailing state-of-the- art methods and garners more favorable user feedback. Our work stands to potentially contribute to virtual reality appli- cations by enabling more authentic and emotionally engaging experiences with more lifelike talking faces. Limitations and Future Work. Nevertheless, it’s im- perative to note that our method exclusively generates 32- dimensional facial blendshape coefficients, lacking the in- corporation of broader elements such as facial expressions and head movements. Furthermore, our method depends on multiple large-scale pre-training models, which extends the inference time of models, thereby posing a challenge to real- time applications. REFERENCES [1] Taleb Alashkar et al. “A 3D dynamic database for unconstrained face recognition”. In: 5th International Conference and Exhibition on 3D Body Scanning Tech- nologies. 2014. [2] Alexei Baevski et al. “wav2vec 2.0: A framework for self-supervised learning of speech representations”. In: Advances in neural information processing systems33 (2020), pp. 12449–12460. [3] Linchao Bao et al. “Learning Audio-Driven Viseme Dynamics for 3D Face Animation”. In: arXiv preprint arXiv:2301.06059 (2023). [4] Chen Cao et al. “Facewarehouse: A 3d facial expression database for visual computing”. In: IEEE Transactions on Visualization and Computer Graphics20.3 (2013), pp. 413–425. [5] Lele Chen et al. “Hierarchical cross-modal talking face generation with dynamic pixel-wise loss”. In: Proceed- ings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 7832–7841. [6] Liu Chen. “An Analysis of the Current and Future State of 3D Facial Animation Techniques and Systems”. In: Communication University of China, BA(2009). [7] Shiyang Cheng et al. “4dfab: A large scale 4d database for facial expression analysis and biometric applica- tions”. In: Proceedings of the IEEE conference on com- puter vision and pattern recognition. 2018, pp. 5117– 5126. [8] Alexis Conneau et al. “Unsupervised cross-lingual rep- resentation learning for speech recognition”. In: arXiv preprint arXiv:2006.13979 (2020). [9] Darren Cosker, Eva Krumhuber, and Adrian Hilton. “A FACS valid 3D dynamic action unit database with ap- plications to 3D dynamic morphable facial modeling”. In: 2011 international conference on computer vision. IEEE. 2011, pp. 2296–2303. [10] Daniel Cudeiro et al. “Capture, learning, and synthe- sis of 3D speaking styles”. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019, pp. 10101–10111. [11] Stéphane Dupont and Juergen Luettin. “Audio-visual speech modeling for continuous speech recognition”. In: IEEE Transactions on Multimedia2.3 (2000), pp. 141– 151. [12] Sefik Emre Eskimez, You Zhang, and Zhiyao Duan. “Speech driven talking face generation from a single image and an emotion condition”. In: IEEE Transac- tions on Multimedia24 (2021), pp. 3480–3490. [13] Yingruo Fan et al. “Faceformer: Speech-driven 3d facial animation with transformers”. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 18770–18780. [14] Yingruo Fan et al. “Joint audio-text model for expres- sive speech-driven 3d facial animation”. In:Proceedings of the ACM on Computer Graphics and Interactive Techniques 5.1 (2022), pp. 1–15. [15] Zhaoxin Fan et al. “Deep learning on monocular ob- ject pose detection and tracking: A comprehensive overview”. In: ACM Computing Surveys 55.4 (2022), pp. 1–40. [16] Zhaoxin Fan et al. “Object level depth reconstruction for category level 6d object pose estimation from monocu- lar rgb image”. In: European Conference on Computer Vision. Springer. 2022, pp. 220–236. [17] Zhaoxin Fan et al. “Reconstruction-Aware Prior Dis- tillation for Semi-supervised Point Cloud Completion”. In: arXiv preprint arXiv:2204.09186(2022). [18] Gabriele Fanelli et al. “A 3-d audio-visual corpus of affective communication”. In: IEEE Transactions on Multimedia 12.6 (2010), pp. 591–598. [19] Gabriele Fanelli et al. “A 3-d audio-visual corpus of affective communication”. In: IEEE Transactions on Multimedia 12.6 (2010), pp. 591–598. [20] Kazi Injamamul Haque and Zerrin Yumak. “FaceX- HuBERT: Text-less Speech-driven E (X) pressive 3D Facial Animation Synthesis Using Self-Supervised Speech Representation Learning”. In: arXiv preprint arXiv:2303.05416 (2023). [21] Fa-Ting Hong et al. “Depth-aware generative adver- sarial network for talking head video generation”. In:10 Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022, pp. 3397–3406. [22] Xinya Ji et al. “Audio-driven emotional video portraits”. In: Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition. 2021, pp. 14080– 14089. [23] Tero Karras et al. “Audio-driven facial animation by joint end-to-end learning of pose and emotion”. In: ACM Transactions on Graphics (TOG) 36.4 (2017), pp. 1–12. [24] Diederik P Kingma and Jimmy Ba. “Adam: A method for stochastic optimization”. In: arXiv preprint arXiv:1412.6980 (2014). [25] Harry McGurk and John MacDonald. “Hearing lips and seeing voices”. In: Nature 264.5588 (1976), pp. 746– 748. [26] Pascal Paysan et al. “A 3D face model for pose and illumination invariant face recognition”. In: 2009 sixth IEEE international conference on advanced video and signal based surveillance. Ieee. 2009, pp. 296–301. [27] Ziqiao Peng et al. “EmoTalk: Speech-driven emotional disentanglement for 3D face animation”. In: Proceed- ings of the IEEE/CVF International Conference on Computer Vision. 2023, pp. 20687–20697. [28] Ziqiao Peng et al. “SelfTalk: A Self-Supervised Com- mutative Training Diagram to Comprehend 3D Talking Faces”. In: 2023. [29] Heng Yu Ping et al. “Computer facial animation: A review”. In: International Journal of Computer Theory and Engineering 5.4 (2013), p. 658. [30] Gerasimos Potamianos et al. “Audio-visual automatic speech recognition: An overview”. In: Issues in visual and audio-visual speech processing22 (2004), p. 23. [31] KR Prajwal et al. “A lip sync expert is all you need for speech to lip generation in the wild”. In: Proceedings of the 28th ACM international conference on multimedia. 2020, pp. 484–492. [32] Ofir Press, Noah A Smith, and Mike Lewis. “Train short, test long: Attention with linear biases en- ables input length extrapolation”. In: arXiv preprint arXiv:2108.12409 (2021). [33] Alec Radford et al. “Learning transferable visual mod- els from natural language supervision”. In: Interna- tional conference on machine learning. PMLR. 2021, pp. 8748–8763. [34] Alexander Richard et al. “Meshtalk: 3d face animation from speech using cross-modality disentanglement”. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021, pp. 1173–1182. [35] Alexander Richard et al. “Meshtalk: 3d face animation from speech using cross-modality disentanglement”. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021, pp. 1173–1182. [36] Arman Savran et al. “Bosphorus database for 3D face analysis”. In: Biometrics and Identity Manage- ment: First European Workshop, BIOID 2008, Roskilde, Denmark, May 7-9, 2008. Revised Selected Papers 1. Springer. 2008, pp. 47–56. [37] Linsen Song et al. “Audio-driven dubbing for user generated contents via style-aware semi-parametric syn- thesis”. In: IEEE Transactions on Circuits and Systems for Video Technology33.3 (2022), pp. 1247–1261. [38] Justus Thies et al. “Neural voice puppetry: Audio-driven facial reenactment”. In: Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23– 28, 2020, Proceedings, Part XVI 16. Springer. 2020, pp. 716–731. [39] Ashish Vaswani et al. “Attention is all you need”. In: Advances in neural information processing systems30 (2017). [40] Qianyun Wang, Zhenfeng Fan, and Shihong Xia. “3d- talkemo: Learning to synthesize 3d emotional talking head”. In: arXiv preprint arXiv:2104.12051(2021). [41] Xinsheng Wang et al. “AnyoneNet: Synchronized Speech and Talking Head Generation for Arbitrary Persons”. In: IEEE Transactions on Multimedia(2022). [42] Haozhe Wu et al. “MMFace4D: A Large-Scale Multi- Modal 4D Face Dataset for Audio-Driven 3D Face An- imation”. In: arXiv preprint arXiv:2303.09797(2023). [43] Jinbo Xing et al. “Codetalker: Speech-driven 3d facial animation with discrete motion prior”. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023, pp. 12780–12790. [44] Haotian Yang et al. “Facescape: a large-scale high quality 3d face dataset and detailed riggable 3d face prediction”. In: Proceedings of the ieee/cvf conference on computer vision and pattern recognition . 2020, pp. 601–610. [45] Tian Ye et al. “Perceiving and modeling density for im- age dehazing”. In: European Conference on Computer Vision. Springer. 2022, pp. 130–145. [46] Zipeng Ye et al. “Audio-driven talking face video gen- eration with dynamic convolution kernels”. In: IEEE Transactions on Multimedia(2022). [47] Hani Yehia, Philip Rubin, and Eric Vatikiotis-Bateson. “Quantitative association of vocal-tract and facial be- havior”. In: Speech Communication 26.1-2 (1998), pp. 23–43. [48] Xing Zhang et al. “A high-resolution spontaneous 3d dynamic facial expression database”. In: 2013 10th IEEE international conference and workshops on auto- matic face and gesture recognition (FG). IEEE. 2013, pp. 1–6. [49] Xing Zhang et al. “Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database”. In: Image and Vision Computing 32.10 (2014), pp. 692– 706. [50] Zheng Zhang et al. “Multimodal spontaneous emotion corpus for human behavior analysis”. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2016, pp. 3438–3446. [51] Yang Zhou et al. “Visemenet: Audio-driven animator- centric speech animation”. In: ACM Transactions on Graphics (TOG) 37.4 (2018), pp. 1–10.",
      "references": [
        "A 3D dynamic database for unconstrained face recognition",
        "wav2vec 2.0: A framework for self-supervised learning of speech representations",
        "Learning Audio-Driven Viseme Dynamics for 3D Face Animation",
        "Facewarehouse: A 3d facial expression database for visual computing",
        "Hierarchical cross-modal talking face generation with dynamic pixel-wise loss",
        "An Analysis of the Current and Future State of 3D Facial Animation Techniques and Systems",
        "4dfab: A large scale 4d database for facial expression analysis and biometric applica- tions",
        "Unsupervised cross-lingual rep- resentation learning for speech recognition",
        "A FACS valid 3D dynamic action unit database with ap- plications to 3D dynamic morphable facial modeling",
        "Capture, learning, and synthe- sis of 3D speaking styles",
        "Audio-visual speech modeling for continuous speech recognition",
        "Speech driven talking face generation from a single image and an emotion condition",
        "Faceformer: Speech-driven 3d facial animation with transformers",
        "Joint audio-text model for expres- sive speech-driven 3d facial animation",
        "Deep learning on monocular ob- ject pose detection and tracking: A comprehensive overview",
        "Object level depth reconstruction for category level 6d object pose estimation from monocu- lar rgb image",
        "Reconstruction-Aware Prior Dis- tillation for Semi-supervised Point Cloud Completion",
        "A 3-d audio-visual corpus of affective communication",
        "FaceX- HuBERT: Text-less Speech-driven E (X) pressive 3D Facial Animation Synthesis Using Self-Supervised Speech Representation Learning",
        "Depth-aware generative adver- sarial network for talking head video generation",
        "Audio-driven emotional video portraits",
        "Audio-driven facial animation by joint end-to-end learning of pose and emotion",
        "Adam: A method for stochastic optimization",
        "Hearing lips and seeing voices",
        "A 3D face model for pose and illumination invariant face recognition",
        "EmoTalk: Speech-driven emotional disentanglement for 3D face animation",
        "SelfTalk: A Self-Supervised Com- mutative Training Diagram to Comprehend 3D Talking Faces",
        "Computer facial animation: A review",
        "Audio-visual automatic speech recognition: An overview",
        "A lip sync expert is all you need for speech to lip generation in the wild",
        "Train short, test long: Attention with linear biases en- ables input length extrapolation",
        "Learning transferable visual mod- els from natural language supervision",
        "Meshtalk: 3d face animation from speech using cross-modality disentanglement",
        "Bosphorus database for 3D face analysis",
        "Audio-driven dubbing for user generated contents via style-aware semi-parametric syn- thesis",
        "Neural voice puppetry: Audio-driven facial reenactment",
        "Attention is all you need",
        "3d- talkemo: Learning to synthesize 3d emotional talking head",
        "AnyoneNet: Synchronized Speech and Talking Head Generation for Arbitrary Persons",
        "MMFace4D: A Large-Scale Multi- Modal 4D Face Dataset for Audio-Driven 3D Face An- imation",
        "Codetalker: Speech-driven 3d facial animation with discrete motion prior",
        "Facescape: a large-scale high quality 3d face dataset and detailed riggable 3d face prediction",
        "Perceiving and modeling density for im- age dehazing",
        "Audio-driven talking face video gen- eration with dynamic convolution kernels",
        "Quantitative association of vocal-tract and facial be- havior",
        "A high-resolution spontaneous 3d dynamic facial expression database",
        "Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database",
        "Multimodal spontaneous emotion corpus for human behavior analysis",
        "Visemenet: Audio-driven animator- centric speech animation"
      ],
      "meta_data": {
        "arxiv_id": "2312.02781v1",
        "authors": [
          "Tianshun Han",
          "Shengnan Gui",
          "Yiqing Huang",
          "Baihui Li",
          "Lijian Liu",
          "Benjia Zhou",
          "Ning Jiang",
          "Quan Lu",
          "Ruicong Zhi",
          "Yanyan Liang",
          "Du Zhang",
          "Jun Wan"
        ],
        "published_date": "2023-12-05T14:12:38Z",
        "github_url": ""
      },
      "llm_extracted_info": {
        "main_contributions": "PMMTalk addresses limited precision/coherence in speech-driven 3D facial animation caused by relying on audio-only cues. It introduces a pseudo multi-modal framework that derives complementary visual (lip video) and textual (ASR) cues from speech, aligns audio-image-text features temporally and semantically, and predicts artist-friendly 3D facial blendshape coefficients with controllable personal speaking styles using only speech plus a random reference face image. The paper also contributes a large-scale Chinese 3D talking-face dataset (3D-CA VFA; 20 subjects, ~15.3h, 60fps) labeled with 61D blendshapes (32D used for training) and proposes cross-subject and cross-gender evaluation protocols. Experiments and user studies show improved lip-sync accuracy over VOCA, MeshTalk, FaceFormer, CodeTalker, and EmoTalk on 3D-CA VFA and VOCA-Test.",
        "methodology": "PMMTalk consists of: (1) Encoder producing three feature streams from speech: audio embedding via wav2vec 2.0 (frozen audio encoder + attention-based decoder), text embedding via a frozen wav2vec2 ASR head mapping framewise audio latents to vocabulary logits, and image embedding by generating a lip-synced pseudo video using a frozen Wav2Lip talking-head generator conditioned on audio and a random reference face image, then encoding that video with a CNN+Transformer. (2) Cross-modal alignment module aligning each modality pair (audio–image, audio–text, image–text) at (a) temporal level using CLIP-style similarity matrices over time with KL-divergence supervision to favor diagonal (framewise) matches, and (b) semantic level by averaging over time and maximizing cosine similarity in a shared space. (3) Decoder: a Transformer-decoder-like network that linearly projects and concatenates aligned audio/image/text features with a 64D personal style embedding; uses periodic positional encoding and biased multi-head self-attention (ALiBi-style) to emphasize nearby frames; outputs per-frame blendshape coefficients. Training uses a weighted sum of losses: position MSE on coefficients, motion/velocity loss to reduce jitter, and the temporal+semantic alignment losses.",
        "experimental_setup": "Datasets: (a) Proposed 3D-CA VFA: 20 native Mandarin speakers (6F/14M), ~15.3h (~3.15M frames) captured with iPhone Live Link Face in a controlled room; 1080p RGB at 60fps, audio at 48kHz; 61D blendshape coefficients with timestamps; corpus includes frequent words/phrases (from FACEGOOD2) and diverse movie-dialog sentences. (b) VOCASET/VOCA-Test: 12 English speakers, 480 sequences, 60fps 4D scans with 5023-vertex meshes; used to test robustness via LVE on VOCA-Test. Preprocessing/training: audio resampled to 16kHz; sequences processed at 30fps for both datasets; only 32 pronunciation-related blendshapes used as labels. Optimization: end-to-end training with Adam, lr=1e-4, batch size=1, 80 epochs (~8h) on 4×RTX 4090; several upstream modules frozen (wav2vec2 encoders/ASR, Wav2Lip). Baselines: VOCA, MeshTalk, FaceFormer, CodeTalker, EmoTalk; for 3D-CA VFA, all models use multilingual wav2vec2 XLSR-53 features and their final layers adapted to blendshape output. Evaluation protocols: cross-subject (split by identity 60/20/20 train/val/test) and cross-gender (train on all male; val/test on female split by identity). Metrics: Lip Vertex Error (LVE; max L2 per frame) and Average Lip Error (ALE; mean L2 per frame averaged over set). Human study: 20 participants, 20 questions, MOS 1–5 for lip realism and perceived lip-sync; instructed to focus on mouth/jaw/cheeks. Qualitative comparisons rendered in Unreal Engine.",
        "limitations": "Outputs are limited to 32-dimensional lip-related blendshape coefficients, omitting broader facial expressions, eye behavior, and head motion, reducing expressiveness beyond lip-sync. The approach depends on multiple large pre-trained components (wav2vec2, ASR head, Wav2Lip, Transformers), increasing inference latency and hindering real-time deployment. It also relies on a generated pseudo talking-head video (from Wav2Lip) whose errors/biases may propagate, and requires a reference face image (random) that may not reflect target character identity. Dataset capture uses Live Link Face blendshapes (device/software-specific rig), which may introduce domain/rig constraints when transferring to other blendshape standards or high-fidelity capture systems.",
        "future_research_directions": "Extend outputs from lip-only (32D) to full-face animation including expressions, emotions, eye blinks/gaze, and head/neck motion—potentially via additional pseudo cues or explicit disentanglement of content vs affect. Improve efficiency for real-time use through model distillation, pruning/quantization, or replacing heavy frozen modules with lightweight encoders; explore streaming/online decoding. Reduce reliance on Wav2Lip-generated pseudo video by learning visual/text cues directly from audio with self-supervised multimodal objectives, or by incorporating uncertainty-aware fusion to mitigate pseudo-feature noise. Enhance cross-lingual/generalization capabilities with multilingual corpora and domain adaptation to different rigs/characters; learn rig-agnostic latent representations and robust retargeting. Enrich dataset diversity (more subjects, accents, speaking styles, spontaneous speech) and provide standardized benchmarks for blendshape-based evaluation and production integration.",
        "experimental_code": "",
        "experimental_info": ""
      }
    }
  ],
  "research_hypothesis": {
    "open_problems": "Iterative prompt optimizers implicitly assume that the evaluation set is IID and that “subgroups” are either known (demographics) or can be ignored. In real deployments, (1) subgroup labels are often unavailable or legally/ethically inappropriate to use, yet prompts can still systematically fail on latent slices (e.g., certain dialects, domains, difficulty regimes); and (2) prompt search evaluates candidates adaptively (racing/promoting winners), which breaks the validity of naive normal-approximation LCBs and exacerbates multiple-comparisons bias—making “robust selection” itself unreliable. The key gap is a *label-budgeted, OPRO-compatible selection rule that is robust to latent distributional slices without requiring protected-attribute labels, while remaining statistically valid under adaptive evaluation and many candidate comparisons.*",
    "method": "**SAVR-OPRO: Slice-Adaptive, Anytime-Valid Racing for prompt optimization**\n\nKeep OPRO’s propose→evaluate→retain loop unchanged, but replace candidate scoring/evaluation with two coupled ideas:\n\n### 1) *Slice discovery without demographic labels*\nInstead of requiring pre-specified groups, define a *slice family* \\(\\mathcal S\\) over available, non-sensitive metadata \\(z\\) (domain tag, length bin, difficulty proxy, source, language ID, etc.). For feasibility and strong generality, use a small, auditable hypothesis class such as:\n- all single-feature slices \\(S_{j,b}=\\{i: z_{i,j}=b\\}\\) for binary metadata,\n- optionally shallow decision stumps/trees (depth-2) over metadata.\n\nFor a prompt \\(p\\), compute accuracy per slice and score by the *worst* slice lower bound:\n\\[\nscore(p)= \\min_{S\\in\\mathcal S} \\text{LCB}(\\hat a(p,S), n(p,S)).\n\\]\nThis targets “unknown subgroup brittleness” via a *discoverable* worst-case objective rather than requiring protected labels.\n\n### 2) *Anytime-valid confidence sequences for adaptive racing*\nUse a concentration-based **confidence sequence** (anytime-valid LCB) for Bernoulli accuracy so bounds remain valid under optional stopping and adaptive sampling (unlike plug-in SE/normal approximations).\nA simple, auditable choice is Hoeffding-style anytime bounds:\n\\[\n\\text{LCB}(\\hat a,n;\\delta)=\\hat a-\\sqrt{\\tfrac{\\log(2/\\delta)}{2\\max(n,1)}}.\n\\]\n(Variants: empirical-Bernstein CS for tighter bounds; union bound across slices/candidates.)\n\n### 3) *Racing with slice-aware allocation*\nUnder a fixed label budget, evaluate all candidates with a small initial sample. Then allocate additional examples to candidates whose *worst-slice LCB* is both promising and uncertain.\nA minimal plug-in racing rule:\n- Stage 1: collect \\(n_0\\) examples, record per-slice counts.\n- Promote top-\\(M\\) by provisional worst-slice LCB.\n- Stage 2: collect \\(n_1\\) more examples *for promoted prompts*.\n\n**Novelty over RR-OPRO:** RR-OPRO assumes known groups and uses non-anytime LCBs. SAVR-OPRO (i) removes the need for sensitive subgroup labels by optimizing over *auditable discovered slices* from metadata, and (ii) uses anytime-valid confidence sequences so robustness claims remain statistically meaningful under adaptive evaluation and many comparisons—conditions intrinsic to iterative prompt search.",
    "experimental_setup": "### Goal\nShow that SAVR-OPRO improves *worst-group generalization* and reduces brittle “hidden-slice” failures under tight evaluation budgets, *without access to true subgroup labels during optimization*.\n\n### Data / environment (Python-only, but stress-tests the intended failure mode)\nSynthetic prompt space \\(x\\in\\{0,1\\}^d\\). Each evaluation example has observable metadata \\(z\\in\\{0,1\\}^m\\) and an *unobserved latent group* \\(g\\in\\{0,1\\}\\) defined by a combination of metadata bits (e.g., parity/AND), so protected labels are not directly given.\nTrue correctness probability depends on \\(x\\) and \\(g\\):\n- base utility shared across groups\n- plus a spurious training reward that correlates with majority-like metadata and disappears at test\n- plus group-specific weights so a prompt can be strong on average but weak on the latent minority.\n\nOptimization-time feedback is sampled Bernoulli correctness with high variance (small n). During optimization, algorithms can observe only (correct/incorrect, z), not g.\n\n### Methods compared (same propose/mutate loop)\n1. **OPRO-train**: rank by train accuracy.\n2. **GP-OPRO**: mean(train,val) − λ·|train−val|.\n3. **RR-OPRO-oracle**: worst-*true group* LCB (upper bound baseline; uses g labels, not realistic).\n4. **SAVR-OPRO (proposed)**: worst-*discovered slice* anytime-valid LCB over \\(\\mathcal S\\) (uses only z).\n\n### Protocol\n- d=30, m=8; iterations=60; candidates/iter=32; top-K=20.\n- Label budget: stage1 n0=64 total examples per candidate; stage2 n1=256 for top-M=8.\n- 100 random seeds.\n\n### Metrics\n- **Primary:** `worst_group_accuracy` on a held-out test distribution with latent group labels available only for evaluation.\n- Secondary: average test accuracy, group disparity (|a0−a1|), stability (std of worst_group_accuracy across seeds), and total labels.\n\n### Expected qualitative outcome\nSAVR-OPRO should approach RR-OPRO-oracle on worst-group accuracy, substantially outperforming GP-OPRO and train-only, while using similar label budgets.",
    "primary_metric": "worst_group_accuracy",
    "experimental_code": "import numpy as np\n\n\ndef sigmoid(z):\n    return 1.0 / (1.0 + np.exp(-z))\n\n\ndef lcb_hoeffding(mean, n, delta=0.05):\n    # anytime-valid under optional stopping for bounded variables\n    rad = np.sqrt(np.log(2.0 / delta) / (2.0 * max(int(n), 1)))\n    return float(mean - rad)\n\n\nclass LatentSliceEnv:\n    \"\"\"Prompt x with observable metadata z; latent group g is a nontrivial function of z.\n\n    Optimization sees (y, z) only; evaluation can access g.\n    \"\"\"\n\n    def __init__(self, d=30, m=8, seed=0, pi_train=0.85, pi_test=0.70, spur_strength=0.25):\n        self.d, self.m = d, m\n        self.rng = np.random.default_rng(seed)\n        self.pi_train, self.pi_test = pi_train, pi_test\n        self.spur_strength = spur_strength\n\n        # group-specific true weights\n        self.w0 = self.rng.normal(0, 1, size=d)\n        self.w1 = self.rng.normal(0, 1, size=d)\n        self.b0 = -0.6 * np.linalg.norm(self.w0)\n        self.b1 = -0.6 * np.linalg.norm(self.w1)\n\n        # spurious prompt features (tempt overfitting)\n        self.spur = self.rng.choice(d, size=max(2, d // 6), replace=False)\n\n        # latent group definition: XOR of two metadata bits (not directly a single slice)\n        self.g_bits = (0, 1)\n\n    def sample_z(self, n, pi):\n        # metadata bit0 controls majority; others are balanced nuisance factors\n        z = self.rng.integers(0, 2, size=(n, self.m), dtype=np.int8)\n        z[:, 0] = (self.rng.random(n) < pi).astype(np.int8)\n        return z\n\n    def latent_g(self, z):\n        a, b = self.g_bits\n        return (z[:, a] ^ z[:, b]).astype(np.int8)\n\n    def p_correct(self, x, z, split):\n        x = np.asarray(x)\n        g = self.latent_g(z)\n        base0 = sigmoid(self.w0 @ x + self.b0)\n        base1 = sigmoid(self.w1 @ x + self.b1)\n        base = np.where(g == 0, base0, base1)\n\n        # spurious correlation: only strong in training, and correlates with majority-like metadata (z0=1)\n        spur = self.spur_strength * float(x[self.spur].mean())\n        maj = z[:, 0].astype(float)\n        if split == \"train\":\n            boost = spur * (0.9 * maj + 0.1 * (1 - maj))\n        else:\n            boost = spur * (0.15 * maj + 0.05 * (1 - maj))\n\n        return np.clip(base + boost, 0, 1)\n\n    def eval_split(self, x, n, split):\n        pi = self.pi_train if split == \"train\" else self.pi_test\n        z = self.sample_z(n, pi)\n        p = self.p_correct(x, z, split)\n        y = self.rng.binomial(1, p).astype(np.int8)\n        return y, z\n\n    def true_test_group_acc(self, x, n=20000):\n        y, z = self.eval_split(x, n, \"test\")\n        g = self.latent_g(z)\n        a0 = y[g == 0].mean() if np.any(g == 0) else 0.0\n        a1 = y[g == 1].mean() if np.any(g == 1) else 0.0\n        return float(a0), float(a1)\n\n\nclass OPROLike:\n    def __init__(self, d=30, K=20, rng=0):\n        self.d, self.K = d, K\n        self.rng = np.random.default_rng(rng)\n        self.hist = []  # list of dicts: x, score\n\n    def propose(self, n, mut=0.15):\n        if not self.hist:\n            return self.rng.integers(0, 2, size=(n, self.d), dtype=np.int8)\n        top = sorted(self.hist, key=lambda r: r[\"score\"], reverse=True)[: min(self.K, len(self.hist))]\n        parents = np.stack([r[\"x\"] for r in top])\n        idx = self.rng.integers(0, len(parents), size=n)\n        xs = parents[idx].copy()\n        flip = self.rng.random(xs.shape) < mut\n        xs[flip] = 1 - xs[flip]\n        return xs\n\n    def keep_topk(self):\n        self.hist = sorted(self.hist, key=lambda r: r[\"score\"], reverse=True)[: self.K]\n\n    def best_x(self):\n        return max(self.hist, key=lambda r: r[\"score\"])[\"x\"]\n\n\ndef score_train(y_tr):\n    return float(y_tr.mean())\n\n\ndef score_gp(y_tr, y_val, lam=0.8):\n    tr = float(y_tr.mean())\n    va = float(y_val.mean())\n    return 0.5 * (tr + va) - lam * abs(tr - va)\n\n\ndef score_savr(y_val, z_val, delta=0.05):\n    \"\"\"Worst-slice anytime-valid LCB over auditable slice family: each metadata bit==0/1 + overall.\"\"\"\n    y_val = y_val.astype(int)\n    z_val = z_val.astype(int)\n\n    # overall slice\n    slices = [(np.ones(len(y_val), dtype=bool), \"all\")]\n    for j in range(z_val.shape[1]):\n        slices.append((z_val[:, j] == 0, f\"z{j}=0\"))\n        slices.append((z_val[:, j] == 1, f\"z{j}=1\"))\n\n    lcb_list = []\n    for mask, _ in slices:\n        n = int(mask.sum())\n        if n == 0:\n            continue\n        mean = float(y_val[mask].mean())\n        lcb_list.append(lcb_hoeffding(mean, n, delta=delta))\n\n    # conservative: if no slice has samples (shouldn't happen), return -inf\n    return float(min(lcb_list)) if lcb_list else -1e9\n\n\ndef run(seed=0, iters=60, batch=32, d=30, m=8, K=20, n_tr=64, n_val0=64, n_val1=256, M=8):\n    env = LatentSliceEnv(d=d, m=m, seed=seed)\n    rng = np.random.default_rng(seed)\n\n    base = OPROLike(d=d, K=K, rng=seed)\n    gp = OPROLike(d=d, K=K, rng=seed + 1)\n    savr = OPROLike(d=d, K=K, rng=seed + 2)\n\n    for _ in range(iters):\n        xs_b = base.propose(batch)\n        xs_g = gp.propose(batch)\n        xs_s = savr.propose(batch)\n\n        # baseline train-only\n        for x in xs_b:\n            ytr, _ = env.eval_split(x, n_tr, \"train\")\n            base.hist.append({\"x\": x.copy(), \"score\": score_train(ytr)})\n        base.keep_topk()\n\n        # GP-OPRO\n        for x in xs_g:\n            ytr, _ = env.eval_split(x, n_tr, \"train\")\n            yva, _ = env.eval_split(x, n_val0, \"val\")\n            gp.hist.append({\"x\": x.copy(), \"score\": score_gp(ytr, yva, lam=0.8)})\n        gp.keep_topk()\n\n        # SAVR-OPRO with 2-stage racing\n        stage1 = []\n        for x in xs_s:\n            ytr, _ = env.eval_split(x, n_tr, \"train\")\n            yva0, zva0 = env.eval_split(x, n_val0, \"val\")\n            s1 = score_savr(yva0, zva0, delta=0.05)\n            stage1.append((x.copy(), ytr, yva0, zva0, s1))\n        stage1.sort(key=lambda t: t[4], reverse=True)\n\n        for i, (x, ytr, yva0, zva0, _) in enumerate(stage1):\n            if i < M:\n                yva1, zva1 = env.eval_split(x, n_val1, \"val\")\n                yva = np.concatenate([yva0, yva1])\n                zva = np.concatenate([zva0, zva1])\n            else:\n                yva, zva = yva0, zva0\n            s = score_savr(yva, zva, delta=0.05)\n            savr.hist.append({\"x\": x.copy(), \"score\": s})\n        savr.keep_topk()\n\n    xb, xg, xs = base.best_x(), gp.best_x(), savr.best_x()\n    a0b, a1b = env.true_test_group_acc(xb)\n    a0g, a1g = env.true_test_group_acc(xg)\n    a0s, a1s = env.true_test_group_acc(xs)\n\n    def pack(a0, a1):\n        return {\n            \"avg\": float(0.5 * (a0 + a1)),\n            \"worst\": float(min(a0, a1)),\n            \"gap\": float(abs(a0 - a1)),\n        }\n\n    return {\"base\": pack(a0b, a1b), \"gp\": pack(a0g, a1g), \"savr\": pack(a0s, a1s)}\n\n\nif __name__ == \"__main__\":\n    outs = [run(seed=s) for s in range(100)]\n\n    def agg(method, key):\n        vals = np.array([o[method][key] for o in outs], dtype=float)\n        return float(vals.mean()), float(vals.std())\n\n    for method in (\"base\", \"gp\", \"savr\"):\n        m, s = agg(method, \"worst\")\n        print(method, \"worst_group_accuracy mean±std:\", round(m, 3), \"±\", round(s, 3))\n\n    for method in (\"base\", \"gp\", \"savr\"):\n        m, _ = agg(method, \"avg\")\n        print(method, \"avg_test_accuracy mean:\", round(m, 3))\n\n    for method in (\"base\", \"gp\", \"savr\"):\n        m, _ = agg(method, \"gap\")\n        print(method, \"group_gap mean:\", round(m, 3))\n",
    "expected_result": "In the latent-slice setting (subgroup labels hidden during optimization, spurious train-only signal correlated with majority metadata), expected outcomes over 100 seeds:\n\n- **Primary (worst_group_accuracy; higher is better):**\n  - OPRO-train: ~0.60 ± 0.06\n  - GP-OPRO:     ~0.65 ± 0.05\n  - **SAVR-OPRO:  ~0.70 ± 0.04**\n\nSecondary (expected trends):\n- Average test accuracy: similar across GP vs SAVR (≈0.74–0.76), indicating SAVR raises the floor more than the mean.\n- Group gap |a0−a1|: train-only highest (≈0.12), GP moderate (≈0.09), SAVR lowest (≈0.05–0.06).\n- Stability: std of worst_group_accuracy reduced by ~20–30% vs train-only due to (i) racing focusing labels on contenders and (ii) anytime-valid bounds reducing “lucky prompt” selection.\n\nIf an oracle-group RR-OPRO baseline is added, SAVR-OPRO is expected to close a substantial fraction of the gap to oracle robustness (e.g., oracle worst_group_accuracy ≈0.72–0.73).",
    "expected_conclusion": "SAVR-OPRO makes prompt optimization both *more socially valuable* and *more methodologically sound* by targeting the realistic setting where (i) harmful brittleness emerges on latent slices and (ii) protected-attribute labels may be missing or unusable. Its novelty is twofold: it replaces “known-group worst-case” with *auditable slice discovery over non-sensitive metadata* (capturing hidden failure pockets), and it uses *anytime-valid confidence sequences* so robustness-oriented selection remains statistically valid under adaptive, budgeted racing and many candidate comparisons—conditions intrinsic to OPRO-style search.\n\nPractically, this yields prompts with higher worst-group accuracy at the same label budget, reducing disparate-impact risk and increasing reliability of automatically optimized prompts when deployed across heterogeneous users/domains."
  },
  "experimental_design": {
    "experiment_summary": "We will run an OPRO-style iterative prompt optimizer on two QA tasks (GSM8K math word problems and ARC-Challenge multiple-choice science QA). The optimizer’s job is to automatically produce a single system prompt/template that makes a fixed target LLM answer questions correctly. The propose→evaluate→retain loop is kept identical across methods (same proposer model, same mutation/proposal policy, same candidate counts). The only change is the candidate *selection/evaluation rule*:\n\n- Baseline (comparative): ranks candidates by overall validation accuracy using naive fixed-time/normal-approx lower-confidence-bounds under adaptive racing.\n- Proposed SAVR-OPRO: ranks candidates by the *worst discovered slice* anytime-valid lower-confidence-bound (confidence sequence), where slices are defined over non-sensitive, auditable metadata z derived from each example (e.g., length bin, number-of-numerals bin, answer-option entropy proxy, presence of units, etc.) plus a small depth-2 decision-tree slice family.\n\nKey experimental trick to test “latent subgroup” robustness without protected labels: for evaluation only, we define an unobserved latent group label g on the test set as an interaction of two metadata bits (e.g., XOR of {long vs short} and {high vs low numeral count}). During optimization, methods see only (correct/incorrect, z) but never g; worst_group_accuracy is computed using g on held-out test.\n\nWorkflow (per dataset, per seed):\n1) Initialize a population of prompt candidates (templates) from a small seed set.\n2) For T iterations, use a proposer LLM to generate/mutate B new candidates from the current top-K.\n3) Evaluate each candidate on a budgeted, two-stage race (n0 examples for all; then allocate n1 additional examples to top-M).\n4) Score candidates using either baseline scoring or SAVR scoring; retain top-K.\n5) After search, evaluate the best prompt on a large held-out test set; compute primary/secondary metrics including worst_group_accuracy.\n\nScale adjusted to fit the provided Runner (1× NVIDIA H200 140GB VRAM, 240GB RAM): we use inference-only (no fine-tuning), a single target model, short outputs (forced-answer format), small candidate batch sizes, and a strict per-iteration label/call budget (two-stage racing). Typical configuration: T=40 iterations, B=24 candidates/iter, n0=24 examples/candidate, n1=96 for promoted prompts, M=6, K=16. This yields ~40*24*24 + 40*6*96 ≈ 23k example-evaluations per dataset per seed. We run 30 seeds (not 100) for statistical power while staying comfortably within single-GPU runtime; seeds can be parallelized across multiple jobs if available.",
    "runner_config": {
      "runner_label": [
        "self-hosted",
        "gpu-runner"
      ],
      "description": "NVIDIA H200, VRAM: 140 GB, RAM: 240 GB"
    },
    "evaluation_metrics": [
      {
        "name": "worst_group_accuracy",
        "description": "**What counts as correct:**\n- GSM8K: Extract the final numeric answer from the model output (last number after normalization); correct if it matches the ground-truth integer exactly. If the dataset contains non-integers, compare as rational/float with tolerance 1e-3 after canonicalization.\n- ARC-Challenge: Model must output a single option label in {A,B,C,D}; correct if it equals the gold answerKey.\n\n**How to compute:**\n1) Define a *latent* group label g_i on the test set only: g_i = XOR(b1_i, b2_i), where b1 and b2 are two binary metadata features derived from non-sensitive signals (e.g., b1=1 if token_length≥median, b2=1 if numeral_count≥median).\n2) Compute per-group accuracy: a_g = (1/|{i:g_i=g}|) * Σ 1[pred_i correct].\n3) worst_group_accuracy = min(a_0, a_1).\n\n**Why appropriate:** Directly measures robustness to an *unknown* subgroup/slice that is not explicitly optimized over, matching the hypothesis about latent slice brittleness.\n\n**Visualizations:**\n- Bar chart of a_0 and a_1 with min highlighted.\n- Box/violin plot of worst_group_accuracy across random seeds per method.\n- Scatter of (avg_accuracy, worst_group_accuracy) to show mean-vs-floor tradeoff."
      },
      {
        "name": "average_test_accuracy",
        "description": "**Correctness criteria:** same as above per dataset.\n\n**How to compute:** avg = (1/N) * Σ 1[pred_i correct] over the full held-out test set.\n\n**Why appropriate:** Checks whether robustness improvements come at the cost of overall capability.\n\n**Visualizations:**\n- Mean ± 95% CI across seeds.\n- Scatter of average_test_accuracy vs group_gap."
      },
      {
        "name": "group_gap",
        "description": "**Correctness criteria:** same as above.\n\n**How to compute:** Using the evaluation-only latent group g: group_gap = |a_0 − a_1|.\n\n**Why appropriate:** Captures disparity/brittleness magnitude; complements worst_group_accuracy.\n\n**Visualizations:**\n- Distribution (histogram/violin) of group_gap across seeds.\n- Paired plot per seed (baseline vs SAVR) to show consistent reduction."
      },
      {
        "name": "label_budget_used",
        "description": "**Correctness criteria:** not applicable (resource metric).\n\n**How to compute:** Count total number of example-evaluations (model calls) used during search:\nlabels = Σ_{candidates} n_eval(candidate), including both race stages.\nReport per dataset and method; ensure methods are matched or report achieved metric per fixed budget.\n\n**Why appropriate:** The hypothesis is explicitly about label-budgeted selection under adaptive evaluation.\n\n**Visualizations:**\n- Line plot of best-so-far worst_group_accuracy vs cumulative labels during search (label-efficiency curve)."
      },
      {
        "name": "anytime_valid_lcb_coverage",
        "description": "**Correctness criteria:** A lower confidence bound (LCB) has valid coverage if P(true_accuracy ≥ LCB_t for all stopping times t) ≥ 1−δ.\n\n**How to compute (empirical diagnostic):**\nFor each method’s reported LCBs during racing (overall and per-slice):\n1) For each candidate prompt p and slice S, at each evaluation time t (after each batch), compute LCB_t(p,S).\n2) Estimate the slice’s true accuracy on a very large Monte-Carlo sample (or full validation set) a*(p,S).\n3) Count violations V = #{(p,S,t): a*(p,S) < LCB_t(p,S)}.\n4) Report violation rate V / total_checks. (This is a diagnostic, not a formal proof.)\n\n**Why appropriate:** Directly tests the claim that SAVR’s confidence sequences remain well-calibrated under optional stopping/adaptive racing, unlike naive bounds.\n\n**Visualizations:**\n- Reliability plot: empirical violation rate vs target δ.\n- Heatmap of violations by slice type (length, numeral_count, etc.)."
      }
    ],
    "models_to_use": [
      "Qwen3-4B (4B parameters)",
      "Qwen3-8B (8B parameters)"
    ],
    "datasets_to_use": [
      "gsm8k",
      "ARC"
    ],
    "proposed_method": {
      "method_name": "SAVR-OPRO (Slice-Adaptive, Anytime-Valid Racing)",
      "description": "Inference-time replacement for OPRO candidate selection: score each prompt by the minimum (worst) slice-level anytime-valid lower confidence bound over an auditable slice family built from non-sensitive metadata/derived features (e.g., length bins, numeral density, option-structure) plus depth-2 decision stumps/trees. Uses confidence sequences (stitched Hoeffding or empirical-Bernstein) with a union-bound allocation of δ across candidates×slices×time, enabling statistically meaningful selection under adaptive racing and many comparisons—without protected-attribute labels.",
      "optuna_config": {
        "enabled": true,
        "n_trials": 20,
        "search_spaces": [
          {
            "param_name": "race_n0",
            "distribution_type": "int",
            "low": 12.0,
            "high": 48.0
          },
          {
            "param_name": "race_n1",
            "distribution_type": "int",
            "low": 48.0,
            "high": 192.0
          },
          {
            "param_name": "promote_M",
            "distribution_type": "int",
            "low": 4.0,
            "high": 10.0
          },
          {
            "param_name": "delta_total",
            "distribution_type": "loguniform",
            "low": 0.001,
            "high": 0.1
          },
          {
            "param_name": "slice_family",
            "distribution_type": "categorical",
            "choices": [
              "single_feature",
              "single_feature+depth2_tree"
            ]
          },
          {
            "param_name": "cs_type",
            "distribution_type": "categorical",
            "choices": [
              "stitched_hoeffding",
              "empirical_bernstein_cs"
            ]
          }
        ]
      }
    },
    "comparative_methods": [
      {
        "method_name": "Naive-Racing OPRO (mean-accuracy + fixed-time LCB)",
        "description": "Standard OPRO-style prompt search with the same proposer/mutation loop and the same two-stage racing budget, but ranks candidates by overall validation accuracy using non-anytime, fixed-time bounds (e.g., normal approximation or simple Hoeffding at the final n) and no explicit union correction across adaptive comparisons/slices. This represents the common implicit-IID selection approach the hypothesis critiques.",
        "optuna_config": {
          "enabled": true,
          "n_trials": 20,
          "search_spaces": [
            {
              "param_name": "race_n0",
              "distribution_type": "int",
              "low": 12.0,
              "high": 48.0
            },
            {
              "param_name": "race_n1",
              "distribution_type": "int",
              "low": 48.0,
              "high": 192.0
            },
            {
              "param_name": "promote_M",
              "distribution_type": "int",
              "low": 4.0,
              "high": 10.0
            },
            {
              "param_name": "lcb_type",
              "distribution_type": "categorical",
              "choices": [
                "normal_approx",
                "fixed_hoeffding"
              ]
            },
            {
              "param_name": "delta",
              "distribution_type": "loguniform",
              "low": 0.001,
              "high": 0.1
            }
          ]
        }
      }
    ]
  }
}